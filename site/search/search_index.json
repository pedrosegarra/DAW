{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Despliegue de aplicaciones web","text":""},{"location":"#indice","title":"\u00cdndice","text":"<p>Apuntes y pr\u00e1cticas del m\u00f3dulo Despliegue de aplicaciones web de 2\u00ba de DAW</p> <ul> <li>0 - Introducci\u00f3n</li> <li>1 - Control de versiones</li> <li>2 - Contenedores</li> <li>3 - Arquitectura web - Implantaci\u00f3n y admnistraci\u00f3n de servidores web</li> <li>4 - Servicios de red implicados en el despliegue de aplicaciones web - DNS y LDAP</li> <li>5 - Servicios de red implicados en el despliegue de aplicaciones web - FTP</li> <li>6 - Servidores de aplicaciones</li> <li>7 - CI/CD (Integraci\u00f3n y despliegue continuo)</li> </ul>"},{"location":"#tabla-de-versiones","title":"Tabla de versiones","text":"version Autor Comentarios 0.0 Ra\u00fal Riesco Montes Versi\u00f3n original de estos apuntes del compa\u00f1ero Ra\u00fal Riesco, del IES Severo Ochoa de Elche Curso23/24 Jos\u00e9 Mu\u00f1oz Jimeno y Noelia Beltr\u00e1n Ma\u00f1as Adaptaci\u00f3n de los materiales a nueva normativa y necesidades del IES El Camin\u00e0s. Curso24/25 Jos\u00e9 Mu\u00f1oz Jimeno Modificaci\u00f3n de los materiales para el nuevo curso escolar."},{"location":"#marco-normativo","title":"Marco normativo","text":"<p>El presente m\u00f3dulo profesional se enmarca en el 2\u00ba curso del t\u00edtulo de T\u00e9cnico Superior en Desarrollo de Aplicaciones Web. Dicho t\u00edtulo viene regulado por:</p> <ul> <li>Real Decreto 686/2010, de 20 de mayo, por el que se establece el t\u00edtulo de T\u00e9cnico Superior en Desarrollo de Aplicaciones Web y se fijan sus ense\u00f1anzas m\u00ednimas.</li> <li>Real Decreto 405/2023, de 29 de mayo, por el que se actualizan los t\u00edtulos de la formaci\u00f3n profesional del sistema educativo de T\u00e9cnico Superior en Desarrollo de Aplicaciones Multiplataforma y T\u00e9cnico Superior en Desarrollo de Aplicaciones Web, de la familia profesional Inform\u00e1tica y Comunicaciones, y se fijan sus ense\u00f1anzas m\u00ednimas., que modifica el RD 686/2010 en sus art\u00edculos 2, 5, 6, 8, 9 y el anexo I, donde se describen los \"Resultados de aprendizaje y criterios de evaluaci\u00f3n\" as\u00ed como los \"Contenidos b\u00e1sicos\" y \"Orientaciones pedag\u00f3gicas\" de los distintos m\u00f3dulos profesionales que conforman el t\u00edtulo.</li> </ul> <p>El curr\u00edculo del m\u00f3dulo viene definido, a nivel auton\u00f3mico por la siguiente normativa:</p> <ul> <li>ORDEN 60/2012, de 25 de septiembre, de la Conselleria de Educaci\u00f3n, Formaci\u00f3n y Empleo por la que se establece para la Comunitat Valenciana el curr\u00edculo del ciclo formativo de Grado Superior correspondiente al t\u00edtulo de T\u00e9cnico Superior en Desarrollo de Aplicaciones Web. donde quedan desarrollados los \"Contenidos\" completos y establecida su duraci\u00f3n en la Comunidad Valenciana (80h - 4h/semana durante 20 semanas)</li> </ul>"},{"location":"#licencia","title":"Licencia","text":"<p>Esta obra est\u00e1 bajo una Licencia Creative Commons Atribuci\u00f3n-NoComercial-CompartirIgual 4.0 Internacional.</p> <p></p>"},{"location":"Ud0%20Introduccion/P0_1/","title":"Linux Server en AWS Academy","text":"<p>En esta nota veremos c\u00f3mo crear un servidor Linux en AWS. El servidor Linux no tendr\u00e1 entorno gr\u00e1fico, s\u00f3lo de comandos, por lo que nos bastar\u00e1 acceder a \u00e9l por SSH.</p> <p>Primero, debemos acceder al portal de AWS Academy utilizando nuestra cuenta de AWS Academy.</p> <p></p> <p></p> <p>En las siguientes im\u00e1genes, mostraremos con un cuadro rojo las opciones a selecciona o en aquellas que deben cambiarse o revisarse. Puedes olvidarte del resto de las opciones disponibles por ahora.</p> <p>Accede al LMS, donde encontrar\u00e1s los cursos disponibles.</p> <p></p> <p>Busca el Learner Lab que tu profesor ha preparado para este curso. Previamente te habr\u00e1 invitado y habr\u00e1s tenido que aceptar la invitaci\u00f3n para tener acceso al mismo.</p> <p></p> <p>Selecciona \"M\u00f3dulos\" o \"Contenidos\" para acceder al laboratorio.</p> <p></p> <p>Abre el \"Laboratorio de Aprendizaje\".</p> <p></p> <p>Inicia el laboratorio:</p> <p></p> <p>Una vez iniciado, ver\u00e1s un punto verde junto a AWS. Haz clic all\u00ed para abrir la consola de AWS y comenzar a trabajar.</p> <p></p> <p>Ahora tienes acceso a la consola de AWS. Dependiendo de tu uso previo de esta consola, es posible que veas diferentes elementos en la pantalla.</p> <p></p> <p>En AWS, los servidores virtuales se llaman EC2, as\u00ed que comencemos por crear un EC2. Puedes hacerlo de diferentes maneras. Veamos una de ellas. Haz clic sobre \"EC2\" y se te abrir\u00e1 una nueva pantalla. En esta selecciona \"Lanzar instancia\"</p> <p></p> <p>Ahora debemos proporcionar los par\u00e1metros necesarios para crear la m\u00e1quina. Sigue las pantallas con los datos proporcionados.</p> <p>Vamos a crear un servidor linux Debian. En primer lugar seleccionamos un nombre y tipo de servidor:</p> <p></p> <p>A continuaci\u00f3n, en \"Tipo de instancia\" seleccionaremos el procesador y la memoria. Ten en cuenta que a mayor potencia, mayor costo. Para esta pr\u00e1ctica nos bastar\u00e1 el m\u00e1s sencillo.</p> <p></p> <p>La secci\u00f3n de \"Par de claves\" (inicio de sesi\u00f3n) es muy importante, ya que aqu\u00ed crearemos el par de claves que nos permitir\u00e1 acceder al servidor de forma remota. Creemos un nuevo par de claves que nos pueden servir para el resto del curso. Te recomiendo que nombres el par de claves como \"daw\".</p> <p></p> <p>Tras crear el par de claves se te abrir\u00e1 un cuadro de di\u00e1logo para guardar la clave privada en tu ordenador. Aseg\u00farate de guardarla en lugar seguro o no podr\u00e1s acceder al servidor despu\u00e9s. Te recomiendo crearte una carpeta donde guardes todo lo de este m\u00f3dulo y gu\u00e1rdala ah\u00ed. Aunque no es imprescindible te recomiendo cambiar el nombre al archivo por \"daw.pem\" para que sea igual al que usaremos en el resto de pr\u00e1cticas.</p> <p></p> <p>Ahora, tras volver a la pantalla anterior, selecciona el par de claves generadas.</p> <p></p> <p>Debemos definir la configuraci\u00f3n de red de nuestra VM. En AWS al Firewall se le denomina \"Grupo de seguridad\", y en \u00e9l definiremos todas las reglas necesarias para permitir y denegar accesos a nuestra VM. En este caso s\u00f3lo habilitaremos el acceso por SSHpara gestionar la m\u00e1quina, as\u00ed que bastar\u00e1 con aceptar la configuraci\u00f3n por defecto ofrecida.</p> <p>Un aspecto importante a la hora de mantener los recursos organizados en AWS es nombrarlos adecuadamente. El grupo de seguridad recibir\u00e1 un nombre aleatorio que no podremos identificar despu\u00e9s f\u00e1cilmente. As\u00ed que antes de nada le cambiaremos el nombre y le pondremos el mismo que a nuestra m\u00e1quina. Para ello haz clic en \"Editar\".</p> <p></p> <p>Ahora cambia el nombre y la descripci\u00f3n del grupo de seguridad como en la imagen.</p> <p></p> <p>Finalmente, debemos configurar el almacenamiento. Proporcionemos un volumen de 20 GiB.</p> <p></p> <p>Verifica todas las opciones seleccionadas y lanza la instancia.</p> <p></p> <p>Si todo va bien, la instancia se crear\u00e1 y obtendremos un mensaje que lo indica.</p> <p></p> <p>Si hacemos click sobre el c\u00f3digo de la instancia pasaremos a la consola de EC2 y veremos que la VM est\u00e1 en ejecuci\u00f3n y todos sus datos relacionados, entre ellos la direcci\u00f3n IP p\u00fablica que necesitaremos m\u00e1s tarde para acceder a la misma. Ojo, no confundamos la Direcci\u00f3n IPv4 p\u00fablica, que es la accesible desde el exterior, de las Direcciones IPv4 pivadas que permitir\u00e1n a las EC2 verse entre ellas desde una red interna, pero que no es accesible desde el exterior.</p> <p></p> <p>Ahora podemos acceder al servidor utilizando SSH. Primero haz clic en \"Conectar\" para permitir la conexi\u00f3n. Selecciona el cliente SSH. Ah\u00ed tienes toda la informaci\u00f3n necesaria para realizar la conexi\u00f3n.</p> <p></p> <p>Warning</p> <p>Si eres usuario de Windows te podr\u00e1s conectar a la EC2 por SSH usando PowerShell. Aqu\u00ed tienes una peque\u00f1a gu\u00eda sobre c\u00f3mo cambiar los permisos de un archivo en PowerShell para hacer el equivalente al chmod 400  Chmod en Windows con PowerShell</p> <p>\u00bfRecuerdas la clave privada que te dije que almacenaras en tu computadora previamente? Ese es el que debes usar ahora. AWS asume que se guard\u00f3 con extensi\u00f3n <code>.pem</code> pero si se ha guardado con otra extensi\u00f3n, c\u00e1mbialo previamente. Aqu\u00ed te muestro una secuencia de conexi\u00f3n, asumiendo que el certificado se guard\u00f3 con extensi\u00f3n <code>.cer</code>.</p> <p></p> <p>Como ver\u00e1s, ya est\u00e1s dentro del servidor debian que hemos instalado.</p> <p>Podemos comprobar c\u00f3mo la capacidad del disco y la memoria coinciden con la que configuramos en la consola AWS.</p> <p></p> <p>Para cerrar la conexi\u00f3n escribe \"exit\"</p> <p>RECUERDA</p> <p>La IP p\u00fablica de la VM podr\u00eda cambiar. Comprueba antes de cada conexi\u00f3n la IP de la m\u00e1quina.</p>"},{"location":"Ud0%20Introduccion/P0_1/#detener-la-instancia","title":"Detener la instancia","text":"<p>En AWS Academy, cada vez que iniciamos el laboratorio, se pondr\u00e1n en marcha todas las m\u00e1quinas y servicios creados. Esto puede suponer un consumo de recursos innecesario si no vamos a utilizar algunas de ellas. Por eso es importante parar aquellas m\u00e1quinas (instancias) que no vayamos a utilizar en un momento dado. </p> <p>Para detener una m\u00e1quina hemos de ir a \"Instancias\", seleccionarla y a continuaci\u00f3n ir al bot\u00f3n \"Estado de la instancia\".</p> <p></p> <p>Seguidamente seleccionaremos \"Detener instancia\"</p> <p></p> <p>Y comprobaremos c\u00f3mo la instancia queda detenida.</p> <p></p>"},{"location":"Ud0%20Introduccion/P0_1/#eliminar-una-instancia","title":"Eliminar una instancia","text":"<p>Aunque tengamos un EC2 detenido, puede estar consumiendo recursos solo por el hecho de estar creada. Es el caso de los recursos de almacenamiento.</p> <p>Por tanto, una vez una m\u00e1quina ya no nos \u00e9s \u00fatil, lo mejor es eliminarla de forma definitiva. Para ello seguiremos el procedimiento visto para pararla, pero seleccionaremos la opci\u00f3n \"Terminar instancia\"</p> <p></p> <p>Veremos que la instancia estar\u00e1 terminada y dejar\u00e1 de aparecer en el listado de instancias en futuras conexiones.</p> <p></p> <p>Al terminar la instancia se liberar\u00e1n algunos de los recursos asociados si as\u00ed lo configuramos al crearla. En nuestro caso seleccionamos que el vol\u00famen se eliminara al eliminar la EC2. </p> <p>Pero puede que otros no se liberen autom\u00e1ticamente, como los grupos de seguridad.</p> <p>Puedes consultar los distintos recursos existentes y eliminar los que no sean necesarios desde el panel de EC2.</p> <p></p> <p>Ve a grupos de seguridad y elimina el que creamos para esta m\u00e1quina. Observa c\u00f3mo te ayudar\u00e1 haber cambiado el nombre cuando lo creaste.</p>"},{"location":"Ud0%20Introduccion/P0_1/#finaliza-el-laboratorio","title":"Finaliza el laboratorio","text":"<p>Al finalizar cada sesion de trabajo recuerda que debes finalizar el laboratorio. Ve a la consola de AWS Academy y presiona \"Finalizar laboratorio\". Si no lo haces, el laboratorio se cerrar\u00e1 autom\u00e1ticamente despu\u00e9s de 4 horas pero habr\u00e1s gastado m\u00e1s saldo del necesario.</p> <p></p> <p>Comprueba que el laboratorio esta parado. El punto junto a AWS deber\u00e1 estar de color rojo.</p> <p></p> <p>Warning</p> <p>Recuerda siempre finalizar el laboratorio tras cada sesi\u00f3n de trabajo</p>"},{"location":"Ud0%20Introduccion/P0_2/","title":"Windows Server en AWS Academy","text":"<p>En esta nota veremos c\u00f3mo crear un servidor Windows en AWS. La principal diferencia con un servidor Linux es que accederemos al servidor mediante un entorno gr\u00e1fico mediante el protocolo RDP.</p> <p>Accederemos a la consola de AWS Academy igual que hicimos en la pr\u00e1ctica anterior. En las siguientes im\u00e1genes, mostraremos con un cuadro rojo las opciones que deben cambiarse o revisarse. Puedes olvidarte del resto de las opciones disponibles por ahora.</p> <p>En AWS, como ya vimos, los servidores virtuales se llaman EC2. Comencemos por crear un EC2 nuevo como aprendimos en la pr\u00e1ctica anterior.</p> <p>Debemos proporcionar los par\u00e1metros para crear la m\u00e1quina. Sigue las pantallas con los datos proporcionados.</p> <p>Un Windows Server 2016 ser\u00e1 suficiente para esta pr\u00e1ctica:</p> <p></p> <p>En este caso, vamos a crear una m\u00e1quina potente. Podemos elegir un tipo de instancia t2.large con 2 CPU virtuales y 8 GiB de memoria.</p> <p></p> <p>La secci\u00f3n de \"Par de claves\" (inicio de sesi\u00f3n) es muy importante, ya que aqu\u00ed seleccionarmeos el par de claves que nos permitir\u00e1 acceder al servidor de forma remota. Podemos crear un nuevo par de claves para acceder a esta m\u00e1quina o usar el que ya creamos en la pr\u00e1ctica anterior. Si usamos las ya creadas podemos saltar este paso.</p> <p></p> <p>Aseg\u00farate de guardar el par de claves en tu computadora o no podr\u00e1s acceder al servidor despu\u00e9s.</p> <p></p> <p></p> <p>Si usamos las claves creadas en la pr\u00e1ctica anterior seguiremos a partir de aqu\u00ed.</p> <p>Debemos definir la configuraci\u00f3n de red de nuestra VM. Necesitamos acceder a trav\u00e9s de RDP. En el m\u00f3dulo de DAW vamos a instalar servicios web, as\u00ed que vamos a habilitar tambi\u00e9n el acceso por HTTP y HTTPS. Permitamos RDP, HTTP y HTTPS desde Internet.</p> <p></p> <p>Recuerda cambiar el nombre al grupo de seguridad para poder identificarlo posteriormente.</p> <p></p> <p>Finalmente, debemos configurar el almacenamiento. Proporcionemos un volumen de 80 GiB.</p> <p></p> <p>Verifica todas las opciones seleccionadas y lanza la instancia.</p> <p></p> <p>Si todo va bien, la instancia se crear\u00e1 y ahora podemos verla en la consola EC2.</p> <p></p> <p>En la consola de EC2, vemos que la VM est\u00e1 en ejecuci\u00f3n y todos los datos relacionados, como la direcci\u00f3n IP p\u00fablica que necesitaremos m\u00e1s tarde para acceder a la misma.</p> <p></p> <p>Ahora podemos acceder al servidor utilizando RDP. Primero haz clic en \"Conectar\" para permitir la conexi\u00f3n. Selecciona el cliente RDP. Ahora las cosas cambiar un poco respecto a un servidor Linux. En primer lugar, hemos de obtener la contrase\u00f1a del \"Administrator\" del servidor Windows.</p> <p></p> <p>Recuerdas la clave privada que te dije que almacenaras en tu computadora previamente. Ese es el que debes usar ahora. Usa \"Cargar archivo de clave privada\" y carga tu \"Clave privada\" almacenada.</p> <p></p> <p>Una vez le\u00eddo, puedes \"Descifrar contrase\u00f1a\"</p> <p></p> <p>Ser\u00e1 una contrase\u00f1a dif\u00edcil de recordar. Solo c\u00f3piala y luego podr\u00e1s cambiarla desde el interior del servidor Windows.</p> <p></p> <p>Es una buena pr\u00e1ctica crear un documento de texto y copiar all\u00ed toda la informaci\u00f3n de la pantalla \"Conectar a la instancia\": ID de instancia, DNS p\u00fablico, nombre de usuario y contrase\u00f1a. </p> <p>Ahora podemos usar un software de escritorio remoto para hacer la conexi\u00f3n. En Lliurex tenemos KRDC y Remmina. Tambi\u00e9n podr\u00edamos usar Windows Remote Desktop en Windows o Mac.</p>"},{"location":"Ud0%20Introduccion/P0_2/#conexion-usando-krdc","title":"Conexi\u00f3n usando KRDC","text":"<p>En las siguientes im\u00e1genes, podemos ver c\u00f3mo usar KRDC para hacer la conexi\u00f3n.</p> <p>Simplemente selecciona el protocolo RDP y el DNS p\u00fablico (en lugar de la IP que se muestra en la imagen).</p> <p></p> <p>Podemos configurar algunas cosas, como la resoluci\u00f3n de pantalla o el teclado. Tambi\u00e9n puedes hacer una carpeta en tu disco duro disponible para tu VM, de la misma manera que usas carpetas compartidas en VirtualBox.</p> <p></p> <p>Luego te pedir\u00e1 el usuario y la contrase\u00f1a.</p> <p></p> <p></p> <p>Y se establecer\u00e1 la conexi\u00f3n.</p> <p></p>"},{"location":"Ud0%20Introduccion/P0_2/#conexion-usando-microsoft-remote-desktop","title":"Conexi\u00f3n usando Microsoft Remote Desktop","text":"<p>Puedes usar Microsoft Remote Desktop en Windows y Mac.</p> <p>Como en KRDC, podemos compartir carpetas entre nuestra computadora y la M\u00e1quina Virtual, de la misma manera que compartimos carpetas en un software de virtualizaci\u00f3n (como VirtualBox).</p> <p>Descarga el software para Windows desde Microsoft Store o para Mac en la App Store.</p> <p>Ahora podemos \"Descargar archivo de escritorio remoto\" para acceder r\u00e1pidamente al servidor. Simplemente descarga el archivo RDP desde AWS y luego haz doble clic en \u00e9l.</p> <p></p> <p>Pero aconsejo hacerlo de esta otra manera para crear primero una carpeta compartida. Abre Microsoft Remote Desktop y ve al men\u00fa \"Conexiones -&gt; Agregar PC\".</p> <p>Luego sigue los pasos. Completa el nombre de PC con el DNS p\u00fablico de la VM. En la cuenta de usuario, crea una nueva para el usuario \"Administrador\" creado previamente con la contrase\u00f1a obtenida.</p> <p></p> <p>En la pesta\u00f1a \"Carpetas\", crea una carpeta compartida con tu computadora. Primero crea la carpeta local. Luego, usa el bot\u00f3n \"+\" para agregarla.</p> <p></p> <p>La pr\u00f3xima vez que abras la conexi\u00f3n, encontrar\u00e1s una unidad de red en tu VM que es la carpeta local en tu PC. Es una forma muy conveniente de compartir archivos entre ambos sistemas.</p> <p></p> <p>Una vez que se haya completado toda la configuraci\u00f3n, lo encontrar\u00e1s en la p\u00e1gina principal cada vez que abras la aplicaci\u00f3n.</p> <p>RECUERDA</p> <p>La IP p\u00fablica de la VM podr\u00eda cambiar. Tendr\u00e1s que editar la conexi\u00f3n creada cada vez que quieras conectarte a la VM, pero solo tendr\u00e1s que cambiar la direcci\u00f3n IP, manteniendo el resto de la configuraci\u00f3n.</p> <p></p>"},{"location":"Ud0%20Introduccion/P0_2/#elimina-la-instancia","title":"Elimina la instancia","text":"<p>Para que la instancia creada no consuma recursos, puedes borrarla al finalizar la pr\u00e1ctica, como vimos en la pr\u00e1ctica anterior.</p> <p>Elimina tambi\u00e9n el grupo de seguridad que creaste para esta m\u00e1quina para no ir dejando \"basura\" en la consola de AWS.</p>"},{"location":"Ud0%20Introduccion/P0_2/#finaliza-el-laboratorio","title":"Finaliza el laboratorio","text":"<p>Al finalizar cada sesion de trabajo recuerda que debes finalizar el laboratorio. Ve a la consola de AWS Academy y presiona \"Finalizar laboratorio\". Si no lo haces, el laboratorio se cerrar\u00e1 autom\u00e1ticamente despu\u00e9s de 4 horas pero habr\u00e1s gastado m\u00e1s saldo del necesario.</p> <p></p>"},{"location":"Ud0%20Introduccion/P0_3/","title":"Conceder acceso a un segundo administrador","text":"<p>En las pr\u00e1cticas anteriores vimos c\u00f3mo crear un servidor virtual en AWS y c\u00f3mo acceder a \u00e9l usando las claves generadas en el propio entorno. Pero, \u00bftenemos claro qu\u00e9 estamos haciendo exactamente? En esta pr\u00e1ctica vamos a suponer que necesitamos conceder acceso a un segundo administrador a nuestra m\u00e1quina, por ejemplo, al profesor para que eval\u00fae nuestro trabajo. </p> <p>Le daremos permisos de superusuario, crearemos un par de claves y le habilitaremos el acceso usando su clave privada.</p>"},{"location":"Ud0%20Introduccion/P0_3/#instalacion-del-servidor-debian","title":"Instalaci\u00f3n del servidor Debian","text":"<p>Entra en el \"Learner Lab\" de AWS Academy y crea un servidor Debian con los m\u00ednimos recursos posibles. Bastar\u00e1 con los que te ofrezca la plataforma por defecto.</p> <p>Puedes usar el par de claves generado en la primera pr\u00e1ctica.</p>"},{"location":"Ud0%20Introduccion/P0_3/#crear-un-nuevo-usuario","title":"Crear un nuevo usuario","text":"<p>Una vez instalada nuestra Debian, tendremos un usuario <code>admin</code> creado autom\u00e1ticamente por AWS. Ese ser\u00e1 nuestro usuario administrador.</p> <p>Accede al servidor por SSH en modo comando con el usuario <code>admin</code>.</p> <p>Pero supongamos que queremos que nuestro profesor pueda acceder a la m\u00e1quina con permisos de administrador. Para ello le crearemos un usuario <code>profe</code> y le daremos permisos de <code>sudo</code> . Estos permisos nos permitir\u00e1n que cualquier comando que ejecutemos en el terminal precedido de la palabra <code>sudo</code> se ejecute como root. De la misma forma, cualquier comando que ejecutemos con nuestro usuario sin <code>sudo</code>, ser\u00e1 ejecutado con los permisos de nuestro usuario, por lo que nos protegemos de liarla con un comando que no toca como root.</p> <p>Dicho esto, hay varias formas de proceder, veamos una sencilla. Se trata de modificar el archivo del sistema encargado de recoger estos permisos: <code>/etc/sudoers</code>. </p> <p>Ya en nuestro servidor remoto, cambiaremos de nuestro usuario al usuario <code>admin</code> a <code>root</code>:</p> <pre><code>admin@ip-172-31-42-159:~$ sudo su -\n</code></pre> <p>Comprueba c\u00f3mo el prompt se convierte en el de root:</p> <pre><code>root@ip-172-31-42-159:~#\n</code></pre> <p>Ahora, puedes crear un nuevo usuario usando el comando <code>adduser nuevo-usuario</code>. Reemplaza \"nuevo-usuario\" con el nombre que desees darle al nuevo usuario y responde a las distintas preguntas que te va haciendo. </p> <p>Para crear el usuario <code>profe</code>:</p> <pre><code>root@ip-172-31-42-159:~# adduser profe\nAdding user `profe' ...\nAdding new group `profe' (1001) ...\nAdding new user `profe' (1001) with group `profe (1001)' ...\nCreating home directory `/home/profe' ...\nCopying files from `/etc/skel' ...\nNew password: \nRetype new password: \npasswd: password updated successfully\nChanging the user information for profe\nEnter the new value, or press ENTER for the default\n    Full Name []: Profesor              \n    Room Number []: \n    Work Phone []: \n    Home Phone []: \n    Other []: \nIs the information correct? [Y/n] Y\nAdding new user `profe' to supplemental / extra groups `users' ...\nAdding user `profe' to group `users' ...\nroot@ip-172-31-42-159:~# \n</code></pre> <p>Luego, agrega al nuevo usuario al grupo \"sudo\" para otorgarle permisos de administrador:</p> <pre><code>root@ip-172-31-42-159:~# usermod -aG sudo profe\n</code></pre> <p>Para confirmar que el usuario se ha agregado correctamente al grupo \"sudo\", puedes verificar el archivo /etc/group:</p> <pre><code>root@ip-172-31-42-159:~# grep '^sudo:' /etc/group\nsudo:x:27:admin,profe\n</code></pre> <p>Comprobamos c\u00f3mo tanto <code>admin</code> como <code>profe</code> pertenecen ahora al grupo de sudoers.</p> <p>Pero ahora todav\u00eda no podemos conectarnos a la m\u00e1quina con el usuario profe, porque solo podemos conectarnos con par de claves y <code>profe</code> no las tiene. Vamos a gener\u00e1rselas.</p>"},{"location":"Ud0%20Introduccion/P0_3/#generacion-del-par-de-claves","title":"Generaci\u00f3n del par de claves.","text":"<p>En primer lugar nos crearemos el par de claves para <code>profe</code>, p\u00fablica y privada, desde del ordenador local o bien desde el terminal de Linux o desde PowerShell en Windows, utiliza el comando (sin sudo):</p> <pre><code>ssh-keygen -b 4096\n</code></pre> <p>Si dej\u00e1is las opciones por defecto, crear\u00e1 una clave privada <code>id_rsa</code> y una clave p\u00fablica <code>id_rsa.pub</code> en el directorio <code>/home/nombreusuario/.ssh</code>. Compru\u00e9balo.</p> <p>Os pedir\u00e1 una contrase\u00f1a para proteger el uso de la clave privada. Puesto que precisamente queremos agilizar el proceso de conexi\u00f3n por SSH para no introducir contrase\u00f1as, deb\u00e9is dejarla vac\u00eda.</p> <p>Una vez creado el par de claves, tal y como hemos visto en el apartado anterior, el servidor SSH (Debian) debe poseer nuestra clave p\u00fablica para que podamos autenticarnos con nuestra clave privada, que como su nombre indica, s\u00f3lo debemos poseer nosotros y por eso nos identifica un\u00edvocamente.</p>"},{"location":"Ud0%20Introduccion/P0_3/#copia-la-clave-publica-desde-el-ordenador-local-al-servidor-debian","title":"Copia la clave p\u00fablica desde el ordenador local al servidor Debian","text":"<p>Este proceso de copia se puede realizar f\u00e1cilmente con el comando <code>ssh-copy-id</code> si nuestro servidor aceptara login por contrase\u00f1a. </p> <pre><code>$ ssh-copy-id usuario@ip_servidor\n</code></pre> <p>Pero como nuestro servidor solo acepta login por claves ssh, entonces deberemos hacerlo manualmente. As\u00ed entenderemos mejor lo que ocurre realmente. Sigue estos pasos:</p> <p>1. Desde el terminal local</p> <p>Copia la clave p\u00fablica generada al portapapeles. Si tienes Windows, utiliza Notepad. Y si tienes Linux puedes utilizar este comando. </p> <pre><code>$ cat ~/.ssh/id_rsa.pub | pbcopy\n</code></pre> <p>2. En el servidor remoto Debian</p> <p>Con\u00e9ctate al servidor Debian como <code>admin</code>. Ya sabes c\u00f3mo.</p> <p>Cada usuario guarda las claves p\u00fablicas en el archivo denominado ~/.ssh/authorized_keys. Puedes ver la clave p\u00fablica del usuario <code>admin</code> correspondiente a la clave privada con la que se conecta con:</p> <pre><code>$ cat /home/admin/.ssh/authorized_keys\n</code></pre> <p>Pero ahora necesitamos crear una nueva clave p\u00fablica para <code>profe</code>, as\u00ed que desde el usuario <code>admin</code> cambiaremos al usuario <code>profe</code></p> <pre><code>admin@ip-172-31-42-159:~$ su profe\nprofe@ip-172-31-42-159:~$\n</code></pre> <p>Cambiaremos a la carpeta raiz de profe:</p> <pre><code>profe@ip-172-31-42-159:~$ cd\nprofe@ip-172-31-42-159:~$ pwd\n/home/profe\n</code></pre> <p>Ahora creamos la carpeta .ssh y creamos y editamos authorized_keys</p> <pre><code>profe@ip-172-31-42-159:~$ mkdir .ssh\nprofe@ip-172-31-42-159:~$ cd .ssh/\nprofe@ip-172-31-42-159:~/.ssh$ nano authorized_keys\n</code></pre> <p>Ahora pegamos el contenido del portapapeles que copiamos anteriormente con CTRL+U y cerramos guardando con CTRL+X.</p> <p>Deberemos cambiar los permisos del fichero authorized_keys.</p> <pre><code>profe@ip-172-31-42-159:~/.ssh$ chmod 600 ~/.ssh/authorized_keys\n</code></pre> <p>Reinicia el servicio SSH para aplicar los cambios:</p> <pre><code>profe@ip-172-31-42-159:~/.ssh$ sudo service ssh restart \n</code></pre>"},{"location":"Ud0%20Introduccion/P0_3/#comprobacion-de-acceso-al-servidor-con-ese-nuevo-usuario","title":"Comprobaci\u00f3n de acceso al servidor con ese nuevo usuario","text":"<p>Ahora ya podemos conectarnos desde nuestro equipo local a la m\u00e1quina remota usando la clave privada que generamos para <code>profe</code>.</p> <pre><code>$ ssh -i ~/.ssh/id_rsa profe@direccion-ip-publica-servidor-debian\n</code></pre> <p>Para finalizar, si vas a generar y usar varias claves para distintas finalidades podr\u00eda ser interesante asignarles nombres descriptivos seg\u00fan las mismas.</p> <p>L\u00f3gicamente, ahora deber\u00edamos proporcionarle al profesor la clave privada para que se pudiera conectarse al servidor. Y deber\u00edamos hacerlo desde un entorno securizado para evitar que terceros pudieran capturarla. Sin embargo, este no ser\u00eda el proceso habitual. Lo hemos hecho as\u00ed para aprender el funcionamiento. Pero en un entorno real ser\u00eda el profesor el que generar\u00eda el par de claves y facilitar\u00eda al alumno la clave p\u00fablica. De esta forma el profesor mantendr\u00eda su clave privada y podr\u00eda acceder a la m\u00e1quina del alumno sin haber expuesto en ning\u00fan momento su clave privada.</p> <p>Para Windows</p> <p>Este m\u00f3dulo est\u00e1 dise\u00f1ado desde un cliente Linux conect\u00e1ndose al servidor Linux, por lo que el cliente SSH est\u00e1 integrado en el propio terminal. Para Windows existen multitud de alternativas como cliente SSH, desde utilizar el propio WSL2 (Windows Subsystem Linux) de forma similar a lo que aqu\u00ed se describe, hasta utilizar cualquier otro de los varios clientes disponibles</p> <p>Por ejemplo, si utiliz\u00e1is Putty, deber\u00e9is seguir los pasos que detallan en este tutorial para configurar las claves.</p> <p>En caso de utilizar otro cliente, buscad la forma de hacerlo pues diferir\u00e1 en cada caso.</p>"},{"location":"Ud0%20Introduccion/P0_4/","title":"Comandos b\u00e1sicos Linux","text":""},{"location":"Ud0%20Introduccion/P0_4/#objetivos","title":"Objetivos.","text":"<ol> <li>Actualizar paquetes del sistema con APT.</li> <li>Recordar c\u00f3mo crear, mover y eliminar archivos y directorios.</li> <li>Entender y gestionar los permisos de archivos y directorios.</li> <li>Trabajar con usuarios y grupos.</li> <li>Introducir la gesti\u00f3n de procesos b\u00e1sicos.</li> </ol> <p>La mayor\u00eda de los servicios que vamos a desplegar se har\u00e1n sobre m\u00e1quinas linux. Por tanto, es importante dominar los comandos b\u00e1sicos de administraci\u00f3n de un sistema linux. Ya has estudiado esto el curso pasado, pero no est\u00e1 de m\u00e1s recordarlo.</p> <p>Te aconsejo que a partir de esta pr\u00e1ctica te hagas un \"cheatsheet\" con todos los comandos que utilices y lo vayas ampliando durante el curso.</p> <p>Como ya has aprendido a crear una EC2 en AWS, empezaremos creando una EC2 b\u00e1sica Debian como la de la primera pr\u00e1ctica. Con\u00e9ctate a ella por ssh y realiza las siguientes operaciones. Apunta el comando o comandos que usas para cada operaci\u00f3n.</p>"},{"location":"Ud0%20Introduccion/P0_4/#actualizacion-de-paquetes-con-apt","title":"Actualizaci\u00f3n de paquetes con APT.","text":"<p>Esto ser\u00e1 lo primero que hagamos en cada pr\u00e1ctica, as\u00ed que apr\u00e9ndelo bien.</p> <ul> <li> <p>Actualiza la lista de paquetes disponibles.</p> </li> <li> <p>Realiza una actualizaci\u00f3n completa del sistema, instalando los paquetes nuevos o actualizados.</p> </li> <li> <p>Limpia paquetes que ya no son necesarios.</p> </li> </ul>"},{"location":"Ud0%20Introduccion/P0_4/#creacion-y-manipulacion-de-archivos-y-directorios","title":"Creaci\u00f3n y manipulaci\u00f3n de archivos y directorios.","text":"<ul> <li> <p>Ve a la carpeta personal del usuario activo.</p> </li> <li> <p>En la carpeta personal del usuario en uso crear un directorio llamado <code>practica01</code>.</p> </li> <li> <p>Entra en el directorio <code>practica01</code>.</p> </li> <li> <p>Muestra el directorio en el que te encuentras.</p> </li> <li> <p>Muestra el contenido de la carpeta</p> </li> <li> <p>Dentro de este directorio, crea tres archivos vac\u00edos llamados: <code>archivo.txt</code>, <code>archivo2.txt</code>, <code>archivo3.txt</code>.</p> </li> <li> <p>Cambia el nombre de <code>archivo.txt</code> a <code>archivo1.txt</code></p> </li> <li> <p>Muestra el contenido del directorio actual en modo \"largo\" (ver permisos, propietario, grupo y fecha creaci\u00f3n)</p> </li> <li> <p>Crear un subdirectorio llamado <code>subdirectorio</code> dentro de <code>practica01</code>.</p> </li> </ul>"},{"location":"Ud0%20Introduccion/P0_4/#manipulacion-de-permisos","title":"Manipulaci\u00f3n de permisos.","text":"<ul> <li> <p>Mostrar los permisos actuales de los archivos.</p> </li> <li> <p>Cambiar los permisos del archivo <code>archivo1.txt</code> para que solo el propietario tenga permisos de lectura y escritura.</p> </li> <li> <p>Cambia los permisos del archivo <code>archivo2.txt</code> para que todos los usuarios tengan acceso de lectura, pero solo el propietario puede escribir. Comprueba los permisos.</p> </li> <li> <p>Cambia los permisos del directorio <code>subdirectorio</code> para que solo el propietario pueda leer, escribir y acceder a \u00e9l.</p> </li> </ul>"},{"location":"Ud0%20Introduccion/P0_4/#gestion-de-usuarios-y-grupos","title":"Gesti\u00f3n de usuarios y grupos.","text":"<ul> <li> <p>Crea un nuevo usuario llamado <code>usuario1</code> con contrase\u00f1a <code>ieselcaminas</code>.</p> </li> <li> <p>Comprueba que el usuario se ha creado correctamente. Y comprueba tambi\u00e9n si se ha creado un grupo con el mismo nombre que ese usuario.</p> </li> <li> <p>Asigna al usuario <code>usuario1</code> la propiedad del directorio <code>practica01</code>.</p> </li> <li> <p>Crear un grupo llamado <code>grupo1</code> y a\u00f1adir a <code>usuario1</code>. Comprueba que se ha a\u00f1adido.</p> </li> <li> <p>Cambiar la propiedad de <code>archivo3.txt</code> a grupo1. Compru\u00e9balo.</p> </li> <li> <p>Quita el usuario1 de grupo1 y compru\u00e9balo.</p> </li> <li> <p>Elimina el grupo1</p> </li> <li> <p>Elimina usuario1 y su directorio home</p> </li> </ul>"},{"location":"Ud0%20Introduccion/P0_4/#gestion-de-procesos-basicos","title":"Gesti\u00f3n de procesos b\u00e1sicos.","text":"<ul> <li> <p>Ver los procesos en ejecuci\u00f3n del usuario actual en formato extendido, con todos los datos.</p> </li> <li> <p>Lanza un proceso \"yes\" en 2\u00ba plano con <code>yes &gt; /dev/null &amp;</code>. Identifica su PID.</p> </li> <li> <p>Vuelve a obtener los procesos en ejecuci\u00f3n del usuario. \u00bfVes el proceso \"yes\" que acabas de lanzar?</p> </li> <li> <p>Obt\u00e9n los trabajos en segundo plano.</p> </li> <li> <p>Trae el proceso al primer plano</p> </li> <li> <p>Ahora ya no podr\u00e1s interactuar con la terminal porque el proceso \"yes\" es infinito y la est\u00e1 utilizando sin devolver el prompt. C\u00f3rtalo.</p> </li> <li> <p>Vuelve a lanzar yes pero ahora en primer plano. Obtendr\u00e1s la lista infinita de \"y\" sin recuperar el prompt. Abre otro terminal y obt\u00e9n la lista de todos los procesos en el sistema. Identifica el \"yes\" que est\u00e1 corriendo en el primer terminal.</p> </li> <li> <p>Det\u00e9n el proceso por su ID sin esperar.</p> </li> <li> <p>Comprueba que recuperas el prompt en el primer terminal.</p> </li> <li> <p>Vuelve a obtener todos los procesos del sistema y comprueba que ya no existe.</p> </li> </ul>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/","title":"\u00bfQu\u00e9 veremos en este m\u00f3dulo?","text":"<p>En este m\u00f3dulo veremos distintas metodolog\u00edas y tecnolog\u00edas que deberemos utilizar para el despliegue de aplicaciones en entornos web.</p> <p>Por un lado trataremos las t\u00e9cnicas y procesos esenciales para llevar a cabo la implementaci\u00f3n exitosa de aplicaciones web en entornos de producci\u00f3n. Esto incluye la instalaci\u00f3n y configuraci\u00f3n b\u00e1sica de servidores web (apache, nginx) y servidores de aplicaciones (tomcat), la implantaci\u00f3n de aplicaciones web sobre los servidores desplegados, as\u00ed como la instalaci\u00f3n y configuraci\u00f3n de servicios de red necesarios (servidor de nombres de dominio DNS y LDAP, transferencia de ficheros mediante FTP, etc).</p> <p>Puesto que hoy en d\u00eda es cada vez m\u00e1s habitual el uso de servidores virtualizados en entornos \"cloud\" veremos el despliegue de todo lo anterior utilizando tecnolog\u00edas de virtualizaci\u00f3n de servidores en la nube y tambi\u00e9n usando contenedores.</p> <p>Otra de las partes importantes del m\u00f3dulo es la instalaci\u00f3n, configuraci\u00f3n y uso de sistemas de control de versiones en proyectos de desarrollo SW. Nosotros nos centraremos en git.</p> <p>Finalmente entraremos en la metodolog\u00eda CI/CD (Continuous Integration/Continuous Deployment) que es un enfoque en el desarrollo de software que busca automatizar y agilizar la entrega de aplicaciones a trav\u00e9s de un ciclo de desarrollo continuo.</p> <p>Veamos cada uno de estos apartados con un poco m\u00e1s de detalle.</p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#sistemas-de-control-de-versiones","title":"Sistemas de control de versiones.","text":"<p>Un sistema de control de versiones (VCS, por sus siglas en ingl\u00e9s, Version Control System) es una herramienta que permite rastrear y gestionar los cambios en el c\u00f3digo fuente y otros archivos a lo largo del tiempo. Su objetivo principal es permitir a los desarrolladores trabajar en colaboraci\u00f3n de manera eficiente, mantener un historial de cambios y revertir a versiones anteriores si es necesario.</p> <p>Actualmente, cualquier proyecto SW es imposible abordar de forma unipersonal. Los proyectos son cada vez m\u00e1s colaborativos y la utilizaci\u00f3n de un sistema de control de versiones ha pasado a ser una necesidad.</p> <p>De entre los sistemas de control de versiones m\u00e1s utilizados para el desarrollo de proyectos de desarrollo se encuentra git. Veremos sus aspectos b\u00e1sicos, uso del sistema y su relaci\u00f3n con repositorios como github.</p> <p></p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#contenedores","title":"Contenedores","text":"<p>Entre las distintas tecnolog\u00edas de virtualizaci\u00f3n existentes ha alcanzado gran relevancia en los \u00faltimos tiempos la llamada de \"contenedores\". De entre las distintas implementaciones de contenedores existentes nos centraremos en docker.</p> <p></p> <p>Veremos c\u00f3mo docker puede ser \u00fatil a administradores de sistemas, pero tambi\u00e9n a desarrolladores. Aprenderemos los conceptos b\u00e1sicos de docker, a instalarlo, manejar im\u00e1genes y desplegar servicios sobre un contenedor.</p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#implantacion-y-administracion-de-servidores-web","title":"Implantaci\u00f3n y administraci\u00f3n de servidores web","text":"<p>Para poder desplegar una aplicaci\u00f3n web lo primero que necesitaremos ser\u00e1 un servidor web. As\u00ed pues, en primer lugar deberemos conocer qu\u00e9 es un servidor web y qu\u00e9 tecnolog\u00edas de servidores web existen.</p> <p>Seguidamente estudiaremos los protocolos utilizados en la transferencia de p\u00e1ginas web (http, https), su historia y funcionamiento.</p> <p>Continuaremos viendo los servidores web m\u00e1s utilizados actualmente (Apache y Nginx), sus diferencias y aplicaciones. Los instalaremos y configuraremos.</p> <p></p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#servidores-de-aplicaciones","title":"Servidores de aplicaciones","text":"<p>En sus primeros tiempos la web fue est\u00e1tica, es decir, el creador de las p\u00e1ginas web defin\u00eda su contenido y los usuarios simplemente lo consultaban. Con el tiempo fueron surgiendo escenarios de interactividad creciente, en los que las p\u00e1ginas servidas depend\u00edan de las acciones del usuario.</p> <p>Pero los servidores web hab\u00edan sido desarrollados solamente para servir p\u00e1ginas web. As\u00ed pues, se hace necesaria la aparici\u00f3n de alg\u00fan agente que pueda generar p\u00e1ginas web de forma din\u00e1mica en funci\u00f3n de los requerimientos del usuario, y entregarlos al servidor web para servirlas. Surge as\u00ed el concepto de \"servidor de aplicaciones\".</p> <p>Veremos, pues, c\u00f3mo funcionan este tipo de servidores y aprenderemos a instalar y configurar uno de los m\u00e1s utilizados Apache Tomcat.</p> <p></p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#servicios-de-red-implicados-en-el-despliegue-de-aplicaciones-web","title":"Servicios de red implicados en el despliegue de aplicaciones web","text":"<p>Adem\u00e1s del propio servidor web se hacen necesarios una serie de servicios adicionales para el correcto funcionamiento del sistema. Necesitamos enviar las p\u00e1ginas al servidor web, traducir las IP a los nombres de dominio, alojar nuestro servidor en alg\u00fan servicio de hosting accesible desde Internet...</p> <p>Para enviar las p\u00e1ginas al servidor web aprenderemos a instalar, configurar y utilizar el servicio FTP.</p> <p></p> <p>En esta parte del m\u00f3dulo veremos, entre otros, el servicio DNS o Domain Name System. Este sistema proporciona un mecanismo eficaz para llevar a cabo la resoluci\u00f3n de nombres de dominio a direcciones IP.  A los humanos nos es m\u00e1s f\u00e1cil recordar un nombre de dominio (de host, de web, de servidor de correo, etc.) utilizando un texto identificativo (por ejemplo, www.gva.es) que la direcci\u00f3n IP pertinente (por ejemplo, 193.144.127.85).</p> <p>En este apartado aprenderemos c\u00f3mo funciona este sistema, los mecanismos de resoluci\u00f3n directa e inversa, los tipos de servidores DNS (maestro, esclavo, cach\u00e9, forwarder), las herramientas para utilizarlo y, como no, aprenderemos a instalar y configurar un servidor DNS.</p> <p></p> <p>Otro aspecto importante en los servidores es la gesti\u00f3n de usuarios y permisos de acceso a los distintos recursos. Un servidor LDAP (Lightweight Directory Access Protocol) es una herramienta que se utiliza para gestionar y acceder a una base de datos de informaci\u00f3n sobre usuarios y recursos en una red. Imagina un gran libro de direcciones que guarda detalles como nombres de usuario, contrase\u00f1as y permisos de acceso, y que los sistemas y aplicaciones pueden consultar para autenticar a los usuarios y autorizar su acceso a diferentes recursos. LDAP ayuda a organizar y centralizar esta informaci\u00f3n para facilitar la administraci\u00f3n y mejorar la seguridad en una red.</p> <p>Aprenderemos los conceptos b\u00e1sicos y a instalar y gestionar accesos mediante un servidor OpenLDAP.</p> <p></p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#cicd-integracion-y-despliegue-continuo","title":"CI/CD (Integraci\u00f3n y despliegue continuo)","text":"<p>Entre el desarrollo de una aplicaci\u00f3n (o nueva versi\u00f3n de una existente) y que el usuario pueda usarla hay un paso, no trivial, la puesta en producci\u00f3n.</p> <p>En las empresas tradicionales dicho proceso es muy complicado y estresante. Se hace pocas veces, cuatro o cinco veces al a\u00f1o, durante el fin de semana cuando todos los servicios est\u00e1n parados. El proceso genera muchos trastornos y dolores de cabeza. Y los resultados, muchas veces, no son los esperados.</p> <p>Una idea fundamental de las metodolog\u00edas \"\u00e1giles\" es entregar valor frecuentemente para obtener una pronta retroalimentaci\u00f3n del cliente. Para ello es necesario tener muy engrasados los procesos de despliegue y puesta en producci\u00f3n del software. Dentro de estas metodolog\u00edas veremos CI/CD (Integraci\u00f3n y despliegue continuo), que busca crear un proceso de desarrollo m\u00e1s fluido y controlado, con el objetivo de entregar software de alta calidad de manera m\u00e1s r\u00e1pida y confiable</p> <p></p>"},{"location":"Ud0%20Introduccion/Ud0_1Introalmodulo/#como-lo-veremos","title":"\u00bfC\u00f3mo lo veremos?","text":"<p>Cada unidad constar\u00e1 de una parte de teor\u00eda donde se tratar\u00e1n los conceptos que son necesarios conocer antes de ponernos \"manos a la obra\".</p> <p>Por otra parte haremos pr\u00e1cticas guiadas que nos permitir\u00e1n instalar y configurar los distintos servicios que vayamos estudiando paso a paso siguiendo ejemplos ya preparados.</p> <p>Puesto que es un objetivo del m\u00f3dulo la instalaci\u00f3n y configuraci\u00f3n b\u00e1sica de tecnolog\u00edas de virtualizaci\u00f3n de servidores en la nube y en contenedores, empezaremos creando nuestros servicios en m\u00e1quinas virtuales que crearemos en AWS Academy (Amazon Web Services Academy). All\u00ed crearemos nuestras m\u00e1quinas virtuales y desplegaremos nuestros servicios.</p> <p></p> <p>Posteriormente pasaremos a desplegar los mismos servicios en un entorno de contenedores \"docker\", a\u00f1adiendo un grado m\u00e1s de complejidad.</p>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/","title":"0.2. Introducci\u00f3n a AWS Academy","text":""},{"location":"Ud0%20Introduccion/Ud0_2AWS/#que-es-aws-academy","title":"\u00bfQu\u00e9 es AWS Academy?","text":"<p>AWS Academy es una iniciativa de Amazon Web Services que proporciona a las instituciones educativas contenido y recursos de formaci\u00f3n en la nube. Su objetivo es preparar a estudiantes y educadores con habilidades pr\u00e1cticas en tecnolog\u00edas \"cloud\", facilitando el acceso a materiales de estudio, laboratorios pr\u00e1cticos y certificaciones oficiales de AWS.</p> <p>Nosotros lo usaremos para crear nuestros servidores en la nube y desplegar sobre ellos nuestros servicios. Esto nos aportar\u00e1 diversas ventajas, entre ellas:</p> <ul> <li>No dependemos del equipo que tenga cada alumno: da igual su potencia, sistema operativo o versi\u00f3n</li> <li>Todos trabajaremos con una m\u00e1quina virtual exactamente igual, evitando los problemas de que a unos les funcione y a otros no</li> <li>Podemos trabajar en el aula y seguir trabajando desde casa sobre la misma m\u00e1quina virtual</li> <li>No necesitamos discos duros de gran capacidad para alojar nuestras m\u00e1quinas virtuales.</li> <li>El despliegue de una m\u00e1quina virtual es casi instant\u00e1neo</li> </ul>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#como-crearemos-nuestras-maquinas-virtuales-en-aws-academy","title":"\u00bfC\u00f3mo crearemos nuestras m\u00e1quinas virtuales en AWS Academy?","text":"<p>En las 2 pr\u00e1cticas de este m\u00f3dulo introductorio aprenderemos a crear servidores virtuales en AWS, conocidos como EC2. Aunque la creaci\u00f3n es siempre igual, independientemente del sistema operativo que instalemos, el acceso posterior ser\u00e1 diferente en funci\u00f3n de que nos conectemos en modo comando o en modo gr\u00e1fico. As\u00ed pues, crearemos una m\u00e1quina linux a la que accederemos en modo comando por SSH y un servidor Windows al que accederemos en modo gr\u00e1fico con RDP.</p> <p>Veamos a continuaci\u00f3n las bases te\u00f3ricas de la conexi\u00f3n SSH que nos permitir\u00e1n entender la conexi\u00f3n que estableceremos posteriormente en las pr\u00e1cticas. No entraremos en detalle en el protocolo RDP.</p>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#como-nos-conectaremos-por-ssh-a-nuestras-maquinas-virtuales-en-aws-academy","title":"\u00bfC\u00f3mo nos conectaremos por SSH a nuestras m\u00e1quinas virtuales en AWS Academy?","text":"<p>Para conectarnos a una m\u00e1quina de forma remota y segura en modo comando, la opci\u00f3n m\u00e1s recomendable es SSH.</p> <p></p> <p>SSH o Secure Shell es un protocolo de red criptogr\u00e1fico para operar servicios de red de forma segura a trav\u00e9s de una red no protegida. Las aplicaciones t\u00edpicas incluyen l\u00ednea de comandos remota, inicio de sesi\u00f3n y ejecuci\u00f3n de comandos remota, pero cualquier servicio de red puede protegerse con SSH.</p> <p>SSH proporciona un canal seguro a trav\u00e9s de una red no segura mediante el uso de una arquitectura cliente-servidor, conectando una aplicaci\u00f3n cliente SSH con un servidor SSH.  El puerto TCP est\u00e1ndar para SSH es 22 y se usa generalmente para acceder a sistemas operativos similares a Unix, pero tambi\u00e9n se puede usar en Microsoft Windows.</p> <p>Proporciona un mecanismo para autenticar un usuario remoto, transferir entradas desde el cliente al servidor y retransmitir la salida de vuelta al cliente.</p> <p>SSH tiene muchas aplicaciones diferentes:</p> <ul> <li>Gesti\u00f3n de servidores a los que no se puede acceder localmente</li> <li>Transferencia segura de archivos</li> <li>Creaci\u00f3n de copias de seguridad</li> <li>Conexi\u00f3n entre dos ordenadores con encriptaci\u00f3n de extremo a extremo</li> <li>Mantenimiento remoto desde otros ordenadores</li> </ul>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#autenticacion","title":"Autenticaci\u00f3n","text":"<p>Los dos m\u00e9todos de autenticaci\u00f3n de usuario SSH m\u00e1s comunes que se utilizan so:</p> <ul> <li>las contrase\u00f1as (cifrado sim\u00e9trico)</li> <li>las claves SSH (cifrado asim\u00e9trico o de clave p\u00fablica). </li> </ul> <p>Los clientes env\u00edan contrase\u00f1as cifradas al servidor de forma segura. Sin embargo, las contrase\u00f1as son un m\u00e9todo de autenticaci\u00f3n arriesgado porque su solidez depende de que el usuario sepa qu\u00e9 hace que una contrase\u00f1a sea segura. </p> <p>Los pares de claves p\u00fablica-privada SSH encriptados asim\u00e9tricamente son una mejor opci\u00f3n. Una vez que el cliente descifra el mensaje, el servidor le otorga acceso al sistema.</p> <p>Note</p> <p>SSH opta por el cifrado h\u00edbrido, donde se utiliza el cifrado asim\u00e9trico para establecer la comunicaci\u00f3n e intercambiar unas claves sim\u00e9tricas que ser\u00e1n las que se utilizar\u00e1n posteriormente en el intercambio de informaci\u00f3n.</p>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#cifrados-simetricos-o-de-clave-privada","title":"Cifrados sim\u00e9tricos o de clave privada","text":"<p>Este tipo de cifrado utiliza la misma clave para cifrar y para descifrar la informaci\u00f3n. Por este motivo, la clave debe ser secreta y solo conocida por el emisor y el receptor del mensaje. Se usa la misma clave para cifrar y descrifrar el mensaje.</p> <p></p> <p>Ventajas</p> <ul> <li>Muy r\u00e1pidos \u2192 cifrar y descifrar un mensaje cada vez requiere un cierto tiempo, que si el algoritmo es complejo, puede ser elevado. </li> </ul> <p>Inconvenientes</p> <ul> <li>Si alguien no autorizado consigue la clave, podr\u00e1 espiar la comunicaci\u00f3n sin problemas</li> <li>\u00bfC\u00f3mo hacemos para que emisor y receptar conozcan la clave en un primer momento?<ul> <li>no se puede transmitir por el canal inseguro</li> <li>hay que transmitirla por otro canal seguro</li> <li>Ejemplos: PIN de la tarjeta del banco o archivo comprimido con contrase\u00f1a</li> </ul> </li> </ul>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#cifrados-asimetricos-o-de-clave-publica","title":"Cifrados asim\u00e9tricos o de clave p\u00fablica","text":"<p>En este tipo de cifrados cada usuario utiliza un par de claves: una clave p\u00fablica y una clave privada. Un mensaje cifrado con la clave p\u00fablica solo se puede descifrar con su correspondiente clave privada y viceversa.</p> <p>La clave p\u00fablica es accesible a cualquier persona que quiera consultarla, no hace falta que sea transmitida por un canal seguro como en el caso anterior.</p> <p>La clave privada solo la debe conocer su due\u00f1o.</p>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#encriptacion-de-un-mensaje-con-clave-publicaprivada","title":"Encriptaci\u00f3n de un mensaje con clave p\u00fablica/privada","text":"<p>Veamos c\u00f3mo podemos usar un par de claves p\u00fablica/privada para cifrar un mensaje por parte del emisor que solo pueda descrifrar el receptor.</p> <ol> <li>El emisor cifra un mensaje con la clave p\u00fablica del receptor</li> <li>El receptor recibe el mensaje y es el \u00fanico que podr\u00e1 descifrarlo porque es el \u00fanico que posee la clave cifrada asociada</li> </ol> <p></p> <p>Ventajas</p> <ul> <li>No se necesita un nuevo canal independiente y seguro para transmitir la clave p\u00fablica del receptor, que puede ser conocida por cualquiera.</li> </ul> <p>Inconvenientes</p> <ul> <li>Son m\u00e1s lentos que los cifrados sim\u00e9tricos</li> <li>Hay que proteger muy bien la clave privada y tenerla siempre disponible para poder descifrar los mensajes (no es una contrase\u00f1a)</li> <li>Hay que asegurarse de que la clave p\u00fablica es de qui\u00e9n dice ser y no de un impostor que se est\u00e9 haciendo pasar por \u00e9l</li> </ul>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#acceso-a-un-servidor-con-clave-publicaprivada","title":"Acceso a un servidor con clave p\u00fablica/privada","text":"<p>El proceso de autenticaci\u00f3n usando pares de claves p\u00fablica y privada, como en SSH, sigue estos pasos:</p> <ol> <li> <p>Generaci\u00f3n de claves: El usuario genera un par de claves, una clave privada y una clave p\u00fablica. La clave privada se mantiene en su m\u00e1quina, y la clave p\u00fablica se copia al servidor al que desea acceder, generalmente en el archivo ~/.ssh/authorized_keys del servidor.</p> </li> <li> <p>Inicio de sesi\u00f3n: Cuando el usuario intenta conectarse al servidor, el servidor utiliza la clave p\u00fablica que tiene almacenada para generar un desaf\u00edo (mensaje aleatorio). Env\u00eda este desaf\u00edo al usuario para que lo firme.</p> </li> <li> <p>Respuesta del cliente: El usuario, con su clave privada (que nunca se comparte), cifra el desaf\u00edo recibido y lo env\u00eda de vuelta al servidor como prueba de que posee la clave privada correspondiente a la clave p\u00fablica.</p> </li> <li> <p>Validaci\u00f3n del servidor: El servidor descifra la respuesta del cliente con la clave p\u00fablica que tiene. Si la respuesta es correcta, el servidor sabe que el usuario tiene la clave privada y, por lo tanto, lo autentica, permitiendo el acceso. </p> </li> </ol> <p></p> <p>Este proceso garantiza que la autenticaci\u00f3n es segura, ya que la clave privada nunca sale de la m\u00e1quina del usuario y no es necesaria una contrase\u00f1a si la clave est\u00e1 correctamente configurada.</p>"},{"location":"Ud0%20Introduccion/Ud0_2AWS/#como-usa-aws-el-cifrado-asimetrico","title":"\u00bfC\u00f3mo usa AWS el cifrado asim\u00e9trico?","text":"<p>En AWS deberemos crear un conjunto de claves p\u00fablica-privada para acceder a nuestros servidores virtuales. Podemos crear tantas claves p\u00fablica/privada c\u00f3mo queramos, pero en nuestro m\u00f3dulo bastar\u00e1 con crear una y usar la misma para acceder a todos los servidores.</p> <p>Crearemos el par de claves en el propio entorno AWS. Descargaremos en nuestro ordenador la clave privada, que solo poseeremos nosotros. En cada servidor que creemos le asociaremos la clave p\u00fablica de la pareja, que se mantiene en AWS. De esta manera, para poder realizar la conexi\u00f3n necesitaremos la clave privada que solo nosotros poseeremos en nuestro equipo local.</p> <p>Es importante mantener la clave privada a buen recaudo y tenerla disponible tanto en el aula como en casa para poder conectarnos a nuestras m\u00e1quinas virtuales en AWS.</p>"},{"location":"Ud1%20Control%20de%20versiones/P1/","title":"P1.1 Introducci\u00f3n a git y GitHub","text":""},{"location":"Ud1%20Control%20de%20versiones/P1/#que-vas-a-aprender-en-este-taller","title":"\u00bfQu\u00e9 vas a aprender en este taller?","text":"<ul> <li>Recordar el uso de git para realizar el control de versiones de los proyectos.</li> <li>Configurar una cuenta en GitHub, servicio que nos ofrece repositorios remotos.</li> <li>Recordar el ciclo de vida de la gesti\u00f3n de nuestros repositorios: creaci\u00f3n, clonaci\u00f3n, sincronizaci\u00f3n, ... y nuestros ficheros:  creaci\u00f3n, modificaci\u00f3n, borrado.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P1/#conceptos-previos-de-git","title":"Conceptos previos de git","text":"<p>Git es un sistema de control de versiones distribuido ampliamente utilizado que permite a los desarrolladores rastrear y gestionar cambios en el c\u00f3digo fuente de proyectos de software. Permite la colaboraci\u00f3n efectiva en equipos, facilita el seguimiento de revisiones, la gesti\u00f3n de ramas de desarrollo y la reversi\u00f3n a versiones anteriores del c\u00f3digo, lo que lo convierte en una herramienta esencial para el desarrollo de software colaborativo y la gesti\u00f3n de proyectos.</p> <p>Para gestionar un proyecto con git crearemos un directorio en el que diremos a git que \"controle\" el estado de los distintos archivos que creemos en dicho directorio. Diremos que ese directorio es un \"Repositorio git\".</p> <p>En un repositorio git existen distintas secciones, que podemos entender como \"lugares\" donde pueden estar los archivos. Adem\u00e1s, cada archivo puede estar en distintos estados en funci\u00f3n de la secci\u00f3n en que se encuentren. Veamos ambos conceptos.</p>"},{"location":"Ud1%20Control%20de%20versiones/P1/#secciones-principales-de-un-repositorio-git","title":"Secciones principales de un repositorio <code>git</code>","text":"<p>En un repositorio <code>git</code> podemos diferenciar las siguientes secciones:</p> <ul> <li>Workspace</li> <li>Staging area (Index)</li> <li>Local repository</li> <li>Remote repository</li> </ul> <p></p> <p>Figura 1: Imagen de Oliver Steele.</p>"},{"location":"Ud1%20Control%20de%20versiones/P1/#estados-de-un-archivo-en-git","title":"Estados de un archivo en <code>git</code>","text":"<p>Un archivo puede estar en alguno de los siguientes estados:</p> <ul> <li>Sin seguimiento (untracked)</li> <li>Preparado (staged)</li> <li>Modificado (modified)</li> <li>Confirmado (commited)</li> </ul> <p>El siguiente diagrama muestra en qu\u00e9 secci\u00f3n se puede encontrar cada archivo en funci\u00f3n de su estado.</p> <pre><code>+-------------+  +-------------+  +-------------+  +-------------+\n|  Workspace  |  |   Staging   |  |    Local    |  |    Remote   |\n|             |  |     Area    |  |  Repository |  |  Repository |\n+------+------+  +------+------+  +------+------+  +------+------+\n       |                |                |                |\n       |                |                |                |\n   Untracked            |                |                |\n       |                |                |                |\n   Modified          Staged          Commited             |\n       |                |                |                |\n       |                |                |                |\n       |                |                |                |\n       +                +                +                +\n</code></pre> <p>Para consultar el estado de los archivos usamos el comando:</p> <pre><code>git status\n</code></pre> <p>Este comando es muy usado ya que es fundamental conocer el estado de los archivos de nuestro repositorio.</p> <p>Utilizando distintos comandos podemos pasar los archivos de una secci\u00f3n a otra y cambiar su estado. A continuaci\u00f3n veremos los comandos b\u00e1sicos que nos permitir\u00e1n una utilizaci\u00f3n b\u00e1sica de git usando como repositorio remoto GitHub.</p>"},{"location":"Ud1%20Control%20de%20versiones/P1/#que-tienes-que-hacer","title":"\u00bfQu\u00e9 tienes que hacer?","text":"<ol> <li> <p>Crea una cuenta en GitHub (Si no la tienes!!!). La forma de acceder a los repositorios remotos de GitHub va a ser por SSH, por lo tanto debes copiar tu clave p\u00fablica RSA a GitHub, para ello:</p> <ul> <li>Genera una par de claves ssh, como hicimos en una pr\u00e1ctica anterior. Puedes usar la que creaste entonces si quieres.</li> <li>Ve a GitHub - Settings - \"SSH and GPG keys\".</li> <li>Crea una `New SSH Key\".</li> <li>Copia el contenido de tu fichero <code>~/.ssh/id_rsa.pub</code> y pega el contenido de tu clave p\u00fablica.</li> </ul> </li> <li> <p>Crea en GitHub un repositorio con el nombre prueba_tu_nombre (inicializa el repositorio con un fichero README) y la descripci\u00f3n Repositorio de prueba de Nombre.</p> </li> <li> <p>Instala git en tu ordenador (si no lo tienes instalado!!!).</p> <pre><code>apt-get install git-all\n</code></pre> </li> <li> <p>Configuraci\u00f3n de git. Lo primero que deber\u00edas hacer cuando instalas Git es establecer tu nombre de usuario y direcci\u00f3n de correo electr\u00f3nico (Asegurate que los datos son correctos y que has puesto tu nombre completo). Esto es importante porque las confirmaciones de cambios (commits) en Git usan esta informaci\u00f3n, y es introducida de manera inmutable en los commits que env\u00edas:</p> <pre><code>    git config --global user.name \"John Doe\"\n    git config --global user.email johndoe@example.com\n</code></pre> <p>De nuevo, s\u00f3lo necesitas hacer esto una vez si especificas la opci\u00f3n <code>--global</code>, ya que Git siempre usar\u00e1 esta informaci\u00f3n para todo lo que hagas en ese sistema.</p> </li> <li> <p>Clonar el repositorio remoto. Copia la url SSH del repositorio (no copies la URL https) y vamos a clonar el repositorio en nuestro ordenador. Sit\u00faate en un directorio, dentro del cual quieras clonar el repositorio remoto.</p> <pre><code>    git clone git@github.com:xxxxxxx/xxxxxxx.git\n</code></pre> <p>Comprueba que dentro del repositorio que hemos creado se encuentra el fichero README.md, en este fichero podemos poner la descripci\u00f3n del proyecto.</p> <p>Comprueba tambi\u00e9n que existe un directorio .git que contiene todos los ficheros que git utiliza para gestionar el proyecto.</p> </li> <li> <p>Vamos a crear un nuevo fichero, lo vamos a a\u00f1adir a nuestro repositorio local y luego lo vamos a sincronizar con nuestro repositorio remoto de GitHub. Cada vez que hagamos una modificaci\u00f3n en un fichero lo podemos se\u00f1alar creando un commit. Los mensajes de los commits son fundamentales para explicar la evoluci\u00f3n de un proyecto. Un commit debe ser un conjunto peque\u00f1o de cambios de los ficheros del proyecto con una cierta coherencia. Comprueba tras cada comando git el estado y \u00e1rea donde se encuentra el archivo con git status.</p> <pre><code>    echo \"Esto es una prueba\"&gt;ejemplo.txt\n    git add ejemplo.txt\n    git status\n    git commit -m \"He creado el fichero ejemplo.txt\"\n    git status\n    git push\n</code></pre> <p>Comprueba ahora en el repositorio remoto de GitHub que se ha subido el fichero ejemplo.txt y los comentarios del commit.</p> </li> <li> <p>Si modificas un fichero en tu repositorio local, pasar\u00e1 al \u00e1rea \"workspace\" y estado \"modificado\". Vamos a probarlo.</p> <pre><code>    echo \" modificada\"&gt;&gt;ejemplo.txt\n    git status\n</code></pre> <p>Comprueba como te dice que el fichero ejemplo.txt esta en estado modificado.</p> </li> <li> <p>Ahora podr\u00edamos pasarlo al \u00e0rea \"stage\" nuevamente con <code>git add ejemplo.txt</code> o pasarlo directamente al \"Repositorio local\" con <code>git commit -a</code>. Por rapidez usaremos esta \u00faltima forma. F\u00edjate que usaremos siempre <code>-m</code> para incluir un comentario descriptivo a cada commit.</p> <pre><code>    git commit -am \"He modificado el fichero ejemplo.txt\"\n    git status\n    git push\n    git status\n</code></pre> <p>Note</p> <p>El git status que realizamos tras cada comando no es necesario. S\u00edmplemente lo hacemos para ir aprendiendo los distintos estados y \u00e1reas por las que pasa el fichero.</p> </li> <li> <p>Si quieres cambiar el nombre de un fichero o directorio de tu repositorio:</p> <pre><code>    git mv ejemplo.txt ejemplo2.txt\n    git commit -am \"He cambiado el nombre del fichero\"\n    git status\n    git push\n    git status\n</code></pre> </li> <li> <p>Si quieres borrar un fichero de tu repositorio:</p> <pre><code>    git rm ejemplo2.txt\n    git status\n    git commit -am \"He borrado el fichero ejemplo2\"\n    git status\n    git push\n</code></pre> </li> <li> <p>Puedes comprobar el historial de commits del proyecto as\u00ed</p> <pre><code>    git log\n</code></pre> </li> <li> <p>Para finalizar comprueba en GitHub el historial de commits.  </p> </li> </ol> <p>Note</p> <p>Puedes clonar tu repositorio de GitHub en varios ordenadores (por ejemplo, si quieres trabajar en tu casa y en el instituto), por lo tanto antes de trabajar en un repositorio local tienes que sincronizar los posibles cambios que se hayan producido en el repositorio remoto, para ello:</p> <pre><code>    git pull\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/P2/","title":"P1.2 Git Trabajando con ramas y uniones","text":""},{"location":"Ud1%20Control%20de%20versiones/P2/#que-vas-a-aprender-en-este-taller","title":"\u00bfQu\u00e9 vas a aprender en este taller?","text":"<ul> <li>Aprender\u00e1s el concepto de rama.</li> <li>La gesti\u00f3n y el ciclo de vida (creaci\u00f3n, modificaci\u00f3n, borrado, ...) de ramas.</li> <li>Aprender\u00e1s el concepto de uni\u00f3n (merge) que nos posibilita la fusi\u00f3n de ramas.</li> <li>A solucionar los posibles conflictos que pueden aparecer en el momento del merge.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P2/#como-trabajar-en-equipo-con-git","title":"C\u00f3mo trabajar en equipo con <code>git</code>","text":"<p>Git nos permite trabajar de forma colaborativa en un proyecto mediante el concepto de \"rama\". Cada miembro del proyecto puede crear una rama del mismo, realizar modificaciones y, posteriormente, unir nuevamente las modificaciones realizadas por cada miembro en la rama principal. Git se encargar\u00e1 de detectar qu\u00e9 se ha modificado (incluso si m\u00e1s de un miembro han modificado la misma parte del proyecto) mostr\u00e1ndonos los cambios y permiti\u00e9ndonos elegir qu\u00e9 integrar en la rama principal y qu\u00e9 no.</p> <p>La siguiente imagen muestra una secuencia de trabajo colaborativa en un proyecto git.</p> <p></p> <p>Figura 2: Imagen extra\u00edda del blog de James Chambers.</p> <p>Se recomienda leer el post Using Git in a team: a cheatsheet. </p> <p>Veamos c\u00f3mo llevar a cabo este trabajo con ramas aunque no abordaremos el proceso completo que muestra este diagrama. De momento nos centraremos en crear una nueva rama, trabajar en ella, unirla con la principal y finalmente eliminarla.</p>"},{"location":"Ud1%20Control%20de%20versiones/P2/#que-tienes-que-hacer","title":"\u00bfQu\u00e9 tienes que hacer?","text":"<p>Trabaja con el repositorio de los talleres anteriores.</p> <ol> <li>Una rama representa una l\u00ednea independiente de desarrollo, es como crear un nuevo \u00e1rea de trabajo que tendr\u00e1 su historial propio de commits.</li> <li> <p>Para  listar las ramas locales ejecuta:</p> <pre><code>    $ git branch\n    * main\n</code></pre> <p>La rama en la que est\u00e1s trabajando actualmente se se\u00f1ala con un asterisco . La rama main (en proyectos antiguos se llama master*) es la rama con la que se comienza en cualquier proyecto, y es la que se utiliza como rama principal donde se encuentra el proyecto en su estado final.</p> </li> <li> <p>Crea una nueva rama con la instrucci\u00f3n:     <pre><code>    $ git branch nuevarama\n</code></pre></p> </li> <li> <p>Vuelve a lista las ramas, comprueba que todav\u00eda est\u00e1s en la rama <code>main</code>, para pasar a la nueva rama utiliza el comando:     <pre><code>    $ git checkout nuevarama\n</code></pre></p> <ul> <li>Comprueba que en la nueva rama tienes los mismos ficheros que en la rama principal.</li> <li>Todos los cambios que realices en los ficheros en esta rama no se ver\u00e1n en la rama principal.</li> <li>Truco: con el comando <code>git checkout -b [rama]</code> se crea una nueva rama y te posicionas en ella.</li> <li>Con el comando <code>git branch -v</code> se ve el \u00faltimo commit de cada rama. Comprueba que coinciden el \u00faltimo commit en las dos ramas.</li> <li>Truco: Puedes usar una extensi\u00f3n de tu shell (bash, zsh,...) para que te muestre en el prompt la rama en la que est\u00e1s trabajando.</li> </ul> </li> <li> <p>Comprueba a modificar alg\u00fan fichero y crea un nuevo fichero en esta rama. Realiza el commit y comprueba que estos cambios no se han reflejado en los ficheros de la rama principal. Ejecuta <code>git branch -v</code> para ver el \u00faltimo commit de cada rama.</p> </li> <li> <p>Las ramas no se crean autom\u00e1ticamente en GitHub, hay que realizar un <code>push</code> para crearlas en remoto. Por lo tanto ejecutamos: </p> <p><pre><code>    $ git push origin nuevarama\n</code></pre> Comprueba en GitHub que se ha creado la nueva rama y que puedes seleccionar las 2 ramas existentes.</p> </li> <li> <p>Una vez que has trabajado en una rama, lo normal es querer incorporar los cambios a la rama principal. Para unir una rama a la principal, ejecutamos:</p> <p><pre><code>    $ git checkout main\n    $ git merge nuevarama\n</code></pre> Cuando s\u00f3lo se han a\u00f1adido o eliminado archivos en una rama, es f\u00e1cil unirla a la principal. El resultado simplemente ser\u00e1 la suma o resta de esos archivos en la principal. Cuando se hacen modificaciones en archivos, incluyendo cambios en los nombres de los archivos, git detecta esos cambios y los adapta autom\u00e1ticamente, pero a veces surgen conflictos.</p> <p>Realiza la fusi\u00f3n de la nueva rama a la principal. \u00bfSe han producido conflictos?</p> </li> <li> <p>Los conflictos aparecen cuando se ha modificado la misma parte del c\u00f3digo en dos ramas diferentes. Veamos un ejemplo:</p> <ul> <li>Crea un fichero <code>prueba.txt</code> en la rama principal. Recuerda hacer un commit.</li> <li>Crea una nueva rama y accede a ella. </li> <li>Modifica el fichero en la nueva rama. Recuerda hacer un commit.</li> <li>Vuelve a la rama principal. Y modifica de nuevo el fichero antes de realizar el merge.</li> <li> <p>Realiza la uni\u00f3n y aparece el conflicto:</p> <pre><code>    $ git merge nuevo \n    Auto-fusionando prueba.txt\n    CONFLICTO (contenido): Conflicto de fusi\u00f3n en prueba.txt\n    Fusi\u00f3n autom\u00e1tica fall\u00f3; arregle los conflictos y luego realice un commit con el resultado.\n</code></pre> </li> <li> <p>Si miramos el fichero:</p> <p><pre><code>    $ cat prueba.txt \n\n    &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n    Hola c\u00f3mo est\u00e1s\n    =======\n    hola que tal\n    &gt;&gt;&gt;&gt;&gt;&gt;&gt; nuevo\n</code></pre>     Tenemos el contenido que estaba en la rama principal (HEAD) y lo que estaba en la rama nuevo. Ser\u00e1 el usuario el que tendr\u00e1 que dejar el contenido del fichero como quiera editando directamente el fichero en la rama main.</p> </li> </ul> </li> <li> <p>Es bastante frecuente crear una rama, hacer los cambios que sean necesarios, unirla a una rama principal y despu\u00e9s eliminar la rama que se hab\u00eda creado.  Para eliminar una rama en local ejecutamos:      <pre><code>    $ git branch -d nuevarama\n</code></pre>     Para eliminarla en remoto     <pre><code>    git push origin --delete nuevarama\n</code></pre>     Si queremos eliminarla tanto en local como en remoto deberemos ejecutar ambos comandos.</p> </li> <li> <p>Acababa la pr\u00e1ctica eliminando el repositorio remoto en GitHub y el directorio local que has creado.</p> <ol> <li>En GitHub ve al proyecto, Settings, General, \"Danger zone\" y selecciona \"Delete this repository\"</li> <li>En local utiliza <code>rm -Rf pruebanombre</code> para eliminar todos el directorio del proyecto.</li> </ol> </li> </ol> <p>Hazlo tu solo</p> <ol> <li>Crea una rama que se llame <code>primera</code> en tu local, y ejecuta la instrucci\u00f3n necesaria para comprobar que se ha creado.</li> <li>Crea un nuevo fichero en esta rama y fusi\u00f3nalo con la principal. \u00bfSe ha producido conflicto? Razona la respuesta.</li> <li>Borra la rama <code>primera</code>.</li> <li>Crea una rama que se llame <code>segunda</code>, y modifica un fichero en ella para producir un conflicto al unirlo a la rama principal. Observa contenido del fichero donde se ha producido el conflicto.</li> <li>Soluciona el conflicto que has creado en el punto anterior y sincroniza la rama <code>segunda</code> en el remoto. Comprueba que se ha creado la rama en el repositorio de GitHub.</li> </ol>"},{"location":"Ud1%20Control%20de%20versiones/P3/","title":"Enunciado ejercicios Git y GitHub","text":""},{"location":"Ud1%20Control%20de%20versiones/P3/#repositorio-deaw","title":"Repositorio DEAW","text":"<ul> <li>Crear un repositorio en vuestro GitHub llamado DEAW.</li> <li>Clonar vuestro repositorio en local.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-1-readme","title":"Ejercicio 1. README","text":"<ul> <li>Crear (si no lo hab\u00e9is creado ya) en vuestro repositorio local un documento README.md.</li> </ul> <p>Note</p> <p>Escribir un peque\u00f1o texto en este README a prop\u00f3sito del repositorio y el m\u00f3dulo para el que se utilizar\u00e1\u00b7</p>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-2-commit-inicial","title":"Ejercicio 2. Commit inicial","text":"<ul> <li>Realizar un commit inicial con el comentario <code>Comenzamos con los ejercicios de Git</code></li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-3-push-inicial","title":"Ejercicio 3. Push inicial","text":"<ul> <li>Subir los cambios al repositorio remoto.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-4-ignorar-archivos","title":"Ejercicio 4. Ignorar archivos","text":"<ul> <li>Crear en el repositorio local un fichero llamado privado.txt.</li> <li>Crear en el repositorio local una carpeta llamada privada.</li> <li>Realizar los cambios oportunos para que tanto el archivo como la carpeta sean ignorados por git.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-5-anadir-fichero-1txt","title":"Ejercicio 5. A\u00f1adir fichero 1.txt","text":"<ul> <li>A\u00f1adir fichero 1.txt al repositorio local.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-6-crear-el-tag-v01","title":"Ejercicio 6. Crear el tag v0.1","text":"<ul> <li>Crear un tag v0.1.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-7-subir-el-tag-v01","title":"Ejercicio 7. Subir el tag v0.1","text":"<ul> <li>Subir los cambios al repositorio remoto.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-8-cuenta-de-github","title":"Ejercicio 8. Cuenta de GitHub","text":"<ul> <li>Poner una foto en vuestro perfil de GitHub.</li> <li>Poner el doble factor de autentificaci\u00f3n en vuestra cuenta de GitHub.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-9-uso-social-de-github","title":"Ejercicio 9. Uso social de GitHub","text":"<ul> <li>Preguntar los nombres de usuario de GitHub de 2 de tus compa\u00f1eros de clase, b\u00fascalos, y sigueles.</li> <li>Seguir los repositorios DEAW del resto de tus compa\u00f1eros.</li> <li>A\u00f1adir una estrella a los repositorios DEAW del resto de tus compa\u00f1eros.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-10-crear-una-tabla","title":"Ejercicio 10. Crear una tabla","text":"<ul> <li>Crear una tabla de este estilo en el fichero README.md con la informaci\u00f3n de varios de tus compa\u00f1eros de clase:</li> </ul> NOMBRE GITHUB Nombre del compa\u00f1ero 1 enlace a github 1 Nombre del compa\u00f1ero 2 enlace a github 1 Nombre del compa\u00f1ero 3 enlace a github 3"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-11-colaboradores","title":"Ejercicio 11. Colaboradores","text":"<ul> <li>Poner a tu profesor/a correspondiente como colaborador del repositorio DEAW (github.com/jmunozji o github.com/noebelma)</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#notas","title":"Notas","text":"<ol> <li>Este ejercicio es continuaci\u00f3n del anterior por lo que tendr\u00e9is que seguir trabajando en el repositorio DEAW.</li> <li>Tambi\u00e9n tendre\u00eds que ir poniendo los comandos que hab\u00e9is tenido que utilizar durante todos los ejercicios y las explicaciones y capturas de pantalla que consider\u00e9is necesarias  en el informe.</li> </ol>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-12-crear-una-rama-v02","title":"Ejercicio 12. Crear una rama v0.2","text":"<ul> <li>Crear una rama v0.2.</li> <li>Posiciona tu carpeta de trabajo en esta rama.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-13-anadir-fichero-2txt","title":"Ejercicio 13. A\u00f1adir fichero 2.txt","text":"<ul> <li>A\u00f1adir un fichero 2.txt en la rama v0.2.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-14-crear-rama-remota-v02","title":"Ejercicio 14. Crear rama remota v0.2","text":"<ul> <li>Subir los cambios al repositorio remoto.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-15-merge-directo","title":"Ejercicio 15. Merge directo","text":"<ul> <li>Posicionarse en la rama master.</li> <li>Hacer un merge de la rama v0.2 en la rama master.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-16-merge-con-conflicto","title":"Ejercicio 16. Merge con conflicto","text":"<ul> <li>En la rama master poner Hola en el fichero 1.txt y hacer commit.</li> <li>Posicionarse en la rama v0.2 y poner Adios en el fichero \"1.txt\" y hacer commit.</li> <li>Posicionarse de nuevo en la rama master y hacer un merge con la rama v0.2</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-17-listado-de-ramas","title":"Ejercicio 17. Listado de ramas","text":"<ul> <li>Listar las ramas con merge y las ramas sin merge.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-18-arreglar-conflicto","title":"Ejercicio 18. Arreglar conflicto","text":"<ul> <li>Arreglar el conflicto anterior y hacer un commit.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-19-borrar-rama","title":"Ejercicio 19. Borrar rama","text":"<ul> <li>Crear un tag v0.2</li> <li>Borrar la rama v0.2</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#ejercicio-20-listado-de-cambios","title":"Ejercicio 20. Listado de cambios","text":"<ul> <li>Listar los distintos commits con sus ramas y sus tags.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P3/#referencias","title":"Referencias","text":"<p>Pro Git book, written by Scott Chacon and Ben Straub and published by Apress</p>"},{"location":"Ud1%20Control%20de%20versiones/P3/#evaluacion","title":"Evaluaci\u00f3n","text":"Criterio Puntuaci\u00f3n README 0.4 puntos Commit inicial 0.4 puntos Push inicial 0.4 puntos Ignorar archivos 0.4 puntos A\u00f1adir fichero 1.txt 0.4 puntos Crear el tag v0.1 0.4 puntos Subir el tag v0.1 0.4 puntos Cuenta de GitHub 0.4 puntos Uso social de GitHub 0.4 puntos Crear una tabla 0.4 puntos Colaboradores 0.4 puntos Crear una rama v0.2 0.4 puntos A\u00f1adir fichero 2.txt 0.4 puntos Crear rama remota v0.2 0.4 puntos Merge directo 1 puntos Merge con conflicto 1 puntos Listado de ramas 0.4 puntos Arreglar conflicto 1.2 puntos Borrar rama 0.4 puntos Listado de cambios 0.4 puntos"},{"location":"Ud1%20Control%20de%20versiones/P4/","title":"Pr\u00e1ctica 1.4 Ejercicios Git y Github (II)","text":"<p>Nota</p> <p>Cuando se habla de zona de intercambio temporal o zona staging, estamos hablando de un <code>add</code>.</p> <p>Si ten\u00e9is dudas para realizar estos ejercicios, pod\u00e9is consultar la siguiente web</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/P4/#enunciados","title":"Enunciados","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicios-de-creacion-y-actualizacion-de-repositorios","title":"Ejercicios de creaci\u00f3n y actualizaci\u00f3n de repositorios","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-1","title":"Ejercicio 1","text":"<ul> <li>Configurar Git definiendo el nombre del usuario, el correo electr\u00f3nico y activar el coloreado de la salida. </li> <li>Mostrar la configuraci\u00f3n final.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-2","title":"Ejercicio 2","text":"<ul> <li>Crear un repositorio nuevo con el nombre libro y mostrar su contenido.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-3","title":"Ejercicio 3","text":"<ul> <li>Comprobar el estado del repositorio.</li> <li>Crear un fichero <code>indice.txt</code> con el siguiente contenido:</li> </ul> <pre><code>Cap\u00edtulo 1: Introducci\u00f3n a Git\nCap\u00edtulo 2: Flujo de trabajo b\u00e1sico\nCap\u00edtulo 3: Repositorios remotos\n</code></pre> <ul> <li>Comprobar de nuevo el estado del repositorio.</li> <li>A\u00f1adir el fichero a la zona de intercambio temporal.</li> <li>Volver a comprobar una vez m\u00e1s el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-4","title":"Ejercicio 4","text":"<ul> <li>Realizar un commit de los \u00faltimos cambios con el mensaje \u201cA\u00f1adido \u00edndice del libro.\u201d y ver el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-5","title":"Ejercicio 5","text":"<ul> <li>Cambiar el fichero <code>indice.txt</code> para que contenga lo siguiente:</li> </ul> <pre><code>Cap\u00edtulo 1: Introducci\u00f3n a Git\nCap\u00edtulo 2: Flujo de trabajo b\u00e1sico\nCap\u00edtulo 3: Gesti\u00f3n de ramas\nCap\u00edtulo 4: Repositorios remotos\n</code></pre> <ul> <li>Mostrar los cambios con respecto a la \u00faltima versi\u00f3n guardada en el repositorio.</li> <li>Hacer un commit de los cambios con el mensaje \u201cA\u00f1adido cap\u00edtulo 3 sobre gesti\u00f3n de ramas\u201d.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-6","title":"Ejercicio 6","text":"<ul> <li>Mostrar los cambios de la \u00faltima versi\u00f3n del repositorio con respecto a la anterior.</li> <li>Cambiar el mensaje del \u00faltimo commit por \u201cA\u00f1adido cap\u00edtulo 3 sobre gesti\u00f3n de ramas al \u00edndice.\u201d</li> <li>Volver a mostrar los \u00faltimos cambios del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicios-de-manejo-del-historial-de-cambios","title":"Ejercicios de manejo del historial de cambios","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-1_1","title":"Ejercicio 1","text":"<ul> <li>Mostrar el historial de cambios del repositorio.</li> <li>Crear la carpeta capitulos y crear dentro de ella el fichero capitulo1.txt con el siguiente texto.</li> </ul> <p><code>Git es un sistema de control de versiones ideado por Linus Torvalds.</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit de los cambios con el mensaje \u201cA\u00f1adido cap\u00edtulo 1.\u201d</li> <li>Volver a mostrar el historial de cambios del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-2_1","title":"Ejercicio 2","text":"<ul> <li>Crear el fichero <code>capitulo2.txt</code> en la carpeta capitulos con el siguiente texto.</li> </ul> <p><code>El flujo de trabajo b\u00e1sico con Git consiste en:  1- Hacer cambios en el repositorio.  2- A\u00f1adir los cambios a la zona de intercambio temporal. 3- Hacer un commit de los cambios.</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit de los cambios con el mensaje \u201cA\u00f1adido cap\u00edtulo 2.\u201d</li> <li>Mostrar las diferencias entre la \u00faltima versi\u00f3n y dos versiones anteriores.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-3_1","title":"Ejercicio 3","text":"<ul> <li>Crear el fichero <code>capitulo3.txt</code> en la carpeta capitulos con el siguiente texto.</li> </ul> <p><code>Git permite la creaci\u00f3n de ramas lo que permite tener distintas versiones del mismo proyecto y trabajar de manera simultanea en ellas.</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit de los cambios con el mensaje \u201cA\u00f1adido cap\u00edtulo 3.\u201d</li> <li>Mostrar las diferencias entre la primera y la \u00faltima versi\u00f3n del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-4_1","title":"Ejercicio 4","text":"<ul> <li>A\u00f1adir al final del fichero <code>indice.txt</code> la siguiente l\u00ednea:</li> </ul> <p><code>Cap\u00edtulo 5: Conceptos avanzados</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit de los cambios con el mensaje \u201cA\u00f1adido cap\u00edtulo 5 al \u00edndice.\u201d.</li> <li>Mostrar qui\u00e9n ha hecho cambios sobre el fichero <code>indice.txt</code>.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicios-de-deshacer-cambios","title":"Ejercicios de deshacer cambios","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-1_2","title":"Ejercicio 1","text":"<ul> <li>Eliminar la \u00faltima l\u00ednea del fichero <code>indice.txt</code> y guardarlo.</li> <li>Comprobar el estado del repositorio.</li> <li>Deshacer los cambios realizados en el fichero <code>indice.txt</code> para volver a la versi\u00f3n anterior del fichero.</li> <li>Volver a comprobar el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-2_2","title":"Ejercicio 2","text":"<ul> <li>Eliminar la \u00faltima l\u00ednea del fichero <code>indice.txt</code> y guardarlo.</li> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Comprobar de nuevo el estado del repositorio. </li> <li>Quitar los cambios de la zona de intercambio temporal, pero mantenerlos en el directorio de trabajo.</li> <li>Comprobar de nuevo el estado del repositorio.</li> <li>Deshacer los cambios realizados en el fichero <code>indice.txt</code> para volver a la versi\u00f3n anterior del fichero.</li> <li>Volver a comprobar el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-3_2","title":"Ejercicio 3","text":"<ul> <li>Eliminar la \u00faltima l\u00ednea del fichero <code>indice.txt</code> y guardarlo.</li> <li>Eliminar el fichero <code>capitulos/capitulo3.txt</code>.</li> <li>A\u00f1adir un fichero nuevo <code>capitulos/capitulo4.txt</code> vac\u00edo.</li> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Comprobar de nuevo el estado del repositorio.</li> <li>Quitar los cambios de la zona de intercambio temporal, pero mantenerlos en el directorio de trabajo.</li> <li>Comprobar de nuevo el estado del repositorio.</li> <li>Deshacer los cambios realizados para volver a la versi\u00f3n del repositorio.</li> <li>Volver a comprobar el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-4_2","title":"Ejercicio 4","text":"<ul> <li>Eliminar la \u00faltima l\u00ednea del fichero <code>indice.txt</code> y guardarlo.</li> <li>Eliminar el fichero <code>capitulos/capitulo3.txt</code>.</li> <li>A\u00f1adir los cambios a la zona de intercambio temporal y hacer un commit con el mensaje \u201cBorrado accidental.\u201d</li> <li>Comprobar el historial del repositorio.</li> <li>Deshacer el \u00faltimo commit pero mantener los cambios anteriores en el directorio de trabajo y la zona de intercambio temporal.</li> <li>Comprobar el historial y el estado del repositorio.</li> <li>Volver a hacer el commit con el mismo mensaje de antes.</li> <li>Deshacer el \u00faltimo commit y los cambios anteriores del directorio de trabajo volviendo a la versi\u00f3n anterior del repositorio.</li> <li>Comprobar de nuevo el historial y el estado del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicios-de-gestion-de-ramas","title":"Ejercicios de gesti\u00f3n de ramas","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-1_3","title":"Ejercicio 1","text":"<ul> <li>Crear una nueva rama bibliografia</li> <li>Mostrar las ramas del repositorio.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-2_3","title":"Ejercicio 2","text":"<ul> <li>Crear el fichero <code>capitulos/capitulo4.txt</code> y a\u00f1adir el texto siguiente</li> </ul> <p><code>En este cap\u00edtulo veremos c\u00f3mo usar GitHub para alojar repositorios en remoto.</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit con el mensaje \u201cA\u00f1adido cap\u00edtulo 4.\u201d</li> <li>Mostrar la historia del repositorio incluyendo todas las ramas.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-3_3","title":"Ejercicio 3","text":"<ul> <li>Cambiar a la rama bibliografia.</li> <li>Crear el fichero <code>bibliografia.txt</code> y a\u00f1adir la siguiente referencia</li> </ul> <p><code>Chacon, S. and Straub, B. Pro Git. Apress.</code></p> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit con el mensaje \u201cA\u00f1adida primera referencia bibliogr\u00e1fica.\u201d</li> <li>Mostrar la historia del repositorio incluyendo todas las ramas.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-4_3","title":"Ejercicio 4","text":"<ul> <li>Fusionar la rama bibliografia con la rama master.</li> <li>Mostrar la historia del repositorio incluyendo todas las ramas.</li> <li>Eliminar la rama bibliografia.</li> <li>Mostrar de nuevo la historia del repositorio incluyendo todas las ramas.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-5_1","title":"Ejercicio 5","text":"<ul> <li>Crear la rama  bibliografia.</li> <li>Cambiar a la rama bibliografia.</li> <li>Cambiar el fichero <code>bibliografia.txt</code> para que contenga las siguientes referencias:</li> </ul> <pre><code>Scott Chacon and Ben Straub. Pro Git. Apress.\nRyan Hodson. Ry\u2019s Git Tutorial. Smashwords (2014)\n</code></pre> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal y hacer un commit con el mensaje \u201cA\u00f1adida nueva referencia bibliogr\u00e1fica.\u201d</li> <li>Cambiar a la rama master.</li> <li>Cambiar el fichero <code>bibliografia.txt</code> para que contenga las siguientes referencias:</li> </ul> <pre><code>Chacon, S. and Straub, B. Pro Git. Apress.\nLoeliger, J. and McCullough, M. Version control with Git. O\u2019Reilly.\n</code></pre> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal y hacer un commit con el mensaje \u201cA\u00f1adida nueva referencia bibliogr\u00e1fica.\u201d</li> <li>Fusionar la rama bibliografia con la rama master.</li> <li>Resolver el conflicto dejando el fichero <code>bibliografia.txt</code> con las referencias:</li> </ul> <pre><code>Chacon, S. and Straub, B. Pro Git. Apress.\nLoeliger, J. and McCullough, M. Version control with Git. O\u2019Reilly.\nHodson, R. Ry\u2019s Git Tutorial. Smashwords (2014)\n</code></pre> <ul> <li>A\u00f1adir los cambios a la zona de intercambio temporal y hacer un commit con el mensaje \u201cResuelto conflicto de bibliograf\u00eda.\u201d</li> <li>Mostrar la historia del repositorio incluyendo todas las ramas.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicios-de-repositorios-remotos","title":"Ejercicios de repositorios remotos","text":""},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-1_4","title":"Ejercicio 1","text":"<ul> <li>Crear un nuevo repositorio p\u00fablico en GitHub con el nombre <code>**libro-git**</code>.</li> <li>A\u00f1adirlo al repositorio local del libro.</li> <li>Mostrar todos los repositorios remotos configurados.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-2_4","title":"Ejercicio 2","text":"<ul> <li>A\u00f1adir los cambios del repositorio local al repositorio remoto de GitHub.</li> <li>Acceder a GitHub y comprobar que se han subido los cambios mostrando el historial de versiones.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-3_4","title":"Ejercicio 3","text":"<ul> <li>Colaborar en el repositorio remoto <code>libro-git</code> de otro usuario.</li> <li>Clonar su repositorio <code>libro-git</code>.</li> <li>A\u00f1adir el fichero <code>autores.txt</code> que contenga el nombre del usuario y su correo electr\u00f3nico.</li> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit con el mensaje \u201cA\u00f1adido autor.\u201d</li> <li>Subir los cambios al repositorio remoto.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#ejercicio-4_4","title":"Ejercicio 4","text":"<ul> <li>Hacer una bifurcaci\u00f3n del repositorio remoto <code>asalber/libro-git</code> en GitHub.</li> <li>Clonar el repositorio creado en la cuenta de GitHub del usuario.</li> <li>Crear una nueva rama autoria y activarla.</li> <li>A\u00f1adir el nombre del usuario y su correo al fichero <code>autores.txt</code>.</li> <li>A\u00f1adir los cambios a la zona de intercambio temporal.</li> <li>Hacer un commit con el mensaje \u201cA\u00f1adido nuevo autor.\u201d</li> <li>Subir los cambios de la rama autoria al repositorio remoto en GitHub.</li> <li>Hacer un Pull Request de los cambios en la rama autoria.                 </li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P4/#evaluacion","title":"Evaluaci\u00f3n","text":"Criterio Puntuaci\u00f3n Ejercicios de creaci\u00f3n y actualizaci\u00f3n de repositorios 2 puntos Ejercicios de manejo del historial de cambios 2 puntos Ejercicios de deshacer cambios 2 puntos Ejercicios de gesti\u00f3n de ramas 2 puntos Ejercicios de repositorios remotos 2 puntos"},{"location":"Ud1%20Control%20de%20versiones/P5/","title":"Pr\u00e1ctica 1.5 Git avanzado - Aprendiendo branching","text":""},{"location":"Ud1%20Control%20de%20versiones/P5/#practica-opcional","title":"Pr\u00e1ctica opcional","text":"<p>Intenta resolver el m\u00e1ximo de niveles posible de esta p\u00e1gina interactiva dedicada a aprender branching: https://learngitbranching.js.org/?locale=es_ES</p>"},{"location":"Ud1%20Control%20de%20versiones/P6/","title":"P1.6 Introducci\u00f3n a Markdown","text":"<p>Markdown es un lenguaje de marcado ligero que se utiliza para dar formato y estructura a documentos de texto de una manera sencilla y legible. Fue creado por John Gruber y Aaron Swartz en 2004 y se ha vuelto ampliamente popular entre escritores, desarrolladores y en la documentaci\u00f3n de proyectos de software debido a su simplicidad y facilidad de uso.</p> <p>En Markdown, puedes agregar formato b\u00e1sico, como encabezados, listas, enlaces, \u00e9nfasis (cursiva y negrita), im\u00e1genes y m\u00e1s, utilizando una sintaxis simple y legible. Aqu\u00ed hay algunos ejemplos de Markdown:</p> <ul> <li> <p>Encabezados:   <pre><code># T\u00edtulo principal\n## Subt\u00edtulo\n</code></pre></p> </li> <li> <p>Listas:   <pre><code>- Elemento de lista 1\n- Elemento de lista 2\n</code></pre></p> </li> <li> <p>\u00c9nfasis:   <pre><code>*Texto en cursiva* o **Texto en negrita**\n</code></pre></p> </li> <li> <p>Enlaces:   <pre><code>[Texto del enlace](URL)\n</code></pre></p> </li> </ul> <p>Markdown es especialmente \u00fatil para crear documentaci\u00f3n, escribir publicaciones de blog, crear README.md en repositorios de Git, y mucho m\u00e1s, ya que permite que el contenido se vea bien formateado tanto en formato de texto plano como en HTML. Muchas plataformas y editores de texto admiten Markdown, lo que facilita su adopci\u00f3n y uso en diversas aplicaciones.</p>"},{"location":"Ud1%20Control%20de%20versiones/P6/#que-vas-a-aprender-en-este-taller","title":"\u00bfQu\u00e9 vas a aprender en este taller?","text":"<ul> <li>Aprender la sintaxis b\u00e1sica del lenguaje de marcas Markdown para estructurar la informaci\u00f3n en nuestros documentos.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P6/#recursos-para-realizar-este-taller","title":"Recursos para realizar este taller","text":"<ul> <li>Puedes usar cualquier manual b\u00e1sico de Markdown, por ejemplo Markdown cheat sheet.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/P6/#que-tienes-que-hacer","title":"\u00bfQu\u00e9 tienes que hacer?","text":"<ol> <li>Crea un repositorio nuevo en GitHub y cl\u00f3nalo en local.</li> <li> <p>A los archivos en markdown les solemos poner extensi\u00f3n md. Crea un fichero llamado <code>miprimermd.md</code>. Este fichero tiene que tener los siguientes elementos en este orden:</p> <ul> <li>Un t\u00edtulo principal</li> <li>Un subt\u00edtulo</li> <li>Un p\u00e1rrafo, con palabras en negrita, en cursiva, en c\u00f3digo (por ejemplo esto est\u00e1 escrito en <code>c\u00f3digo</code>).</li> <li>Un trozo de c\u00f3digo.</li> <li>Una lista ordenada</li> <li>Una lista desordenada.</li> <li>Un enlace a una URL externa.</li> <li>Un enlace a otro fichero Markdown que tengas en el repositorio.</li> <li>Una imagen</li> <li>Una tabla</li> </ul> </li> <li> <p>Sube el fichero al repositorio remoto y visualizalo all\u00ed.</p> </li> </ol>"},{"location":"Ud1%20Control%20de%20versiones/T01_index_git/","title":"Control de versiones","text":""},{"location":"Ud1%20Control%20de%20versiones/T01_index_git/#contenido","title":"Contenido","text":"<ol> <li>Introducci\u00f3n</li> <li>Sistemas de control de versiones</li> <li>Introducci\u00f3n a Git</li> <li>Instalaci\u00f3n y configuraci\u00f3n de Git</li> <li>Uso b\u00e1sico de Git</li> <li>Uso avanzado de Git</li> <li>Ramas</li> <li>Administraci\u00f3n de repositorios GitHub</li> <li>Flujo de trabajo con GitHub</li> <li>Colaboraci\u00f3n con GitHub</li> <li>Flujo de trabajo con Git (git flow)</li> <li>Citar proyectos en GitHub</li> <li>Otros comandos git</li> <li>Terminolog\u00eda y referencias</li> </ol>"},{"location":"Ud1%20Control%20de%20versiones/T01_index_git/#licencia","title":"Licencia","text":"<p>El material est\u00e1 publicado con licencia Atribuci\u00f3n-NoComercial 4.0 Internacional (CC BY-NC 4.0)</p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/","title":"Sistemas de control de versiones","text":""},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#definicion-clasificacion-y-funcionamiento","title":"Definici\u00f3n, clasificaci\u00f3n y funcionamiento","text":"<p>Se llama control de versiones a la gesti\u00f3n de los diversos cambios que se realizan sobre los elementos de alg\u00fan producto o una configuraci\u00f3n del mismo. Una versi\u00f3n, revisi\u00f3n o edici\u00f3n de un producto, es el estado en el que se encuentra dicho producto en un momento dado de su desarrollo o modificaci\u00f3n. Aunque un sistema de control de versiones puede realizarse de forma manual, es muy aconsejable disponer de herramientas que faciliten esta gesti\u00f3n dando lugar a los llamados sistemas de control de versiones o SVC (del ingl\u00e9s System Version Control).</p> <p>Estos sistemas facilitan la administraci\u00f3n de las distintas versiones de cada producto desarrollado, as\u00ed como las posibles especializaciones realizadas (por ejemplo, para alg\u00fan cliente espec\u00edfico). Ejemplos de este tipo de herramientas son entre otros: CVS, Apache Subversion, Ms Visual Studio Team Foundation Server, IBM ClearCase, Darcs, Canonical Bazaar, Plastic SCM, Git, Mercurial, Perforce.</p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#clasificacion","title":"Clasificaci\u00f3n","text":"<p>Podemos clasificar los sistemas de control de versiones atendiendo a la arquitectura utilizada para el almacenamiento del c\u00f3digo: locales, centralizados y distribuidos.</p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#locales","title":"Locales","text":"<p>Los cambios son guardados localmente y no se comparten con nadie. Esta arquitectura es la antecesora de las dos siguientes.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#centralizados","title":"Centralizados","text":"<p>Existe un repositorio centralizado de todo el c\u00f3digo, del cual es responsable un \u00fanico usuario (o conjunto de ellos). Se facilitan las tareas administrativas a cambio de reducir flexibilidad, pues todas las decisiones fuertes (como crear una nueva rama) necesitan la aprobaci\u00f3n del responsable. Algunos ejemplos son CVS y Subversion.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#distribuidos","title":"Distribuidos","text":"<p>Cada usuario tiene su propio repositorio. Los distintos repositorios pueden intercambiar y mezclar revisiones entre ellos. Es frecuente el uso de un repositorio, que est\u00e1 normalmente disponible, que sirve de punto de sincronizaci\u00f3n de los distintos repositorios locales. Ejemplos: Git y Mercurial.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T02_cvs/#ventajas-de-sistemas-distribuidos","title":"Ventajas de sistemas distribuidos","text":"<ul> <li>No es necesario estar conectado para guardar cambios.</li> <li>Posibilidad de continuar trabajando si el repositorio remoto no est\u00e1 accesible.</li> <li>El repositorio central est\u00e1 m\u00e1s libre de ramas de pruebas.</li> <li>Se necesitan menos recursos para el repositorio remoto.</li> <li>M\u00e1s flexibles al permitir gestionar cada repositorio personal como se quiera.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/","title":"Introducci\u00f3n a git","text":"<p>Git es un sistema de control de versiones distribuido que se diferencia del resto en el modo en que modela sus datos. La mayor\u00eda de los dem\u00e1s sistemas almacenan la informaci\u00f3n como una lista de cambios en los archivos, mientras que Git modela sus datos m\u00e1s como un conjunto de instant\u00e1neas de un mini sistema de archivos.</p> <p></p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/#los-tres-estados","title":"Los tres estados","text":"<p>Git tiene tres estados principales en los que se pueden encontrar tus archivos: confirmado (committed), modificado (modified), y preparado (staged). </p> <ul> <li>Modificado modified significa que has modificado el archivo pero todav\u00eda no lo has preparado ni confirmado a tu repositorio local.</li> <li>Preparado staged significa que has marcado un archivo modificado en su versi\u00f3n actual para que vaya en tu pr\u00f3xima confirmaci\u00f3n.</li> <li>Confirmado committed significa que los datos est\u00e1n almacenados de manera segura en tu repositorio local. </li> </ul> <p>Esto nos lleva a las tres secciones principales de un proyecto de Git: el directorio de Git (Git directory), el directorio de trabajo (working directory), y el \u00e1rea de preparaci\u00f3n (staging area).</p> <p></p> <p>Esto es solo una introducci\u00f3n. Lo veremos en detalle m\u00e1s adelante.</p>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/#flujos-de-trabajo-distribuidos-con-git","title":"Flujos de trabajo distribuidos con git","text":"<p>Hemos visto en qu\u00e9 consiste un entorno de control de versiones distribuido, pero m\u00e1s all\u00e1 de la simple definici\u00f3n, existe m\u00e1s de una manera de gestionar los repositorios. Estos son los flujos de trabajo m\u00e1s comunes en Git.</p>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/#flujo-de-trabajo-centralizado","title":"Flujo de trabajo centralizado","text":"<p>Existe un \u00fanico repositorio o punto central que guarda el c\u00f3digo y todo el mundo sincroniza su trabajo con \u00e9l. Si dos desarrolladores clonan desde el punto central, y ambos hacen cambios, tan solo el primero de ellos en enviar sus cambios de vuelta lo podr\u00e1 hacer limpiamente. El segundo desarrollador deber\u00e1 fusionar previamente su trabajo con el del primero, antes de enviarlo, para evitar el sobreescribir los cambios del primero</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/#flujo-de-trabajo-del-gestor-de-integraciones","title":"Flujo de trabajo del Gestor-de-Integraciones","text":"<p>Al permitir m\u00faltiples repositorios remotos, en Git es posible tener un flujo de trabajo donde cada desarrollador tenga acceso de escritura a su propio repositorio p\u00fablico y acceso de lectura a los repositorios de todos los dem\u00e1s. Habitualmente, este escenario suele incluir un repositorio can\u00f3nico, representante \"oficial\" del proyecto.</p> <p></p> <p>Info</p> <p>Este modelo se puso muy de moda a ra\u00edz de la forja GitHub que se ver\u00e1 m\u00e1s adelante.</p>"},{"location":"Ud1%20Control%20de%20versiones/T03_introduccion/#flujo-de-trabajo-con-dictador-y-tenientes","title":"Flujo de trabajo con Dictador y Tenientes","text":"<p>Es una variante del flujo de trabajo con m\u00faltiples repositorios. Se utiliza generalmente en proyectos muy grandes, con cientos de colaboradores. Un ejemplo muy conocido es el del kernel de Linux. Unos gestores de integraci\u00f3n se encargan de partes concretas del repositorio; y se denominan tenientes. Todos los tenientes rinden cuentas a un gestor de integraci\u00f3n; conocido como el dictador benevolente. El repositorio del dictador benevolente es el repositorio de referencia, del que recuperan (pull) todos los colaboradores.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/","title":"Instalaci\u00f3n y configuraci\u00f3n de Git","text":""},{"location":"Ud1%20Control%20de%20versiones/T04_git/#instalacion","title":"Instalaci\u00f3n","text":""},{"location":"Ud1%20Control%20de%20versiones/T04_git/#instalando-en-linux","title":"Instalando en Linux","text":"<p>Si quieres instalar Git en Linux a trav\u00e9s de un instalador binario, en general puedes hacerlo a trav\u00e9s de la herramienta b\u00e1sica de gesti\u00f3n de paquetes que trae tu distribuci\u00f3n. Si est\u00e1s en Fedora, puedes usar yum:</p> <pre><code>$ yum install git-core\n</code></pre> <p>O si est\u00e1s en una distribuci\u00f3n basada en Debian como Ubuntu, prueba con apt-get:</p> <pre><code>$ apt-get install git-all\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/#instalando-en-windows","title":"Instalando en Windows","text":"<p>Instalar Git en Windows es muy f\u00e1cil. El proyecto \"Gti for Windows\" (antes msysGit) tiene uno de los procesos de instalaci\u00f3n m\u00e1s sencillos. Simplemente descarga el archivo exe del instalador desde la p\u00e1gina de GitHub, y ejec\u00fatalo:</p> <p>https://gitforwindows.org/</p> <p>Una vez instalado, tendr\u00e1s tanto la versi\u00f3n de l\u00ednea de comandos (incluido un cliente SSH que nos ser\u00e1 \u00fatil m\u00e1s adelante) como la interfaz gr\u00e1fica de usuario est\u00e1ndar. Se recomienda no modificar las opciones que trae por defecto el instalador.</p>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/#instalando-en-macos","title":"Instalando en MacOS","text":"<p>En MacOS se recomienda tener instalada la herramienta homebrew. Despu\u00e9s, es tan f\u00e1cil como ejecutar:</p> <pre><code>$ brew install git\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/#recomendacion","title":"Recomendaci\u00f3n","text":"<p>En este curso estamos acostumbrados a usar m\u00e1quinas virtuales en AWS. Si vas a estar trabajando en casa y en el instituto, te recomiendo que crees una MV Debian con par\u00e1metros por defecto en AWS para ir siguiendo el curso. De esta forma tendr\u00e1s lo mismo en ambos lugares.</p> <p>Si optas por esa opci\u00f3n recuerda realizar lo primero un <code>sudo apt-get update &amp;&amp; upgrade</code> antes de instalar git para contar con la \u00faltima versi\u00f3n disponible.</p> <p>Informaci\u00f3n</p> <p>Puedes comprobar la versi\u00f3n de git que est\u00e1s usando con <code>git --version</code>. En el momento de escribir estas notas la versi\u00f3n es la 2.39.2</p>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/#configuracion","title":"Configuraci\u00f3n","text":""},{"location":"Ud1%20Control%20de%20versiones/T04_git/#tu-identidad","title":"Tu identidad","text":"<p>Lo primero que deber\u00edas hacer cuando instalas Git es establecer tu nombre de usuario y direcci\u00f3n de correo electr\u00f3nico. Esto es importante porque las confirmaciones de cambios (commits) en Git usan esta informaci\u00f3n, y es introducida de manera inmutable en los commits que env\u00edas:</p> <pre><code>$ git config --global user.name \"John Doe\"\n$ git config --global user.email johndoe@example.com\n</code></pre> <p>Tambi\u00e9n se recomienda configurar el siguiente par\u00e1metro:</p> <pre><code>$ git config --global push.default simple\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T04_git/#bash-completion","title":"Bash Completion","text":"<p>Si est\u00e1s trabajando en linux Bash completion es una utilidad que permite a bash completar \u00f3rdenes y par\u00e1metros. Por defecto suele venir desactivada en Ubuntu y es necesario modificar el archivo <code>$HOME/.bashrc</code> para poder activarla. Simplemente hay que descomentar las l\u00edneas que lo activan.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/","title":"Uso b\u00e1sico de Git","text":"<p>Vamos primero a recordar algunas cuestiones b\u00e1sicas de git.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#secciones-principales-de-un-repositorio-git","title":"Secciones principales de un repositorio <code>git</code>","text":"<p>En un repositorio <code>git</code> podemos diferenciar las siguientes secciones:</p> <ul> <li>Workspace</li> <li>Staging area (aparece en la imagen como Index)</li> <li>Local repository</li> <li>Remote repository</li> </ul> <p></p> <p>Figura 1: Imagen de Oliver Steele.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#estados-de-un-archivo-en-git","title":"Estados de un archivo en <code>git</code>","text":"<p>Un archivo puede estar en alguno de los siguientes estados:</p> <ul> <li>Sin seguimiento (untracked)</li> <li>Modificado (modified)</li> <li>Preparado (staged)</li> <li>Confirmado (commited)</li> </ul> <p>El siguiente diagrama muestra en qu\u00e9 secci\u00f3n se puede encontrar cada archivo en funci\u00f3n de su estado.</p> <pre><code>+-------------+  +-------------+  +-------------+  +-------------+\n|  Working    |  |   Staging   |  |    Local    |  |    Remote   |\n|  Directory  |  |     Area    |  |  Repository |  |  Repository |\n+------+------+  +------+------+  +------+------+  +------+------+\n       |                |                |                |\n   Untracked            |                |                |\n       |                |                |                |\n   Modified          Staged          Commited             |\n       |                |                |                |\n       +                +                +                +\n</code></pre> <p>Para consultar el estado de los archivos usamos el comando:</p> <pre><code>git status\n</code></pre> <p>Este comando es muy usado ya que es fundamental conocer el estado de los archivos de nuestro repositorio.</p> <p>Utilizando distintos comandos podemos pasar los archivos de una secci\u00f3n a otra y cambiar su estado. A continuaci\u00f3n veremos los comandos b\u00e1sicos que nos permitir\u00e1n una utilizaci\u00f3n b\u00e1sica de git usando como repositorio remoto GitHub.</p> <p>Para ir recordando los distintos comandos que vayamos aprendiendo es muy recomendable utilizar un \"cheatsheet\" o ir creando el nuestro propio. Aqu\u00ed ten\u00e9is uno que pod\u00e9is utilizar. Pod\u00e9is ir marcando con un subrayador los comandos que vais aprendiendo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#crear-un-proyecto","title":"Crear un proyecto","text":""},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#crear-un-programa-hola-mundo","title":"Crear un programa \"Hola Mundo\"","text":"<p>Creamos un directorio donde colocar el c\u00f3digo</p> <pre><code>$ mkdir curso-de-git\n$ cd curso-de-git\n</code></pre> <p>Creamos un fichero <code>hola.php</code> que muestre Hola Mundo.</p> <pre><code>&lt;?php\necho \"Hola Mundo\\n\";\n?&gt;\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#crear-el-repositorio","title":"Crear el repositorio","text":"<p>Para crear un nuevo repositorio se usa la orden <code>git init</code></p> <pre><code>$ git init\nInitialized empty Git repository in /home/admin/curso-de-git/.git/\n</code></pre> <p>Comprueba con un <code>ls -la</code> que hay un nuevo directorio oculto .git donde git guardar\u00e1 toda la informaci\u00f3n que necesite de forma transparente al usuario.</p> <p>Al inicializar nuestro proyecto, el archivo <code>hola.php</code> estar\u00e1 en el Workspace o Working Directory.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                | \n   hola.php             |                | \n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#anadir-la-aplicacion","title":"A\u00f1adir la aplicaci\u00f3n","text":"<p>Vamos a almacenar el archivo que hemos creado en el repositorio para poder trabajar, despu\u00e9s explicaremos para qu\u00e9 sirve cada orden.</p> <pre><code>$ git add hola.php\n</code></pre> <p>Al ejecutar el git add, el archivo pasar\u00e1 a la \"Staging area\" o \u00e1rea de preparaci\u00f3n. Podemos ejecutar el siguiente comando tras cada orden para ir comprobando el estado del proyecto:</p> <pre><code>    $ git status\n</code></pre> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                | \n       |             hola.php            |\n       |                |                | \n       +                +                +\n</code></pre> <pre><code>$ git commit -m \"Creaci\u00f3n del proyecto\"\n[master (root-commit) e19f2c1] Creaci\u00f3n del proyecto\n 1 file changed, 3 insertions(+)\n create mode 100644 hola.php\n</code></pre> <p>El archivo pasar\u00e1 al \"Local Ropository\" y se le asignar\u00e1 un hash o c\u00f3digo de inserci\u00f3n.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Workspace  |  |   Staging   |  |    Local    | \n|             |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                | \n       |                |             hola.php (e19f2c1)\n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#comprobar-el-estado-del-repositorio","title":"Comprobar el estado del repositorio","text":"<p>Con la orden <code>git status</code> podemos ver en qu\u00e9 estado se encuentran los archivos de nuestro repositorio.</p> <pre><code>$ git status\nOn branch master\nnothing to commit (working tree clean)\n</code></pre> <p>Si modificamos el archivo <code>hola.php</code>:</p> <pre><code>&lt;?php\n@print \"Hola {$argv[1]}\\n\";\n?&gt;\n</code></pre> <p>Y volvemos a comprobar el estado del repositorio:</p> <pre><code>    $ git status\n    On branch master\n    Changes not staged for commit:\n      (use \"git add &lt;file&gt;...\" to update what will be committed)\n      (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n       modified:   hola.php\n\n    no changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> <p>Nos indica que <code>hola.php</code> vuelve a estar en el working directory, porque lo hemos modificado. Y nos dice que podemos usar <code>git add hola.php</code> para volverlo a pasar a la \"Staging Area\" o bien <code>git restore hola.php</code> para descartar los cambios en el Working Directory y recuperar la version anterior en \"Local Repository\". En nuestro esquema veremos m\u00e1s arriba las versiones m\u00e1s recientes y m\u00e1s abajo las m\u00e1s antiguas, que es como nos lo mostrar\u00e1n los comandos git para ver hist\u00f3ricos. Es como una pila en la que la nueva versi\u00f3n queda sobre las anteriores.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n   hola.php             |                | \n       |                |             hola.php (e19f2c1)       \n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#anadir-cambios","title":"A\u00f1adir cambios","text":"<p>Con la orden <code>git add</code> indicamos a git que prepare los cambios para que sean almacenados.</p> <pre><code>    $ git add hola.php\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n      modified:   hola.php\n</code></pre> <p>Hemos vuelto a pasar <code>hola.php</code> a la \"Staging area\"</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |             hola.php            |\n       |                |             hola.php (e19f2c1)         \n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#confirmar-los-cambios","title":"Confirmar los cambios","text":"<p>Con la orden <code>git commit</code> confirmamos los cambios definitivamente, lo que hace que se guarden permanentemente en nuestro repositorio.</p> <pre><code>    $ git commit -m \"Parametrizaci\u00f3n del programa\"\n    [master efc252e] Parametrizaci\u00f3n del programa\n     1 file changed, 1 insertion(+), 1 deletion(-)\n    $ git status\n    On branch master\n    nothing to commit, working tree clean\n</code></pre> <p>El archivo pasar\u00e1 al \"Local Ropository\" con un nuevo hash.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1)          \n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#diferencias-entre-workdir-y-staging","title":"Diferencias entre workdir y staging.","text":"<p>Modificamos nuestra aplicaci\u00f3n para que soporte un par\u00e1metro por defecto y a\u00f1adimos los cambios.</p> <pre><code>&lt;?php\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Al modificarlo volvemos a tenerlo en \"Working Directory\"</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+  \n       |                |                |\n     hola.php           |                |  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1)          \n       |                |                | \n       +                +                +\n</code></pre> <p>Este vez a\u00f1adimos los cambios a la fase de staging pero sin confirmarlos (commit).</p> <pre><code>git add hola.php\n</code></pre> <p>Al hacer el add volvemos a tenerlo en \"Staging Area\"</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+  \n       |                |                |\n       |             hola.php            |\n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>Volvemos a modificar el programa para indicar con un comentario lo que hemos hecho.</p> <pre><code>&lt;?php\n// El nombre por defecto es Mundo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y vemos el estado en el que est\u00e1 el repositorio</p> <pre><code>    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n      modified:   hola.php\n\n    Changes not staged for commit:\n      (use \"git add &lt;file&gt;...\" to update what will be committed)\n      (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n      modified:   hola.php\n</code></pre> <p>Podemos ver como aparecen el archivo <code>hola.php</code> dos veces. El primero est\u00e1 preparado para ser confirmado y est\u00e1 almacenado en la \"Staging Area\" y es el que hicimos el add en primer lugar. El segundo indica que el archivo <code>hola.php</code> est\u00e1 modificado otra vez en la zona de trabajo \"Working Directory\". Como vemos en el gr\u00e1fico, el mismo archivo est\u00e1 en 2 zonas distintas en este momento, adem\u00e1s de las 2 versiones anteriores que hicimos commit.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |    \n     hola.php        hola.php            |\n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1)\n       |                |                | \n       +                +                +\n</code></pre> <p>Warning</p> <p>Si volvieramos a hacer un <code>git add hola.php</code> sobreescribir\u00edamos los cambios previos que hab\u00eda en la zona de staging.</p> <p>Almacenamos los cambios por separado:</p> <pre><code>    $ git commit -m \"Se a\u00f1ade un par\u00e1metro por defecto\"\n    [master 3283e0d] Se a\u00f1ade un par\u00e1metro por defecto\n     1 file changed, 2 insertions(+), 1 deletion(-)\n\n    $ git status\n    On branch master\n    Changes not staged for commit:\n      (use \"git add &lt;file&gt;...\" to update what will be committed)\n      (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n       modified:   hola.php\n\n    no changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> <p>Con el commit hemos pasado el hola.php que estaba en Staging Area al Local Repository quedando en el \"Working Directory\" el \u00faltimo que hab\u00edamos editado.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |           \n     hola.php           |                |\n       |                |             hola.php (3283e0d) \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1)\n       |                |                | \n       +                +                +\n</code></pre> <p>Si ahora hacemos un git add:</p> <pre><code>    $ git add .\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n      modified:   hola.php\n</code></pre> <p>El archivo en Working Directory pasa a Staging Area.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |             hola.php            |\n       |                |             hola.php (3283e0d) \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1)               \n       |                |                | \n       +                +                +\n</code></pre> <p>Y si ahora hacemos un commit.</p> <pre><code>    $ git commit -m \"Se a\u00f1ade un comentario al cambio del valor por defecto\"\n    [master fd4da94] Se a\u00f1ade un comentario al cambio del valor por defecto\n     1 file changed, 1 insertion(+)\n</code></pre> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |             \n       |                |             hola.php (fd4da94) \n       |                |             hola.php (3283e0d) \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>Info</p> <p>El valor \".\" despues de <code>git add</code> indica que se a\u00f1adan todos los archivos de forma recursiva.</p> <p>Warning</p> <p>Cuidado cuando uses <code>git add .</code> aseg\u00farate de que no est\u00e1s a\u00f1adiendo archivos que no quieres a\u00f1adir.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#ignorando-archivos","title":"Ignorando archivos","text":"<p>La orden <code>git add .</code> o <code>git add nombre_directorio</code> es muy c\u00f3moda, ya que nos permite a\u00f1adir todos los archivos del proyecto o todos los contenidos en un directorio y sus subdirectorios. Es mucho m\u00e1s r\u00e1pido que tener que ir a\u00f1adi\u00e9ndolos uno por uno. El problema es que, si no se tiene cuidado, se puede terminar por a\u00f1adir archivos innecesarios o con informaci\u00f3n sensible.</p> <p>Por lo general se debe evitar a\u00f1adir archivos que se hayan generado como producto de la compilaci\u00f3n del proyecto, los que generen los entornos de desarrollo (archivos de configuraci\u00f3n y temporales) y aquellos que contentan informaci\u00f3n sensible, como contrase\u00f1as o tokens de autenticaci\u00f3n. Por ejemplo, en un proyecto de <code>C/C++</code>, los archivos objeto no deben incluirse, solo los que contengan c\u00f3digo fuente y los make que los generen.</p> <p>Para indicarle a git que debe ignorar un archivo, se puede crear un fichero llamado .gitignore, bien en la ra\u00edz del proyecto o en los subdirectorios que queramos. Dicho fichero puede contener patrones, uno en cada l\u00ednea, que especiquen qu\u00e9 archivos deben ignorarse. El formato es el siguiente:</p> <pre><code># .gitignore\ndir1/           # ignora todo lo que contenga el directorio dir1\n!dir1/info.txt  # El operador ! excluye del ignore a dir1/info.txt (s\u00ed se guardar\u00eda)\ndir2/*.txt      # ignora todos los archivos txt que hay en el directorio dir2\ndir3/**/*.txt   # ignora todos los archivos txt que hay en el dir3 y sus subdirectorios\n*.o             # ignora todos los archivos con extensi\u00f3n .o en todos los directorios\n</code></pre> <p>Cada tipo de proyecto genera sus ficheros temporales, as\u00ed que para cada proyecto hay un <code>.gitignore</code> apropiado. Existen repositorios que ya tienen creadas plantillas. Pod\u00e9is encontrar uno en https://github.com/github/gitignore</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#ignorando-archivos-globalmente","title":"Ignorando archivos globalmente","text":"<p>Si bien, los archivos que hemos metido en <code>.gitignore</code>, deben ser aquellos ficheros temporales o de configuraci\u00f3n que se pueden crear durante las fases de compilaci\u00f3n o ejecuci\u00f3n del programa, en ocasiones habr\u00e1 otros ficheros que tampoco debemos introducir en el repositorio y que son recurrentes en todos los proyectos. En dicho caso, es m\u00e1s \u00fatil tener un gitignore que sea global a todos nuestros proyectos. Esta configuraci\u00f3n ser\u00eda complementaria a la que ya tenemos. Ejemplos de lo que se puede ignorar de forma global son los ficheros temporales del sistema operativo (<code>*~</code>, <code>.nfs*</code>) y los que generan los entornos de desarrollo.</p> <p>Para indicar a git que queremos tener un fichero de gitignore global, tenemos que configurarlo con la siguiente orden:</p> <pre><code>git config --global core.excludesfile $HOME/.gitignore_global\n</code></pre> <p>Ahora podemos crear un archivo llamado <code>.gitignore_global</code> en la ra\u00edz de nuestra cuenta con este contenido:</p> <pre><code># Compiled source #\n###################\n*.com\n*.class\n*.dll\n*.exe\n*.o\n*.so\n\n# Packages #\n############\n# it's better to unpack these files and commit the raw source\n# git has its own built in compression methods\n*.7z\n*.dmg\n*.gz\n*.iso\n*.jar\n*.rar\n*.tar\n*.zip\n\n# Logs and databases #\n######################\n*.log\n*.sql\n*.sqlite\n\n# OS generated files #\n######################\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n*~\n*.swp\n\n# IDEs               #\n######################\n.idea\n.settings/\n.classpath\n.project\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#trabajando-con-el-historial","title":"Trabajando con el historial","text":""},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#observando-los-cambios","title":"Observando los cambios","text":"<p>Con la orden <code>git log</code> podemos ver todos los cambios que hemos hecho. Antes de nada vuelve al directorio <code>curso-de-git</code> en el que est\u00e1bamos trabajando:</p> <pre><code>    $ git log\n    commit fd4da946326fbe8b24e89282ad25a71721bf40f6  (HEAD -&gt; master)\n    Author: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n    Date:   Sun Jun 16 12:51:01 2013 +0200\n\n        Se a\u00f1ade un comentario al cambio del valor por defecto\n\n    commit 3283e0d306c8d42d55ffcb64e456f10510df8177\n    Author: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n    Date:   Sun Jun 16 12:50:00 2013 +0200\n\n        Se a\u00f1ade un par\u00e1metro por defecto\n\n    commit efc252e11939351505a426a6e1aa5bb7dc1dd7c0\n    Author: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n    Date:   Sun Jun 16 12:13:26 2013 +0200\n\n        Parametrizaci\u00f3n del programa\n\n    commit e19f2c1701069d9d1159e9ee21acaa1bbc47d264\n    Author: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n    Date:   Sun Jun 16 11:55:23 2013 +0200\n\n        Creaci\u00f3n del proyecto\n</code></pre> <p>Para salir escribe <code>q</code>.</p> <p>Recuerda los distintos hash que se hab\u00edan generado cada vez que hac\u00edamos un commit. F\u00edjate que antes vimos solo los primeros caracteres hexadecimales del hash.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |                |             hola.php (fd4da94) \n       |                |             hola.php (3283e0d) \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>Tambi\u00e9n es posible ver versiones abreviadas o limitadas, dependiendo de los par\u00e1metros:</p> <pre><code>    $ git log --oneline\n    fd4da94 (HEAD -&gt; master) Se a\u00f1ade un comentario al cambio del valor por defecto\n    3283e0d Se a\u00f1ade un par\u00e1metro por defecto\n    efc252e Parametrizaci\u00f3n del programa\n    e19f2c1 Creaci\u00f3n del proyecto\n</code></pre> <p>Prueba estas otras opciones y comprobar\u00e1s lo que hace cada una.</p> <pre><code>    git log --oneline --max-count=2\n    git log --oneline --since='5 minutes ago'\n    git log --oneline --until='5 minutes ago'\n    git log --oneline --author=sergio   # Cambia sergio por tu nombre de usuario\n    git log --oneline --all\n</code></pre> <p>Una versi\u00f3n muy \u00fatil de <code>git log</code> es la siguiente, pues nos permite ver en que lugares est\u00e1 master y HEAD, entre otras cosas:</p> <pre><code>    $ git log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short\n    * fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (HEAD, master) [Sergio G\u00f3mez]\n    * 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto [Sergio G\u00f3mez]\n    * efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n    * e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#crear-alias","title":"Crear alias","text":"<p>Como estas \u00f3rdenes son demasiado largas, Git nos permite crear alias para crear nuevas \u00f3rdenes parametrizadas. Para ello podemos configurar nuestro entorno con la orden <code>git config</code> de la siguiente manera:</p> <pre><code>git config --global alias.hist \"log --pretty=format:'%h %ad | %s%d [%an]' --graph --date=short\"\n</code></pre> <p>Ahora basta con ejecutar:</p> <pre><code>git hist\n</code></pre> <p>Example</p> <p>Puedes configurar incluso alias para abreviar comandos. Algunos ejemplos de alias \u00fatiles:</p> <pre><code>git config --global alias.br branch\ngit config --global alias.co checkout\ngit config --global alias.ci commit\ngit config --global alias.st \"status -u\"\ngit config --global alias.cane \"commit --amend --no-edit\"\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#recuperando-versiones-anteriores","title":"Recuperando versiones anteriores","text":"<p>Cada cambio es etiquetado por un hash, para poder regresar a ese momento del estado del proyecto se usa la orden <code>git checkout</code>. Prueba con el hash de tu primer commit.</p> <pre><code>    $ git checkout e19f2c1\n    Note: switching to 'e19f2c1'.\n\n    You are in 'detached HEAD' state. You can look around, make experimental\n    changes and commit them, and you can discard any commits you make in this\n    state without impacting any branches by switching back to a branch.\n\n    If you want to create a new branch to retain commits you create, you may\n    do so (now or later) by using -c with the switch command. Example:\n\n    git switch -c &lt;new-branch-name&gt;\n\n    Or undo this operation with:\n\n    git switch -\n\n    urn off this advice by setting config variable advice.detachedHead to false\n\n    HEAD is now at e19f2c1 Parametrizaci\u00f3n del programa     \n</code></pre> <p>Hemos vuelto a aqu\u00ed:</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |                |             hola.php (e19f2c1)          \n       |                |                | \n       +                +                +\n</code></pre> <p>El aviso que nos sale nos indica que estamos en un estado donde no trabajamos en ninguna rama concreta. Eso significa que los cambios que hagamos podr\u00edan \"perderse\" porque si no son guardados en una nueva rama, en principio no podr\u00edamos volver a recuperarlos. Hay que pensar que Git es como un \u00e1rbol donde un nodo tiene informaci\u00f3n de su nodo padre, no de sus nodos hijos, con lo que siempre necesitar\u00edamos informaci\u00f3n de d\u00f3nde se encuentran los nodos finales o de otra manera no podr\u00edamos acceder a ellos. Vamos a comprobarlo.</p> <p>Edita <code>hola.php</code> y a\u00f1ade un comentario. Haz un commit y comentalo como \"Prueba en detached HEAD\". Despu\u00e9s haz un log para comprobar la rama.</p> <p>Antes de continuar desharemos con </p> <pre><code>$ git switch -\n</code></pre> <p>Comprueba que todos los cambios que hiciste en el \"detached HEAD\" se han perdido.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#volver-a-la-ultima-version-de-la-rama-master","title":"Volver a la \u00faltima versi\u00f3n de la rama master.","text":"<p>Ya hemos tratado el concepto de HEAD, pero no lo hemos definido formalmente. HEAD hace referencia al puntero que se\u00f1ala a la referencia actual de la rama activa o commit en el que est\u00e1s trabajando. En otras palabras, es un indicador que te dice en qu\u00e9 commit est\u00e1s situado en ese momento.</p> <p>Vamos a ver otra forma de llevar nuevamente el HEAD a nuestro primer commit, como hicimos en el punto anterior. \u00bfRecuerdas c\u00f3mo lo hicimos?</p> <p>A continuaci\u00f3n usamos <code>git checkout</code> indicando el nombre de la rama:</p> <pre><code>$ git checkout master\nPrevious HEAD position was e19f2c1... Creaci\u00f3n del proyecto\n</code></pre> <p>Comprueba en qu\u00e9 posici\u00f3n est\u00e1s con alguno de los comandos que aprendiste anteriormente.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#etiquetando-versiones","title":"Etiquetando versiones","text":"<p>Para poder recuperar versiones concretas en la historia del repositorio, podemos etiquetarlas, lo cual es m\u00e1s facil que usar un hash. Para eso usaremos la orden <code>git tag</code>.</p> <pre><code>$ git tag v1\n</code></pre> <p>Ahora vamos a etiquetar la versi\u00f3n inmediatamente anterior como v1-beta. Para ello podemos usar los modificadores <code>^</code> o <code>~</code> que nos llevar\u00e1n a un ancestro determinado. Las siguientes dos \u00f3rdenes son equivalentes:</p> <pre><code>$ git checkout v1^\n$ git checkout v1~1\n</code></pre> <p>Asignamos ahora el tag v1-beta a la versi\u00f3n anterior.</p> <pre><code>$ git tag v1-beta\n</code></pre> <p>Vuelve al estado final con </p> <pre><code>$ git switch -\n</code></pre> <p>Si ejecutamos la orden sin par\u00e1metros nos mostrar\u00e1 todas las etiquetas existentes.</p> <pre><code>$ git tag\nv1\nv1-beta\n</code></pre> <p>Y para verlas en el historial:</p> <pre><code>$ git hist master --all\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1, master) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (HEAD, tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>En nuestro esquema:</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |                |             hola.php (fd4da94) tag: v1 \n       |                |             hola.php (3283e0d) tag: v1-beta  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#borrar-etiquetas","title":"Borrar etiquetas","text":"<p>Para borrar etiquetas:</p> <pre><code>git tag -d nombre_etiqueta\n</code></pre> <p>De momento no borres las que hemos creado.</p>"},{"location":"Ud1%20Control%20de%20versiones/T05_usobasico/#visualizar-cambios","title":"Visualizar cambios","text":"<p>Para ver los cambios que se han realizado en el c\u00f3digo usamos la orden <code>git diff</code>. La orden sin especificar nada m\u00e1s, mostrar\u00e1 los cambios que no han sido a\u00f1adidos a\u00fan, es decir, todos los cambios que se han hecho antes de usar la orden <code>git add</code>. Despu\u00e9s se puede indicar un par\u00e1metro y dar\u00e1 los cambios entre la versi\u00f3n indicada y el estado actual. O para comparar dos versiones entre s\u00ed, se indica la m\u00e1s antigua y la m\u00e1s nueva. Ejemplo:</p> <pre><code>    $ git diff v1-beta v1\n    diff --git a/hola.php b/hola.php\n    index a31e01f..25a35c0 100644\n    --- a/hola.php\n    +++ b/hola.php\n    @@ -1,3 +1,4 @@\n     &lt;?php\n    +// El nombre por defecto es Mundo\n     $nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n     @print \"Hola, {$nombre}\\n\";\n     ?&gt;\n</code></pre> <p>La salida del comando git diff v1-beta v1 muestra las diferencias entre dos puntos en la historia del repositorio de Git, espec\u00edficamente entre las versiones \"v1-beta\" y \"v1\". Aqu\u00ed est\u00e1 el desglose de la salida:</p> <ul> <li> <p>diff --git a/hola.php b/hola.php: Esto indica que se est\u00e1 comparando el archivo hola.php entre las dos versiones. La letra \"a/\" indica la versi\u00f3n original (en este caso, la versi\u00f3n de \"v1-beta\"), y la letra \"b/\" indica la versi\u00f3n modificada (en este caso, la versi\u00f3n de \"v1\").</p> </li> <li> <p>index a31e01f..25a35c0 100644: Los valores del \u00edndice (hash) para las dos versiones que est\u00e1n siendo comparadas. En este caso, el commit original (v1-beta) tiene el hash a31e01f y el commit modificado (v1) tiene el hash 25a35c0. El n\u00famero 100644 es el modo de archivo.</p> </li> <li> <p>--- a/hola.php: Indica que el archivo original (hola.php en la versi\u00f3n de \"v1-beta\") tiene el contenido que sigue.</p> </li> <li> <p>+++ b/hola.php: Indica que el archivo modificado (hola.php en la versi\u00f3n de \"v1\") tiene el contenido que sigue.</p> </li> <li> <p>@@ -1,3 +1,4 @@: Muestra la secci\u00f3n modificada del archivo. En este caso, indica que desde la l\u00ednea 1 hasta la l\u00ednea 3 en la versi\u00f3n original y desde la l\u00ednea 1 hasta la l\u00ednea 4 en la versi\u00f3n modificada hay diferencias.</p> </li> <li> <p>&lt;?php: Este es el contenido original de la l\u00ednea 1.</p> </li> <li> <p>+// El nombre por defecto es Mundo: Esta l\u00ednea fue agregada en la versi\u00f3n modificada.</p> </li> <li> <p>$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";: Esta l\u00ednea est\u00e1 presente tanto en la versi\u00f3n original como en la versi\u00f3n modificada, por lo que no hay cambios aqu\u00ed.</p> </li> <li> <p>@print \"Hola, {$nombre}\\n\";: Esta l\u00ednea est\u00e1 presente tanto en la versi\u00f3n original como en la versi\u00f3n modificada.</p> </li> </ul> <p>En resumen, la salida indica que se ha agregado un comentario en la l\u00ednea 2 de la versi\u00f3n \"v1\", y la diferencia en el contenido de la l\u00ednea 3 se debe a la adici\u00f3n del comentario en la versi\u00f3n \"v1\".</p> <p>No borres lo que hemos hecho hasta aqu\u00ed. Seguiremos con este ejemplo en el siguiente apartado.</p>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/","title":"Uso avanzado de Git","text":""},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#deshacer-cambios","title":"Deshacer cambios","text":""},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#deshaciendo-cambios-antes-de-la-fase-de-staging","title":"Deshaciendo cambios antes de la fase de staging.","text":"<p>Volvemos a la rama m\u00e1ster y vamos a modificar el comentario que pusimos:</p> <pre><code>$ git checkout master\nPrevious HEAD position was 3283e0d... Se a\u00f1ade un par\u00e1metro por defecto\nSwitched to branch 'master'\n</code></pre> <p>Recordamos, la situaci\u00f3n es la siguiente:</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |                |             hola.php (fd4da94) tag: v1 \n       |                |             hola.php (3283e0d) tag: v1-beta  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>Modificamos hola.php de la siguiente manera:</p> <pre><code>&lt;?php\n// Este comentario est\u00e1 mal y hay que borrarlo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y comprobamos:</p> <pre><code>    $ git status\n    On branch master\n    Changes not staged for commit:\n      (use \"git add &lt;file&gt;...\" to update what will be committed)\n      (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n       modified:   hola.php\n\n    no changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> <p>Tenemos hola.php en Working Directory y nada en Staging Area.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n    hola.php            |                |\n       |                |             hola.php (fd4da94) tag: v1 \n       |                |             hola.php (3283e0d) tag: v1-beta  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>El mismo Git nos indica que debemos hacer para a\u00f1adir los cambios o para deshacerlos. En este caso los desharemos:</p> <pre><code>    $ git restore hola.php\n\n    $ git status\n    On branch master\n    nothing to commit, working tree clean\n\n    $ cat hola.php\n    &lt;?php\n    // El nombre por defecto es Mundo\n    $nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n    @print \"Hola, {$nombre}\\n\";\n    ?&gt;\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#deshaciendo-cambios-antes-del-commit","title":"Deshaciendo cambios antes del commit","text":"<p>Vamos a hacer lo mismo que la vez anterior, pero esta vez s\u00ed a\u00f1adiremos el cambio al staging (sin hacer commit). As\u00ed que volvemos a modificar hola.php igual que la anterior ocasi\u00f3n:</p> <pre><code>&lt;?php\n// Este comentario est\u00e1 mal y hay que borrarlo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y lo a\u00f1adimos al staging</p> <pre><code>    $ git add hola.php\n\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n       modified:   hola.php\n</code></pre> <p>Ahora tenemos una nueva versi\u00f3n de hola.php en Staging Area.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n       |             hola.php            |\n       |                |             hola.php (fd4da94) tag: v1 \n       |                |             hola.php (3283e0d) tag: v1-beta  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>De nuevo, Git nos indica qu\u00e9 debemos hacer para deshacer el cambio. Primero lo sacamos del Staging Area.</p> <pre><code>    $ git restore --staged hola.php\n\n    $ git status\n    On branch master\n    Changes not staged for commit:\n      (use \"git add &lt;file&gt;...\" to update what will be committed)\n      (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n       modified:   hola.php\n\n    no changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> <p>Vuelve a estar en Working Directory.</p> <pre><code>+-------------+  +-------------+  +-------------+  \n|  Working    |  |   Staging   |  |    Local    | \n|  Directory  |  |     Area    |  |  Repository | \n+------+------+  +------+------+  +------+------+ \n       |                |                |\n    hola.php            |                |\n       |                |             hola.php (fd4da94) tag: v1 \n       |                |             hola.php (3283e0d) tag: v1-beta  \n       |                |             hola.php (efc252e)\n       |                |             hola.php (e19f2c1) \n       |                |                | \n       +                +                +\n</code></pre> <p>Y ahora restaruramos la \u00faltima versi\u00f3n en Local Repository, eliminando la versi\u00f3n en Working Directory.</p> <pre><code>$ git restore hola.php\n</code></pre> <p>Y ya tenemos nuestro repositorio limpio otra vez. Como vemos hay que hacerlo en dos pasos: uno para pasar el fichero de Staging Area a Working Directory y limpiar as\u00ed la Staging Area; y otro para descartar los cambios en Working Directory.</p>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#deshaciendo-commits-no-deseados","title":"Deshaciendo commits no deseados.","text":"<p>Si a pesar de todo hemos hecho un commit y nos hemos equivocado, podemos deshacerlo con la orden <code>git revert</code>. Modificamos otra vez el archivo como antes:</p> <pre><code>&lt;?php\n// Este comentario est\u00e1 mal y hay que borrarlo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Pero ahora s\u00ed hacemos commit:</p> <pre><code>    $ git add hola.php\n\n    $ git commit -m \"Ups... este commit est\u00e1 mal.\"\n    master 5a5d067] Ups... este commit est\u00e1 mal\n     1 file changed, 1 insertion(+), 1 deletion(-)\n</code></pre> <p>Bien, una vez confirmado el cambio, vamos a deshacer el cambio con la orden <code>git revert</code>:</p> <pre><code>    $ git revert HEAD --no-edit\n    [master 817407b] Revert \"Ups... este commit est\u00e1 mal\"\n    1 file changed, 1 insertion(+), 1 deletion(-)\n</code></pre> <p>Explicaci\u00f3n del comando:</p> <ul> <li>git revert HEAD: Reviertes el \u00faltimo commit (el que apunta HEAD). Esto crea un nuevo commit que deshace los cambios realizados en ese commit.</li> <li>--no-edit: Este par\u00e1metro le indica a Git que use el mensaje de commit por defecto que genera autom\u00e1ticamente (algo como \"Revert 'mensaje original del commit'\") y no abra el editor para modificarlo.</li> </ul> <pre><code>    $ git hist\n    * 817407b 2013-06-16 | Revert \"Ups... este commit est\u00e1 mal\" (HEAD -&gt; master) [Sergio G\u00f3mez]\n    * 5a5d067 2013-06-16 | Ups... este commit est\u00e1 mal [Sergio G\u00f3mez]\n    * fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n    * 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n    * efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n    * e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#borrar-commits-de-una-rama","title":"Borrar commits de una rama","text":"<p>El anterior apartado revierte un commit, pero deja huella en el historial de cambios. Para hacer que no aparezca hay que usar la orden <code>git reset</code>.</p> <pre><code>    $ git reset --hard v1\n    HEAD is now at fd4da94 Se a\u00f1ade un comentario al cambio del valor por defecto\n\n    $ git hist\n    * fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (HEAD -&gt; master, tag: v1) [Sergio G\u00f3me\n    * 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n    * efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n    * e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>El resto de cambios no se han borrado (a\u00fan), simplemente no est\u00e1n accesibles porque git no sabe como referenciarlos. Si sabemos su hash podemos acceder a\u00fan a ellos. Pasado un tiempo, eventualmente Git tiene un recolector de basura que los borrar\u00e1. Se puede evitar etiquetando el estado final.</p> <p>Danger</p> <p>La orden reset es una operaci\u00f3n delicada. Debe evitarse si no se sabe bien lo que se est\u00e1 haciendo, sobre todo cuando se trabaja en repositorios compartidos, porque podr\u00edamos alterar la historia de cambios lo cual puede provocar problemas de sincronizaci\u00f3n.</p>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#modificar-un-commit","title":"Modificar un commit","text":"<p>Esto se usa cuando hemos olvidado a\u00f1adir un cambio a un commit que acabamos de realizar. Tenemos nuestro archivo hola.php de la siguiente manera:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez\n// El nombre por defecto es Mundo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y lo confirmamos:</p> <pre><code>$ git commit -a -m \"A\u00f1adido el autor del programa\"\n[master cf405c1] A\u00f1adido el autor del programa\n 1 file changed, 1 insertion(+)\n</code></pre> <p>Tip</p> <p>El par\u00e1metro <code>-a</code> hace un <code>git add</code> antes de hacer commit de todos los archivos modificados  o borrados (de los nuevos no), con lo que nos ahorramos un paso.</p> <p>Ahora nos percatamos que se nos ha olvidado poner el correo electr\u00f3nico. As\u00ed que volvemos a modificar nuestro archivo:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n// El nombre por defecto es Mundo\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y en esta ocasi\u00f3n usamos <code>commit --amend</code> que nos permite modificar el \u00faltimo estado confirmado, sustituy\u00e9ndolo por el estado actual:</p> <pre><code>    $ git add hola.php\n\n    $ git commit --amend -m \"A\u00f1adido el autor del programa y su email\"\n    [master 96a39df] A\u00f1adido el autor del programa y su email\n     1 file changed, 1 insertion(+)\n\n    $ git hist\n    * 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email (HEAD -&gt; master) [Sergio G\u00f3mez]\n    * fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n    * 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n    * efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n    * e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Danger</p> <p>Nunca modifiques un commit que ya hayas sincronizado con otro repositorio o que hayas recibido de \u00e9l. Estar\u00edas alterando la historia de cambios y provocar\u00edas problemas de sincronizaci\u00f3n.</p>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#moviendo-y-borrando-archivos","title":"Moviendo y borrando archivos","text":""},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#mover-un-archivo-a-otro-directorio-con-git","title":"Mover un archivo a otro directorio con git","text":"<p>Para mover archivos usaremos la orden <code>git mv</code>:</p> <pre><code>    $ mkdir lib\n\n    $ git mv hola.php lib\n\n    $ git status\n    On branch master\n    Changes to be committed:\n      (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n\n      renamed:    hola.php -&gt; lib/hola.php\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T06_usoavanzado/#mover-y-borrar-archivos","title":"Mover y borrar archivos.","text":"<p>Pod\u00edamos haber hecho el paso anterior con la \u00f3rden del sistema mv y el resultado hubiera sido el mismo. Lo siguiente es a modo de ejemplo y no es necesario que lo ejecutes:</p> <pre><code>    $ mkdir lib\n    $ mv hola.php lib\n    $ git add lib/hola.php\n    $ git rm hola.php\n</code></pre> <p>Y, ahora s\u00ed, ya podemos guardar los cambios:</p> <pre><code>    $ git commit -m \"Movido hola.php a lib.\"\n    [master 8c2a509] Movido hola.php a lib.\n     1 file changed, 0 insertions(+), 0 deletions(-)\n     rename hola.php =&gt; lib/hola.php (100%)\n</code></pre> <p>Info</p> <p>Hasta aqu\u00ed hemos aprendido los aspectos b\u00e1sicos de git trabajando en entorno local. Hemos instalado git, configurado sus par\u00e1metros globales, creado un proyecto y aprendido los 3 estados en los que puede estar un archivo. Tambi\u00e9n hemos aprendido los comandos para incorporar cambios a la zona \"staged\" y a \"working directory\". En las pr\u00f3ximas secciones aprenderemos a trabajar con ramas y a utilizar un repositorio compartido en GitHub</p>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/","title":"Ramas","text":""},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#administracion-de-ramas","title":"Administraci\u00f3n de ramas","text":""},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#crear-una-nueva-rama","title":"Crear una nueva rama","text":"<p>Cuando vamos a trabajar en una nueva funcionalidad, es conveniente hacerlo en una nueva rama, para no modificar la rama principal y dejarla inestable. Aunque la orden para manejar ramas es <code>git branch</code> podemos usar tambi\u00e9n <code>git checkout</code>.</p> <p>Vamos a crear una nueva rama:</p> <pre><code>git branch hola\n</code></pre> <p>Info</p> <p>Si usamos <code>git branch</code> sin ning\u00fan argumento, nos devolver\u00e1 la lista de ramas disponibles.</p> <p>La orden anterior no devuelve ning\u00fan resultado y tampoco nos cambia de rama, para eso debemos usar checkout:</p> <pre><code>$ git checkout hola\nSwitched to branch 'hola'\n</code></pre> <p>Tip</p> <p>Hay una forma m\u00e1s rapida de hacer ambas acciones en un solo paso. Con el par\u00e1metro <code>-b</code> de <code>git checkout</code> podemos cambiarnos a una rama que, si no existe, se crea instant\u00e1neamente.</p> <pre><code>$ git checkout -b hola\nSwitched to a new branch 'hola'\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#modificaciones-en-la-rama-secundaria","title":"Modificaciones en la rama secundaria","text":"<p>A\u00f1adimos un nuevo archivo en el directorio <code>lib</code> llamado <code>HolaMundo.php</code>:</p> <pre><code>&lt;?php\n\nclass HolaMundo\n{\n   private $nombre;\n\n   function __construct($nombre)\n   {\n      $this-&gt;nombre = $nombre;\n   }\n\n   function __toString()\n   {\n      return sprintf (\"Hola, %s.\\n\", $this-&gt;nombre);\n   }\n}\n?&gt;\n</code></pre> <p>Y modificamos <code>hola.php</code>:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n// El nombre por defecto es Mundo\nrequire('HolaMundo.php');\n\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\nprint new HolaMundo($nombre);\n?&gt;\n</code></pre> <p>Podr\u00edamos confirmar los cambios todos de golpe, pero lo haremos de uno en uno, con su comentario.</p> <pre><code>$ git add lib/HolaMundo.php\n\n$ git commit -m \"A\u00f1adida la clase HolaMundo\"\n[hola 6932156] A\u00f1adida la clase HolaMundo\n 1 file changed, 17 insertions(+)\n create mode 100644 lib/HolaMundo.php\n\n$ git add lib/hola.php\n\n$ git commit -m \"hola usa la clase HolaMundo\"\n[hola 9862f33] hola usa la clase HolaMundo\n 1 file changed, 3 insertions(+), 1 deletion(-)\n</code></pre> <p>Y ahora con la orden <code>git checkout</code> podemos movernos entre ramas:</p> <pre><code>$ git checkout master\nSwitched to branch 'master'\n\n$ git checkout hola\nSwitched to branch 'hola'\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#modificaciones-en-la-rama-master","title":"Modificaciones en la rama master","text":"<p>Podemos volver y a\u00f1adir un nuevo archivo a la rama principal:</p> <pre><code>$ git checkout master\nSwitched to branch 'master'\n</code></pre> <p>Creamos un archivo llamado <code>README.md</code> en la ra\u00edz de nuestro proyecto con el siguiente contenido:</p> <pre><code># Curso de GIT\n\nEste proyecto contiene el curso de introducci\u00f3n a GIT\n</code></pre> <p>Y lo a\u00f1adimos a nuestro repositorio en la rama en la que estamos:</p> <pre><code>$ git add README.md\n\n$ git commit -m \"A\u00f1adido README.md\"\n[master c3e65d0] A\u00f1adido README.md\n 1 file changed, 3 insertions(+)\n create mode 100644 README.md\n</code></pre> <p>Vamos a usar nuestro comando <code>git hist</code> con el modificador --all que nos mostrar\u00e1 los cambios en todas las ramas.</p> <pre><code>$ git hist --all\n* c3e65d0 2013-06-16 | A\u00f1adido README.md (HEAD -&gt; master) [Sergio G\u00f3mez]\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Y vemos como <code>git hist --all</code> muestra la bifurcaci\u00f3n en nuestro c\u00f3digo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#fusion-de-ramas-y-resolucion-de-conflictos","title":"Fusi\u00f3n de ramas y resoluci\u00f3n de conflictos","text":""},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#mezclar-ramas","title":"Mezclar ramas","text":"<p>Podemos incorporar los cambios de una rama a otra con la orden <code>git merge</code>. Primero nos posicionamos en la rama en la que queremos incorporar los cambios. En nuestro caso \"hola\".</p> <pre><code>$ git checkout hola\nSwitched to branch 'hola'\n</code></pre> <p>Y en esta rama ejecutamos el <code>git merge nombrerama</code> con el nombre de la rama cuyos cambios queremos incorporar a la actual.</p> <pre><code>$ git merge master\nMerge made by the 'ort' strategy.\n README.md | 3 +++\n 1 file changed, 3 insertions(+)\n create mode 100644 README.md\n\n$ git hist --all\n*   9c6ac06 2013-06-16 | Merge branch 'master' into hola (HEAD -&gt; hola) [Sergio G\u00f3mez]\n|\\\n| * c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* | 9862f33 2013-06-16 | hola usa la clase HolaMundo [Sergio G\u00f3mez]\n* | 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>De esa forma se puede trabajar en una rama secundaria incorporando los cambios de la rama principal o de otra rama.</p>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#resolver-conflictos","title":"Resolver conflictos","text":"<p>Un conflicto es cuando se produce una fusi\u00f3n que Git no es capaz de resolver. Vamos a modificar la rama master para crear uno con la rama hola.</p> <pre><code>$ git checkout master\nSwitched to branch 'master'\n</code></pre> <p>Modificamos nuestro archivo hola.php de nuevo:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\nprint \"Introduce tu nombre:\";\n$nombre = trim(fgets(STDIN));\n@print \"Hola, {$nombre}\\n\";\n?&gt;\n</code></pre> <p>Y guardamos los cambios:</p> <pre><code>$ git add lib/hola.php\n\n$ git commit -m \"Programa interactivo\"\n[master 9c85275] Programa interactivo\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\n$ git hist --all\n</code></pre> <p>Comprueba el resultado</p> <pre><code>$ git hist --all\n* 8ca56f7 2013-06-16 | Programa interactivo (HEAD -&gt; master) [Sergio G\u00f3mez]\n| *   9c6ac06 2013-06-16 | Merge branch 'master' into hola (hola) [Sergio G\u00f3mez]\n| |\\  \n| |/  \n|/| \n* | c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Volvemos a la rama hola y fusionamos. Recuerda que hemos modificado hola.php en la rama <code>master</code> y ahora hay l\u00edneas distintas dentro de ese fichero en cada una de las ramas.</p> <pre><code>$ git checkout hola\nSwitched to branch 'hola'\n\n$ git merge master\nAuto-merging lib/hola.php\nCONFLICT (content): Merge conflict in lib/hola.php\nAutomatic merge failed; fix conflicts and then commit the result.\n</code></pre> <p>Si editamos nuestro archivo <code>lib/hola.php</code> obtendremos algo similar a esto:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n// El nombre por defecto es Mundo\nrequire('HolaMundo.php');\n\n$nombre = isset($argv[1]) ? $argv[1] : \"Mundo\";\nprint new HolaMundo($nombre);\n=======\nprint \"Introduce tu nombre:\";\n$nombre = trim(fgets(STDIN));\n@print \"Hola, {$nombre}\\n\";\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; master\n?&gt;\n</code></pre> <p>La primera parte marca el c\u00f3digo que estaba en la rama donde trabaj\u00e1bamos (HEAD), que era la rama <code>hola</code> y la parte final el c\u00f3digo desde donde fusion\u00e1bamos, que era <code>master</code>. Resolvemos el conflicto, dejando el archivo como sigue:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\nrequire('HolaMundo.php');\n\nprint \"Introduce tu nombre:\";\n$nombre = trim(fgets(STDIN));\nprint new HolaMundo($nombre);\n?&gt;\n</code></pre> <p>Y resolvemos el conflicto confirmando los cambios:</p> <pre><code>$ git add lib/hola.php\n$ git commit -m \"Solucionado el conflicto al fusionar con la rama master\"\n[hola a36af04] Solucionado el conflicto al fusionar con la rama master\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#rebasing-vs-merging","title":"Rebasing vs Merging","text":"<p>Rebasing es otra t\u00e9cnica para fusionar distinta a merge y usa la orden <code>git rebase</code>. Vamos a dejar nuestro proyecto como estaba antes del fusionado. Para ello necesitamos anotar el hash anterior al de la acci\u00f3n de merge. El que tiene la anotaci\u00f3n \"hola usa la clase HolaMundo\".</p> <p>Para ello podemos usar la orden <code>git reset</code> que nos permite mover HEAD donde queramos.</p> <pre><code>$ git checkout hola\nSwitched to branch 'hola'\n$ git hist\n*   a36af04 2013-06-16 | Solucionado el conflicto al fusionar con la rama master (HEAD -&gt; hola) [Sergio G\u00f3mez]\n|\\\n| * 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* | 9c6ac06 2013-06-16 | Merge branch 'master' into hola [Sergio G\u00f3mez]\n|\\|\n| * c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* | 9862f33 2013-06-16 | hola usa la clase HolaMundo [Sergio G\u00f3mez]\n* | 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n$ git reset --hard 9862f33\nHEAD is now at 9862f33 hola usa la clase HolaMundo\n</code></pre> <p>Y nuestro estado ser\u00e1:</p> <pre><code>$ git hist --all\n* 9862f33 2013-06-16 | hola usa la clase HolaMundo (HEAD, hola) [Sergio G\u00f3mez]\n* 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n| * 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n| * c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n|/\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Hemos desecho todos los merge y nuestro \u00e1rbol est\u00e1 \"limpio\". Vamos a probar ahora a hacer un rebase. Continuamos en la rama <code>hola</code> y ejecutamos lo siguiente:</p> <pre><code>$ git rebase master\nAuto-merging lib/hola.php\nCONFLICT (content): Merge conflict in lib/hola.php\nerror: could not apply 9862f33... hola usa la clase HolaMundo\nhint: Resolve all conflicts manually, mark them as resolved with\nhint: \"git add/rm &lt;conflicted_files&gt;\", then run \"git rebase --continue\".\nhint: You can instead skip this commit: run \"git rebase --skip\".\nhint: To abort and get back to the state before \"git rebase\", run \"git rebase --abort\".\nCould not apply 9862f33... hola usa la clase HolaMundo\n</code></pre> <p>El conflicto, por supuesto, se sigue dando. Resolvemos guardando el archivo <code>hola.php</code> como en los casos anteriores:</p> <pre><code>&lt;?php\n// Autor: Sergio G\u00f3mez &lt;sergio@uco.es&gt;\nrequire('HolaMundo.php');\n\nprint \"Introduce tu nombre:\";\n$nombre = trim(fgets(STDIN));\nprint new HolaMundo($nombre);\n?&gt;\n</code></pre> <p>A\u00f1adimos los cambios en staging y en esta ocasi\u00f3n, y tal como nos indicaba en el mensaje anterior, no tenemos que hacer <code>git commit</code> sino continuar con el rebase:</p> <pre><code>$ git add lib/hola.php\n$ git status\ninteractive rebase in progress; onto 269eaca\nLast commands done (2 commands done):\n    pick 4e0f425 A\u00f1adida clase HolaMundo\n    pick 9862f33 hola usa la clase HolaMundo\nNo commands remaining.\nYou are currently rebasing branch 'hola' on '8ca56f7'.\n    (all conflicts fixed: run \"git rebase --continue\")\n\nChanges to be committed:\n    (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   lib/hola.php\n\n\n$ git rebase --continue\n[detached HEAD 9862f33] hola usa la clase HolaMundo\n1 file changed, 3 insertions(+), 1 deletion(-)\nSuccessfully rebased and updated refs/heads/hola.\n</code></pre> <p>Y ahora vemos que nuestro \u00e1rbol tiene un aspecto distinto, mucho m\u00e1s limpio:</p> <pre><code>$ git hist --all\n* 9862f33 2013-06-16 | hola usa la clase HolaMundo (HEAD -&gt; hola) [Sergio G\u00f3mez]\n* 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Lo que hace rebase es volver a aplicar todos los cambios a la rama m\u00e1ster, desde su nodo m\u00e1s reciente. Eso significa que se modifica el orden o la historia de creaci\u00f3n de los cambios. Por eso rebase no debe usarse si el orden es importante o si la rama es compartida.</p>"},{"location":"Ud1%20Control%20de%20versiones/T07_ramas/#mezclando-con-la-rama-master","title":"Mezclando con la rama master","text":"<p>Ya hemos terminado de implementar los cambios en nuestra rama secundaria y es hora de llevar los cambios a la rama principal. Usamos <code>git merge</code> para hacer una fusi\u00f3n normal:</p> <pre><code>$ git checkout master\nSwitched to branch 'master'\n$ git merge hola\nUpdating c3e65d0..491f1d2\nFast-forward\n lib/HolaMundo.php | 16 ++++++++++++++++\n lib/hola.php      |  4 +++-\n 2 files changed, 19 insertions(+), 1 deletion(-)\n create mode 100644 lib/HolaMundo.php\n $ git hist --all\n * 9862f33 2013-06-16 | hola usa la clase HolaMundo (HEAD -&gt; master, hola) [Sergio G\u00f3mez]\n * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n * 9c85275 2013-06-16 | Programa interactivo [Sergio G\u00f3mez]\n * c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n * 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n * 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n * fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n * 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n * efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n * e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Vemos que indica que el tipo de fusi\u00f3n es fast-forward. Este tipo de fusi\u00f3n tiene el problema que no deja rastro de la fusi\u00f3n, por eso suele ser recomendable usar el par\u00e1metro <code>--no-ff</code> para que quede constancia siempre de que se ha fusionado una rama con otra.</p> <p>Vamos a volver a probar ahora sin hacer fast-forward. Reseteamos master al estado \"Programa interactivo\".</p> <pre><code>$ git reset --hard 9c85275\n$ git hist\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Vemos que estamos como en el final de la secci\u00f3n anterior, as\u00ed que ahora mezclamos:</p> <pre><code>$ git merge -m \"Aplicando los cambios de la rama hola\" --no-ff hola\nMerge made by the 'recursive' strategy.\n lib/HolaMundo.php | 16 ++++++++++++++++\n lib/hola.php      |  4 +++-\n 2 files changed, 19 insertions(+), 1 deletion(-)\n create mode 100644 lib/HolaMundo.php\n$ git hist --all\n*   2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola (HEAD -&gt; master) [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>En la siguiente imagen se puede ver la diferencia:</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/","title":"Github","text":"<p>Github es lo que se denomina una forja, un repositorio de proyectos que usan Git como sistema de control de versiones. Es la forja m\u00e1s popular, ya que alberga m\u00e1s de 10 millones de repositorios. Debe su popularidad a sus funcionalidades sociales, principalmente dos: </p> <ul> <li>la posibilidad de hacer forks de otros proyectos y </li> <li>la posibilidad de cooperar aportando c\u00f3digo para arreglar errores o mejorar el c\u00f3digo. </li> </ul> <p>Si bien, no es que fuera una novedad, s\u00ed lo es lo f\u00e1cil que resulta hacerlo. A ra\u00edz de este proyecto han surgido otros como Gitorius o Gitlab, pero Github sigue siendo el m\u00e1s popular y el que tiene mejores y mayores caracter\u00edsticas. Algunas de estas son:</p> <ul> <li>Un wiki para documentar el proyecto, que usa MarkDown como lenguaje de marca.</li> <li>Un portal web para cada proyecto.</li> <li>Funcionalidades de redes sociales como followers.</li> <li>Gr\u00e1ficos estad\u00edsticos.</li> <li>Revisi\u00f3n de c\u00f3digo y comentarios.</li> <li>Sistemas de seguimiento de incidencias.</li> </ul> <p>Lo primero es entrar en el portal (https://github.com/) para crearnos una cuenta si no la tenemos a\u00fan.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#tu-clave-publicaprivada","title":"Tu clave p\u00fablica/privada","text":"<p>Muchos servidores Git utilizan la autentificaci\u00f3n a trav\u00e9s de claves p\u00fablicas SSH. Y, para ello, cada usuario del sistema ha de generarse una, si es que no la tiene ya. El proceso para hacerlo es similar en casi cualquier sistema operativo. Ante todo, asegurarte que no tengas ya una clave. (comprueba que el directorio <code>$HOME/usuario/.ssh</code> no tiene un archivo id_dsa.pub o id_rsa.pub).</p> <p>Para crear una nueva clave usamos la siguiente orden:</p> <pre><code>$ ssh-keygen -t rsa -C \"Cuenta GitHub\"\n</code></pre> <p>Warning</p> <p>Tu clave RSA te identifica contra los repositorios remotos, aseg\u00farate de no compartir la clave privada con nadie. Por defecto la clave se crea como solo lectura.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#configuracion","title":"Configuraci\u00f3n","text":"<p>Vamos a aprovechar para a\u00f1adir la clave RSA que generamos antes, para poder acceder desde git a los repositorios. Para ellos nos vamos al men\u00fa de configuraci\u00f3n de usuario (Settings)</p> <p></p> <p>Nos vamos al men\u00fa 'SSH and GPG Keys' y a\u00f1adimos una nueva clave. En Title indicamos una descripci\u00f3n que nos ayude a saber de d\u00f3nde procede la clave y en key volcamos el contenido del archivo <code>~/.ssh/id_rsa.pub</code>. Y guardamos la clave.</p> <p></p> <p>Con esto ya tendriamos todo nuestro entorno para poder empezar a trabajar desde nuestro equipo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#clientes-graficos-para-github","title":"Clientes gr\u00e1ficos para GitHub","text":"<p>Adem\u00e1s, para Github existe un cliente propio tanto para Windows como para MacOSX:</p> <ul> <li> <p>Cliente Windows: http://windows.github.com/</p> </li> <li> <p>Cliente MacOSX: http://mac.github.com/</p> </li> </ul> <p>Para Linux no hay cliente propio, pero s\u00ed hay plugin para la mayor\u00eda de editores de texto como atom, netbeans, eclipe o los editores de jetbrains.</p> <p>De todas maneras, estos clientes solo tienen el fin de facilitar el uso de Github, pero no son necesarios para usarlo. Es perfectamente v\u00e1lido usar el cliente de consola de Git o cualquier otro cliente gen\u00e9rico para Git. Uno de los m\u00e1s usados actualmente es GitKraken.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#crear-un-repositorio","title":"Crear un repositorio","text":"<p>Vamos a crear un repositorio donde guardar nuestro proyecto. Para ello pulsamos el signo <code>+</code> que hay en la barra superior y seleccionamos <code>New repository</code>.</p> <p>Ahora tenemos que designar un nombre para nuestro repositorio, por ejemplo: 'taller-de-git'.</p> <p></p> <p>Nada m\u00e1s crear el repositorio nos saldr\u00e1 una pantalla con instrucciones precisas de como proceder a continuaci\u00f3n.</p> <p>B\u00e1sicamente podemos partir de 3 situaciones:</p> <ol> <li>Quick setup - olvidamos por ahora</li> <li>Todav\u00eda no hemos creado ning\u00fan repositorio en nuestro equipo. (\u2026or create a new repository on the command line)</li> <li>Ya tenemos un repositorio creado y queremos sincronizarlo con Github. (\u2026or push an existing repository from the command line)</li> </ol> <p>Warning</p> <p>Veremos una pantalla similar a esta. Los comandos pueden variar ligeramente si existe una nueva versi\u00f3n de git. F\u00edjate en los comandos que a ti te aparecen.</p> <p>En el momento de revisar estas notas la \u00faltima de las opciones que se ve en la captura ya no aparece en GitHub</p> <p></p> <p>Nuestra situaci\u00f3n es la tercera, ya tenemos un repositorio creado y vamos a sincronizarlo con github as\u00ed que seguiremos las instrucciones de la apartado \"\u2026or push an existing repository from the command line\" desde la consola de nuestro equipo y dentro del directorio <code>curso-de-git</code> que venimos utilizando en estas notas.</p> <pre><code>$ git remote add origin git@github.com:sgomez/taller-de-git.git\n$ git branch -M main\n$ git push -u origin main\nCounting objects: 33, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (24/24), done.\nWriting objects: 100% (33/33), 3.35 KiB | 1.12 MiB/s, done.\nTotal 33 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), done.\nTo github.com:sgomez/taller-de-git.git\n * [new branch]      main -&gt; main\nrama 'main' configurada para rastrear 'origin/main'.\n</code></pre> <p>Atenci\u00f3n</p> <p>En la versi\u00f3n de git utilizada al realizar estos apuntes a la rama principal le llama \"master\". En la versi\u00f3n actual le denomina \"main\". Cambiar\u00e9 los comandos y salidas para evitar errores, aunque podr\u00edan diferir ligeramente de lo que obtengas.</p> <p>Si recargamos la p\u00e1gina veremos que ya aparece nuestro proyecto.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#clonar-un-repositorio","title":"Clonar un repositorio","text":"<p>Una vez que ya tengamos sincronizado el repositorio contra Github, eventualmente vamos a querer descargarlo en otro de nuestros ordenadores para poder trabajar en \u00e9l. Esta acci\u00f3n se denomina clonar y para ello usaremos la orden <code>git clone</code>.</p> <p>En la p\u00e1gina principal de nuestro proyecto podemos ver un bot\u00f3n que indica <code>Clone or download</code>. Si la pulsamos nos da, de nuevo, la opci\u00f3n de elegir entre clonar con ssh o https. Recordad que si est\u00e1is en otro equipo y quer\u00e9is seguir utilizando ssh deber\u00e9is generar otra para de claves privada/p\u00fablica como hicimos en la secci\u00f3n de Tu clave p\u00fablica/privada y instalarla en nuestro perfil de Github, como vimos anteriormente.</p> <p>Para clonar nuestro repositorio y poder trabajar con \u00e9l todo lo que debemos hacer es lo siguiente:</p> <pre><code>$ git clone git@github.com:sgomez/taller-de-git.git\n$ cd taller-de-git\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#ramas-remotas","title":"Ramas remotas","text":"<p>Si ahora vemos el estado de nuestro proyecto veremos algo similar a esto:</p> <pre><code>$ git hist --all\n* 2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola (HEAD -&gt; main, origin/main) [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Aparece que hay una nueva rama llamada <code>origin/main</code>. Esta rama indica el estado de sincronizaci\u00f3n de nuestro repositorio con un repositorio remoto llamado origin/main   . En este caso el de Github.</p> <p>Info</p> <p>Por norma se llama autom\u00e1ticamente origin al primer repositorio con el que sincronizamos nuestro repositorio.</p> <p>Podemos ver la configuraci\u00f3n de este repositorio remoto con la orden <code>git remote</code>:</p> <pre><code>$ git remote show origin\n* remote origin\n  Fetch URL: git@github.com:sgomez/taller-de-git.git\n  Push  URL: git@github.com:sgomez/taller-de-git.git\n  HEAD branch: main\n  Remote branch:\n    main tracked\n  Local ref configured for 'git push':\n    main pushes to main (up to date)\n</code></pre> <p>De la respuesta tenemos que fijarnos en las l\u00edneas que indican fetch y push puesto que son las acciones de sincronizaci\u00f3n de nuestro repositorio con el remoto. Mientras que fetch se encarga de traer los cambios desde el repositorio remoto al nuestro, push los env\u00eda.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#enviando-actualizaciones","title":"Enviando actualizaciones","text":"<p>Vamos a a\u00f1adir una licencia a nuestra aplicaci\u00f3n. Creamos un fichero LICENSE con el siguiente contenido:</p> <pre><code>MIT License\n\nCopyright (c) [year] [fullname]\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre> <p>Y a\u00f1adidos y confirmamos los cambios:</p> <pre><code>$ git add LICENSE\n$ git commit -m \"A\u00f1adida licencia\"\n[master 3f5cb1c] A\u00f1adida licencia\n 1 file changed, 21 insertions(+)\n create mode 100644 LICENSE\n$ git hist --all\n* 3f5cb1c 2013-06-16 | A\u00f1adida licencia (HEAD -&gt; main) [Sergio G\u00f3mez]\n*   2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola (origin/main) [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Viendo la historia podemos ver como nuestro master no est\u00e1 en el mismo punto que <code>origin/main</code>. Si vamos a la web de Github veremos que <code>LICENSE</code> no aparece a\u00fan. As\u00ed que vamos a enviar los cambios con la primera de las acciones que vimos <code>git push</code>:</p> <pre><code>$ git push\nCounting objects: 3, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 941 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo git@github.com:sgomez/taller-de-git.git\n   2eab8ca..3f5cb1c  main -&gt; main\n</code></pre> <p>Info</p> <p>La orden <code>git push</code> necesita dos par\u00e1metros para funcionar: el repositorio y la rama destino. As\u00ed que realmente lo que ten\u00edamos que haber escrito es:</p> <pre><code>$ git push origin main\n</code></pre> <p>Para ahorrar tiempo escribiendo git nos deja vincular nuestra rama local con una rama remota, de tal manera que no tengamos que estar siempre indic\u00e1ndolo. Eso es posible con el par\u00e1metro <code>--set-upstream</code> o <code>-u</code> en forma abreviada.</p> <pre><code>$ git push -u origin main\n</code></pre> <p>Si repasas las \u00f3rdenes que te indic\u00f3 Github que ejecutaras ver\u00e1s que el par\u00e1metro <code>-u</code> estaba presente y por eso no ha sido necesario indicar ning\u00fan par\u00e1metro al hacer push.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#recibiendo-actualizaciones","title":"Recibiendo actualizaciones","text":"<p>Si trabajamos con m\u00e1s personas, o trabajamos desde dos ordenadores distintos, nos encontraremos con que nuestro repositorio local es m\u00e1s antiguo que el remoto. Necesitamos descargar los cambios para poder incorporarlos a nuestro directorio de trabajo.</p> <p>Para la prueba, Github nos permite editar archivos directamente desde la web. Pulsamos sobre el archivo <code>README.md</code>. En la vista del archivo, veremos que aparece el icono de un l\u00e1piz. Esto nos permite editar el archivo.</p> <p></p> <p>Info</p> <p>Los archivos con extensi\u00f3n <code>.md</code> est\u00e1n en un formato denominado MarkDown. Se trata de un lenguaje de marca que nos permite escribir texto enriquecido de manera muy sencilla.</p> <p>Dispones de un tutorial aqu\u00ed: https://www.markdowntutorial.com/</p> <p>Modificamos el archivo como queramos, por ejemplo, a\u00f1adiendo nuestro nombre:</p> <pre><code># Curso de GIT\n\nEste proyecto contiene el curso de introducci\u00f3n a GIT\n\nDesarrollado por Sergio G\u00f3mez.\n</code></pre> <p></p> <p>El cambio quedar\u00e1 incorporado al repositorio de Github, pero no al nuestro. Necesitamos traer la informaci\u00f3n desde el servidor remoto. La orden asociada es <code>git fetch</code>:</p> <pre><code>$ git fetch\n$ git hist --all\n* cbaf831 2013-06-16 | Actualizado README.md (origin/main) [Sergio G\u00f3mez]\n* 3f5cb1c 2013-06-16 | A\u00f1adida licencia (HEAD -&gt; main) [Sergio G\u00f3mez]\n*   2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Ahora vemos el caso contrario, tenemos que <code>origin/master</code> est\u00e1 por delante que <code>HEAD</code> y que la rama <code>main</code> local.</p> <p>Atenci\u00f3n</p> <p><code>git fetch</code> trae la informaci\u00f3n de los cambios realizados en GitHub, pero no importa directamente los cambios en local</p> <p>Ahora necesitamos incorporar los cambios de la rama remota en la local. La forma de hacerlo lo vimos en el cap\u00edtulo de ramas usando <code>git merge</code> o <code>git rebase</code>.</p> <p>Habitualmente se usa <code>git merge</code>:</p> <pre><code>$ git merge origin/main\nUpdating 3f5cb1c..cbaf831\nFast-forward\n README.md | 2 ++\n 1 file changed, 2 insertions(+)\n$ git hist --all\n* cbaf831 2013-06-16 | Actualizado README.md (HEAD -&gt; main, origin/main) [Sergio G\u00f3mez]\n* 3f5cb1c 2013-06-16 | A\u00f1adida licencia [Sergio G\u00f3mez]\n* 2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Como las operaciones de traer cambios (<code>git fetch</code>) y de mezclar ramas (<code>git merge</code> o <code>git rebase</code>) est\u00e1n muy asociadas, git nos ofrece una posibilidad para ahorrar pasos que es la orden <code>git pull</code> que realiza las dos acciones simult\u00e1neamente.</p> <p>Para probar, vamos a editar de nuevo el archivo README.md en GitHub y a\u00f1adimos algo m\u00e1s:</p> <pre><code># Curso de GIT\n\nEste proyecto contiene el curso de introducci\u00f3n a GIT del Aula de Software Libre.\n\nDesarrollado por Sergio G\u00f3mez.\n</code></pre> <p>Como mensaje del commit: 'Indicado que se realiza en el ASL'.</p> <p>Y ahora probamos a actualizar con <code>git pull</code>:</p> <pre><code>$ git pull\nremote: Enumerating objects: 5, done.\nremote: Counting objects: 100% (5/5), done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\nUnpacking objects: 100% (3/3), 811 bytes | 811.00 KiB/s, done.\nFrom github.com:sgomez/taller-de-git\n   cbaf831..d8922e4  main     -&gt; origin/main\nUpdating 6e4cda3..bb3dc3e\nFast-forward\n README.md | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n$ git hist --all\n* d8922e4 2013-06-16 | Update README.md (HEAD -&gt; main, origin/main) [Sergio G\u00f3mez]\n* cbaf831 2013-06-16 | Update README.md [Sergio G\u00f3mez]\n* 3f5cb1c 2013-06-16 | A\u00f1adida licencia [Sergio G\u00f3mez]\n* 2eab8ca 2013-06-16 | Aplicando los cambios de la rama hola [Sergio Gomez]\n*\\\n| * 9862f33 2013-06-16 | hola usa la clase HolaMundo (hola) [Sergio G\u00f3mez]\n| * 6932156 2013-06-16 | A\u00f1adida la clase HolaMundo [Sergio G\u00f3mez]\n|/\n* 9c85275 2013-06-16 | Programa interactivo (master) [Sergio G\u00f3mez]\n* c3e65d0 2013-06-16 | A\u00f1adido README.md [Sergio G\u00f3mez]\n* 81c6e93 2013-06-16 | Movido hola.php a lib [Sergio G\u00f3mez]\n* 96a39df 2013-06-16 | A\u00f1adido el autor del programa y su email [Sergio G\u00f3mez]\n* fd4da94 2013-06-16 | Se a\u00f1ade un comentario al cambio del valor por defecto (tag: v1) [Sergio G\u00f3mez]\n* 3283e0d 2013-06-16 | Se a\u00f1ade un par\u00e1metro por defecto (tag: v1-beta) [Sergio G\u00f3mez]\n* efc252e 2013-06-16 | Parametrizaci\u00f3n del programa [Sergio G\u00f3mez]\n* e19f2c1 2013-06-16 | Creaci\u00f3n del proyecto [Sergio G\u00f3mez]\n</code></pre> <p>Vemos que los cambios se han incorporado y que las ramas remota y local de master est\u00e1n sincronizadas.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#problemas-de-sincronizacion","title":"Problemas de sincronizaci\u00f3n","text":""},{"location":"Ud1%20Control%20de%20versiones/T08_github/#no-puedo-hacer-push","title":"No puedo hacer push","text":"<p>Al intentar subir cambios nos podemos encontrar un mensaje como este:</p> <pre><code>$ git push\ngit push\nTo git@github.com:sgomez/taller-de-git.git\n ! [rejected]        main -&gt; main (fetch first)\nerror: failed to push some refs to 'git@github.com:sgomez/taller-de-git.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\n</code></pre> <p>La causa es que el repositorio remoto tambi\u00e9n se ha actualizado y nosotros a\u00fan no hemos recibido esos cambios. Es decir, ambos repositorios se han actualizado y el remoto tiene preferencia. Hay un conflicto en ciernes y se debe resolver localmente antes de continuar.</p> <p>Vamos a provocar una situaci\u00f3n donde podamos ver esto en acci\u00f3n. Vamos a modificar el archivo <code>README.md</code> tanto en local como en remoto a trav\u00e9s del interfaz web.</p> <p>En el web vamos a cambiar el t\u00edtulo para que aparezca de la siguiente manera.</p> <pre><code>Curso de GIT, 2020\n</code></pre> <p>En local vamos a cambiar el t\u00edtulo para que aparezca de la siguiente manera.</p> <pre><code>Curso de GIT, febrero\n</code></pre> <p>Question</p> <p>Haz el commit para guardar el cambio en local.</p> Respuesta al ejercicio anterior <p>A\u00f1adimos el fichero actualizado:</p> <pre><code>$ git commit -am \"A\u00f1adido el mes al README\"\n[master 1e8c0b7] A\u00f1adido el mes al README\n1 file changed, 1 insertion(+), 1 deletion(-)\n</code></pre> <p>La forma de proceder en este caso es hacer un <code>git fetch</code> y un <code>git rebase</code>. Si hay conflictos deber\u00e1n resolverse. Cuando est\u00e9 todo solucionado ya podremos hacer <code>git push</code>.</p> <p>Info</p> <p>Por defecto <code>git pull</code> lo que hace es un <code>git merge</code>, si queremos hacer <code>git rebase</code> deberemos especificarlos con el par\u00e1metro <code>-r</code>:</p> <pre><code>$ git pull --rebase\n</code></pre> <p>Vamos a hacer el pull con rebase y ver qu\u00e9 sucede.</p> <pre><code>$ git pull --rebase\nFirst, rewinding head to replay your work on top of it...\nApplying: A\u00f1adido el mes al README\nUsing index info to reconstruct a base tree...\nM   README.md\nFalling back to patching base and 3-way merge...\nAuto-merging README.md\nCONFLICT (content): Merge conflict in README.md\nerror: Failed to merge in the changes.\nPatch failed at 0001 A\u00f1adido el mes al README\nhint: Use 'git am --show-current-patch' to see the failed patch\n\nResolve all conflicts manually, mark them as resolved with\n\"git add/rm &lt;conflicted_files&gt;\", then run \"git rebase --continue\".\nYou can instead skip this commit: run \"git rebase --skip\".\nTo abort and get back to the state before \"git rebase\", run \"git rebase --abort\".\n</code></pre> <p>Evidentemente hay un conflicto porque hemos tocado el mismo archivo. Se deja como ejercicio resolverlo.</p> Respuesta al ejercicio anterior <p>El contenido del fichero final podr\u00eda ser:</p> <pre><code>Curso de GIT, febrero, 2020\n</code></pre> <p>A continuaci\u00f3n confirmamos los cambios y los enviamos al servidor</p> <pre><code>$ git add README.md\n$ git rebase --continue\n$ git push\n</code></pre> <p>Warning</p> <p>\u00bfPor qu\u00e9 hemos hecho rebase en master si a lo largo del curso hemos dicho que no se debe cambiar la linea principal?</p> <p>B\u00e1sicamente hemos dicho que lo que no debemos hacer es modificar la l\u00ednea temporal compartida. En este caso nuestros cambios en master solo estaban en nuestro repositorio, porque al fallar el env\u00edo nadie m\u00e1s ha visto nuestras actualizaciones. Al hacer rebase estamos deshaciendo nuestros cambios, bajarnos la \u00faltima actualizaci\u00f3n compartida de master y volvi\u00e9ndolos a aplicar. Con lo que realmente la historia compartida no se ha modificado.</p> <p>Este es un problema que debemos evitar en la medida de lo posible. La menor cantidad de gente posible debe tener acceso de escritura en master y las actualizaciones de dicha rama deben hacerse a trav\u00e9s de ramas secundarias y haciendo merge en master como hemos visto en el cap\u00edtulo de ramas.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#no-puedo-hacer-pull","title":"No puedo hacer pull","text":"<p>Al intentar descargar cambios nos podemos encontrar un mensaje como este:</p> <pre><code>$ git pull\nerror: Cannot pull with rebase: You have unstaged changes.\n</code></pre> <p>O como este:</p> <pre><code>$ git pull\nerror: Cannot pull with rebase: Your index contains uncommitted changes.\n</code></pre> <p>B\u00e1sicamente lo que ocurre es que tenemos cambios sin confirmar en nuestro espacio de trabajo. Una opci\u00f3n es confirmar (commit) y entonces proceder como el caso anterior.</p> <p>Pero puede ocurrir que a\u00fan estemos trabajando todav\u00eda y no nos interese confirmar los cambios, solo queremos sincronizar y seguir trabajando. Para casos como estos git ofrece una pila para guardar cambios temporalmente. Esta pila se llama stash y nos permite restaurar el espacio de trabajo al \u00faltimo commit.</p> <p>De nuevo vamos a modificar nuestro proyecto para ver esta situaci\u00f3n en acci\u00f3n.</p> <p>Example</p> <p>En remoto borra el a\u00f1o de la fecha y en local borra el mes. Pero esta vez no hagas commit en local. El archivo solo debe quedar modificado.</p> <p>La forma de proceder es la siguiente:</p> <pre><code>$ git stash save # Guardamos los cambios en la pila\n$ git pull # Sincronizamos con el repositorio remoto, -r para hacer rebase puede ser requerido\n$ git stash pop # Sacamos los cambios de la pila\n</code></pre> <p>Info</p> <p>Como ocurre habitualmente, git nos proporciona una forma de hacer todos estos pasos de una sola vez. Para ello tenemos que ejecutar lo siguiente:</p> <pre><code>$ git pull --autostash\n</code></pre> <p>En general no es mala idea ejecutar lo siguiente si somos conscientes, adem\u00e1s, de que tenemos varios cambios sin sincronizar:</p> <pre><code>$ git pull --autostash --rebase\n</code></pre> <p>Podr\u00eda darse el caso de que al sacar los cambios de la pila hubiera alg\u00fan conflicto. En ese caso actuamos como con el caso de merge o rebase.</p> <p>De nuevo este tipo de problemas no deben suceder si nos acostumbramos a trabajar en ramas.</p>"},{"location":"Ud1%20Control%20de%20versiones/T08_github/#practicar","title":"Practicar","text":"<p>Llegados a este punto es buen momento para empezar a practicar solos. Realiza las siguientes pr\u00e1cticas antes de continuar con los contenidos del tema:</p> <ul> <li>P1.1 Introducci\u00f3n a git y GitHub</li> <li>P1.2 Git Trabajando con ramas y uniones</li> <li>P1.3 Ejercicios Git y GitHub</li> <li>P1.4 Ejercicios Git y GitHub II</li> <li>P1.5 Git avanzado - Aprendiendo branching</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/","title":"Flujo de trabajo en GitHub","text":""},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-0-abrir-una-incidencia-issue","title":"Paso 0. Abrir una incidencia (issue)","text":"<p>Habitualmente el trabajo puede partir a ra\u00edz de una reporte por parte de un miembro del equipo o de una persona externa. Para eso tenemos la secci\u00f3n Issues.</p> <p></p> <p>Una issue cuando se crea se compone de un t\u00edtulo y una descripci\u00f3n en Markdown. Si la persona es miembro del equipo, opcionalmente puede asignarle una serie de metadatos: etiquetas (labels), hitos (milestone), proyecto al que pertenece o responsables encargados de cerrar la incidencia.</p> <p></p> <p>Una vez creado, al mismo se le asignar\u00e1 un n\u00famero.</p> <p>Example</p> <p>Vamos a crear una incidencia llamada \"Crear archivo de autores\", donde indiquemos que vamos a crear un archivo <code>AUTHORS.md</code> con la lista de desarrolladores del proyecto.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-1-crear-una-rama","title":"Paso 1. Crear una rama","text":"<p>Crearemos una rama cada vez que queramos implementar una nueva caracter\u00edstica al proyecto que estamos realizando. La misma puede estar provocada por una incidencia o no.</p> <p>Tip</p> <p>Es una buena costumbre crear en Issues el listado de casos de uso, requisitos, historias de usuario o tareas (como lo queramos llamar), para tener un registro del trabajo que llevamos y el que nos queda.</p> <p>El nombre de la rama puede ser el que creamos conveniente, pero hay que intentar ser coherente y usar siempre el mismo m\u00e9todo, sobre todo si trabajamos en equipo.</p> <p>Un m\u00e9todo puede ser el siguiente (\u00a1No lo hagas, es solo un ejemplo!):</p> <pre><code>$ # tipo-n\u00famero/descripci\u00f3n\n$ git checkout -b feature-1/create-changelog\n$ git checkout -b hotfix-2/updated-database\n</code></pre> <p>En entornos de trabajo multiusuario se puede usar el siguiente (\u00a1No lo hagas, es solo un ejemplo!):</p> <pre><code>$ # usuario/tipo-n\u00famero/descripci\u00f3n\n$ git checkout -b sgomez/feature-1/create-changelog\n$ git checkout -b sgomez/hotfix-2/updated-database\n</code></pre> <p>De esa manera, podemos seguir f\u00e1cilmente qui\u00e9n abri\u00f3 la rama, en qu\u00e9 consiste y a qu\u00e9 issues est\u00e1 conectada. Pero como decimos es m\u00e1s un convenio que una imposici\u00f3n, pudi\u00e9ndole poner el nombre que queramos.</p> <p>Vamos a crear la rama y los commits correspondientes y subir la rama con push al servidor.</p> <pre><code>$ git checkout -b sgomez/feature-1/create-changelog\n</code></pre> <p>Ahora creamos el fichero AUTHORS.md</p> <pre><code>$ git add AUTHORS.md\n$ git commit -m \"A\u00f1adido fichero de autores\"\n</code></pre> <p>El archivo puede contener, por ejemplo, lo siguiente:</p> <pre><code># AUTHORS\n\n* Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n</code></pre> <p>Hacemos push y obtenemos algo como esto:</p> <pre><code>$ git push\nfatal: The current branch sgomez/feature-1/create-changelog has no upstream branch.\nTo push the current branch and set the remote as upstream, use\n\n    git push --set-upstream origin sgomez/feature-1/create-changelog\n</code></pre> <p>Como la rama es nueva, git no sabe d\u00f3nde debe hacer push. Le indicamos que debe hacerla en origin y adem\u00e1s que guarde la vinculaci\u00f3n (equivalente al par\u00e1metro -u que vimos en el cap\u00edtulo anterior). Probamos de nuevo:</p> <pre><code>$ git push -u origin sgomez/feature-1/create-changelog\nEnumerating objects: 4, done.\nCounting objects: 100% (4/4), done.\nDelta compression using up to 4 threads\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 1.03 KiB | 1.03 MiB/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nremote:\nremote: Create a pull request for 'sgomez/feature-1/create-changelog' on GitHub by visiting:\nremote:      https://github.com/sgomez/taller-de-git/pull/new/sgomez/feature-1/create-changelog\nremote:\nTo github.com:sgomez/taller-de-git.git\n* [new branch]      sgomez/feature-1/create-changelog -&gt; sgomez/feature-1/create-changelog\nBranch 'sgomez/feature-1/create-changelog' set up to track remote branch 'sgomez/feature-1/create-changelog' from 'origin'.\n</code></pre> <p>Ahora la rama ya se ha subido y nos informa, adem\u00e1s, de que podemos crear un Pull Request (PR). Si vamos al enlace que nos aparece veremos lo siguiente:</p> <p></p> <p>Informaci\u00f3n</p> <p>Un pull request (tambi\u00e9n conocido como \"PR\" en la jerga de desarrollo) es una funci\u00f3n que facilita la colaboraci\u00f3n en proyectos de Git, especialmente en plataformas como GitHub, GitLab o Bitbucket. Un pull request es una solicitud que un desarrollador hace para que los cambios que ha realizado en una rama de su repositorio se fusionen con otra rama, generalmente con la rama principal (como master o main).</p> <p>Aqu\u00ed podemos informar de en qu\u00e9 consiste la rama que estamos enviando. Si ya tenemos una issue abierta, no es necesario repetir la misma informaci\u00f3n. Podemos hacer referencia con el siguiente texto en el contenido (no en el t\u00edtulo):</p> <pre><code>Closes #1\n</code></pre> <p>Esto lo que le indica a GitHub que esta PR cierra el issues n\u00famero 1. Cuando se haga el merge de la rama, autom\u00e1ticamente se cerrar\u00e1 la incidencia.</p> <p>Lo hacemos y le damos a crear.</p> <p></p> <p>Ahora podr\u00edamos hacer ya el merge con nuestra rama master, pero vamos a esperar un poco y la haremos m\u00e1s adelante.</p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-2-crear-commits","title":"Paso 2. Crear commits","text":"<p>A partir de ahora podemos seguir creando commits en local y enviarlos hasta que terminemos de trabajar.</p> <p>Editamos el archivo AUTHORS.md .</p> <pre><code># AUTHORS\n\n* Sergio G\u00f3mez &lt;sergio@uco.es&gt;\n* John Doe\n</code></pre> <p>Y mandamos otro commit</p> <pre><code>$ git commit -am \"Actualizado AUTHORS.md\"\n$ git push\n</code></pre> <p>Si volvemos a la p\u00e1gina de PR, veremos que aparece el nuevo commit que acabamos de enviar.</p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-3-discutir","title":"Paso 3. Discutir","text":"<p>GitHub permite que entre los desarrolladores se pueda abrir una discusi\u00f3n sobre el c\u00f3digo, de tal manera que el trabajo de crear la rama sea colaborativo. Se puede incluso pedir revisiones por parte de terceros y que esas revisiones sean obligatorias antes de aceptar los cambios.</p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-4-desplegar","title":"Paso 4. Desplegar","text":"<p>Una vez que hemos terminado de crear la funci\u00f3n de la rama ya podemos incorporar los cambios a master. Este trabajo ya no es necesario hacerlo en local y GitHub nos proporciona 3 maneras de hacerlo:</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#crear-un-merge-commit","title":"Crear un merge commit","text":"<p>Esta opci\u00f3n es el equivalente a hacer lo siguiente en nuestro repositorio:</p> <pre><code>$ git checkout main\n$ git merge --no-ff sgomez/feature-1/create-changelog\n$ git push\n</code></pre> <p>Es decir, el equivalente a hacer un merge entre nuestra rama y master.</p> <p>Info</p> <p>GitHub siempre desactiva el fast forward.</p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#crear-un-rebase-y-merge","title":"Crear un rebase y merge","text":"<p>Esta opci\u00f3n es el equivalente a hacer lo siguiente en nuestro repositorio</p> <pre><code>$ git rebase main\n$ git checkout main\n$ git merge --no-ff sgomez/feature-1/create-changelog\n$ git push\n</code></pre> <p>Es decir, nos aseguramos de que nuestra rama est\u00e1 al final de main haciendo rebase, como vimos en el cap\u00edtulo de ramas, y posteriormente se hace el merge.</p>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#crear-un-squash-commit-y-un-merge","title":"Crear un squash commit y un merge","text":"<p>Esta opci\u00f3n es el equivalente a hacer lo siguiente en nuestro repositorio:</p> <pre><code>$ git checkout main\n$ git merge --squash sgomez/feature-1/create-changelog\n$ git push\n</code></pre> <p>Esta opci\u00f3n es algo especial. En vez de aplicar cada uno de los commits en la rama main, ya sea directamente (fast forward) o no, lo que hace es crear un solo commit con los cambios de todos los commits de la rama. El efecto final es como si en la rama solo hubiera producido un solo commit.</p> <p>Vamos a seleccionar este \u00faltimo (squash and merge) y le damos al bot\u00f3n para activarlo. Nos saldr\u00e1 una caja para que podamos crear una descripci\u00f3n del commit y le damos a confirmar.</p> <p></p> <p>Ya hemos terminado y nos aparecer\u00e1 una opci\u00f3n para borrar la rama, lo m\u00e1s recomendado para no tener ramas obsoletas.</p> <p>Las consecuencias de esta acci\u00f3n son las siguientes:</p> <ol> <li>El PR aparecer\u00e1 como estado merged y en la lista de PR como cerrado.</li> <li>El issue que abrimos se habr\u00e1 cerrado autom\u00e1ticamente.</li> <li>En el listado de commits aparecer\u00e1 solo uno con un enlace al PR (en vez de los dos commits que hicimos).</li> </ol>"},{"location":"Ud1%20Control%20de%20versiones/T09_github-flow/#paso-5-sincronizar","title":"Paso 5. Sincronizar","text":"<p>Hemos cambiado el repositorio en GitHub, pero nuestra rama master no contiene los mismos cambios que el de origin. As\u00ed que nos toca sincronizar y borrar la rama obsoleta:</p> <pre><code>$ git checkout main\n$ git pull --rebase --autostash\n$ git branch -D sgomez/feature-1/create-changelog\n</code></pre> <p>Info</p> <p>\u00bfPor qu\u00e9 squash and merge y no un merge o rebase? De nuevo depende de los gustos de cada equipo de desarrollo. Las cracter\u00edsticas de squash es que elimina (relativamente) rastros de errores intermedios mientras se implementaba la rama, deja menos commits en la rama master y nos enlace al PR donde se implementaron los cambios.</p> <p>Para algunas personas estas caracter\u00edsticas son unas ventajas, para otras no. Lo mejor es experimentar cada opci\u00f3n y cada uno decida como quiere trabajar.</p>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/","title":"Github avanzado","text":"<p>Esta secci\u00f3n trata de c\u00f3mo colaborar con proyectos de terceros.</p>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#clonar-un-repositorio","title":"Clonar un repositorio","text":"<p>Nos vamos a la web del proyecto en el que queremos colaborar. En este caso el proyecto se encuentra en https://github.com/sgomez/miniblog. Pulsamos en el bot\u00f3n de fork y eso crear\u00e1 una copia en nuestro perfil.</p> <p></p> <p>Una vez se termine de clonar el repositorio, nos encontraremos con el espacio de trabajo del mismo:</p> <ul> <li>Arriba del todo un men\u00fa para cambiar de contexto entre: explorador de c\u00f3digo, peticiones de colaboraci\u00f3n (pull request), wiki, configuraci\u00f3n, etc.</li> <li>Un explorador de archivos con los archivos del proyecto.</li> <li>Justo encima informaci\u00f3n sobre los commits, ramas, etiquetas, etc.</li> <li>Un bot\u00f3n verde con informaci\u00f3n sobre como clonar localmente o descargar un proyecto.</li> </ul> <p></p> <p>Github nos permite clonar localmente un proyecto por tres v\u00edas: HTTPS, SSH y Subversion. Seleccionamos SSH y copiamos el texto que despu\u00e9s a\u00f1adiremos a la orden <code>git clone</code> como en la orden siguiente:</p> <pre><code>$ git clone git@github.com:miusuario/miniblog.git\n</code></pre> <p>Si queremos probar el funcionamiento de este programa deberemos hacer lo siguiente, aunque no es necesario para seguir la pr\u00e1ctica, ya que ahora nos interesa la forma de trabajar con los cambios, m\u00e1s que el funcionamiento del programa.</p> <pre><code>$ cd miniblog\n$ composer.phar install\n$ php console create-schema\n</code></pre> <p>Lo que hace el c\u00f3digo anterior es:</p> <ol> <li>Clona el repositorio localmente</li> <li>Entramos en la copia</li> <li>Instalamos las dependencias que la aplicaci\u00f3n tiene</li> <li>Arrancamos un servidor web para pruebas</li> </ol> <p>Y probamos que nuestra aplicaci\u00f3n funciona:</p> <pre><code>$ php -S localhost:9999 -t web/\n</code></pre> <p>Podemos usar dos direcciones para probarla:</p> <ul> <li>Frontend: <code>http://localhost:9999/index_dev.php</code></li> <li>Backend: <code>http://localhost:9999/index_dev.php/admin/</code> con usuario admin y contrase\u00f1a 1234.</li> </ul> <p>Pero insisto, no es relevante que podamos hacer funcionar el programa descargado.</p>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#sincronizar-con-el-repositorio-original","title":"Sincronizar con el repositorio original","text":"<p>Cuando clonamos un repositorio de otro usuario hacemos una copia del original. Pero esa copia es igual al momento en el que hicimos la copia. Cuando el repositorio original cambie, que lo har\u00e1, nuestro repositorio no se actualizar\u00e1 solo. \u00a1Son dos repositorios diferentes! Necesitamos una manera de poder incorporar los cambios que vaya teniendo el repositorio original en el nuestro. Para eso crearemos una nueva rama remota. Por convenio, y como vimos anteriormente, ya existe una rama remota llamada origin que apunta al repositorio de donde clonamos el proyecto, en este caso apunta a nuestro fork en github:</p> <pre><code>$ git remote show origin\n* remote origin\n  Fetch URL: git@github.com:miusuario/miniblog.git\n  Push  URL: git@github.com:miusuario/miniblog.git\n  HEAD branch (remote HEAD is ambiguous, may be one of the following):\n    develop\n    master\n  Remote branches:\n    develop tracked\n    master  tracked\n  Local branch configured for 'git pull':\n    master merges with remote master\n  Local ref configured for 'git push':\n    master pushes to master (up to date)\n</code></pre> <p>Tambi\u00e9n por convenio, la rama remota que hace referencia al repositorio original se llama upstream y se crea de la siguiente manera:</p> <pre><code>$ git remote add upstream git@github.com:sgomez/miniblog.git\n$ git remote show upstream\n* remote upstream\n  Fetch URL: git@github.com:sgomez/miniblog.git\n  Push  URL: git@github.com:sgomez/miniblog.git\n  HEAD branch: master\n  Remote branches:\n    develop new (next fetch will store in remotes/upstream)\n    master  new (next fetch will store in remotes/upstream)\n  Local ref configured for 'git push':\n    master pushes to master (local out of date)\n</code></pre> <p>En este caso, la URI debe ser siempre la del proyecto original. Y ahora para incorporar actualizaciones, usaremos el merge en dos pasos:</p> <pre><code>$ git fetch upstream\n$ git merge upstream/master\n</code></pre> <p>Recordemos que fetch solo trae los cambios que existan en el repositorio remoto sin hacer ning\u00fan cambio en nuestro repositorio. Es la orden merge la que se encarga de que todo est\u00e9 sincronizado. En este caso decimos que queremos fusionar con la rama master que est\u00e1 en el repositorio upstream.</p>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#creando-nuevas-funcionalidades","title":"Creando nuevas funcionalidades","text":"<p>Vamos a crear una nueva funcionalidad: vamos a a\u00f1adir una licencia de uso. Para ello preferentemente crearemos una nueva rama.</p> <pre><code>$ git checkout -b add-license\n$ echo \"LICENCIA MIT\" &gt; LICESE    #\u00a0el error es intencionado\n$ git add LICESE\n$ git commit -m \"Archivo de licencia de uso\"\n</code></pre> <p>En principio habr\u00eda que probar que todo funciona bien y entonces integraremos en la rama master de nuestro repositorio y enviamos los cambios a Github:</p> <pre><code>$ git checkout master\n$ git merge add-license --no-ff\n\n$ git push --set-upstream origin add-license    # Enviamos la rama a nuestro repositorio origin\n</code></pre> <p>Si volvemos a Github, veremos que nos avisa de que hemos subido una nueva rama y si queremos crear un pull request.</p> <p></p> <p>Pulsamos y entramos en la petici\u00f3n de Pull Request. Este es el momento para revisar cualquier error antes de enviar al due\u00f1o del repositorio. Como vemos hemos cometido uno, nombrando el fichero, si lo correguimos debemos hacer otro push para ir actualizando la rama. Cuando est\u00e9 lista volvemos aqu\u00ed y continuamos. Hay que dejar una descripci\u00f3n del cambio que vamos a hacer.</p> <p></p> <p>Una vez hemos terminado y nos aseguramos que todo est\u00e1 correcto, pulsamos Send pull request y le llegar\u00e1 nuestra petici\u00f3n al due\u00f1o del proyecto.</p> <p></p> <p>Sin embargo, para esta prueba, no vamos a cambiar el nombre del archivo y dejaremos el error como est\u00e1. As\u00ed de esta manera al administrador del proyecto le llegar\u00e1 el Pull Request y la lista de cambios. Ahora en principio, cabr\u00eda esperar que el administrador aprobara los cambios, pero podr\u00eda pasar que nos indicara que cambiemos algo. En ese caso solo habr\u00eda que modificar la rama y volverla a enviar.</p> <pre><code>$ git mv LICESE LICENSE\n$ git commit -m \"Fix: Nombre de archivo LICENSE\"\n$ git push\n</code></pre> <p>Ahora s\u00ed, el administrador puede aprobar la fusi\u00f3n y borrar la rama del repositorio. El panel de Github permite aceptar los cambios directamente o informa de como hacer una copia de la rama ofrecida por el usuario para hacer cambios, como puede verse en la siguiente imagen.</p> <p></p> <p>Una vez que se han aceptado los cambios, podemos borrar la rama y actualizar nuestro repositorio con los datos del remoto como hicimos antes. \u00bfPor qu\u00e9 actualizar desde el remoto y no desde nuetra rama add-license? Pues porque usualmente el administrador puede haber modificado los cambios que le hemos propuesto, o incluso una tercera persona. Recordemos el cariz colaborativo que tiene Github.</p> <pre><code>$ git checkout master\n$ git branch -d add-license\n# Esto borra la rama local\n$ git push origin --delete add-license\n# Esto borra la rama remota. Tambi\u00e9n puede hacerse desde la web.\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#todo-esto-es-algo-complicado","title":"Todo esto es algo complicado...","text":"<p>S\u00ed, lo es, al menos al principio. Git tiene una parte muy sencilla que es el uso del repositorio local (\u00f3rdenes tales como add, rm, mv y commit). El siguiente nivel de complejidad lo componen las \u00f3rdenes para trabajar con ramas y fusionarlas (checkout, branch, merge, rebase) y por \u00faltimo, las que trabajan con repositorios remotos (pull, push, fetch, remote). Adem\u00e1s hay otra serie de \u00f3rdenes para tener informaci\u00f3n (diff, log, status) o hacer operaciones de mantenimiento (fsck, gc). Lo importante para no perderse en Git, es seguir la siguiente m\u00e1xima:</p> <p>No avanzar al siguiente nivel de complejidad, hasta no haber entendido completamente el anterior.</p> <p>Muy poco sentido tiene ponernos a crear ramas en github si a\u00fan no entendemos c\u00f3mo se crean localmente y para que deben usarse. En la parte de referencias hay varios manuales en l\u00ednea, incluso tutoriales interactivos. Tambi\u00e9n hay mucha documentaci\u00f3n disponible en Github que suele venir muy bien explicada. En caso de que tengamos un problema que no sepamos resolver, una web muy buena es StackOverflow. Es una web de preguntas y respuestas para profesionales; es muy dif\u00edcil que se os plantee una duda que no haya sido ya preguntada y respondida en esa web. Eso s\u00ed, el ingl\u00e9s es imprescindible.</p>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#ultimo-paso-documentacion","title":"\u00daltimo paso, documentaci\u00f3n.","text":"<p>Github permite crear documentaci\u00f3n. En primer lugar, generando un archivo llamado <code>README.md</code>. Tambi\u00e9n permite crear una web propia para el proyecto y, adem\u00e1s, una wiki. Para marcar el texto, se utiliza un lenguaje de marcado de texto denominado Markdown. En la siguiente web hay un tutorial interactivo: http://www.markdowntutorial.com/. Como en principio, no es necesario saber Markdown para poder trabajar con Git o con Github, no vamos a incidir m\u00e1s en este asunto.</p> <p>En el propio GitHub podemos encontrar algunas plantillas que nos sirvan de referencia.</p> <p>Algunos ejemplos:</p> <ul> <li>Plantilla b\u00e1sica</li> <li>Plantilla avanzada</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T10_colaboracion/#documentacion-del-curso","title":"Documentaci\u00f3n del curso","text":"<p>Esta documentaci\u00f3n est\u00e1 hecha en Markdown y pasada a HTML gracia a la herramienta mkdocs. La plantilla usada es Material for MkDocs.</p> <p>El material est\u00e1 publicado con licencia Atribuci\u00f3n-NoComercial 4.0 Internacional (CC BY-NC 4.0)</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/","title":"Flujo de trabajo con Git (git flow)","text":""},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#la-importancia-de-la-organizacion-del-flujo-de-trabajo","title":"La importancia de la organizaci\u00f3n del flujo de trabajo","text":"<p>En la introducci\u00f3n vimos los diferentes esquemas de organizaci\u00f3n externa de los repositorios (es decir, en lo relativo a los usuarios que componen el equipo de trabajo). </p> <p>Pero el repositorio en s\u00ed tambi\u00e9n tiene su esquema de organizaci\u00f3n.</p> <p>En los ejemplos hemos visto que usabamos una rama m\u00e1ster y cre\u00e1bamos ramas para a\u00f1adir funcionalidades que luego integr\u00e1bamos. Es un forma de trabajar de las muchas que hay propuestas, posiblemente la m\u00e1s simple, pero tiene el inconveniente de dejar la rama m\u00e1ster a expensas de una mala actualizaci\u00f3n y quedarnos sin una rama estable. Por eso, hay otras propuestas mejores que permiten separar el trabajo de desarrollo con el mantenimiento de las versiones estables. Una de las m\u00e1s conocidas es la propuesta por Vincent Driessen y que podemos ver en la figura siguiente.</p> <p></p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#las-ramas-principales","title":"Las ramas principales","text":"<p>En este esquema hay dos ramas principales con un tiempo de vida indefinido:</p> <ul> <li>master (origin/master): el c\u00f3digo apuntado por HEAD siempre contiene un estado listo para producci\u00f3n.</li> <li>develop (origin/develop): el c\u00f3digo apuntado por HEAD siempre contiene los \u00faltimos cambios desarrollados para la pr\u00f3xima versi\u00f3n del software. Tambi\u00e9n se le puede llamar rama de integraci\u00f3n. No es necesariamente estable.</li> </ul> <p>Cuando el c\u00f3digo de la rama de desarrollo es lo suficientemente estable, se integra con la rama master y una nueva versi\u00f3n es lanzada.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#las-ramas-auxiliares","title":"Las ramas auxiliares","text":"<p>Para labores concretas, pueden usarse otro tipo de ramas, las cuales tienen un tiempo de vida definido. Es decir, cuando ya no son necesarias se eliminan:</p> <ul> <li>Ramas de funcionalidad (feature branches)</li> <li>Ramas de versi\u00f3n (release branches)</li> <li>Ramas de parches (hotfix branches)</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#feature-branches","title":"Feature branches","text":"<ul> <li>Pueden partir de: develop</li> <li>Deben fusionarse con: develop</li> <li>Convenici\u00f3n de nombres: feature-NUMissue-*.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#release-branches","title":"Release branches","text":"<ul> <li>Pueden partir de: develop</li> <li>Deben fusionarse con: develop y master</li> <li>Convenici\u00f3n de nombres: release-*</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#hotfix-branches","title":"Hotfix branches","text":"<ul> <li>Pueden partir de: master</li> <li>Deben fusionarse con: develop y master</li> <li>Convenici\u00f3n de nombres: hotfix-*</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#la-extension-flow-de-git","title":"La extensi\u00f3n flow de Git","text":"<p>Una de las ventajas de Git es que, adem\u00e1s, es extensible. Es decir, se pueden crear nuevas \u00f3rdenes como si de plugins se tratara. Una de las m\u00e1s usadas es gitflow, que est\u00e1 basada en el art\u00edculo que hablamos al principio de este cap\u00edtulo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#instalacion","title":"Instalaci\u00f3n","text":"<p>Aunque la fuente original de la extensi\u00f3n es del mismo autor del art\u00edculo, el c\u00f3digo no se encuentra ya muy actualizado y hay un fork bastante m\u00e1s activo en petervanderdoes/gitflow. En el wiki del repositorio est\u00e1n las instrucciones de instalaci\u00f3n para distintos sistemas. Una vez instalados tendremos una nueva \u00f3rden: <code>git flow</code>.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#uso","title":"Uso","text":"<p>Para cambiar a las ramas master y develop, seguiremos usando <code>git checkout</code>, pero para trabajar con las ramas antes indicadas gitflow nos facilita las siguientes \u00f3rdenes:</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#-git-flow-init","title":"- git flow init:","text":"<p>Inicializa el espacio de trabajo. De forma autom\u00e1tica, crea las ramas que necesitamos y permite configurar el nombre de las mismas.</p> <pre><code>$ git flow init\nInitialized empty Git repository in ~/project/.git/\nNo branches exist yet. Base branches must be created now.\nBranch name for production releases: [master]\nBranch name for \"next release\" development: [develop]\n\nHow to name your supporting branch prefixes?\nFeature branches? [feature/]\nRelease branches? [release/]\nHotfix branches? [hotfix/]\nSupport branches? [support/]\nVersion tag prefix? []\n\n$ git branch\n* develop\n master\n</code></pre> <p>Podemos ver que por defecto (usando intro en vez de escribir nada) pone nombres por defecto a cada rama. Con <code>git branch</code> comprobamos que ramas existen y en cual nos encontramos.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#-git-flow-feature","title":"- git flow feature:","text":"<p>Permite crear y trabajar con ramas de funcionalidades.</p> <pre><code>$ git flow feature start feature_branch\n</code></pre> <p>As\u00ed creamos una rama 'feature/feature_branch' y nos mueve autom\u00e1ticamente a ella. En esta haremos los cambios que queramos en nuestro repositorio. Cuando queramos acabar de usar la rama, haremos un commit y la finalizaremos:</p> <pre><code>$ git flow feature stop feature_branch\n</code></pre> <p>Esto finaliza nuestra rama y la integra autom\u00e1ticamente a la rama develop. Si queremos seguir cambiando nuestro repositorio abriremos una nueva rama feature.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#-git-flow-release","title":"- git flow release:","text":"<p>Permite crear y trabajar con ramas de versiones. Cuando entendemos que despues de todas las funcionalidades (features, cambios en nuestro repositorio) nuestro trabajo esta listo para ser publicado, abriremos una rama release, que nacera de nuestra rama develop. </p> <pre><code>$ git flow release start 0.1.0\nSwitched to a new branch 'release/0.1.0'\n</code></pre> <p>Usaremos un tag para identificar de que release se trata. Ahora podemos hacer los cambios que estimemos oportuno para integrar todas las features que el repositorio ha sufrido hasta el momento. Tras hacer commit a todo el proceso, podemos cerrar la rama release.</p> <pre><code>$git flow release finish '0.1.0'\n</code></pre> <p>Esto la integrar\u00e1 de forma autom\u00e1tica con master (con esto finalizamos el proceso de 'subir a producci\u00f3n' nuestro codigo) y con la rama develop, para que las futuras features est\u00e9n al d\u00eda.</p>"},{"location":"Ud1%20Control%20de%20versiones/T11_gitflow/#-git-flow-hotfix","title":"- git flow hotfix:","text":"<p>Permite crear y trabajar con ramas de parches. Esto lo usaremos para hacer cambios rapidos que no puedan esperar a la proxima integracion de una release.</p> <pre><code>$ git flow hotfix start hotfix_branch\n</code></pre> <p>Tras hacer commit finalizamos la rama hotfix. Esta se fusionar\u00e1 con nuestra rama master y con nuestra rama develop para que esta tambi\u00e9n est\u00e9 al d\u00eda de los \u00faltimos cambios.</p> <pre><code>$ git flow hotfix finish hotfix_branch\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/","title":"Citar proyectos en GitHub","text":"<p>Extra\u00eddo de la gu\u00eda oficial de GitHub.</p> <p>A trav\u00e9s de una aplicaci\u00f3n de terceros (Zenodo, financiado por el CERN), es posible crear un DOI para uno de nuestros proyectos.</p> <p>Nota</p> <p>DOI significa \"Digital Object Identifier\" (Identificador de Objeto Digital, en espa\u00f1ol). Es un sistema \u00fanico y permanente de identificaci\u00f3n alfanum\u00e9rica que se utiliza para identificar de manera \u00fanica y un\u00edvoca documentos digitales. Los DOI se utilizan com\u00fanmente para identificar y enlazar de manera \u00fanica a documentos acad\u00e9micos, como art\u00edculos de investigaci\u00f3n, informes t\u00e9cnicos, conjuntos de datos y otros tipos de contenidos digitales.</p> <p>Un DOI proporciona un enlace persistente a un objeto digital, lo que significa que el enlace deber\u00eda seguir siendo v\u00e1lido a lo largo del tiempo, incluso si la ubicaci\u00f3n f\u00edsica o la URL del objeto cambia. Esto es especialmente \u00fatil en el \u00e1mbito acad\u00e9mico y de la investigaci\u00f3n, donde la referencia y la citaci\u00f3n de trabajos anteriores son fundamentales.</p> <p>Los DOI son gestionados por organizaciones llamadas \"Registradores de DOI\", que asignan y mantienen estos identificadores. Cada DOI consta de un prefijo que identifica al registrador y un sufijo \u00fanico que identifica espec\u00edficamente el objeto digital.</p> <p>Cuando se encuentra un DOI, se puede utilizar para acceder r\u00e1pidamente al documento al que hace referencia, ya que se trata de un identificador \u00fanico y permanente.</p> <p>Estos son los pasos</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-1-elegir-un-repositorio","title":"Paso 1. Elegir un repositorio","text":"<p>Este repositorio debe ser abierto (p\u00fablico), o de lo contrario Zenodo no podr\u00e1 acceder al mismo. Hay que recordar escoger una licencia para el proyecto. Esta web puede ayudarnos http://choosealicense.com/.</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-2-entrar-en-zenodo","title":"Paso 2. Entrar en Zenodo","text":"<p>Iremos a Zenodo y haremos login con GitHub. Lo \u00fanico que tenemos que hacer en esta parte es autorizar a Zenodo a conectar con nuestra cuenta de GitHub.</p> <p>Important</p> <p>Si deseas archivar un repositorio que pertenece a una organizaci\u00f3n en GitHub, deber\u00e1s asegurarte de que el administrador de la organizaci\u00f3n haya habilitado el acceso de terceros a la aplicaci\u00f3n Zenodo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-3-seleccionar-los-repositorios","title":"Paso 3. Seleccionar los repositorios","text":"<p>En este punto, hemos autorizado a Zenodo para configurar los permisos necesarios para permitir el archivado y la emisi\u00f3n del DOI. </p> <p>En primer lugar ve al desplegable, arriba a la derecha, despliega y selecciona GitHub.</p> <p></p> <p>Para habilitar esta funcionalidad, simplemente haremos clic en el bot\u00f3n que est\u00e1 junto a cada uno de los repositorios que queremos archivar.</p> <p>Important</p> <p>Zenodo solo puede acceder a los repositorios p\u00fablicos, as\u00ed que debemos asegurarnos de que el repositorio que deseamos archivar sea p\u00fablico.</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-4-crear-una-nueva-release","title":"Paso 4. Crear una nueva release","text":"<p>Por defecto, Zenodo realiza un archivo de nuestro repositorio de GitHub cada vez que crea una nueva versi\u00f3n. </p> <p>Nota</p> <p>En GitHub, un \"release\" (lanzamiento) se refiere a una versi\u00f3n espec\u00edfica de un proyecto de software que se considera estable y lista para ser distribuida. Un release generalmente est\u00e1 asociado con un conjunto de cambios, nuevas caracter\u00edsticas, correcciones de errores y mejoras en el c\u00f3digo fuente del proyecto.</p> <p>Cuando un proyecto alcanza un punto en el que los desarrolladores consideran que ha alcanzado una cierta estabilidad y desean compartir una versi\u00f3n espec\u00edfica con los usuarios o colaboradores, pueden crear un release. Los releases en GitHub proporcionan una forma estructurada de empaquetar y distribuir versiones espec\u00edficas de un proyecto.</p> <p>Un release suele estar vinculado a una etiqueta espec\u00edfica en el repositorio de Git. Esta etiqueta marca un punto espec\u00edfico en la historia del c\u00f3digo fuente que se corresponde con la versi\u00f3n del release.</p> <p>Como a\u00fan no tenemos ninguna, tenemos que volver a la vista del repositorio principal y hacer clic en el elemento del encabezado de versiones (releases).</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-5-acunar-un-doi","title":"Paso 5. Acu\u00f1ar un DOI","text":"<p>Antes de que Zenodo pueda emitir un DOI para nuestro repositorio, deberemos proporcionar cierta informaci\u00f3n sobre el repositorio de GitHub que acaba de archivar.</p> <p>Una vez que estemos satisfechos con la descripci\u00f3n, heremos clic en el bot\u00f3n publicar.</p>"},{"location":"Ud1%20Control%20de%20versiones/T12_github-zenodo/#paso-6-publicar","title":"Paso 6. Publicar","text":"<p>De vuelta a nuestra p\u00e1gina de Zenodo, ahora deber\u00edamos ver el repositorio listado con una nueva insignia que muestra nuestro nuevo DOI.</p> <p>Tip</p> <p>Podemos colocar la insigna en nuestro proyecto. Para eso haremos clic en la imagen DOI gris y azul. Se abrir\u00e1 una ventana emergente y el texto que aparece como Markdown es el que deberemos copiar en nuestro archivo README.md.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/","title":"Comandos de git","text":"<p>Esta secci\u00f3n describe algunos de los comandos m\u00e1s interesantes de git</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-reserva","title":"Git stash (reserva)","text":"<p>La orden <code>git stash</code> nos permite salvar moment\u00e1neamente el espacio de trabajo cuando tenemos que cambiar de rama o preparar la rama actual para sincronizar cambios.</p> <p>Las operaciones m\u00e1s importantes que podemos hacer con <code>git stash</code> son:</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-save","title":"git stash save","text":"<p>Es equivalente a poner solo <code>git stash</code> pero nos permite realizar m\u00e1s acciones como:</p> <pre><code>git stash save \"Tu mensaje\"\ngit stash save -u\n</code></pre> <p>El par\u00e1metro <code>-u</code> permite que se almacen tambi\u00e9n los ficheros sin seguimiento previo (untracked en ingl\u00e9s, aquellos ficheros que no se han metido nunca en el repositorio).</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-list","title":"git stash list","text":"<p>Permite mostrar la pila del stash.</p> <pre><code>$ git stash list\nstash@{0}: On master: Stash con mensaje\nstash@{1}: WIP on master: 4ab21df First commit\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-apply","title":"git stash apply","text":"<p>Esta orden coge el stash que est\u00e1 arriba en la pila y lo aplica al espacio de trabajo actual. En este caso siempre es <code>stash@{0}</code>. El stash permanece en la pila.</p> <p>Se puede indicar como par\u00e1metro un stash en concreto.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-pop","title":"git stash pop","text":"<p>Funciona igual que <code>git apply</code> con la diferencia de que el stash s\u00ed se borra de la pila.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-show","title":"git stash show","text":"<p>Muestra un resumen de los ficheros que se han modificado en ese stash.</p> <pre><code>$ git stash show\nA.txt | 1 +\nB.txt | 3 +++\n2 file changed, 4 insertions(+)\n</code></pre> <p>Para ver los cambios podemos usar el par\u00e1metro <code>-p</code></p> <pre><code>$ git stash show -p\n--- a/A.txt\n+++ b/A.txt\n@@ -45,6 +45,7 @@ nav:\n+ This is a change\n</code></pre> <p>Por defecto siempre muestra la cabeza de la pila. Igual que en casos anteriores podemos indicar un stash en concreto.</p> <pre><code>$ git stash show stash@{1}\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-branch","title":"git stash branch","text":"<p>Permite crear una nueva rama a partir del \u00faltimo stash. Adem\u00e1s, el mismo es borrado de la pila. Se puede especificar uno en concreto si lo queremos, como en el resto de comandos.</p> <pre><code>git stash branch nombre-de-nueva-rama stash@{1}\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-clear","title":"git stash clear","text":"<p>Este comando borrar todos los stash de la pila. Es destructiva y no se puede deshacer.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-stash-drop","title":"git stash drop","text":"<p>Permite borrar un stash en concreto (o el \u00faltimo si no se indica ninguno). Como con clear, borrarlo implica que no se puede recuperar.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-worktree","title":"Git worktree","text":"<p>Uno de los problemas m\u00e1s habituales es tener que tocar una rama distinta a la que tenemos actualmente. Eso implica que si estamos en medio de un trabajo tendr\u00edamos que hacer un commit o un stash, lo cual a veces es bastante molesto.</p> <p>Con <code>git worktree</code> podemos crear un directorio de trabajo que contenga otra rama distinta, de forma temporal. No supone otro clon del repositorio porque ambos usan el mismo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-worktree-add","title":"git worktree add","text":"<p>Esta funci\u00f3n es la que crea el espacio de trabajo temporal. Imaginemos que estamos en una rama llamada <code>develop</code>:</p> <pre><code>$ git worktree add ../project-master master\n$ git worktree add -b fix ../project-fix master\n</code></pre> <p>La primera orden crea un directorio llamado project-master que contiene el estado de master. La segunda, que contiene el par\u00e1metro <code>-b</code> equivale a crear una nueva rama llamada fix, que se crea desde master (suponemos que no existe fix).</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-worktree-list","title":"git worktree list","text":"<p>Muestra el listado de directorios y espacios de trabajo.</p> <pre><code>$git worktree list\n/home/sergio/taller-de-git  3b63b4b [master]\n/home/sergio/fix           3b63b4b [fix]\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-worktree-remove","title":"git worktree remove","text":"<p>Borrar un espacio de trabajo. Hay que indicar el nombre entre corchetes que aparece en el listado</p> <pre><code>$ git worktree delete fix\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-worktree-prune","title":"git worktree prune","text":"<p>Una cuesti\u00f3n importante, es que las ramas que est\u00e9n desplegadas en otro espacio de trabajo, se encuentran bloqueadas y no se pueden desbloquear en otro distinto.</p> <p>Esto significa que si estamos trabajando en la rama developer, creamos otro worktree en otro directorio de la rama master, no podemos hacer pasar a master. No es posible tener la misma rama en varios espacios de trabajo.</p> <p>Si se ha borrado el directorio a mano (en vez de usando remove), eso no implica que el bloqueo desparezca. Con esta orden podemos hacer que git compruebe que los espacios de trabajo secundario se comprueben de nuevo para ver si siguen existiendo y se elimine el bloqueo.</p>"},{"location":"Ud1%20Control%20de%20versiones/T13_othercommands/#git-blame","title":"Git blame","text":"<p>Lo ideal en un equipo de desarrollo es que el c\u00f3digo pase por todas las manos para as\u00ed mejorar su calidad.</p> <p>Con git blame podemos saber qui\u00e9n fue el \u00faltimo en modificar una l\u00ednea concreta de c\u00f3digo, en qu\u00e9 commit y en qu\u00e9 fecha lo hizo.</p> <pre><code>$ git blame ejemplo.php\n33cdd02c (Sergio G\u00f3mez 2020-01-20 16:58:52 +0100  8)   name: \"material\"\n33cdd02c (Sergio G\u00f3mez 2020-01-20 16:58:52 +0100  9)   language: \"es\"\n</code></pre>"},{"location":"Ud1%20Control%20de%20versiones/T14_referencias/","title":"1.14 Terminolog\u00eda y referencias","text":""},{"location":"Ud1%20Control%20de%20versiones/T14_referencias/#terminologia","title":"Terminolog\u00eda","text":"<p>Al trabajar con git haremos uso de cierta terminolog\u00eda com\u00fan a todos los usuarios de este sistema. Aqu\u00ed tienes una lista de t\u00e9rminos que te servir\u00e1n de referencia en un futuro.</p> <p>Repositorio (\"repository\") : El repositorio es el lugar en el que se almacenan los datos actualizados e hist\u00f3ricos de cambios.</p> <p>Revisi\u00f3n (\"revision\") : Una revisi\u00f3n es una versi\u00f3n determinada de la informaci\u00f3n que se gestiona. Hay sistemas que identifican las revisiones con un contador (Ej. subversion). Hay otros sistemas que identifican las revisiones mediante un c\u00f3digo de detecci\u00f3n de modificaciones (Ej. git usa SHA1).</p> <p>Etiqueta (\"tag\") : Los tags permiten identificar de forma f\u00e1cil revisiones importantes en el proyecto. Por ejemplo se suelen usar tags para identificar el contenido de las versiones publicadas del proyecto.</p> <p>Rama (\"branch\") : Un conjunto de archivos puede ser ramificado o bifurcado en un punto en el tiempo de manera que, a partir de ese momento, dos copias de esos archivos se pueden desarrollar a velocidades diferentes o en formas diferentes de forma independiente el uno del otro.</p> <p>Cambio (\"change\") : Un cambio (o diff, o delta) representa una modificaci\u00f3n espec\u00edfica de un documento bajo el control de versiones. La granularidad de la modificaci\u00f3n que es considerada como un cambio var\u00eda entre los sistemas de control de versiones.</p> <p>Desplegar (\"checkout\") : Es crear una copia de trabajo local desde el repositorio. Un usuario puede especificar una revisi\u00f3n en concreto u obtener la \u00faltima. El t\u00e9rmino 'checkout' tambi\u00e9n se puede utilizar como un sustantivo para describir la copia de trabajo.</p> <p>Confirmar (\"commit\") : Confirmar es escribir o mezclar los cambios realizados en la copia de trabajo del repositorio. Los t\u00e9rminos 'commit' y 'checkin' tambi\u00e9n se pueden utilizar como sustantivos para describir la nueva revisi\u00f3n que se crea como resultado de confirmar.</p> <p>Conflicto (\"conflict\") : Un conflicto se produce cuando diferentes partes realizan cambios en el mismo documento, y el sistema es incapaz de conciliar los cambios. Un usuario debe resolver el conflicto mediante la integraci\u00f3n de los cambios, o mediante la selecci\u00f3n de un cambio en favor del otro.</p> <p>Cabeza (\"head\") : Tambi\u00e9n a veces se llama tip (punta) y se refiere a la \u00faltima confirmaci\u00f3n, ya sea en el tronco ('trunk') o en una rama ('branch'). El tronco y cada rama tienen su propia cabeza, aunque HEAD se utiliza a veces libremente para referirse al tronco.</p> <p>Tronco (\"trunk\") : La \u00fanica l\u00ednea de desarrollo que no es una rama (a veces tambi\u00e9n llamada l\u00ednea base, l\u00ednea principal o m\u00e1ster).</p> <p>Fusionar, integrar, mezclar (\"merge\") : Una fusi\u00f3n o integraci\u00f3n es una operaci\u00f3n en la que se aplican dos tipos de cambios en un archivo o conjunto de archivos. Algunos escenarios de ejemplo son los siguientes:</p> <ul> <li>Un usuario, trabajando en un conjunto de archivos, actualiza o sincroniza su copia de trabajo con los cambios realizados y confirmados, por otros usuarios, en el repositorio.</li> <li>Un usuario intenta confirmar archivos que han sido actualizado por otros usuarios desde el \u00faltimo despliegue ('checkout'), y el software de control de versiones integra autom\u00e1ticamente los archivos (por lo general, despu\u00e9s de preguntarle al usuario si se debe proceder con la integraci\u00f3n autom\u00e1tica, y en algunos casos s\u00f3lo se hace si la fusi\u00f3n puede ser clara y razonablemente resuelta).</li> <li>Un conjunto de archivos se bifurca, un problema que exist\u00eda antes de la ramificaci\u00f3n se trabaja en una nueva rama, y la soluci\u00f3n se combina luego en la otra rama.</li> <li>Se crea una rama, el c\u00f3digo de los archivos es independiente editado, y la rama actualizada se incorpora m\u00e1s tarde en un \u00fanico tronco unificado.</li> </ul>"},{"location":"Ud1%20Control%20de%20versiones/T14_referencias/#referencias","title":"Referencias","text":"<ul> <li>Aula de Software Libre de la Universidad de C\u00f3rdoba.</li> <li>Documentaci\u00f3n oficial en ingl\u00e9s.</li> <li>Documentaci\u00f3n oficial en espa\u00f1ol (quiz\u00e1s incompleta).</li> <li>Curso de Git (ingl\u00e9s). La mayor\u00eda de la documentaci\u00f3n de este manual est\u00e1 basada en este curso.</li> <li>Curso interactivo de Git (ingl\u00e9s).</li> <li>P\u00e1gina de referencia de todas las \u00f3rdenes de Git (ingl\u00e9s).</li> <li>Chuleta con las \u00f3rdenes m\u00e1s usuales de Git.</li> <li>Gitmagic (ingles y espa\u00f1ol). Otro manual de Git</li> <li>Art\u00edculo t\u00e9cnico: Un modelo exitoso de ramificaci\u00f3n en Git .</li> <li>Curso detallado y gratuito sobre Git y github</li> <li>Otra guia r\u00e1pida de git</li> <li>Gu\u00eda de estilos seg\u00fan Udacity</li> <li>Flujo de trabajo de Gitflow</li> <li>Libro Pro Git</li> </ul>"},{"location":"Ud2%20Contenedores/T01_introduction/","title":"Introducci\u00f3n","text":"<p>En esta unidad, realizaremos una introducci\u00f3n al concepto de contenedores. Nos centraremos en contenedores Linux y, en concreto, en la tecnolog\u00eda de Docker.</p> <p>Para ello vamos a utilizar los contenidos de este fant\u00e1stico curso:</p> <p>Introducci\u00f3n a los contenedores y a Docker</p> <p>Para nuestro curso estudiaremos con atenci\u00f3n los apartados:</p> <p>1 . Introducci\u00f3n</p> <p>2 . Conceptos previos</p> <pre><code>2.1. Virtualizaci\u00f3n\n\n2.2. \u00bfQu\u00e9 es una m\u00e1quina virtual?\n\n2.3. \u00bfQu\u00e9 es una m\u00e1quina virtual de proceso?\n\n2.4. \u00bfQu\u00e9 es un hipervisor?\n</code></pre> <p>3 . Contenedores</p> <pre><code>3.1. \u00bfQu\u00e9 son los contenedores?\n\n3.2. Analog\u00eda con contenedores de transporte mar\u00edtimo\n\n3.3. Contenedores para desarrollo y despliegue de aplicaciones\n\n3.4. Contenedores para despliegue de servicios\n\n3.5. Ventajas e inconvenientes del uso de contenedores\n\n3.6. En resumen \u00bfCuando es adecuado usar contenedores?\n</code></pre> <p>5 . Contenedores Docker</p> <pre><code>5.1. \u00bfQu\u00e9 es Docker?\n\n5.2. La arquitectura de Docker\n</code></pre> <p>Los siguientes cap\u00edtulos resultan interesantes aunque no los veremos ni evaluaremos en nuestro curso. Recomendamos una lectura de los mismos:</p> <p>4 . Contenedores en sistemas Linux</p> <pre><code>4.1. \u00bfEs nuevo el concepto de entornos privados en sistemas Unix?\n\n4.2. Sistemas privados modernos en Linux: contenedores\n\n4.3. \u00bfC\u00f3mo funcionan los contenedores modernos en Linux?\n\n4.4. \u00bfPuedo poner en marcha un contenedor Linux \u201cA mano\u201d?\n\n4.5. Los contenedores Linux \u00bfPueden funcionar en sistemas como Windows o MacOS?\n</code></pre> <p>5 . Contenedores Docker</p> <pre><code>5.3. Docker en sistemas Windows y MacOS\n\n5.4. Docker corriendo contenedores Windows Server Core y contenedores MacOS\n</code></pre> <p>8 . Conclusi\u00f3n</p> <p>9 . Bibliograf\u00eda</p> <p>10 . Licencias de elementos externos utilizados</p>"},{"location":"Ud2%20Contenedores/T02_installation/","title":"Instalaci\u00f3n","text":"<p>En el curso que estamos utilizando tenemos un cap\u00edtulo completo dedicado a la instalaci\u00f3n de Docker tanto en Linux, Windows y MacOSX. Puedes consultarlo aqu\u00ed:</p> <p>Instalaci\u00f3n de Docker</p> <p>Vamos a aprender a usar Docker sobre una distribuci\u00f3n Linux Debian como hemos hecho hasta ahora. Si cuentas con un sistema operativo Linux basado en Debian puedes seguir el curso directamente sobre tu S.O. Sino, te aconsejo crear una m\u00e1quina virtual en AWS con un Debian con opciones por defecto y seguir all\u00ed el curso. Recuerda, lo primero actualizar paquetes para contar con las \u00faltimas versiones disponibles:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\n</code></pre> <p>Puedes seguir las instrucciones de instalaci\u00f3n del PDF anterior. No obstante, yo te aconsejo que sigas el presente manual que te llevar\u00e1 a las instrucciones oficiales, m\u00e1s actualizadas.</p>"},{"location":"Ud2%20Contenedores/T02_installation/#disponibilidad","title":"Disponibilidad","text":"<p>Existe dos versiones de Docker, una libre y otra que no lo es. En nuestro curso nos ocuparemos exclusivamente de la primera: Docker CE (Community Edition).</p> <p>Docker CE est\u00e1 disponible para los siguientes sistemas GNU/Linux: CentOS, Debian, Fedora y Ubuntu. No todas est\u00e1n en m\u00faltiples arquitecturas, pero s\u00ed todas soportan x86_64/amd64. Si tienes otra arquitectura u otro sistema es mejor que uses una m\u00e1quina virtual para arrancar una distribuci\u00f3n compatible.</p> <p>Para m\u00e1s informaci\u00f3n sobre sistemas privativos soportados, leer la secci\u00f3n de plataformas soportadas de la documentaci\u00f3n oficial.</p>"},{"location":"Ud2%20Contenedores/T02_installation/#instalacion_1","title":"Instalaci\u00f3n","text":"<p>Debido a que, dependiendo de la distribuci\u00f3n, la forma de instalarlo difiere, es mejor consultar la documentaci\u00f3n oficial para saber como instalar Docker en tu m\u00e1quina.</p> <ul> <li>Ubuntu: https://docs.docker.com/install/linux/docker-ce/ubuntu/</li> <li>Debian: https://docs.docker.com/install/linux/docker-ce/debian/</li> <li>CentOS: https://docs.docker.com/install/linux/docker-ce/centos/</li> <li>Fedora: https://docs.docker.com/install/linux/docker-ce/fedora/</li> </ul> <p>Como hemos quedado nosotros usaremos una Debian sobre AWS. As\u00ed pues, sigue las instrucciones anteriores para dicha distribuci\u00f3n. No har\u00e1 falta que hagas la parte de \"Uninstall old versions\" ya que es una m\u00e1quina virtual reci\u00e9n instalada. Y utiliza la opcion \"Install using the apt repository\".</p> <p>Una vez finalizado el proceso comprueba que Docker engine CE se ha instalado correctamente con:</p> <pre><code>sudo docker version\n</code></pre> <p>Para saber si tienes Docker bien instalado, los tutoriales oficiales siempre te indican inicies un contenedor de ejemplo. Esto es lo que sucede:</p> <p>Example</p> <p>Los c\u00f3digos de ejemplo ir\u00e1n acompa\u00f1ados de una caja como esta para poder copiar y pegar los comandos.</p> <pre><code>sudo docker run hello-world\n</code></pre> <p>El resultado es el siguiente:</p> <pre><code>$ sudo docker run hello-world\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nd1725b59e92d: Pull complete \nDigest: sha256:0add3ace90ecb4adbf7777e9aacf18357296e799f81cabc9fde470971e499788\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n1. The Docker client contacted the Docker daemon.\n2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n$ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\nhttps://hub.docker.com/\n\nFor more examples and ideas, visit:\nhttps://docs.docker.com/get-started/\n</code></pre> <p>En la l\u00ednea 1 estamos ejecutando el cliente de Docker, y estamos indicando que queremos ejecutar un contenedor a partir de la imagen hello-world del registro p\u00fablico de Docker.</p> <p>Si es la primera vez que hemos ejecutado esa imagen, nos aparecer\u00e1 la l\u00ednea 2, que indica que la imagen no puede ser encontrada y va a proceder a buscarla, por defecto, en el registro p\u00fablico. Si tenemos conexi\u00f3n a Internet se descargar\u00e1 la imagen  (l\u00ednea 6) y autom\u00e1ticamente crear\u00e1 un contenedor.</p> <p>Tanto si se ha descargado la imagen o ya estaba descargada, el contenedor se ejecutar\u00e1, obteniendo el texto de bienvenida que se ve en el cuadro anterior.</p>"},{"location":"Ud2%20Contenedores/T02_installation/#post-instalacion","title":"Post instalaci\u00f3n","text":"<p>Para finalizar la instalaci\u00f3n vamos a hacer un par de cosas que nos simplificar\u00e1n la vida.</p>"},{"location":"Ud2%20Contenedores/T02_installation/#permitir-administrar-docker-a-un-usuario-sin-privilegios","title":"Permitir administrar Docker a un usuario sin privilegios","text":"<p>Si estamos usando Docker en nuestro ordenador personal, podemos configurar nuestro usuario para usar el cliente sin tener que poner sudo delante. Para ello ejecuta lo siguiente:</p> <p>Example</p> <p>A\u00f1ade tu usuario al grupo de docker.</p> <pre><code>sudo usermod -aG docker $USER\n</code></pre> <p>Para que los nuevos permisos surtan efecto, debes cerrar y volver a abrir la sesi\u00f3n. Para problemas relacionados con los permisos visitad la p\u00e1gina del manual oficial.</p>"},{"location":"Ud2%20Contenedores/T02_installation/#instalar-docker-compose","title":"Instalar Docker Compose","text":"<p>Tambi\u00e9n es necesario traer una herramienta llamada <code>Docker Compose</code>. Puedes instalarla con las instrucciones que hay en la p\u00e1gina de Instalaci\u00f3n de Docker Compose.</p> <p>Sin embargo, si usas Ubuntu o Debian puedes instalarlo de forma m\u00e1s f\u00e1cil con apt:</p> <p>Example</p> <p>Instalaci\u00f3n de Docker Compose:</p> <pre><code>sudo apt install docker-compose\n</code></pre> <p>Llegados a este punto deber\u00edamos tener todas las herramientas necesarias para seguir este curso.</p>"},{"location":"Ud2%20Contenedores/T03_principales_acciones/","title":"Principales acciones con Docker","text":"<p>En este apartado vamos a empezar a realizar acciones con Docker. Para ello seguiremos este documento.</p> <p>Principales acciones con Docker</p> <p>Para ir recordando los distintos comandos que vayamos usando imprime y ve marcando los comandos que uses en este CheatSheet:</p> <p>Cheatsheet</p>"},{"location":"Ud2%20Contenedores/T03_principales_acciones/#docker-exec","title":"Docker exec","text":"<p>En el apartado 9. E JECUTANDO COMANDOS EN UN CONTENEDOR CON \u201c DOCKER EXEC \u201d nos explica c\u00f3mo hacerlo pero no nos gu\u00eda para probarlo. Vamos a verlo aqu\u00ed.</p> <p>Vamos primero a crear un contenedor ubuntu y a lanzar una terminal. </p> <pre><code>docker run -it --name=ubuntu_pruebas ubuntu /bin/bash\nroot@e0f7b22e64d7:/#\n</code></pre> <p>F\u00edjate que el prompt ahora es \"root@e0f7b22e64d7:/#\", es decir, estamos trabajando dentro de nuestro contenedor. Vamos a ver qu\u00e9 hay dentro del directorio /tmp</p> <pre><code>root@e0f7b22e64d7:/# ls /tmp\n</code></pre> <p>Est\u00e1 vac\u00edo.</p> <p>Ahora abre en tu m\u00e1quina host otra terminal y con\u00e9ctate por ssh a la m\u00e1quina virtual AWS en la que estamos trabajando. Desde este otro terminal vamos a lanzar comandos a nuestro contenedor <code>ubuntu_pruebas</code>. A este otro terminal le llamaremos <code>terminal2</code> y al primero, en el que estamos trabajando directamente dentro del contenedor <code>terminal1</code>. Vamos a ejecutar en <code>terminal2</code> el primer comando que nos indica nuestro manual:</p> <pre><code>docker exec -d ubuntu_pruebas touch /tmp/prueba\n</code></pre> <p>En este ejemplo se ejecuta ejecuta en \u201cbackground\u201d, gracias al par\u00e1metro \u201c-d\u201d. Este ejemplo simplemente crea mediante el comando \u201ctouch\u201d un fichero \u201cprueba\u201d en \u201c/tmp\u201d.</p> <p>Ahora vuelve a <code>terminal1</code> y vuelve a comprobar si hay algo en /tmp</p> <pre><code>root@e0f7b22e64d7:/# ls /tmp\nprueba\n</code></pre> <p>Ahora deber\u00edas tener el fichero prueba que creaste con <code>docker exec</code>.</p> <p>Siguiendo con los comandos del manual vamos a conectarnos al contenedor en <code>terminal2</code>. Luego salimos con <code>exit</code>.</p> <pre><code>docker exec -it ubuntu_pruebas bash\nroot@e0f7b22e64d7:/# exit\nexit\n</code></pre> <p>Esta orden que ejecutar\u00e1 la \u201cshell\u201d bash en nuestra consola (gracias al par\u00e1metro \u201c-it\u201d se enlaza la entrada y salida est\u00e1ndar a nuestra terminal). A efectos pr\u00e1cticos, con esta orden accederemos a una \u201cshell\u201d bash dentro del contenedor.</p> <p>Seguimos con las pruebas. Vamos a crear una variable de entorno en el contenedor. Comando que establece un variable de entorno con el par\u00e1metro \u201c-e\u201d . Se enlaza la entrada y salida de la ejecuci\u00f3n del comando con \u201c-it\u201d . A efectos pr\u00e1cticos, en esa \u201cshell\u201d estar\u00e1 disponible la variable de entorno \u201cVAR\u201d con valor 1. Lo podemos probar con \u201cecho $VAR\u201d.</p> <pre><code>$ docker exec -it -e VAR=1 ubuntu_pruebas bash\nroot@e0f7b22e64d7:/# echo $VAR \n1\nroot@e0f7b22e64d7:/# exit\nexit\n$\n</code></pre>"},{"location":"Ud2%20Contenedores/T03_principales_acciones/#docker-cp","title":"Docker cp","text":"<p>En el apartado 10. COPIANDO FICHEROS ENTRE ANFITRI\u00d3N Y CONTENEDORES CON \u201c DOCKER CP \u201d nos explica como copiar ficheros entre la m\u00e1quina anfitri\u00f3n y el contenedor. Sustituye en los comandos <code>idcontainer</code> por el nombre que le hemos dado a nuestro contenedor <code>ubuntu_pruebas</code> para probar los distintos comandos. Puedes lanzar los comandos en <code>terminal2</code> y probar que los ficheros se guardan en el contenedor en <code>terminal1</code>.</p>"},{"location":"Ud2%20Contenedores/T03_principales_acciones/#docker-attach","title":"Docker attach","text":"<p>Para probar los comandos del apartado 11. A CCEDIENDO A UN PROCESO EN EJECUCI\u00d3N CON \u201c DOCKER ATTACH \u201d sal del contenedor <code>ubuntu_pruebas</code> en <code>terminal1</code>. Ahora no deber\u00edas estar dentro de ning\u00fan contenedor en ninguno de los 2 terminales que tienes abiertos.</p> <p>En <code>terminal1</code> lanzaremos el comando que nos propone el manual:</p> <pre><code>docker run -d --name=muchotexto busybox sh -c \"while true; do $(echo date) ; sleep 1; done\"\n</code></pre> <p>Ahora en <code>terminal2</code> ejecuta el comando:</p> <pre><code>docker attach muchotexto\n</code></pre> <p>Vemos c\u00f3mo hemos anlazado la salida del contenedor <code>muchotexto</code> a la salida estandar del <code>terminal2</code> y vemos la salida del comando que se est\u00e1 ejecutando en el contendor.</p>"},{"location":"Ud2%20Contenedores/T03_principales_acciones/#docker-logs","title":"Docker logs","text":"<p>Para probar este comando mant\u00e9n el contenedor <code>muchotexto funcionando</code>. En <code>terminal2</code> ejecuta:</p> <pre><code>docker logs -f --until=2s muchotexto\n</code></pre> <p>Una vez finalices la parte te\u00f3rica prueba a realizar esta pr\u00e1ctica para afianzar conocimientos:</p> <p>Caso pr\u00e1ctico 01- Pr\u00e1ctica de comandos en contenedor Docker</p>"},{"location":"Ud2%20Contenedores/T04_images/","title":"Im\u00e1genes","text":"<p>Las im\u00e1genes son la base de Docker. Nuestros contenedores se iniciar\u00e1n a partir de ellas. Como se indic\u00f3 en la introducci\u00f3n, es una plantilla de solo lectura, que se crea incorporando los requisitos necesarios para cumplir el objetivo para el cual fue creada.</p> <p>Por ejemplo, si estamos creando un proyecto con PHP, incorporar\u00e1 el int\u00e9rprete del lenguaje de PHP. Si es una p\u00e1gina web, incorporar\u00e1 el servidor web (apache, nginx, etc.).</p> <p>En este apartado vamos a ver el manejo de im\u00e1genes con Docker. Para ello seguiremos este documento.</p> <p>Im\u00e1genes Docker</p> <p>Para ir recordando los distintos comandos que vayamos usando imprime y ve marcando los comandos que uses en este CheatSheet:</p> <p>Cheatsheet</p> <p>Una vez finalices la parte te\u00f3rica prueba a realizar estas dos pr\u00e1cticas para afianzar conocimientos:</p>"},{"location":"Ud2%20Contenedores/T04_images/#caso-practico-01-creando-una-imagen-ubuntu-con-nano","title":"Caso pr\u00e1ctico 01 - Creando una imagen Ubuntu con nano","text":"<p>Caso pr\u00e1ctico 01 - Creando una imagen Ubuntu con nano</p>"},{"location":"Ud2%20Contenedores/T04_images/#caso-practico-02-apache-2-con-php-desde-alpine","title":"Caso pr\u00e1ctico 02 - Apache 2 con PHP desde Alpine","text":"<p>Caso pr\u00e1ctico 02 - Apache 2 con PHP desde Alpine</p> <p>Warning</p> <p>Esta pr\u00e1ctica despliega un servidor web APACHE con Php. Todav\u00eda no hemos visto el tema de servidores web as\u00ed que no te preocupes por los detalles referentes al servidor web. Lo importante de esta pr\u00e1ctica es ver c\u00f3mo usa los distintos comandos en el Dockerfile ADD, RUN, EXPOSE... Lo que va detr\u00e1s no es necesario que lo entiendas ahora</p> <p>En esta pr\u00e1ctica, en el punto 2 ver\u00e9is que el Dockerfile contiene la l\u00ednea \"ADD ./start.sh /start.sh\". Ten\u00e9is que crear en el mismo directorio donde est\u00e1 el Dockerfile un archivo <code>start.sh</code> con este contenido:</p> <pre><code>#/bin/sh\n#Lanzamos servicio Apache2 en segundo plano\n/usr/sbin/httpd -D FOREGROUND\n</code></pre> <p>En el punto 3. Probando la imagen te propone lanzar la aplicaci\u00f3n sobre el puerto 80 de nuestra m\u00e1quina. Si ese puerto ya estuviera usado por otra aplicaci\u00f3n te podr\u00eda dar problemas. En ese caso puedes lanzarlo sobre el puerto 8080 con el comando:</p> <pre><code>docker run -d -p 8080:80 alpineapache\n</code></pre> <p>En este caso para acceder despu\u00e9s desde el navegador tendr\u00edas que usar:</p> <pre><code>http://localhost:8080\n</code></pre> <p>Recuerda que si estuvieras trabajando sobre una m\u00e1quina virtual en AWS Academy, deber\u00e1s abrir el puerto 8080 y sustituir localhost por la IP p\u00fablica de esa m\u00e1quina virtual.</p>"},{"location":"Ud2%20Contenedores/T05_volumes/","title":"Persistiendo datos","text":"<p>Por defecto ya hemos indicado que un contenedor est\u00e1 aislado de todo. Hemos visto como podemos conectar el contenedor a un puerto de red para poder acceder a \u00e9l. Eso incluye al sistema de archivos que contiene. De tal manera que si se elimina el contenedor, se eliminan tambi\u00e9n sus archivos.</p> <p>Si queremos almacenar datos (una web, una base de datos, etc.) dentro de un contenedor necesitamos una manera de almacenarlos sin perderlos.</p> <p>Docker ofrece tres maneras:</p> <ul> <li>A trav\u00e9s de vol\u00famenes, que son objetos de Docker como las im\u00e1genes y los contenedores.</li> <li>Montando un directorio de la m\u00e1quina anfitri\u00f3n dentro del contenedor.</li> <li>Almacen\u00e1ndolo en la memoria del sistema (aunque tambi\u00e9n se perder\u00edan al reiniciar el servidor).</li> </ul> <p>Lo normal es usar vol\u00famenes, pero habr\u00e1 ocasiones en que es preferible montar directamente un directorio de nuestro espacio de trabajo. Por ejemplo, para guardar los datos de una base de datos usaremos vol\u00famenes, pero para guardar el c\u00f3digo de una aplicaci\u00f3n o de una p\u00e1gina web montaremos el directorio.</p> <p>La raz\u00f3n para esto \u00faltimo es que tanto nuestro entorno de desarrollo como el contenedor tengan acceso a los archivos del c\u00f3digo fuente. Los vol\u00famenes, al contrario que los directorios montados, no deben accederse desde la m\u00e1quina anfitri\u00f3n.</p>"},{"location":"Ud2%20Contenedores/T05_volumes/#crear-un-volumen","title":"Crear un volumen","text":"<p>Como en la siguiente secci\u00f3n necesitaremos crear una base de datos para instalar un blog con WordPress vamos a crear un volumen donde guardar la informaci\u00f3n:</p> <pre><code>$ docker volume create wordpress-db\nwordpress-db\n</code></pre>"},{"location":"Ud2%20Contenedores/T05_volumes/#listar-volumenes","title":"Listar vol\u00famenes","text":"<p>Con <code>docker volume ls</code> podemos visualizar todos los vol\u00famenes disponibles.</p> <pre><code>$ docker volume ls\nDRIVER              VOLUME NAME\nlocal               wordpress-db\n</code></pre>"},{"location":"Ud2%20Contenedores/T05_volumes/#visualizar-volumenes","title":"Visualizar vol\u00famenes","text":"<p>Los vol\u00famenes se crean en un directorio del sistema y no es recomendable acceder a \u00e9l, no al menos mientras haya un contenedor us\u00e1ndolo. En cualquier caso, si queremos ver los metadatos de un volumen podemos usar <code>docker volume inspect</code></p> <pre><code>$ docker volume inspect wordpress-db \n[\n    {\n        \"CreatedAt\": \"yyyy-mm-ddThh:ii:ss+Z\",\n        \"Driver\": \"local\",\n        \"Labels\": {},\n        \"Mountpoint\": \"/var/lib/docker/volumes/wordpress-db/_data\",\n        \"Name\": \"wordpress-db\",\n        \"Options\": {},\n        \"Scope\": \"local\"\n    }\n]\n</code></pre>"},{"location":"Ud2%20Contenedores/T05_volumes/#borrar-volumenes","title":"Borrar vol\u00famenes","text":"<p>Como todos los objetos de Docker, los vol\u00famenes tambi\u00e9n pueden ser borrados, pero solo si no est\u00e1n en uso. Mucha precauci\u00f3n al borrar los vol\u00famenes, porque perder\u00edamos todos los datos que contenga.</p> <p>Para borrar un contenedor usaremos <code>docker volume rm</code> y el nombre del volumen.</p> <pre><code>$ docker volume rm wordpress-db\n</code></pre>"},{"location":"Ud2%20Contenedores/T05_volumes/#para-saber-mas","title":"Para saber m\u00e1s","text":"<p>Se puede profundizar mucho m\u00e1s en el tema de vol\u00famenes en Docker, pero para el prop\u00f3sito de nuestro curso es suficiente con lo visto hasta aqu\u00ed. Si quieres profundizar m\u00e1s en el tema, as\u00ed como aprender c\u00f3mo trata Docker el \"Networking\" puedes consultar este documento.</p> <p>Redes Y vol\u00famenes</p> <p>En este cheatsheet tienes los principales comandos de vol\u00famenes y networking:</p> <p>Cheatsheet</p> <p>Y aqu\u00ed tienes esta pr\u00e1ctica para afianzar conocimientos:</p> <p>Caso pr\u00e1ctico 02 - Balanceo de carga con HAProxy</p>"},{"location":"Ud2%20Contenedores/T06_integrandovolsyconts/","title":"Integrar contenedores y vol\u00famenes","text":"<p>Ya tenemos suficientes conocimientos para montar un servicio completo usando Docker. Para ello vamos a necesitar levantar contenedores que trabajen juntos y accedan a vol\u00famenes para guardar los datos. </p> <p>En este caso vamos a montar un blog con WordPress. </p> <p>Atenci\u00f3n</p> <p>Lo importante de este cap\u00edtulo no es saber montar un Wordpress. Eso es solo un ejemplo y no necesitas saber c\u00f3mo se monta un Wordpress. Lo importante es saber crear los contenedores, enlazarlos entre ellos, usar un volumen. No te preocupes si no entiendes los detalles de los par\u00e1metros que se pasan a Wordpress. No es relevante.</p> <p>Wordpress es un servicio de blogs y p\u00e1ginas web que necesita para funcionar:</p> <ul> <li>PHP</li> <li>Una base de datos MySQL o MariaDB.</li> <li>Soporte HTTPS</li> </ul> <p>En una instalaci\u00f3n tradicional bastar\u00eda un servidor donde instalar\u00edamos PHP, una base de datos, un servidor web Apache o Nginx con soporte https y el propio servidor worpress. La base de datos se almacenar\u00eda en el sistema de archivos del propio servidor. Los ficheros de configuraci\u00f3n y las p\u00e1ginas que se fueran creando se almacenar\u00edan tambi\u00e9n en el propio servidor.</p> <p>Pero en el despliegue con contenedores usaremos:</p> <ul> <li>Un contenedor, que llamaremos wordpress, conendr\u00e1 el servidor Wordpress.</li> <li>Este contenedor almacenar\u00e1 los ficheros de configuraci\u00f3n y p\u00e1ginas que creemos en una carpeta de la m\u00e1quina host </li> <li>Otro contenedor, que llamaremos wordpress-db, contendr\u00e1 el sistema gestor de base de datos MariaDB. </li> <li>Dicho gestor MariaDB guardar\u00e1 la base de datos en un volumen docker, no en el propio contenedor. Usaremos el volumen creado en el cap\u00edtulo anterior y que llamamos vol-wordpress-db.</li> <li>Enlazaremos ambos contenedores wordpress y wordpres-db</li> </ul> <p>Importante</p> <p>Como vemos al hacer un despliegue en docker independizamos los servidores de los datos. De esta forma podremos actualizar el sistema a otra versi\u00f3n, o hacer pruebas de plugins o modificaciones simplemente creando o sustituyendo el contenedor del servidor por uno nuevo que acceda a los mismos datos.</p>"},{"location":"Ud2%20Contenedores/T06_integrandovolsyconts/#crear-el-volumen","title":"Crear el volumen","text":"<p>Empezaremos creando un volumen que se llame vol-wordpress-db</p> <pre><code>    $ docker volume create vol-wordpress-db\n</code></pre>"},{"location":"Ud2%20Contenedores/T06_integrandovolsyconts/#crear-un-contenedor-con-mariadb","title":"Crear un contenedor con MariaDB.","text":"<p>WordPress soporta los motores relaciones MySQL y MariaDB. Usaremos este \u00faltimo. Vamos a crear nuestra base de datos usando volumen el volumen que acabamos de crear para que guarde los datos.</p> <p><pre><code>docker run -d --name wordpress-db \\\n    --mount source=vol-wordpress-db,target=/var/lib/mysql \\\n    -e MYSQL_ROOT_PASSWORD=secret \\\n    -e MYSQL_DATABASE=wordpress \\\n    -e MYSQL_USER=manager \\\n    -e MYSQL_PASSWORD=secret \\\n    mariadb:10.3.9\n</code></pre> La imagen se descargar\u00e1, si no lo estaba ya, y se iniciar\u00e1 nuestro contenedor de MariaDB:</p> <pre><code>docker run -d --name wordpress-db \\\n    --mount source=vol-wordpress-db,target=/var/lib/mysql \\\n    -e MYSQL_ROOT_PASSWORD=secret \\\n    -e MYSQL_DATABASE=wordpress \\\n    -e MYSQL_USER=manager \\\n    -e MYSQL_PASSWORD=secret \\\n    mariadb:10.3.9\nUnable to find image 'mariadb:10.3.9' locally\n10.3.9: Pulling from library/mariadb\n124c757242f8: Pull complete \n9d866f8bde2a: Pull complete \nfa3f2f277e67: Pull complete \n398d32b153e8: Pull complete \nafde35469481: Pull complete \n31f2ae82b3e3: Pull complete \n3eeaf7e45ea6: Pull complete \n716982328e17: Pull complete \n34ce605c9036: Pull complete \n4502ed9073c0: Pull complete \n2afafbdf5a96: Pull complete \n43d52b11dd31: Pull complete \n30c7b70556f3: Pull complete \n8b1b39f2f89a: Pull complete \n41480b9319d7: Pull complete \nDigest: sha256:b7894bd08e5752acdd41fea654cb89467c99e67b8293975bb5d787b27e66ce1a\nStatus: Downloaded newer image for mariadb:10.3.9\n30634831d17108aa553a5774e27f398760bdbdf32debc3179843e73aa5957956\n\n$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\n30634831d171        mariadb:10.3.9      \"docker-entrypoint.s\u2026\"   20 seconds ago      Up 16 seconds       3306/tcp            wordpress-db\n</code></pre> <p>Analicemos las distintas partes del comando.</p> <ul> <li> <p>Lo primero que habremos notado es que el contenedor ya no se queda en primer plano. El par\u00e1metro <code>-d</code> indica que debe ejecutarse como un proceso en segundo plano. As\u00ed no podremos pararlo por accidente con <code>Control+C</code>.</p> </li> <li> <p>Lo segundo es que vemos que el contenedor usa un puerto, el <code>3306/tcp</code>, pero no est\u00e1 enlazado a ning\u00fan puerto de la m\u00e1quina anfitri\u00f3n. Nosotros no hemos usado el par\u00e1metro <code>-p PUERTOANFITRION:PUERTOCONTENEDOR</code> como en otros casos ni hemos dicho en la configuraci\u00f3n nada respecto al puerto a exponer. Esa informaci\u00f3n ya est\u00e1 en la imagen que usamos. Con esta configuraci\u00f3n no tenemos forma de acceder a la base de datos directamente. Nuestra intenci\u00f3n es que solo el contenedor de WordPress (que crearemos a continuaci\u00f3n) pueda acceder. En este caso el puerto 3306/tcp, por el que se accede al servidor de MariaDB se est\u00e1 exponiendo, es decir, haci\u00e9ndolo disponible solo a otros contenedores. Ni siquiera se podr\u00e1 acceder desde la m\u00e1quina anfitri\u00f3n.</p> </li> <li> <p>Luego una serie de par\u00e1metros <code>-e</code> que nos permite configurar nuestra base de datos pas\u00e1ndole variables de entorno al contenedor. Como dijimos anteriormente no nos preocupan estos par\u00e1metros, aunque son bastante autoexplicativos.</p> <p>Info</p> <p>Los contenedores se configuran a trav\u00e9s de variables de entorno, que podemos configurar con el par\u00e1metro <code>-e</code> que vemos en la orden anterior. Gracias a ellos hemos creado una base de datos, un usuario y configurado las contrase\u00f1as.</p> <p>Se recomienda buscar en el registro de Docker la imagen oficial de MariaDB para entender el uso de los par\u00e1metros.</p> </li> <li> <p>Por \u00faltimo, el par\u00e1metro <code>--mount</code> nos permite enlazar el volumen vol-wordpress-db que creamos en el paso anterior con el directorio <code>/var/lib/mysql</code> del contenedor. Ese directorio es donde se guardan los datos de MariaDB. Eso significa que si borramos el contenedor, o actualizamos el contenedor a una nueva versi\u00f3n, no perderemos los datos porque ya no se encuentran en \u00e9l, sino en el volumen. Solo lo perder\u00edamos si borramos expl\u00edcitamente el volumen.</p> <p>Warning</p> <p>Cada contendor que usemos tendr\u00e1 uno o varios directorios donde se deben guardar los datos no vol\u00e1tiles. Nos corresponde a nosotros conocer la herramienta y saber de qu\u00e9 directorios se tratan. Usualmente est\u00e1n en la documentaci\u00f3n del contenedor, pero no siempre.</p> <p>Info</p> <p>El par\u00e1metro <code>--mount</code> se empez\u00f3 a utilizar desde la versi\u00f3n <code>17.06</code> para contenedores independientes (los que no pertenecen a un enjambre o swarm). Los que conozcan Docker de versiones m\u00e1s antiguas estar\u00e1n m\u00e1s acostumbrados a usar el par\u00e1metro <code>--volume</code> que hace algo similar. Sin embargo la documentaci\u00f3n aconseja usar ya <code>--mount</code>, sobre todo para nuevos usuarios.</p> <p>Nosotros somos muy obedientes as\u00ed que en este taller usaremos <code>--mount</code>.</p> </li> <li> <p>Finalmente indicamos la imagen que vamos a usar: <code>mariadb:10.3.9</code>.</p> </li> </ul>"},{"location":"Ud2%20Contenedores/T06_integrandovolsyconts/#creando-nuestro-blog","title":"Creando nuestro blog","text":"<p>Vamos ahora a crear nuestro contenedor de WordPress, y a conectarlo con nuestra base de datos. Adem\u00e1s, queremos poder editar los ficheros de las plantillas, por si tenemos que modificar algo, as\u00ed que necesitaremos montar el directorio del contenedor donde est\u00e1 instalado WordPress con nuestra cuenta de usuario en la m\u00e1quina anfitri\u00f3n.</p> <p>Vamos a crear el espacio de trabajo en la m\u00e1quina anfitri\u00f3n donde estamos usando docker:</p> <pre><code>mkdir -p ~/Sites/wordpress/target &amp;&amp; cd ~/Sites/wordpress\n</code></pre> <p>Y dentro de este directorio arrancamos el contenedor:</p> <pre><code>docker run -d --name wordpress \\\n    --link wordpress-db:mysql \\\n    --mount type=bind,source=\"$(pwd)\"/target,target=/var/www/html \\\n    -e WORDPRESS_DB_USER=manager \\\n    -e WORDPRESS_DB_PASSWORD=secret \\\n    -p 8080:80 \\\n    wordpress:4.9.8\n</code></pre> <p>Revisa bien los distintos par\u00e1metros, la mayor\u00eda ya los hemos visto antes:</p> <ul> <li><code>-d</code> para lanzar en 2\u00ba plano</li> <li>--mount para enlazar un directorio en el contenedor con un directorio en la m\u00e1quina anfitri\u00f3n</li> <li>-e para definir par\u00e1metros en el contenedor</li> <li>-p 8080:80 para enlazar el puerto 8080 en el anfitri\u00f3n con el 80 en el contenedor.</li> </ul> <p>Pero encontramos un par\u00e1metro nuevo:</p> <ul> <li>--link wordpress-db:mysql: indica que este contenedor se vincula con otro llamado \"wordpress-db\", y permite que este contenedor lo referencie utilizando el alias \"mysql\".</li> </ul> <p>Info</p> <p>Puedes encontrar toda la informaci\u00f3n referente a esta imagen en DockerHub buscando la imagen wordpress.</p> <p>Pero insisto, no se trata de saber montar un Wordpress, sino de aprender c\u00f3mo usar contenedores que se enlazan, usan un volumen, etc.</p> <p>Cuando termine la ejecuci\u00f3n, si accedemos a la direcci\u00f3n http://localhost:8080/, ahora s\u00ed podremos acabar el proceso de instalaci\u00f3n de nuestro WordPress. Recuerda que si accedes desde un navegador en un equipo distinto al que est\u00e1s lanzando los contenedores deber\u00e1s usar <code>http://IPSERVER:8080</code> sustituyendo IPSERVER por la IP de tu m\u00e1quina anfitri\u00f3n.</p> <p>Si listamos el directorio target comprobaremos que tenemos todos los archivos de instalaci\u00f3n accesibles desde el directorio anfitri\u00f3n.</p> <p>Ejercicios</p> <p>Ejercicios:</p> <ol> <li>Para los contenedores, tanto wordpress como wordpress-db.</li> <li>Borra ambos.</li> <li>Comprueba que sigue existiendo el volumen vol-wordpress-db que contiene la base de datos.</li> <li>Comprueba que sigue existiendo el directorio ~/Sites/worpress/target en la m\u00e1quina anfitri\u00f3n con los ficheros de configuraci\u00f3n.</li> <li>Vuelve a crear el contenedor wordpress-db pero actualizando la versi\u00f3n de MariaDb. Usa la imagen mariadb:11.</li> <li>Vuelve a crear el contenedor wordpress pero actualizando la versi\u00f3n de Wordpress. Usa la imagen wordpress:5.0.0-apache.</li> <li>Vuelve a acceder a tu wordpress y comprueba lo que ha costado actualizar la versi\u00f3n y c\u00f3mo se han mantenido los datos de la base de datos y de los ficheros guardados en el anfitri\u00f3n.</li> <li>Vuelve a borrarlos y borra tambi\u00e9n el volumen y el contenido de ~/Sites/worpress/target</li> <li>Vuelve a crear el volumen y los contenedores y comprueba que ahora s\u00ed hay que volver a instalar WordPress. Ahora puedes hacerlo con la versi\u00f3n latest de ambos servidores.</li> </ol> <p>Nota</p> <p>Si intentas actualizar a las versiones latest de ambos servidores sin eliminar el volumen y los ficheros en ~/Sites/worpress/target no te funcionar\u00e1. Probablemente en alg\u00fan cambio de versi\u00f3n, bien de MariaDB o de Wordpress, cambi\u00f3 la forma de almacenar la informaci\u00f3n y se perdi\u00f3 la compatibilidad hacia atr\u00e1s, con lo que no son capaces de leer los datos existentes</p>"},{"location":"Ud2%20Contenedores/T06_integrandovolsyconts/#para-saber-mas","title":"Para saber m\u00e1s","text":"<p>Para los efectos de este curso es suficiente con lo visto hasta aqu\u00ed. Pero si quieres saber m\u00e1s y estudiaste el documento de \"Para saber m\u00e1s\" de la secci\u00f3n anterior donde profundizaba en vol\u00famenes y redes docker, puedes hacer la pr\u00e1ctica siguiente.</p> <p>En esta pr\u00e1ctica hace lo mismo que hemos visto anteriormente pero no usa el par\u00e1metro --link para enlazar los contenedores. A partir de Docker 1.13, el uso de --link ha sido desaconsejado en favor de la creaci\u00f3n de redes para conectar contenedores.</p> <p>Caso pr\u00e1ctico 01 - Wordpress + MySQL</p>"},{"location":"Ud2%20Contenedores/T07_docker-compose/","title":"Docker Compose","text":"<p>En el cap\u00edtulo anterior hemos levantado un Wordpress usado el cliente de Docker para crear los contenedores, as\u00ed como para crear el resto de objetos y vincularlos entre s\u00ed. Si recuerdas los comandos son complejos y extensos. Adem\u00e1s hemos de ejecutar primero la creaci\u00f3n del contenedor con la base de datos y luego el contenedor con Wordpress. Vemos que ser\u00eda mucho m\u00e1s c\u00f3modo poder configurarlo todo en un solo archivo y lanzar todos los contenedores, convenientemente enlazados, con un solo comando. </p> <p>Para automatizar la creaci\u00f3n, inicio y parada de un contenedor o un conjunto de ellos, Docker proporciona una herramienta llamada Docker Compose.</p> <p>Para esta parte vamos a levantar el mismo Wordpress del cap\u00edtulo anterior pero usando esta herramienta. Empezaremos por detener y borrar lo que hemos creado:</p> <pre><code>    docker container stop wordpress wordpress-db\n    docker container rm wordpress wordpress-db\n    docker volume rm vol-wordpress-db\n    sudo rm -R -f ~/Sites/wordpress/target/*\n</code></pre>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#docker-compose_1","title":"Docker Compose","text":"<p>Compose es una herramienta para definir y ejecutar aplicaciones multi-contenedor. Con un solo comando podremos crear e iniciar todos los servicios que necesitamos para nuestra aplicaci\u00f3n.</p> <p>Los casos de uso m\u00e1s habituales para docker-compose son:</p> <ul> <li>Entornos de desarrollo</li> <li>Entornos de testeo autom\u00e1ticos (integraci\u00f3n cont\u00ednua)</li> <li>Despliegue en host individuales (no clusters)</li> </ul> <p>Compose tiene comandos para manejar todo el ciclo de vida de nuestra aplicaci\u00f3n:</p> <ul> <li>Iniciar, detener y rehacer servicios.</li> <li>Ver el estado de los servicios.</li> <li>Visualizar los logs.</li> <li>Ejecutar un comando en un servicio.</li> </ul>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#creacion-de-contenedores-automatizada","title":"Creaci\u00f3n de contenedores automatizada","text":"<p>En el mismo directorio donde est\u00e1bamos en el paso anterior (<code>~/Sites/wordpress</code>), vamos a crear un fichero llamado <code>docker-compose.yaml</code> con el siguiente contenido:</p> <pre><code>version: '3'\n\nservices:\n    db:\n        image: mariadb:10.3.9\n        volumes:\n            - data:/var/lib/mysql\n        environment:\n            - MYSQL_ROOT_PASSWORD=secret\n            - MYSQL_DATABASE=wordpress\n            - MYSQL_USER=manager\n            - MYSQL_PASSWORD=secret\n    web:\n        image: wordpress:4.9.8\n        depends_on:\n            - db\n        volumes:\n            - ./target:/var/www/html\n        environment:\n            - WORDPRESS_DB_USER=manager\n            - WORDPRESS_DB_PASSWORD=secret\n            - WORDPRESS_DB_HOST=db\n        ports:\n            - 8080:80\n\nvolumes:\n    data:\n</code></pre> <p>Info</p> <p>YAML es un lenguaje de serializaci\u00f3n de datos dise\u00f1ado para ser le\u00eddo y escrito por personas. Se recomienda que sigas alg\u00fan tutorial para entender su formato: Aprende YAML en Y minutos.</p> <p>Los ficheros de Compose est\u00e1n divididos en tres secciones: services, volumes y networks; y deben indicar un n\u00famero de versi\u00f3n de Docket compose que estamos usando. Nos permite realizar practicamente lo mismo que podemos hacer con el cliente de docker, pero de forma autom\u00e1tica.</p> <p>     Fuente: https://medium.com/@laurap_85411/docker-compose-stop-vs-down-e4e8d6515a85</p> <p>Note</p> <p>En este taller no entramos en el apartado de networks.</p> <p>Con este fichero podemos hacer lo mismo que hemos hecho en el cap\u00edtulo anterior, pero con la ventaja de describir todos nuestros requisitos en un solo archivo.</p>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#iniciar-servicios","title":"Iniciar servicios","text":"<p>Vamos a ejecutar esta aplicaci\u00f3n y luego procederemos a explicarla:</p> <p>Example</p> <p>Arranca la aplicaci\u00f3n con Compose:</p> <pre><code>docker-compose up -d\n</code></pre> <p>Cuando arrancamos la aplicaci\u00f3n, Compose nos informa de los servicios que ha ido levantando:</p> <pre><code>$ docker-compose up -d\nCreating network \"wordpress_default\" with the default driver\nCreating volume \"wordpress_data\" with local driver\nCreating wordpress_db_1 ... \nCreating wordpress_db_1 ... done\nCreating wordpress_web_1 ... \nCreating wordpress_web_1 ... done\n</code></pre> <p>El par\u00e1metro <code>-d</code> es similar al que hemos visto en <code>docker run</code>: nos permite levantar los servicios en segundo plano.</p> <p>Veamos los contenedores activos:</p> <p><pre><code>$ docker ps\nCONTAINER ID  IMAGE            COMMAND      CREATED         STATUS         PORTS                  NAMES\na07b5d4d3982  wordpress:4.9.8  \"docker.s\u2026\"  10 seconds ago  Up 8 seconds   0.0.0.0:8080-&gt;80/tcp   wordpress_web_1\nd9204884cec5  mariadb:10.3.9   \"docker.s\u2026\"  11 seconds ago  Up 10 seconds  3306/tcp               wordpress_db_1\n</code></pre> Tambi\u00e9n podemos ver los contenedores con Compose:</p> <p><pre><code>$ docker-compose ps\n    Name                    Command               State          Ports        \n-------------------------------------------------------------------------------\nwordpress_db_1    docker-entrypoint.sh mysqld      Up      3306/tcp            \nwordpress_web_1   docker-entrypoint.sh apach ...   Up      0.0.0.0:8080-&gt;80/tcp\n</code></pre> Lo que tenemos que tener en cuenta es lo siguiente:</p> <ul> <li><code>docker-compose ps</code> solo muestra informaci\u00f3n de los servicios que se define en <code>docker-compose.yaml</code>, mientras que <code>docker ps</code> muestra todos.</li> <li>Cuando creamos contenedores con <code>docker</code> sin indicar un nombre, por defecto asigna uno aleatorio; mientras que en Compose el prefijo es el nombre del directorio en que se encuentra el fichero .yaml y el sufijo el nombre del servicio: wordpress_db_1. El n\u00famero final indica el n\u00famero de instancia. Es posible levantar m\u00e1s de una instancia de un mismo servicio.</li> </ul> <p>Si accedemos a la direcci\u00f3n http://localhost:8080/, veremos de nuevo la instalaci\u00f3n de WordPress.</p> <p>Warning</p> <p>Recuerda que si est\u00e1s trabajando en AWS Academy y accedes a la EC2 desde tu PC host, deber\u00e1s sustituir localhost por la IP p\u00fablica de tu EC2.</p> <p>F\u00edjate bien que accedemos a wordpress con http y no https. Los navegadores modernos intentar\u00e1n usar https si no les dices lo contrario. </p> <p>Recuerda que deber\u00e1s crear una regla de entrada en el \"grupo de seguridad\" que usa tu EC2 de AWS para permitir el acceso a la m\u00e1quina por http.</p>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#detener-servicios","title":"Detener servicios","text":"<p>Podemos detener servicios con</p> <pre><code>docker-compose stop\n</code></pre>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#borrar-servicios","title":"Borrar servicios","text":"<p>Podemos borrar servicios con</p> <pre><code>docker-compose down\n</code></pre> <p>Esto borra los contenedores, pero no los vol\u00famenes. As\u00ed que si hemos creado bien la aplicaci\u00f3n nuestros datos est\u00e1n a salvo.</p> <p>Si queremos borrar tambi\u00e9n los vol\u00famenes:</p> <pre><code>docker-compose down -v\n</code></pre>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#estructura-de-la-configuracion","title":"Estructura de la configuraci\u00f3n","text":"<p>Veamos la configuraci\u00f3n por partes:</p> <pre><code>version: '3'\n</code></pre> <p>Compose se actualiza a menudo, con lo que el archivo de configuraci\u00f3n va adquiriendo nuevas funcionalidades. La versi\u00f3n '3' (es una cadena, importante poner comillas) es la \u00faltima en el momento de escribir estas notas. Para conocer todas sus caracter\u00edsticas mira la p\u00e1gina de referencia de la versi\u00f3n 3 de Compose.</p> <pre><code>volumes:\n    data:\n</code></pre> <p>Ya hemos indicado que es importante guardar los datos vol\u00e1tiles de las aplicaciones en vol\u00famenes. En este caso hemos creado un volumen llamado <code>data</code>. Recordemos que Compose siempre a\u00f1ade como prefijo el nombre del directorio, con lo que el nombre real del volumen es <code>wordpress_data</code>. Podemos comprobarlo con el cliente de docker como hicimos en el cap\u00edtulo de vol\u00famenes:</p> <p><pre><code>$ docker volume ls\nDRIVER              VOLUME NAME\nlocal               wordpress_data\n</code></pre> Nos saltamos la secci\u00f3n de redes (networks) y vamos a la secci\u00f3n de servicios, que son los contenedores que precisa o componen nuestra aplicaci\u00f3n.</p> <p>Primero la base de datos:</p> <p><pre><code>services:\n    db:\n        image: mariadb:10.3.9\n        volumes:\n            - data:/var/lib/mysql\n        environment:\n            - MYSQL_ROOT_PASSWORD=secret\n            - MYSQL_DATABASE=wordpress\n            - MYSQL_USER=manager\n            - MYSQL_PASSWORD=secret\n</code></pre> Despu\u00e9s de abrir la parte de servicios, el primer nivel indica el nombre del servicio <code>db</code>, que genera el contenedor <code>wordpress_db</code>. Lo que vemos a continuaci\u00f3n es lo mismo que hicimos en la secci\u00f3n anterior pero de forma parametrizada. Si recordamos, para levantar nuestra base de datos, indicamos la imagen (l\u00ednea 3), luego montamos los vol\u00famenes (l\u00ednea 4), y despu\u00e9s indicamos las variables de entorno que configuraban el contenedor (l\u00ednea 6).</p> <p>Es decir, lo anterior es equivalente, excepto por el nombre, a:</p> <pre><code>$ docker run -d --name wordpress-db \\\n        --mount source=wordpress-db,target=/var/lib/mysql \\\n        -e MYSQL_ROOT_PASSWORD=secret \\\n        -e MYSQL_DATABASE=wordpress \\\n        -e MYSQL_USER=manager \\\n        -e MYSQL_PASSWORD=secret mariadb:10.3.9\n</code></pre> <p>Y despu\u00e9s nuestro WordPress:</p> <pre><code>services:\n    web:\n        image: wordpress:4.9.8\n        depends_on:\n            - db\n        volumes:\n            - ./target:/var/www/html\n        environment:\n            - WORDPRESS_DB_USER=manager\n            - WORDPRESS_DB_PASSWORD=secret\n            - WORDPRESS_DB_HOST=db\n        ports:\n            - 8080:80\n</code></pre> <p>En este caso la equivalencia es al comando:</p> <p><pre><code>$ docker run -d --name wordpress \\\n    --link wordpress-db:mysql \\\n    --mount type=bind,source=\"$(pwd)\"/target,target=/var/www/html \\\n    -e WORDPRESS_DB_USER=manager \\\n    -e WORDPRESS_DB_PASSWORD=secret \\\n    -p 8080:80 \\\n    wordpress:4.9.8\n</code></pre> La equivalencia de los par\u00e1metros es la siguiente:</p> par\u00e1metro Docker par\u00e1metro Composer --link depends_on --mount volumes -e environment -p, --publish ports image <p>Note</p> <p>Si reiniciamos el ordenador, los contenedores estar\u00e1n detenidos (stop), podremos reiniciarlos con <code>docker start</code> o <code>docker-compose start</code>. Este es el comportamiento predeterminado y el que nos interesa en un entorno de desarrollo.</p> <p>Sin embargo, en otros entornos, o para casos concretos, igual queremos que un contenedor tenga el mismo estado en el que estaba antes de reiniciar la m\u00e1quina (iniciado o parado).</p> <p>Para eso usaremos el par\u00e1metro <code>restart</code>. En el caso de la base de datos de nuestro ejemplo, la configuraci\u00f3n quedar\u00eda como:</p> <p><pre><code>services:\n    db:\n        image: mariadb:10.3.9\n        restart: unless-stopped\n        volumes:\n            - data:/var/lib/mysql\n        environment:\n            - MYSQL_ROOT_PASSWORD=secret\n            - MYSQL_DATABASE=wordpress\n            - MYSQL_USER=manager\n            - MYSQL_PASSWORD=secret\n</code></pre> El equivalente en la consola ser\u00eda:</p> <pre><code>$ docker run -d --name wordpress-db \\\n    --restart unless-stopped\n    --mount source=wordpress-db,target=/var/lib/mysql \\\n    -e MYSQL_ROOT_PASSWORD=secret \\\n    -e MYSQL_DATABASE=wordpress \\\n    -e MYSQL_USER=manager \\\n    -e MYSQL_PASSWORD=secret mariadb:10.3.9\n</code></pre> <p>Otros valores son: <code>no</code> (por defecto), <code>always</code> y <code>on-failure</code>.</p>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#crear-nuestras-propias-aplicaciones-con-docker-compose","title":"Crear nuestras propias aplicaciones con docker compose","text":"<p>En este ejemplo hemos visto c\u00f3mo podemos montar un servicio a partir de im\u00e1genes docker que descargamos del repositorio, en este caso una imagen \"wordpress\" y una imagen \"mariadb\". Pero \u00bfse puede desplegar un servicio a partir de una aplicaci\u00f3n propia? Por supuesto que si, en este caso en lugar de decirle a docker compose la imagen a usar con:</p> <pre><code>`image: mariadb:10.3.9`\n</code></pre> <p>Usaremos</p> <pre><code>`build: .`\n</code></pre> <p>Y en el mismo directorio donde tenemos nuestro docker-compose.yaml incluiremos un fichero Dockerfile con los comandos para crear la imagen que necesitemos.</p> <p>Esto es solo un avance. Lo veremos con m\u00e1s detalle cuando veamos la unidad de \"Servidores de aplicaciones\"</p>"},{"location":"Ud2%20Contenedores/T07_docker-compose/#para-saber-mas","title":"Para saber m\u00e1s","text":"<p>Se puede profundizar mucho m\u00e1s en el tema de Docker compose, pero para el prop\u00f3sito de nuestro curso es suficiente con lo visto hasta aqu\u00ed. Si quieres profundizar m\u00e1s en el tema puedes consultar este documento.</p> <p>Docker Compose</p> <p>En este cheatsheet tienes los principales comandos de Docker Compose:</p> <p>Cheatsheet</p> <p>Y aqu\u00ed tienes un par de pr\u00e1cticas para afianzar conocimientos:</p> <p>Caso pr\u00e1ctico 01 - Wordpress + MySQL - Muy similar a lo hecho en el este cap\u00edtulo</p> <p>Caso pr\u00e1ctico 03 - Proxy Nginx y balanceo escalado con Docker Compose</p>"},{"location":"Ud2%20Contenedores/T09_tips/","title":"Trucos","text":""},{"location":"Ud2%20Contenedores/T09_tips/#portainer","title":"Portainer","text":"<p>Portainer es una gestor de contenedores a trav\u00e9s de una interfaz web. Para usarlo creamos un directorio donde guardar nuestro docker-compose.yaml.</p> <pre><code>mkdir -p ~/Sites/portainer\ncd ~/Sites/portainer\n</code></pre> <p>Guardamos el siguiente fichero como docker-compose.yaml en nuestro directorio:</p> <pre><code>version: '2'\n\nservices:\n  portainer:\n    image: portainer/portainer\n    command: -H unix:///var/run/docker.sock\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - portainer_data:/data\n    ports:\n      - 9000:9000\n\nvolumes:\n  portainer_data:\n</code></pre> <p>Y ejecutamos el contenedor:</p> <pre><code>docker-compose up -d\n</code></pre> <p>Ahora puedes acceder via web a http://IPSERVER:9000 y gestionar via web los contenedores e imagenes.</p>"},{"location":"Ud2%20Contenedores/T09_tips/#limpieza","title":"Limpieza","text":"<p>Para borrar objetos que no est\u00e1n en uso:</p> <p><pre><code>docker system prune\n</code></pre> Para borrar vol\u00famenes que no est\u00e1n asociados a ning\u00fan contenedor:</p> <pre><code>docker volume rm $(docker volume ls -q -f \"dangling=true\")\n</code></pre> <p>Para borrar contenedores que han terminado su ejecuci\u00f3n:</p> <pre><code>docker rm $(docker ps -q -f \"status=exited\")\n</code></pre> <p>Para borrar im\u00e1genes que no est\u00e1n etiquetadas:</p> <pre><code>docker rmi $(docker images -q -f \"dangling=true\")\n</code></pre>"},{"location":"Ud2%20Contenedores/T09_tips/#copias-de-seguridad","title":"Copias de seguridad","text":"<p>Para hacer una copia de seguridad:</p> <pre><code>docker run --rm -v /tmp:/backup \\\n    --volumes-from &lt;container-name&gt; \\\n    busybox tar -cvf /backup/backup.tar &lt;path-to-data&gt;\n</code></pre> <p>Para restaurar:</p> <pre><code>docker run --rm -v /tmp:/backup \\\n    --volumes-from &lt;container-name&gt; \n    busybox tar -xvf /backup/backup.tar &lt;path-to-data&gt;\n</code></pre>"},{"location":"Ud2%20Contenedores/T09_tips/#fuentes-de-esta-pagina","title":"Fuentes de esta p\u00e1gina:","text":"<ol> <li>https://codefresh.io/docker-tutorial/everyday-hacks-docker/</li> <li>http://blog.labianchin.me/2016/02/15/docker-tips-and-tricks</li> </ol>"},{"location":"Ud2%20Contenedores/T09_tips/#imagenes-base","title":"Im\u00e1genes base","text":"<p>Son las im\u00e1genes m\u00e1s conocidas por las que podemos usar para no partir desde cero para crear la nuestra.</p> <ul> <li>phusion/baseimage: 209mb</li> <li>centos: 200mb</li> <li>debian: 101mb</li> <li>ubuntu: 84mb</li> <li>alpine: 4.4mb</li> <li>busybox: 1.16mb</li> </ul>"},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/","title":"Im\u00e1genes","text":"<p>Las im\u00e1genes son la base de Docker. Nuestros contenedores se iniciar\u00e1n a partir de ellas. Como se indic\u00f3 en la introducci\u00f3n, es una plantilla de solo lectura, que se crea incorporando los requisitos necesarios para cumplir el objetivo para el cual fue creada.</p> <p>Por ejemplo, si estamos creando un proyecto con PHP, incorporar\u00e1 el int\u00e9rprete del lenguaje de PHP. Si es una p\u00e1gina web, incorporar\u00e1 el servidor web (apache, nginx, etc.).</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/#buscar-imagenes","title":"Buscar im\u00e1genes","text":"<p>Crear una imagen desde cero supone un esfuerzo demasiado grande, as\u00ed que lo normal es partir o usar una ya creada.</p> <p>Para ellos buscaremos en los registros, el lugar donde se almacenan. Hay un registro oficial (https://hub.docker.com), pero nada impide a otras organizaciones, o a nosotros mismo, tener un registro propio. Estos registros pueden ser privados o p\u00fablicos.</p> <p>Imaginemos que queremos crear una web con WordPress. Si buscamos en el registro encontraremos una imagen llamada wordpress, con la etiqueta oficial. La recomendaci\u00f3n es que siempre busquemos im\u00e1genes oficiales, est\u00e1n mantenidas y bien documentadas.</p> <p>En la p\u00e1gina encontraremos las diferentes opciones que tiene esta imagen para configurarla, aunque las veremos con m\u00e1s detalle m\u00e1s adelante.</p> <p>Por ahora iniciemos la imagen como se indica:</p> <p>Example</p> <p>Iniciar una imagen de WordPress:</p> <pre><code>docker run -p 8080:80 wordpress\n</code></pre> <p>Y comprobaremos como se inicia el contenedor:</p> <pre><code>$ docker run -p 8080:80 wordpress\nUnable to find image 'wordpress:latest' locally\nlatest: Pulling from library/wordpress\n802b00ed6f79: Pull complete \n59f5a5a895f8: Pull complete \n6898b2dbcfeb: Pull complete \n8e0903aaa47e: Pull complete \n2961af1e196a: Pull complete \n71f7016f79a0: Pull complete \n5e1a48e5719c: Pull complete \n7ae5291984f3: Pull complete \n725b65166f31: Pull complete \ne90b121f9520: Pull complete \nb5a272809bbd: Pull complete \nf045f3ae0e2b: Pull complete \n7f51c9ea2d8e: Pull complete \n5aa9d0ed164a: Pull complete \n8eea44e2bfc7: Pull complete \n48918885026e: Pull complete \n8ac3e8ada01a: Pull complete \nd3da911b920f: Pull complete \n94c7e0af5b20: Pull complete \ne1f39ac90dec: Pull complete \nDigest: sha256:7121cdf8e9f01816653a3b2d2f4fc7bfe1dab956f00db5c7e7689e5f1454029a\nStatus: Downloaded newer image for wordpress:latest\nWordPress not found in /var/www/html - copying now...\nComplete! WordPress has been successfully copied to /var/www/html\nAH00558: apache2: Could not reliably determine the server's fully qualified domain name,     using 10.17.0.1. Set the 'ServerName' directive globally to suppress this message\nAH00558: apache2: Could not reliably determine the server's fully qualified domain name,     using 10.17.0.1. Set the 'ServerName' directive globally to suppress this message\n[DDD mmm dd hh:mm:ss.iiiiii yyyy] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.25     (Debian) PHP/7.2.10 configured -- resuming normal operations\n[DDD mmm dd hh:mm:ss.iiiiii yyyy] [core:notice] [pid 1] AH00094: Command line: 'apache2     -D FOREGROUND'\n</code></pre> <p>Vemos en la l\u00ednea nueva un nuevo par\u00e1metro: <code>-p 8080:80</code>. Por defecto, un contenedor est\u00e1 totalmente aislado. Pero si estamos montando un blog con WordPress vamos a necesitar acceder a \u00e9l desde el navegador.</p> <p>Con el par\u00e1metro <code>-p</code>, versi\u00f3n corta de <code>--publish</code>, podemos indicar que estamos enlazando un puerto de la m\u00e1quina anfitri\u00f3n con el contenedor. En este caso estamos enlazando el puerto 8080 de la m\u00e1quina anfitri\u00f3n con el 80 del contenedor.</p> <p>Info</p> <p>No vamos a explicar todas las opciones posibles, el tutorial ser\u00eda demasiado largo. Puedes consultar la p\u00e1gina del manual con <code>man docker-run</code> o llamando a la ayuda desde el cliente con <code>docker run --help</code>.</p> <p>En este caso, el formato de <code>publish</code> es:</p> <pre><code>    -p, --publish ip:[hostPort]:containerPort | [hostPort:]containerPort\n        Publish a container's port, or range of ports, to the host.\n\n    Both hostPort and containerPort can be specified as a range.  When specifying ranges for both, the number of ports in ranges should be equal.\n\n    Examples: -p 1234-1236:1222-1224, -p 127.0.0.1:$HOSTPORT:$CONTAINERPORT.\n\n    Use docker port(1) to see the actual mapping, e.g. docker port CONTAINER $CONTAINERPORT.\n</code></pre> <p>Vamos a abrir la siguiente p\u00e1gina web en nuestro navegador:</p> <p>http://localhost:8080</p> <p>La cual nos mostrar\u00e1 el asistente de instalaci\u00f3n de WordPress, el cual no vamos a instalar porque necesitamos una base de datos que a\u00fan no tenemos.</p> <p></p> <p>En su lugar vamos a la consola e interrumpimos la ejecuci\u00f3n del contenedor con <code>Control+C</code>:</p> <pre><code>^C[DDD mmm dd hh:mm:ss.iiiiii yyyy] [mpm_prefork:notice] [pid 1] AH00169: caught SIGTERM, shutting down\n</code></pre>"},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/#gestion-de-imagenes","title":"Gesti\u00f3n de im\u00e1genes","text":""},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/#descarga","title":"Descarga","text":"<p>Las imagenes que nos descargamos se identifican, adem\u00e1s de por el nombre, por una versi\u00f3n. De esa manera podemos tener distintas versiones de una misma imagen. En la p\u00e1gina del registro de WordPress veremos una pesta\u00f1a con el nombre Tags, con las versiones disponibles.</p> <p>Para usar una en concreto se usa dos puntos seguido del nombre de la versi\u00f3n. Si no se indica nada, como hasta ahora, por defecto se descarga la etiquetada como latest.</p> <p>Podemos descargar im\u00e1genes con la orden <code>docker pull</code>:</p> <pre><code>$ docker pull wordpress:latest\nlatest: Pulling from library/wordpress\nDigest: sha256:7121cdf8e9f01816653a3b2d2f4fc7bfe1dab956f00db5c7e7689e5f1454029a\nStatus: Image is up to date for wordpress:latest\n\n$ \u00a0docker pull wordpress:php7.1\nphp7.1: Pulling from library/wordpress\n802b00ed6f79: Already exists \n59f5a5a895f8: Already exists \n6898b2dbcfeb: Already exists \n8e0903aaa47e: Already exists \n2961af1e196a: Already exists \n71f7016f79a0: Already exists \n5e1a48e5719c: Already exists \n7ae5291984f3: Already exists \n725b65166f31: Already exists \na2d738459b49: Pull complete \n24830994a3eb: Pull complete \nb3807dc98c17: Pull complete \n59365c2968b5: Pull complete \n36bea53859bb: Pull complete \na777908b01b4: Pull complete \nbd3efa4fff20: Pull complete \n662f2add84f7: Pull complete \n4340a5e4d9f8: Pull complete \n2dbeaf456768: Pull complete \nDigest: sha256:2cc529d3d4ac538f8565d18a893bd1308d6f5522422f4696d87267695f69702c\nStatus: Downloaded newer image for wordpress:php7.1\n</code></pre> <p>En el primer caso no hay descarga porque esa versi\u00f3n ya estaba descargada, en la segunda nos descargamos la versi\u00f3n de la imagen que usa php7.1 en vez de php7.2</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/#listado","title":"Listado","text":"<p>Para ver el listado de images disponibles usamos <code>docker images</code>:</p> <pre><code>$\u00a0docker images\nREPOSITORY   TAG     IMAGE ID      CREATED      SIZE\nwordpress    latest  ca0fefec932b  7 days ago   409MB\nwordpress    php7.1  37664bd9863e  7 days ago   400MB\nhello-world  latest  4ab4c602aa5e  2 weeks ago  1.84kB\n</code></pre>"},{"location":"Ud2%20Contenedores/_TallerUd7_04_images/#borrado","title":"Borrado","text":"<p>Si queremos dejar de usar alguna imagen usaremos <code>docker rmi</code>:</p> <pre><code>$\u00a0docker rmi wordpress:php7.1 \nUntagged: wordpress:php7.1\nUntagged: wordpress@sha256:2cc529d3d4ac538f8565d18a893bd1308d6f5522422f4696d87267695f69702c\nDeleted: sha256:37664bd9863efe67a83cb2ff293f1816a9b5f918668ae19ca36b2af3d3b9f62d\nDeleted: sha256:77c97f008777c89455c8e5f248a626b192b62cf07ed1993c9acdfab73be210ee\nDeleted: sha256:14f58345b0bb2efaede03f9424412dce141ea275343305a79952c9c8bda3d1ba\nDeleted: sha256:5902e2becea5be6d672e8a6a84cc66a2f3b8e1b209302a9995de2b9afac8535f\nDeleted: sha256:a5b592bce0a767eed15cce29e5e4a941341a0b8de1633ab8836079c03af31b9e\nDeleted: sha256:6cc2318a4f6975aa87358d9f2852d8b91b335515a1d42ef141af368ee0b6fc05\nDeleted: sha256:c3c8b98ead26315e76cd9625fd59f67cab81afa7810b84a229f4e612097a3db4\nDeleted: sha256:a641d6d5a4f43b035946f9a82c9f126189e8502567bb17c41d25e922a5b314a3\nDeleted: sha256:a7338078acb6f6e8b1a152dabd6e7e47b3e530e1f2e2169b8b69127c9578f8fe\nDeleted: sha256:8f416a21cdea7d5b42d6b799ab4ade2dffe1f6a3b9d83dd02be47a82699922de\nDeleted: sha256:53862f425fbc706f70bd1238a0e929bf6d648547481acfad4910c4c1bde39b95\n</code></pre> <p>Warning</p> <p>Si una imagen est\u00e1 en uso por alg\u00fan contenedor, no nos dejar\u00e1 eliminarla.</p> <pre><code>$\u00a0docker rmi hello-world:latest\nError response from daemon: conflict: unable to remove repository reference \"hello-world:latest\" (must force) - container 5ae8bbb8768d is using its referenced image 4ab4c602aa5e\n</code></pre>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/","title":"Contenedores","text":"<p>Los contenedores son instancias de las im\u00e1genes que hemos creado o hemos descargado que se ejecutan de forma aislada.</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/#listado","title":"Listado","text":"<p>La orden para ver el listado de contenedores del sistema es <code>docker container ls</code> o la forma abreviada <code>docker ps</code>. Si lo ejecutamos nos dar\u00e1 un listado vac\u00edo porque no hay ning\u00fan contenedor activo.</p> <p>Probemos con el par\u00e1metro <code>--all</code> o <code>-a</code>.</p> <p><pre><code>$ docker container ls -a\nCONTAINER ID  IMAGE        COMMAND     CREATED         STATUS      PORTS  NAMES\n4bd76e08b07f  wordpress    \"docker-\u2026\"  11 minutes ago  Exited (0)         peaceful_murdock\n69a3c34c224d  hello-world  \"/hello\"    18 minutes ago  Exited (0)         blissful_goldwasser\n</code></pre> Estos contenedores est\u00e1n parados y se pueden volver a ejecutar, con el mismo estado que tuviera el sistema de archivos cuando se detuvieron.</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/#ejecutar-comandos-dentro-de-un-contenedor","title":"Ejecutar comandos dentro de un contenedor","text":"<p>Ya hemos usado <code>docker run</code> para crear e iniciar un contenedor. Tambi\u00e9n podemos usar este comando para ejecutar programas que est\u00e9n dentro del contenedor. Por ejemplo:</p> <pre><code>docker run --name ubuntu_bash --rm -i -t ubuntu bash\n</code></pre> <p>Info</p> <p>Las primeras versiones de Docker eran m\u00e1s limitadas, respecto a la creaci\u00f3n de objetos. As\u00ed que sali\u00f3 con comandos como <code>docker start</code>, <code>docker stop</code>, etc. relacionados con los contenedores. Cuando surgieron m\u00e1s objetos no hab\u00eda consistencia entre los comandos de otros objetos (como <code>docker volumes ls</code>) y los de los contenedores.</p> <p>As\u00ed que se ha creado una jerarqu\u00eda nueva de subcomandos bajo el comando <code>container</code> que son equivalentes y se mantienen por compatibilidad:</p> Antiguo Nuevo <code>docker run</code> <code>docker container run</code> <code>docker start</code> <code>docker container start</code> <code>docker stop</code> <code>docker container stop</code> <code>docker rm</code> <code>docker container rm</code> <code>docker inspect</code> <code>docker container inspect</code> <code>docker exec</code> <code>docker container exec</code> <p>No hay m\u00e1s diferencia entre ellos que el nombre.</p> <p>Pero esta forma de ejecutar cosas, crea un nuevo contenedor. Si queremos ejecutar un comando en un contenedor que ya est\u00e9 iniciado, debemos usar <code>docker container exec</code>.</p> <p>Ejecuta lo siguiente en otro terminal (no cierres el anterior).</p> <pre><code>docker exec -w /tmp ubuntu_bash touch my_file.sh\n</code></pre> <p>El par\u00e1metro <code>-w</code> indica el directorio de trabajo, despu\u00e9s indicamos el contenedor donde queremos ejecutar el comando (<code>ubuntu_bash</code>) y por \u00faltimo el comando a ejecutar (<code>touch my_file.sh</code>).</p> <p>Si en el primer terminal ejecutamos un listado del directorio tmp:</p> <p><pre><code># ls /tmp\nmy_file.sh\n</code></pre> Vemos como podemos modificar un contenedor ya iniciado con <code>docker container exec</code>.</p> <p>Pulsa <code>Control+C</code> en el primer terminal para cerrar y borrar el contenedor.</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/#iniciar-un-contenedor","title":"Iniciar un contenedor","text":"<p>Con <code>docker container start</code> podemos iniciar un contenedor parado:</p> <p><pre><code>$ docker container start peaceful_murdock \npeaceful_murdock\n$ docker ps\nCONTAINER ID  IMAGE      COMMAND    CREATED         STATUS  PORTS                 NAMES\n4bd76e08b07f  wordpress  \"docker\u2026\"  14 minutes ago  Up      0.0.0.0:8080-&gt;80/tcp  peaceful_murdock\n</code></pre> Veremos que la web de instalaci\u00f3n de WordPress est\u00e1 de nuevo disponible. Solo que ahora el contenedor se ejecuta en segundo plano y no lo podemos detener como antes.</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/#detener-un-contenedor","title":"Detener un contenedor","text":"<p>Con <code>docker container stop</code> podemos detener un contenedor iniciado, indicando su id o su nombre</p> <pre><code>$ docker container stop 4bd76e08b07f\n4bd76e08b07f\n</code></pre> <p>Tip</p> <p>Podemos hacer referencia a los contenedores por su ID o por su nombre.</p>"},{"location":"Ud2%20Contenedores/_TallerUd7_05_containers/#borrar-un-contenedor","title":"Borrar un contenedor","text":"<p>Un contenedor detenido ocupa espacio. Si hemos dejado de necesitar un contenedor podemos borrarlo con <code>docker container rm</code>. Igualmente hay que indicar id o nombre.</p> <pre><code>$ docker container rm 4bd76e08b07f\n4bd76e08b07f\n</code></pre> <p>Danger</p> <p>Hay que tener cuidado al borrar contenedores. Cuando un contenedor se borra se elimina cualquier informaci\u00f3n que contenga y no est\u00e9 almacenada en alg\u00fan lugar externo al propio contenedor.</p>"},{"location":"Ud3%20Servidores%20web/P01/","title":"Pr\u00e1ctica 3.1 \u2013 Instalaci\u00f3n y configuraci\u00f3n de servidores web","text":""},{"location":"Ud3%20Servidores%20web/P01/#instalacion-servidor-web-nginx","title":"Instalaci\u00f3n servidor web Nginx","text":"<p>Vamos a instalar el servidor Nginx en una VM Debian en AWS. Crear una nueva EC2 con las siguientes caracter\u00edsticas:</p> <ul> <li>Nombre: servidorNginx</li> <li>SO: Debian</li> <li>Tipo de instancia: t2.micro</li> <li>Par de clave: el que usas habitualmente</li> <li>Grupo de seguridad:<ul> <li>crea uno nuevo y ll\u00e1male \"ServidorWeb\"</li> <li>de momento habilita solo acceso por SSH</li> </ul> </li> </ul> <p>Primero actualizamos los repositorios y actualizamos el sistema para despu\u00e9s instalar el paquete correspondiente: </p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade\n\nsudo apt install nginx\n</code></pre> <p>Comprobamos que nginx se ha instalado y que est\u00e1 funcionando correctamente: </p> <pre><code>systemctl status nginx\n</code></pre> <p>Info</p> <p>Esta pr\u00e1ctica se ha hecho con Nginx 1.22.1-9</p>"},{"location":"Ud3%20Servidores%20web/P01/#comprobacion-de-la-instalacion","title":"Comprobaci\u00f3n de la instalaci\u00f3n","text":"<p>Igual que ocurre en Apache, todos los archivos que formar\u00e1n parte de un sitio web que servir\u00e1 nginx se organizar\u00e1n en carpetas. Estas carpetas, t\u00edpicamente est\u00e1n dentro de <code>/var/www</code>.</p> <p>Tras instalarlo podemos encontrar un ficher de muestra <code>/var/www/htm/index.nginx-debian.html</code> que nos permitir\u00e1 comprobar que el sistema est\u00e1 funcionando correctamente. Vamos a intentar acceder al servidor web instalado usando la IP p\u00fablica de la VM o bien la DNS de IPv4 p\u00fablica. Puedes obtenerlas en la consola de <code>Instancias</code> de AWS.</p> <p></p> <p>Haz clic en cualquiera de los enlaces o copia y pega en la barra de direcciones de tu navegador web. \u00bfConsigues acceder al servidor? \u00bfPor qu\u00e9 crees que ser\u00e1? Reflexiona brevemente antes de seguir leyendo.</p> <p>La respuesta es que el firewall de AWS est\u00e1 bloqueando los accesos. Si recuerdas, al configurar el \"Grupo de seguridad\" (firewall de AWS) le permitimos el acceso solo a SSH, pero no a HTTP ni a HTTPS. Vamos a hacerlo ahora. En la pesta\u00f1a seguridad busca \"Grupos de seguridad\" y observa c\u00f3mo s\u00f3lo el puerto 22 (ssh) est\u00e1 abierto como entrada. Haz click sobre el grupo de seguridad para editarlo.</p> <p></p> <p>En \"Reglas de entrada\" vamos a \"Editar reglas de entrada\"</p> <p></p> <p>Agrega nueva regla.</p> <p></p> <p>A\u00f1ade HTTP con origen \"Anywhere-IPv4\". Repite para HTTPS y \"Guarda reglas\"</p> <p></p> <p>Vuelve a intentar acceder al servidor haciendo clic sobre los enlaces en AWS. \u00bfPuedes acceder? Si no puedes, \u00bfpor qu\u00e9 crees que ser\u00e1? Comprueba el protocolo con el que est\u00e1s intentando acceder, \u00bfes http o https? Los enlaces en AWS intentan acceder al servidor usando https, pero no lo hemos activado todav\u00eda en nuestro servidor Nginx. Intenta acceder por http y si deber\u00edas acceder a la p\u00e1gina de muestra.</p> <p></p> <p>Comprueba que realmente est\u00e1s viendo la p\u00e1gina <code>/var/www/html/index.nginx-debian.html</code>. Editala para que muestre tu nombre en la bienvenida.</p> <p></p>"},{"location":"Ud3%20Servidores%20web/P01/#comprobar-registros-del-servidor","title":"Comprobar registros del servidor","text":"<p>Comprobad que las peticiones se est\u00e1n registrando correctamente en los archivos de logs, tanto las correctas como las err\u00f3neas: </p> <ul> <li> <p><code>/var/log/nginx/access.log</code>: cada solicitud a su servidor web se registra en este archivo de registro, a menos que Nginx est\u00e9 configurado para hacer algo diferente. </p> </li> <li> <p><code>/var/log/nginx/error.log</code>: cualquier error de Nginx se asentar\u00e1 en este registro.</p> </li> </ul> <p>Info</p> <p>Si no os aparece nada en los logs, podr\u00eda pasar que el navegador ha cacheado la p\u00e1gina web y que, por tanto, ya no est\u00e1 obteniendo la p\u00e1gina del navegador sino de la propia memoria. Para solucionar esto, pod\u00e9is acceder con el modo privado del navegador y ya os deber\u00eda registrar esa actividad en los logs.</p>"},{"location":"Ud3%20Servidores%20web/P01/#instalacion-servidor-web-apache","title":"Instalaci\u00f3n servidor web Apache","text":"<p>El otro servidor web con m\u00e1s presencia en el mercado es Apache en su versi\u00f3n Apache2.</p> <p>En esta pr\u00e1ctica crea una nueva EC2 en AWS con estas caracter\u00edsticas:</p> <ul> <li>Nombre: servidorApach</li> <li>SO: Debian</li> <li>Tipo de instancia: t2.micro</li> <li>Par de clave: el que usas habitualmente</li> <li>Grupo de seguridad: usa el que creaste para el servidor Nginx - \"ServidorWeb\"</li> </ul> <p>Atenci\u00f3n</p> <p>En AWS puedes reutilizar servicios, como un \"Grupo de seguridad\". En este caso tanto nuestro servidor Nginx como el Apache2 son servidores web a los que tendremos que abrir los mismos puertos, as\u00ed que podemos reutilizar el grupo de seguridad.</p> <p>En esta pr\u00e1ctica no te voy a guiar paso a paso. La instalaci\u00f3n es tan sencilla como <code>nginx</code> pero sustituyendo en los comandos <code>ngnix</code> por <code>apache2</code>. Instala y comprueba que el servicio est\u00e1 en marcha.</p> <p>Localiza el directorio donde Apache guarda las p\u00e1ginas web e identifica la p\u00e1gina que muestra por defecto tras la instalaci\u00f3n. Modif\u00edcala y comprueba el resultado.</p> <p></p>"},{"location":"Ud3%20Servidores%20web/P01/#instalacion-servidor-nginx-dockerizado","title":"Instalaci\u00f3n servidor Nginx dockerizado","text":""},{"location":"Ud3%20Servidores%20web/P01/#instalacion-a-partir-de-una-imagen-ubuntu","title":"Instalaci\u00f3n a partir de una imagen Ubuntu","text":"<p>Ahora ya sabemos instalar un servidor Nginx y crear un contenedor docker a partir de un Dockerfile. Vamos a crear un contenedor Docker a partir de una imagen Alpine instalando un servidor Nginx en su interior.</p> <p>Podr\u00edamos crear un contenedor Debian interactivo y ejecutar los comandos en su interior, pero ya aprendimos a crear un Dockerfile y hacerlo todo en un paso. As\u00ed pues, crearemos el siguiente Dockerfile:</p> <pre><code>FROM debian:latest\nMAINTAINER Jos\u00e9 Mu\u00f1oz &lt;j.munozjimeno@edu.gva.es&gt;\n\n# Actualizamos e instalamos Nginx\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; apt install -y nginx &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Exponemos el puerto 80\nEXPOSE 80\n\n# Comando para iniciar Nginx en primer plano\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>F\u00edjate que: </p> <ul> <li>Usamos <code>rm -rf /var/lib/apt/lists/*</code> para limpiar el tama\u00f1o de la cach\u00e9 y reducir el tama\u00f1o de la imagen</li> <li>La l\u00ednea CMD [\"nginx\", \"-g\", \"daemon off;\"] asegura que Nginx se ejecute en primer plano, lo que es fundamental en Docker.</li> </ul> <p>Ahora podemos crear nuestra imagen nginx a partir del Dockerfile con:</p> <pre><code>docker build -t servernginx .\n</code></pre> <p>Y una vez creada la imagen crear un contenedor con:</p> <pre><code>docker run --name=miservernginx -d -p 80:80 servernginx\n</code></pre> <p>Ahora prueba a acceder al servidor nginx dockerizado con <code>http://IPSERVIDOR</code>. Recuerda que si est\u00e1s usando docker en tu m\u00e1quina host puedes usas <code>http://localhost</code> pero si lo tienes en AWS tendr\u00e1s que sustituir la IPSERVIDOR por la IP p\u00fablica de la EC2 y asegurar que el Grupo de seguridad de esa EC2 tenga una regla de entrada que permita el acceso al puerto http - 80 -.</p> <p>Para ahora y borra el contenedor creado:</p> <pre><code>docker stop miservernginx \n\ndocker rm miservernginx  \n</code></pre> <p>Recordemos del tema de docker que no deb\u00edamos mantener los datos persistentes en el contenedor y que es recomendable guardarlos en un volumen docker o en un directorio de nuestra m\u00e1quina host si son datos de desarrollo. Las p\u00e1ginas web entran dentro de esta segunda categor\u00eda, as\u00ed que crearemos en nuestra m\u00e1quina host un directorio para guardar las p\u00e1ginas web y montaremos el directorio /var/www/html del contenedor en dicho directorio.</p> <pre><code>mkdir -p ~/web\n</code></pre> <p>Incluye dentro de ~/web un fichero index.html que visualizaremos despu\u00e9s y que contendr\u00e1 lo siguiente:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Servidor dockerizado!&lt;/title&gt;\n&lt;style&gt;\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Bienvendido al servidor web dockerizado!&lt;/h1&gt;\n&lt;p&gt; Este es un servidor web dockerizado &lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Ahora lanza nuevamente el docker run con los siguientes par\u00e1metros:</p> <pre><code>docker run -d --name=miservernginx \\\n    --mount type=bind,source=/home/admin/web,target=/var/www/html \\\n    -p 80:80 \\\n    servernginx\n</code></pre> <p>Atenci\u00f3n</p> <p>En la opci\u00f3n --mount estamos montando el directorio /var/www/html en el directorio host /home/admin/web. Si tu usuario no es <code>admin</code> deber\u00e1s cambiarlo por tu nombre de usuario.</p> <p>Deber\u00edas ver el fichero creado:</p> <p></p>"},{"location":"Ud3%20Servidores%20web/P01/#instalacion-a-partir-de-la-imagen-oficial-de-nginx","title":"Instalaci\u00f3n a partir de la imagen oficial de Nginx","text":"<p>En el apartado anterior hemos levantado un servidor Nginx a partir de una imagen Debian y hemos realizado la instalaci\u00f3n como har\u00edamos en cualquier servidor linux.</p> <p>Pero en dockerhub encontramos una imagen docker oficial de Nginx que puede acelerar la tarea. Y simplificarla o complicarla, ahora lo veremos.</p> <p>La imagen oficial est\u00e1 aqu\u00ed.</p> <p>Vamos a intentar crear nuestro servidor Nginx dockerizado simplemente usando el mismo comando que antes y cambiando la imagen a usar. Recuerda que los archivos html a mostrar los tenermos en <code>~/web</code>.</p> <pre><code>docker run -d --name=miservernginx2 \\\n    --mount type=bind,source=/home/admin/web,target=/var/www/html \\\n    -p 80:80 \\\n    nginx:latest\n</code></pre> <p>F\u00edjate que hemos cambiado el nombre del servidor y la imagen que usamos. </p> <p>Parece que todo va bien. Ahora accede a <code>http://IPSERVER</code> y comprueba que ves lo siguiente:</p> <p></p> <p>No vemos lo que esperamos. Eso es porque la imagen nginx est\u00e1 mostrando un fichero html que no es <code>~/web/index.html</code>. Por tanto, estamos mapeando /var/www/html pero la imagen Nginx no busca las im\u00e1genes en ese directorio. Podr\u00edamos buscar el directorio que usa la imagen de varias formas. Una de ellas es consultar la informaci\u00f3n oficial de la imagen en DockerHub. En el apartado \"How to use this image\" - \"Hosting som simle static content\" nos dice que el uso b\u00e1sico es:</p> <p><code>docker run --name some-nginx -v /some/content:/usr/share/nginx/html:ro -d nginx</code></p> <p>El par\u00e1metro -v realiza la misma funci\u00f3n que el  --mount que usamos nosotros anteriormente, montando un directorio local en uno del contenedor. Vemos que la segunda parte del par\u00e1metro es <code>/usr/share/nginx/html</code> y ese es el directorio que usa la imagen Nginx para guardar los archivos html. Por tanto, podemos crear nuestro contenedor as\u00ed:</p> <pre><code>docker run -d --name=miservernginx2 \\\n    --mount type=bind,source=/home/admin/web,target=/usr/share/nginx/html \\\n    -p 80:80 \\\n    nginx:latest\n</code></pre> <p>o bien, usando el par\u00e1metro -v que acabamos de aprender:</p> <pre><code>docker run -d --name=miservernginx2 \\\n    -v /home/admin/web:/usr/share/nginx/html:ro \\\n    -p 80:80 \\\n    nginx:latest\n</code></pre> <p>Vemos como le a\u00f1ade :ro al final para hacerlo \"read only\" y que el contenedor solo lea los archivos en nuestro directorio local, pero no pueda modificarlos.</p> <p>Comprueba si ahora el contenedor si est\u00e1 accediendo al directorio correcto y mostrando el archivo .html esperado.</p>"},{"location":"Ud3%20Servidores%20web/P01/#comprueba-lo-aprendido","title":"Comprueba lo aprendido.","text":"<p>Si has comprendido bien todo lo que hemos hecho hasta ahora no te ser\u00e1 dif\u00edcil lo que te voy a plantear a continuaci\u00f3n.</p> <p>Dockeriza un servidor Apache2 instalado en una m\u00e1quina Debian para que muestre los archivos en <code>~/web</code>.</p> <p>Pistas</p> <p>Primero configura el Dockerfile para crear una imagen llamada \"serverapache\" con el servidor apache2</p> <p>La l\u00ednea que lanza el servidor Apache2 en el Dockerfile es CMD [\"apache2ctl\", \"-D\", \"FOREGROUND\"]</p> <p>Crea un contenedor docker a partir de la imagen creada y comprueba que accedes a la web por defecto de Apache</p> <p>Cuando eso funcione borra el contenedor y vuelve a lanzarlo montando el directorio <code>~/web</code>. Ll\u00e1male \"miserverapache\".</p> <p>Una vez comprobado el funcionamiento para el contenedor \"miserverapache\".</p> <p>Ahora dockeriza un servidor apache como el anterior pero usando la imagen oficial de apache en dockerhub y ll\u00e1male \"miserverapache2\".</p> <p>Pistas</p> <p>El demonio de apache se llama <code>httpd</code>, as\u00ed que la imagen oficial de Apache 2 en dockerhub tiene ese mismo nombre.</p> <p>El comando es similar al que usaste para el servidor Nginx pero cambiando la ruta en la que el servidor apache2 buscar\u00e1 los archivos html. Podr\u00e1s encontrar la ruta en la documentaci\u00f3n de la imagen httpd en dockerhub.</p>"},{"location":"Ud3%20Servidores%20web/P02/","title":"Sitios virtuales","text":"<p>Un servidor web puede estar sirviendo varias p\u00e1ginas web que pueden pertenecer a varios usuarios. A cada una de ellas la denominaremos un \"sitio virtual\". Veamos c\u00f3mo podemos hacer que nuestro servidor sirva varias p\u00e1ginas.</p>"},{"location":"Ud3%20Servidores%20web/P02/#el-sitio-web-predeterminado","title":"El sitio web predeterminado","text":"<p>Cuando hemos instalado nuestro servidor web (sea Nginx o Apache2), se ha creado un sitio web predeterminado que se aloja en <code>/var/www/html</code>. Y si observamos sus permisos:</p> <pre><code>drwxr-xr-x  2 root root 4096 Oct 23 07:25 html\n</code></pre> <p>Por defecto esa carpeta y su contenido pertenecen a root y cualquiera puede entrar y leer. Esta es la configuraci\u00f3n m\u00e1s segura si nuestro servidor web solo va a leer archivos. Pero puede plantearnos problemas si el servidor va a permitir la subida de ficheros o la modificaci\u00f3n de archivos (por ejemplo a trav\u00e9s de un gestor de contenido como Wordpress)</p> <p>En el caso de Nginx, si ejecutamos un <code>ps -ef | grep nginx</code> observaremos 2 procesos:</p> <pre><code>root         415       1  0 18:13 ?        00:00:00 nginx: master process /usr/sbin/nginx -g daemon on; master_process on;\nwww-data     417     415  0 18:13 ?        00:00:00 nginx: worker process\n</code></pre> <p>Nginx sigue un modelo multiproceso compuesto por un proceso \"master\" y uno o varios procesos \"workers\".</p> <ul> <li>Master: inicia y controla los procesos trabajadores. Su funci\u00f3n principal es leer la configuraci\u00f3n de Nginx, gestionar las se\u00f1ales del sistema, y encargarse de la creaci\u00f3n y supervisi\u00f3n de los procesos trabajadores. El usuario debe de ser root.</li> <li>Worker: son los que manejan las conexiones entrantes, procesan las solicitudes y sirven el contenido. El proceso trabajador se ejecuta bajo el usuario www-data (un usuario sin privilegios), lo que reduce el riesgo de seguridad al manejar conexiones de red.</li> </ul> <p>El usuario www-data pertenece al grupo www-data. La configuraci\u00f3n por defecto en la que <code>/var/www/html</code> pertecen a root es la m\u00e1s segura, pero hace necesario que sea el administrador o un usuario con privilegios (sudo) quien actualice los ficheros de la web. Lo normal es que sea un desarrollador o un usuario normal quien actualice esos ficheros. Por tanto, una pr\u00e1ctica com\u00fan es hacer que el directorio pertenezca al usuario www-data (o un usuario est\u00e1ndar del sistema) y al grupo www-data. Para ello podemos hacer lo siguiente:</p> <pre><code>sudo chown -R www-data:www-data /var/www/html\n</code></pre> <p>En cuanto a los ficheros del grupo es importante que tengan los siguientes permisos:</p> <ul> <li> <p>Ficheros: 644 Esto permite que el propietario tenga permisos de lectura y escritura, y el grupo (es decir, www-data) y otros usuarios tengan solo permisos de lectura.</p> <ul> <li><code>sudo chmod 644 /var/www/html/index.html</code></li> </ul> </li> <li> <p>Directorios: 755 para que el servidor web pueda leer el contenido y navegar dentro de los directorios.</p> <ul> <li><code>sudo chmod 755 /var/www/html/images</code></li> </ul> </li> </ul> <p>Comprueba los permisos del fichero <code>index.nginx-debian.html</code> y como el servidor sigue sirviendo la p\u00e1gina web sin problemas.</p>"},{"location":"Ud3%20Servidores%20web/P02/#el-sitio-web-virtual","title":"El sitio web virtual","text":"<p>Al crear nuevos sitios virtuales vamos a suponer que cada sitio puede pertenecer a un usuario diferente y que solo \u00e9l tendr\u00e1 acceso a modificar los ficheros de su web. Vamos a hacer un ejemplo en el que seremos administradores de un servidor web que presta servicio a usuarios externos. A cada usuario le crearemos un usuario y le daremos un espacio de alojamiento para su sitio web.</p> <p>Empezaremos creando un sitio virtual que llamaremos \"sitio1\" y ser\u00e1 propiedad de \"usuario1\".</p> <p>Crearemos el \"usuario1\" y haremos que su grupo sea www-data:</p> <pre><code>sudo useradd -m usuario1\nsudo usermod -g www-data usuario1\nsudo passwd usuario1    #Y le daremos passwd \"usuario1\"\n</code></pre> <p>En segundo lugar crearemos el espacio para el sitio virtual y le asignaremos el propietario y grupo correcto:</p> <pre><code>sudo mkdir -p /var/www/sitio1\nsudo chown usuario1:www-data /var/www/sitio1\n</code></pre> <p>Y le daremos los permisos adecuados seg\u00fan vimos anteriormente: </p> <pre><code>sudo chmod 755 /var/www/sitio1\n</code></pre> <p>Ahora hagamos que \"usuario1\" cree su primera p\u00e1gina web <code>index.html</code> en <code>/var/www/sitio1</code> entrando como \"usuario1\":</p> <pre><code>su usuario1\nnano /var/www/sitio1/index.html\n</code></pre> <p>Y copiamos el siguiente contenido</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Sitio1!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Bienvendido al sitio1!&lt;/h1&gt;\n&lt;p&gt; Este es el sitio1 de usuario1&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Comprueba que los permisos del fichero son 644 como comentamos anteriormente, de forma que solo usuario1 puede modificarlo pero www-data podr\u00e1 leerlo.</p> <p>Ahora volvemos a nuestro usuario administrador para realizar las configuraciones en Nginx para poder visualizar ese sitio virtual.</p> <pre><code>exit\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P02/#modificamos-la-configuracion","title":"Modificamos la configuraci\u00f3n","text":"<p>Los archivos de configuraci\u00f3n de nginx los podemos encontrar en <code>/etc/nginx</code>.</p> <p></p> <p>En Nginx hay dos rutas importantes. La primera de ellas es <code>sites-available</code>, que contiene los archivos de configuraci\u00f3n de los hosts virtuales o bloques disponibles en el servidor. Es decir, cada uno de los sitios webs que alberga el servido. La otra es <code>sites-enabled</code>, que contiene los archivos de configuraci\u00f3n de los sitios habilitados, es decir, los que funcionan en ese momento. </p> <p>Dentro de <code>sites-available</code> hay un archivo de configuraci\u00f3n por defecto (default), que es la p\u00e1gina que se muestra si accedemos al servidor sin indicar ning\u00fan sitio web o cuando el sitio web no es encontrado en el servidor (debido a una mala configuraci\u00f3n por ejemplo). Esta es la p\u00e1gina que nos ha aparecido en el apartado anterior. </p> <p>Para que Nginx presente el contenido de nuestra web, es necesario crear un bloque de servidor con las directivas correctas. En vez de modificar el archivo de configuraci\u00f3n predeterminado directamente, crearemos uno nuevo en <code>/etc/nginx/sites-available/nombre_web</code>: </p> <pre><code>sudo nano /etc/nginx/sites-available/sitio1\n</code></pre> <p>Y el contenido de ese archivo de configuraci\u00f3n: </p> <pre><code>server {\n        listen 80;\n        listen [::]:80;\n        root /var/www/sitio1;\n        index index.html index.htm index.nginx-debian.html;\n        server_name sitio1;\n        location / {\n                try_files $uri $uri/ =404;\n        }\n}\n</code></pre> <p>Aqu\u00ed la directiva root debe ir seguida de la ruta absoluta d\u00f3nde se encuentre el archivo index.html de nuestra p\u00e1gina web.</p> <p>Y crearemos un archivo simb\u00f3lico entre este archivo y el de sitios que est\u00e1n habilitados, para que se d\u00e9 de alta autom\u00e1ticamente. </p> <pre><code>sudo ln -s /etc/nginx/sites-available/sitio1 /etc/nginx/sites-enabled/\nls -la /etc/nginx/sites-enabled/\n</code></pre> <p>Y reiniciamos el servidor para aplicar la configuraci\u00f3n: </p> <pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P02/#comprobacion-del-correcto-funcionamiento","title":"Comprobaci\u00f3n del correcto funcionamiento","text":"<p>Como a\u00fan no poseemos un servidor DNS que traduzca los nombres a IPs, debemos hacerlo de forma local en nuestro equipo. Vamos a editar el archivo <code>/etc/hosts</code> de nuestra m\u00e1quina anfitriona para que asocie la IP de la m\u00e1quina virtual, a nuestro <code>server_name</code>.</p> <p>Este archivo, en Linux, est\u00e1 en: <code>/etc/hosts</code></p> <p>Y en Windows: <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code></p> <p>Y deberemos a\u00f1adirle la l\u00ednea:</p> <p><code>IP_PUBLICA_SERVIDOR sitio1</code></p> <p>donde deb\u00e9is sustituir la IP_PUBLICA_SERVIDOR por la que tenga vuestra m\u00e1quina virtual. Si queremos tener varios dominios o sitios web en el mismo servidor nginx (es decir, que tendr\u00e1n la misma IP) debemos repetir todo el proceso anterior con el nuevo nombre de dominio que queramos configurar.</p> <p>Atenci\u00f3n</p> <pre><code>Recuerda dejar tu archivo `/etc/hosts` o ` C:\\Windows\\System32\\drivers\\etc\\hosts` cuando finalices las comprobaciones.\n</code></pre> <p>Si no tuvieras permisos en tu m\u00e1quina host puedes lanzar google chrome pas\u00e1ndole las DNS que quieres que aplique de la siguiente forma </p> <pre><code>google-chrome --host-resolver-rules=\"MAP midominio.com 123.45.67.89, MAP otrodominio.com 98.76.54.32\" --ignore-certificate-errors\n</code></pre> <p>En nuestro caso puedes usar lo siguiente sustituyendo IPSERVER por la IP p\u00fablica de nuestra EC2 en AWS.</p> <pre><code>google-chrome --host-resolver-rules=\"MAP sitio1 IPSERVER\" --ignore-certificate-error\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P02/#cuestiones-finales","title":"Cuestiones finales","text":"<p>Cuesti\u00f3n 1</p> <p>\u00bfQu\u00e9 pasa si no hago el link simb\u00f3lico entre <code>sites-available</code> y <code>sites-enabled</code> de mi sitio web?</p> <p>Cuesti\u00f3n 2</p> <p>\u00bfQu\u00e9 pasa si no le doy los permisos adecuados a <code>/var/www/nombre_web</code>?</p>"},{"location":"Ud3%20Servidores%20web/P02/#practica","title":"Practica","text":"<p>Para ver si has comprendido bien la pr\u00e1ctica crea un segundo sitio virtual que llamar\u00e1s \"sitio2\" y que pertenezca al usuario \"usuario2\" y comprueba su funcionamiento.</p>"},{"location":"Ud3%20Servidores%20web/P02/#sitios-web-virtuales-en-apache2","title":"Sitios web virtuales en Apache2","text":"<p>En esta pr\u00e1ctica guiada hemos visto c\u00f3mo crear sitios web virtuales en Nginx. \u00bfSabr\u00edas tu crear sitios web virtuales en Apache2?</p> <p>Abre tu m\u00e1quina virtual EC2 de AWS que creamos como \"servidorApache\" y crea ah\u00ed 2 sitios web virtuales como los que hemos creado en Nginx:</p> <ul> <li>sitio1 perteneciente a usuario1</li> <li>sitio2 perteneciente a usuario2</li> </ul> <p>Pista1</p> <pre><code>En Apache2 hay 2 directorios que se llaman /etc/apache2/sites-available/ y /etc/apache2/sites-enabled/\n</code></pre> <p>Pista2</p> <pre><code>Un fichero de configuraci\u00f3n de sitio web en Apache2 tiene esta pinta:\n```\n&lt;VirtualHost *:80&gt;\n        ServerName sitiovirtual\n        DocumentRoot /var/www/sitiovirtual\n        &lt;Directory /var/www/sitiovirtual&gt;\n                AllowOverride All\n                Require all granted\n        &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n```\n</code></pre> <p>Pista3</p> <pre><code>En apache no hay que crear el enlace simb\u00f3lico manualmente. Hay que habilitar el sitio mediante un comando que habilita el nuevo sitio virtual y adem\u00e1s crea el enlace. Busca cu\u00e1l es ese comando.\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P02/#sitios-virtuales-en-servidor-nginx-dockerizado","title":"Sitios virtuales en servidor Nginx dockerizado","text":"<p>Ya hemos creado un par de sitios virtuales sobre un servidor Nginx corriendo sobre una EC2 en AWS. Ahora vamos a hacer lo mismo pero sobre un servidor dockerizado. En la pr\u00e1ctica anterior ya creamos un servidor Nginx dockerizado, as\u00ed que aprovecharemos todo lo que hicimos en esa pr\u00e1ctica.</p> <p>Vamos a crear, en primer lugar, la estructura de directorios que necesitaremos en la m\u00e1quina que corre Docker. Dentro de nuestro home crearemos:</p> <pre><code>~\n\u251c\u2500\u2500 sitiosvirtuales/\n\u2502   \u251c\u2500\u2500 html\n\u2502   \u2502\u00a0\u00a0 \u2514\u2500\u2500 index.html\n\u2502   \u2514\u2500\u2500 sitio1\n\u2502       \u2514\u2500\u2500 index.html\n\u2514\u2500\u2500 nginxvirtual\n    \u251c\u2500\u2500 Dockerfile\n    \u251c\u2500\u2500 docker-compose.yaml\n    \u251c\u2500\u2500 entrypoint.sh\n    \u2514\u2500\u2500 sites-available\n        \u251c\u2500\u2500 default\n        \u2514\u2500\u2500 sitio1\n</code></pre> <p>En <code>sitiosvirtuales</code> incluiremos los ficheros html de nuestras p\u00e1ginas web. En <code>nginxvirtual</code> los ficheros que necesitaremos para la dockerizaci\u00f3n. En <code>sites-available</code> incluiremos los ficheros de configuraci\u00f3n tanto del sitio por defecto como de nuestro \"sitio1\". Puedes copiar ambos de la instalaci\u00f3n anterior sin docker.</p> <p>Veamos el docker-compose.yaml</p> <pre><code>services:\n    nginx:\n        build: .\n        volumes:\n            - ../sitiosvirtuales:/var/www\n            - ./sites-available:/etc/nginx/sites-available\n        ports:\n            - 80:80\n</code></pre> <p>Es importante destacar que lo primero que se montan son los volumenes. Por tanto, cuando arranquemos el contenedor ya leer\u00e1 el contenido de nuestros directorios en la m\u00e1quina host.</p> <p>Ahora vamos con el Dockerfile:</p> <pre><code>FROM debian:latest\nMAINTAINER Jos\u00e9 Mu\u00f1oz &lt;j.munozjimeno@edu.gva.es&gt;\n\n# Actualizamos e instalamos Nginx\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; apt install -y nginx &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Copiar el script de arranque\nCOPY entrypoint.sh /entrypoint.sh\n\n# Hacer que sea ejecutable\nRUN chmod +x /entrypoint.sh\n\n# Exponemos el puerto 80\nEXPOSE 80\n\n# Establecer el script como el entrypoint\nENTRYPOINT [\"/entrypoint.sh\"]\n</code></pre> <p>La particularidad de este Dockerfile es que copia al interior de la imagen un fichero .sh y lo haremos ejecutable. Vemos que al final, en lugar de CMD hemos usado ENTRYPOINT. La diferencia es que CMD es el comando predeterminado, pero que puede sustituir por otro al lanzar el contenedor, pero ENTRYPOINT impide que se pueda lanzar otro comando y siempre lanzar\u00e1 ese. Es m\u00e1s estricto. Y vemos que lanzamos el comando entrypoint.sh. Eso nos permitir\u00e1 que cada vez que se arranque el contenedor se ejecute lo que contenga ese script. Vamos a ver qu\u00e9 contiene.</p> <p>entrypoint.sh</p> <pre><code>#!/bin/bash\n\n# Borraremos todos los enlaces que ya existan en sites-enabled para poderlos crear luego nuevamente\nrm -f /etc/nginx/sites-enabled/*\n\n# Crear enlaces simb\u00f3licos de todos los archivos en sites-available a sites-enabled\nfor file in /etc/nginx/sites-available/*; do\n    ln -s \"$file\" /etc/nginx/sites-enabled/ || true\ndone\n\n# Iniciar el servidor Nginx\nnginx -g \"daemon off;\"\n</code></pre> <p>Ten en cuenta que este script se ejecutar\u00e1 cada vez que se arranque el contenedor y, por tanto, se crear\u00e1n los enlaces simb\u00f3licos cada vez.</p> <p>Ahora prueba a levantar el servicio con </p> <p><code>docker-compose up -d</code></p> <p>Y realiza las comprobaciones de funcionamiento como en el caso anterior. Recuerda que deber\u00e1s modificar el fichero /etc/hosts de la m\u00e1quina desde la que usas el navegador.</p> <p>Cuando lo tengas, para el servicio con </p> <p><code>docker-compose down</code></p> <p>Y ahora hazlo tu mismo como antes. Crea un \"site2\" y levanta el servicio nuevamente. </p> <p>Ejercicio</p> <pre><code>\u00bfSer\u00edas capaz de levantar un Apache2 dockerizado que sirva los 2 sitios virtuales que has creado en `~/sitiosvirtuales/?\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P03/","title":"Pr\u00e1ctica 3.3 \u2013 Autenticaci\u00f3n","text":""},{"location":"Ud3%20Servidores%20web/P03/#autenticacion-en-nginx","title":"Autenticaci\u00f3n en Nginx","text":"<p>Requisitos antes de comenzar la pr\u00e1ctica</p> <p>Atenci\u00f3n, muy importante antes de empezar</p> <ul> <li>La pr\u00e1ctica de creaci\u00f3n de sitios virtuales en Nginx ha de estar funcionando correctamente</li> <li>No empezar la pr\u00e1ctica antes de tener esa pr\u00e1ctica funcionando y comprobada</li> </ul> <p>En el contexto de una transacci\u00f3n HTTP, la autenticaci\u00f3n de acceso b\u00e1sica es un m\u00e9todo dise\u00f1ado para permitir a un navegador web, u otro programa cliente, proveer credenciales en la forma de usuario y contrase\u00f1a cuando se le solicita una p\u00e1gina al servidor. </p> <p>La autenticaci\u00f3n b\u00e1sica, como su nombre lo indica, es la forma m\u00e1s b\u00e1sica de autenticaci\u00f3n disponible para las aplicaciones Web. Fue definida por primera vez en la especificaci\u00f3n HTTP en s\u00ed y no es de ninguna manera elegante, pero cumple su funci\u00f3n. M\u00e1s adelante en este curso ya veremos otras formas de autenticaci\u00f3n, como el uso de un servidor LDAP.</p> <p>Este tipo de autenticaci\u00f3n es el tipo m\u00e1s simple disponible pero adolece de importantes problemas de seguridad que no la hacen recomendable en muchas situaciones. No requiere el uso ni de cookies, ni de identificadores de sesi\u00f3n, ni de p\u00e1gina de ingreso. </p>"},{"location":"Ud3%20Servidores%20web/P03/#preparando-el-entorno","title":"Preparando el entorno","text":"<p>En esta pr\u00e1ctica vamos a proveer de autenticaci\u00f3n a una p\u00e1gina web completa o a una parte de ella. Para ello necesitaremos una p\u00e1gina web con varias partes creada en nuestro servidor. </p> <p>Partiremos del estado de la pr\u00e1ctica anterior y trabajaremos sobre el sitio web \"sitio1\", que recuerda se encuetra en <code>/var/www/sitio1</code> y que pertenece a \"usuario1\". Por tanto, entra como \"usuario1\" antes de hacer los pasos siguientes.</p> <p>Crea junto a tu fichero <code>index.html</code> un directorio nuevo y ll\u00e1male <code>intranet</code>. Dentro haz una copia de <code>index.html</code> y modifica el contenido del encabezado &lt; h1 &gt; para que diga \"Intranet\".</p> <p>Ya puedes dejar de trabajar con \"usuario1\" y volver a ser usuario administrador.</p> <p>Accede desde el navegador de tu equipo a la nueva p\u00e1gina y comprueba que accedes correctamente.</p> <p><code>http://sitio1/intranet</code></p> <p>Atenci\u00f3n</p> <p>Recuerda que habr\u00e1s de modificar el fichero <code>/etc/hosts</code> en Linux o en Windows <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code> del equipo en el que est\u00e9s usando el navegador. O tambi\u00e9n puedes lanzar chrome con el comando: <code>google-chrome --host-resolver-rules=\"MAP sitio1 IPSERVER\" --ignore-certificate-error</code></p>"},{"location":"Ud3%20Servidores%20web/P03/#creando-el-fichero-de-passwords","title":"Creando el fichero de passwords","text":"<p>Para esta pr\u00e1ctica podemos utilizar la herramienta <code>htpasswd</code> para crear las contrase\u00f1as. Dicha herramienta se encuentra en el paquete <code>apache2-utils</code> as\u00ed que lo primero ser\u00e1 instalarlo</p> <pre><code>sudo apt install apache2-utils\n</code></pre> <p>Crearemos un archivo oculto llamado \u201c.htpasswd\u201d en el directorio de configuraci\u00f3n <code>/etc/nginx</code> donde guardar nuestros usuarios y contrase\u00f1as (la -c es para crear el archivo) e incluiremos es primer usuario y contrase\u00f1a para el usuario \"profe\": </p> <pre><code>sudo htpasswd -c /etc/nginx/.htpasswd profe\n</code></pre> <p>Te pedir\u00e1 introducir la contrase\u00f1a y repetirla. Ponle tambi\u00e9n \"profe\" para no olvidarla.</p> <p>Comprueba la existencia y contenido del archivo creado.</p> <p>Para el resto de usuarios usaremos la misma orden, pero sin \"-c\" ya que el fichero ya existir\u00e1.  </p> <pre><code>sudo htpasswd /etc/nginx/.htpasswd otro_usuario\n</code></pre> <ul> <li>Crea dos usuarios, uno con tu nombre y otro con tu primer apellido</li> <li>Comprueba que el usuario y la contrase\u00f1a aparecen cifrados en el fichero: </li> </ul> <pre><code>cat /etc/nginx/.htpasswd\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P03/#configurando-el-servidor-nginx-para-usar-autenticacion-basica","title":"Configurando el servidor Nginx para usar autenticaci\u00f3n b\u00e1sica","text":"<p>Inicialmente vamos a hacer que se requiera autenticaci\u00f3n para acceder a toda la p\u00e1gina web \"sitio1\"</p> <p>Editaremos la configuraci\u00f3n del server block sobre el cual queremos aplicar la restricci\u00f3n de acceso. Utilizaremos para esta autenticaci\u00f3n el sitio web de sitio1:  </p> <p>Info</p> <p>Recuerda que un server block es cada uno de los dominios (<code>server {...}</code> dentro del archivo de configuraci\u00f3n de alguno de los sitios web que hay en el servidor.</p> <pre><code>sudo nano /etc/nginx/sites-available/sitio1\n</code></pre> <p>Debemos decidir qu\u00e9 recursos estar\u00e1n protegidos. Nginx permite a\u00f1adir restricciones a nivel de servidor o en un location (directorio o archivo) espec\u00edfico. Para nuestro ejemplo, vamos a proteger el root (la ra\u00edz, la p\u00e1gina principal) de nuestro sitio. </p> <p>Utilizaremos la directiva <code>auth_basic</code> dentro del location y le pondremos el nombre a nuestro dominio que ser\u00e1 mostrado al usuario al solicitar las credenciales. Por \u00faltimo, configuramos Nginx para que utilice el fichero que previamente hemos creado con la directiva <code>auth_basic_user_file</code> : </p> <pre><code>server {\n        listen 80;\n        listen [::]:80;\n        root /var/www/sitio1;\n        index index.html index.htm index.nginx-debian.html;\n        server_name sitio1;\n        location / {\n            auth_basic  \"\u00c1rea restringida\";\n            auth_basic_user_file    /etc/nginx/.htpasswd;\n            try_files $uri $uri/ =404;\n        }\n}\n</code></pre> <p>Una vez terminada la configuraci\u00f3n, reiniciamos el servicio para que aplique nuestra pol\u00edtica de acceso. </p> <pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P03/#probando-la-nueva-configuracion","title":"Probando la nueva configuraci\u00f3n","text":"<p>Cuidado</p> <p>Si us\u00e1is el mismo navegador que antes de activar la autenticaci\u00f3n de sitio1, es muy probable que no os pida autenticaros porque os mostrar\u00e1 la p\u00e1gina en cach\u00e9 local.</p> <p>Igualmente, una vez os autentic\u00e1is con \u00e9xito, el navegador guardar\u00e1 esta autencaci\u00f3n exitosa y no volver\u00e1 a pediros usuario/contrase\u00f1a. </p> <p>As\u00ed pues, para cada prueba, si quer\u00e9is volver a probar a autenticaros, tendr\u00e9is que abriros una Nueva ventana privada o Nueva ventana de inc\u00f3gnito del navegador.</p> <p>Realiza las siguientes pruebas:</p> <p>Comprobaci\u00f3n 1</p> <p>Comprueba desde tu m\u00e1quina f\u00edsica/anfitri\u00f3n que puedes acceder a <code>http://sitio1</code> y que se te solicita autenticaci\u00f3n</p> <p>Comprobaci\u00f3n 2</p> <p>Comprueba que si decides cancelar la autenticaci\u00f3n, se te negar\u00e1 el acceso al sitio con un error. \u00bfQu\u00e9 error es?</p> <p>Comprobaci\u00f3n 3</p> <p>Comprueba desde tu m\u00e1quina f\u00edsica/anfitri\u00f3n que ocurre al intentar acceder a <code>http://sitio1/page2.html</code> y <code>http://sitio1/page3.html</code>. Recuerda, int\u00e9ntalo cada vez en una ventana de inc\u00f3gnito nueva</p>"},{"location":"Ud3%20Servidores%20web/P03/#tareas","title":"Tareas","text":"<p>Tarea 1</p> <ul> <li> <p>Intenta entrar primero con un usuario err\u00f3neo y luego con otro correcto. Puedes ver todos los sucesos y registros en los logs access.log y error.log </p> </li> <li> <p>Comprueba los logs donde se vea que intentas entrar primero con un usuario inv\u00e1lido y con otro v\u00e1lido. Busca d\u00f3nde podemos ver los errores de usuario inv\u00e1lido o no encontrado, as\u00ed como donde podemos ver el n\u00famero de error que os aparec\u00eda antes</p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/P03/#autenticacion-de-una-parte-de-la-web","title":"Autenticaci\u00f3n de una parte de la web","text":"<p>Cuando hemos configurado el siguiente bloque: </p> <pre><code>    location / {\n        auth_basic  \"\u00c1rea restringida\";\n        auth_basic_user_file    /etc/nginx/.htpasswd;\n        try_files $uri $uri/ =404;\n    }\n</code></pre> <p>La autenticaci\u00f3n se aplica al directorio o archivo que le indicamos en la declaraci\u00f3n del <code>location</code> y que en este caso el ra\u00edz <code>/</code>.</p> <p>As\u00ed pues, esta restricci\u00f3n se aplica al directorio ra\u00edz o base donde residen los archivos del sitio web y que es: </p> <pre><code>/var/www/sitio1\n</code></pre> <p>Y a todos los archivos que hay dentro, ya que no hemos especificado ninguno en concreto. </p> <p>Ahora bien, vamos a probar a aplicar la autenticaci\u00f3n solo a una parte de la web, en este caso a \"intranet\". </p> <p>Tarea 2</p> <p>Borra las dos l\u00edneas que hacen referencia a la autenticaci\u00f3n b\u00e1sica en el location del directorio ra\u00edz. Tras ello, a\u00f1ade un nuevo location debajo con la autenticaci\u00f3n b\u00e1sica para el directorio <code>/intranet</code> \u00fanicamente. </p> <p>Warning</p> <p>Fij\u00e1os que deb\u00e9is tener cuidado porque la \u00faltima l\u00ednea del archivo ha de ser <code>}</code> que cierra la primera l\u00ednea <code>server {</code> del archivo.</p> <p>Comprueba ahora que si accedes a la p\u00e1gina principal no te solicita autenticaci\u00f3n, pero si intentas acceder a la \"intranet\" si te la solicita.</p>"},{"location":"Ud3%20Servidores%20web/P03/#combinacion-de-la-autenticacion-basica-con-la-restriccion-de-acceso-por-ip","title":"Combinaci\u00f3n de la autenticaci\u00f3n b\u00e1sica con la restricci\u00f3n de acceso por IP","text":"<p>La autenticaci\u00f3n b\u00e1sica HTTP puede ser combinada de forma efectiva con la restricci\u00f3n de acceso por direcci\u00f3n IP. Se pueden implementar dos escenarios: </p> <ul> <li> <p>Un usuario debe estar ambas cosas, autenticado y tener una IP v\u00e1lida</p> </li> <li> <p>Un usuario debe o bien estar autenticado, o bien tener una IP v\u00e1lida </p> </li> </ul> <p>Veamos c\u00f3mo lo har\u00edamos:</p> <ol> <li> <p>Como permitir o denegar acceso sobre una IP concreta (directivas allow y deny, respectivamente). Dentro del block server o archivo de configuraci\u00f3n del dominio web, que recordad est\u00e1 en el directorio sites-available: </p> <p></p> <p>El acceso se garantizar\u00e1 ala IP <code>192.168.1.1/24</code>, excluyendo a la direcci\u00f3n <code>192.168.1.2</code>.</p> <p>Hay que tener en cuenta que las directivas allow y deny se ir\u00e1n aplicando en el orden en el que aparecen el archivo.</p> <p>Aqu\u00ed aplican sobre la <code>location /api</code> (esto es s\u00f3lo un ejemplo de un hipot\u00e9tico directorio o archivo), pero podr\u00edan aplicar sobre cualquiera, incluida todo el sitio web, la location ra\u00edz <code>/</code>.</p> <p>La \u00faltima directiva <code>deny all</code> quiere decir que por defecto denegaremos el acceso a todo el mundo. Por eso hay que poner los allow y deny m\u00e1s espec\u00edficos justo antes de esta, porque al evaluarse en orden de aparici\u00f3n, si los pusi\u00e9ramos debajo se denegar\u00eda el acceso a todo el mundo, puesto que <code>deny all</code> ser\u00eda lo primero que se evaluar\u00eda. </p> </li> <li> <p>Combinar la restricci\u00f3n IP y la autenticaci\u00f3n HTTP con la directiva satisfy. </p> <p>Si establecemos el valor de la directiva a \u201call\u201d, el acceso se permite si el cliente satisface ambas condiciones (IP y usario v\u00e1lido). Si lo establecemos a \u201cany\u201d, el acceso se permite si se satisface al menos una de las dos condiciones.</p> <p></p> </li> </ol> <p>Vamos a probar lo anterior. Para ello deberermos obtener, en primer lugar, la IP desde la que le llegan las peticiones a nuestro servidor nginx cuando pedimos una p\u00e1gina web. Lo puedes obtener desde el archivo le log de nginx</p> <pre><code>tail -n 3 /var/log/nginx/access.log\n</code></pre> <p>Una vez obtenida la IP, puedes hacer las tareas siguientes</p>"},{"location":"Ud3%20Servidores%20web/P03/#tareas-y-cuestiones-finales","title":"Tareas y cuestiones finales","text":"<p>Tarea 1</p> <p>Configura Nginx para que no deje acceder con la IP de la m\u00e1quina anfitriona al directorio <code>intranet</code>. Modifica su server block o archivo de configuraci\u00f3n. Comprueba como se deniega el acceso.</p> <ul> <li> <p>Muestra la p\u00e1gina de error en el navegador </p> </li> <li> <p>Muestra el mensaje de error de error.log </p> </li> </ul> <p>Tarea 2</p> <p>Configura Nginx para solo se pueda acceder a <code>intranet</code> desde tu m\u00e1quina anfitriona y se tenga que tener tanto una IP v\u00e1lida como un usuario v\u00e1lido, ambas cosas a la vez, y comprueba que s\u00ed puede acceder sin problemas.</p> <p>Responde a las siguientes cuestiones.</p> <p>Cuesti\u00f3n 1</p> <p>Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio <code>web_muy_guay</code> de mi sitio web, equivoc\u00e1ndome al poner el usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder? \u00bfPor qu\u00e9?</p> <pre><code>    location /web_muy_guay {\n    #...\n    satisfy all;    \n    deny  172.1.10.6;\n    allow 172.1.10.15;\n    allow 172.1.3.14;\n    deny  all;\n    auth_basic \"Cuesti\u00f3n final 1\";\n    auth_basic_user_file conf/htpasswd;\n}\n</code></pre> <p>Cuesti\u00f3n 2</p> <p>ask \"Cuesti\u00f3n 1\" Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio <code>web_muy_guay</code> de mi sitio web, introduciendo correctamente usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder?\u00bfPor qu\u00e9?</p> <pre><code>    location /web_muy_guay {\n    #...\n    satisfy all;    \n    deny  all;\n    deny  172.1.10.6;\n    allow 172.1.10.15;\n    allow 172.1.3.14;\n\n    auth_basic \"Cuesti\u00f3n final 2: The revenge\";\n    auth_basic_user_file conf/htpasswd;\n}\n</code></pre> <p>Cuesti\u00f3n 3</p> <p>Supongamos que yo soy el cliente con la IP 172.1.10.15 e intento acceder al directorio <code>web_muy_guay</code> de mi sitio web, introduciendo correctamente usuario y contrase\u00f1a. \u00bfPodr\u00e9 acceder?\u00bfPor qu\u00e9?</p> <pre><code>    location /web_muy_guay {\n    #...\n    satisfy any;    \n    deny  172.1.10.6;\n    deny 172.1.10.15;\n    allow 172.1.3.14;\n\n    auth_basic \"Cuesti\u00f3n final 3: The final combat\";\n    auth_basic_user_file conf/htpasswd;\n}\n</code></pre> <p>Cuesti\u00f3n 4</p> <p>A lo mejor no sab\u00e9is que tengo una web para documentar todas mis excursiones espaciales con Jeff, es esta: Jeff Bezos y yo</p> <p>Supongamos que quiero restringir el acceso al directorio de proyectos porque es muy secreto, eso quiere decir a\u00f1adir autenticaci\u00f3n b\u00e1sica a la URL:Proyectos</p> <p>Completa la configuraci\u00f3n para conseguirlo:</p> <pre><code>    server {\n        listen 80;\n        listen [::]:80;\n        root /var/www/freewebsitetemplates.com/preview/space-science;\n        index index.html index.htm index.nginx-debian.html;\n        server_name freewebsitetemplates.com www.freewebsitetemplates.com;\n        location              {\n\n            try_files $uri $uri/ =404;\n        }\n    }\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P03/#autenticacion-en-apache2","title":"Autenticaci\u00f3n en Apache2","text":"<p>La gran mayor\u00eda de servidores web permiten la instalaci\u00f3n de m\u00f3dulos para ampliar sus funcionalidades. Tener funcionalidades en forma de m\u00f3dulo permite adaptar mejor el consumo de recursos del servidor web a nuestras necesidades (el servidor web solo cargar\u00e1 y ejecutar\u00e1 los m\u00f3dulos que como administradores tenemos instalados y configurados).</p> <p>El servidor web Apache HTTP Server permite a\u00f1adir funcionalidades adicionales a las que nos ofrece su configuraci\u00f3n b\u00e1sica en forma de m\u00f3dulos instalables. La autenticaci\u00f3n es una de dichas funcionalidades. Veamos c\u00f3mo aplicar una autenticaci\u00f3n b\u00e1sica equivalente a la que usamos anteriormente en Ngnix.</p> <p>Recuperaremos nuestra EC2 en AWS que denominamos \"servidorApache\" y en la que configuramos 2 sitios virtuales. </p> <p>En primer lugar vamos a crear el directorio \"intranet\" en \"sitio1\" con un fichero index.html en su interior. Comprobaremos su buen funcionamiento.</p> <p>Y a continuaci\u00f3n crearemos el fichero htpasswd como hicimos anteriormente para Nginx y crearemos el usuario \"profe\" con password \"profe\". Ten en cuenta que ahora la ruta del fichero debe cambiar.</p> <pre><code>sudo htpasswd -c /etc/apache2/.htpasswd profe\n</code></pre> <p>Ahora vamos a configurar las directivas en el fichero de configuraci\u00f3n del sitio1: <code>ls /etc/apache2/sites-available/sitio1.conf</code>:</p> <pre><code>&lt;VirtualHost *:80&gt;\n        ServerName sitio1\n        DocumentRoot /var/www/sitio1\n        &lt;Directory /var/www/sitio1&gt;\n                AllowOverride All\n                Require all granted\n        &lt;/Directory&gt;\n        &lt;Directory /var/www/sitio1/intranet&gt;\n                AuthType Basic\n                AuthName \"Intranet\"\n                AuthBasicProvider file\n                AuthUserFile /etc/apache2/.htpasswd\n                Require valid-user\n        &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n</code></pre> <p>Veamos las directivas aplicadas:</p> <ul> <li> <p>AuthType: indica que el tipo de autenticaci\u00f3n es b\u00e1sica (en lugar de digest que implica comunicaciones cifradas).</p> </li> <li> <p>AuthName: declara el \"reialme\" al cual pertenece el recurso restringido. Esto permite que si hay otros recursos restringidos asociados a este \"reialme\" el usuario que ya se ha autenticado en uno de ellos no lo tenga que hacer en los otros. El nombre del reino lo pone el administrador web.</p> </li> <li> <p>AuthBasicProvider: indica el m\u00e9todo de autenticaci\u00f3n que se tiene que usar. Puede tomar valores tipos ldap, pam, dbm, bdb, file y otros. El valor file significa que se utilizar\u00e1 un fichero de usuarios.</p> </li> <li> <p>AuthUserFile: indica cu\u00e1l es el fichero que contiene las cuentas de los usuarios locales del servidor Apache. Es el fichero que hemos creado con los usuarios.</p> </li> <li> <p>Require: esta directiva es la que determina cu\u00e1l es la autorizaci\u00f3n que se tiene que hacer. En el ejemplo se permitir\u00e1 el acceso a los usuarios presentes en el fichero .htpasswd.</p> </li> </ul> <p>Vamos a reiniciar el servicio y comprobar que funciona la restricci\u00f3n de acceso aplicada.</p> <pre><code>sudo systemctl restart apache2\n</code></pre> <p>Probablemente no has tenido que hacer nada m\u00e1s porque los m\u00f3dulos de autenticaci\u00f3n de apache est\u00e1n activados por defecto. Como dijimos antes Apache usa m\u00f3dulos para poder activar y desactivar funcionalidades. La instalaci\u00f3n de los m\u00f3dulos se hace mediante ficheros guardados en 2 directorios:</p> <ul> <li><code>/etc/apache2/mods-available/</code>. Tiene 1 \u00f3 2 ficheros por m\u00f3dulo<ul> <li>Fichero .load - Contiene la directiva para cargar el m\u00f3dulo</li> <li>Fichero . conf - Contiene las directivas de configuraci\u00f3n del m\u00f3dulo (no todos los m\u00f3dulos lo tienen)</li> </ul> </li> <li><code>/etc/apache2/mods-enabled/</code>. Los m\u00f3dulos se activan mediante un enlace simb\u00f3lico en esta carpeta a cada uno de los ficheros en la carpeta <code>/etc/apache2/mods-available/</code></li> </ul> <p>Comprueba ambas carpetas y c\u00f3mo hay muchos m\u00e1s m\u00f3dulos disponibles que activados:</p> <p><pre><code>ls -la /etc/apache2/mods-available/\nls -la /etc/apache2/mods-enabled/\n</code></pre> \u00bfY cu\u00e1les son los m\u00f3dulos que permiten la autenticaci\u00f3n que hemos usado? Usamos 3 m\u00f3dulos, cada uno de los cuales tiene una funcionalidad</p> <ul> <li>Tipo de autenticaci\u00f3n: Puede ser \"basic\" o \"digest\". Los m\u00f3dulos son auth_basic y auth_digest. Comprueba c\u00f3mo ambos m\u00f3dulos est\u00e1n instalados (est\u00e1n presentes en <code>/etc/apache2/mods-available/</code>) pero solo la b\u00e1sica est\u00e1 activada (existe el enlace simb\u00f3lico en <code>/etc/apache2/mods-enabled/</code>)</li> <li>Proveedor de autenticaci\u00f3n: indica cu\u00e1l es el mecanismos parar autenticar usuarios. Puede ser un fichero local authn_file o LDAP authnz_ldap entre otros.Comprueba nuevamente cu\u00e1l est\u00e1 activada y cu\u00e1l no.</li> <li>Autorizaci\u00f3n: indica si la autorizaci\u00f3n de acceso a los recursos se hace a nivel de usuarios authz_user, ldap authz_ldap, etc</li> </ul> <p>Para activar y desactivar m\u00f3dulos se usan unos comandos que se encargan de crear o eliminar los enlaces simb\u00f3licos. </p> <pre><code>a2enmod *modulo*\na2dismod *modulo*\n</code></pre> <p>As\u00ed, si alguno de los m\u00f3dulos anteriores no estuvieran activos los podr\u00edamos activar con:</p> <pre><code>a2enmod auth_basic\na2enmod authn_file\na2enmod authz_user\n</code></pre> <p>Recuerda que despu\u00e9s de cada activaci\u00f3n deber\u00edamos reinicial el servidor con:</p> <pre><code>sudo systemctl restart apache2\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P03/#dockerizacion","title":"Dockerizaci\u00f3n","text":"<p>Para dockerizar un servidor Nginx o Apache2 con autenticaci\u00f3n usar\u00edamos las mismas estrategias que ya conocemos y que vimos en las pr\u00e1cticas de instalaci\u00f3n y creaci\u00f3n de servidores virtuales.</p>"},{"location":"Ud3%20Servidores%20web/P04/","title":"Practica 3.4 - Activaci\u00f3n HTTPS","text":""},{"location":"Ud3%20Servidores%20web/P04/#activacion-https-en-nginx","title":"Activaci\u00f3n HTTPS en Nginx","text":"<p>Atenci\u00f3n, muy importante antes de empezar</p> <ul> <li>La pr\u00e1ctica de creaci\u00f3n de Autenticaci\u00f3n en Nginx ha de estar funcionando correctamente</li> <li>No empezar la pr\u00e1ctica antes de tener esa pr\u00e1ctica funcionando y comprobada</li> </ul> <p>Como vimos en la teor\u00eda el protocolo HTTP es un procotoco inseguro, ya que las comunicaciones entre cliente web y servidor web no est\u00e1n cifradas. Por tanto, no podemos tener la seguridad de que la p\u00e1gina que estamos visualizando no ha sido modificada en el trayecto del servidor al cliente. Gracias a HTTPS, las comunicaciones est\u00e1n cifradas mediante un certificado SSL/TSL. Veamos c\u00f3mo hacer que las comunicaciones en nuestra <code>intranet</code>, que definimos en la pr\u00e1ctica anterior, est\u00e9n cifradas.</p>"},{"location":"Ud3%20Servidores%20web/P04/#certificados","title":"Certificados","text":"<p>HTTPS se basa en el uso de certificados digitales. </p> <p>Grosso modo, cuando entramos en una web v\u00eda HTTPS, esta nos presenta un certificado digital para asegurar que es qui\u00e9n dice ser. \u00bfC\u00f3mo sabemos que ese certificado es v\u00e1lido? Debemos consultar a la Autoridad de Certificaci\u00f3n (CA) que emiti\u00f3 ese certificado si es v\u00e1lido. </p> <p>Las CA son entidades que emiten certificados y su funcionamiento se basa en la confianza. Confiamos en que los certificados emitidos y firmados por esas entidades son reales y funcionales.  </p> <p></p> <p>Los navegadores web tienen precargadas las Autoridades de Certificaci\u00f3n en las que conf\u00edan por defecto a la hora de navegar por webs HTTPS: </p> <p></p> <p>Si accedemos a una web cuyo certificado no haya sido emitido y firmado por una de estas entidades, nos saltar\u00e1 el famoso aviso: </p> <p></p> <p>Ya que si el certificado no ha sido emitido y firmado por una CA de confianza, puede que se trate de una web maliciosa que nos suponga un riesgo de seguridad, como bien dice el aviso. </p>"},{"location":"Ud3%20Servidores%20web/P04/#tarea","title":"Tarea","text":"<p>Partimos de la configuraci\u00f3n de la pr\u00e1ctica anterior donde configuramos una <code>intranet</code> a la que solo pod\u00edamos acceder habi\u00e9ndonos validado previamente con nuestro usuario y contrase\u00f1a: </p> <p>Por lo que en esta pr\u00e1ctica simplemente debemos a\u00f1adir la configuraci\u00f3n SSL para el cifrado en el nuestro sitio virtual. </p>"},{"location":"Ud3%20Servidores%20web/P04/#creacion-de-certificado-autofirmado","title":"Creaci\u00f3n de certificado autofirmado","text":"<p>Nosotros no utilizaremos certificados de ninguna CA de confianza, b\u00e1sicamente porque: </p> <ul> <li> <p>Nuestros servicios no est\u00e1n publicados en Internet </p> </li> <li> <p>Estos certificados son de pago </p> </li> </ul> <p>As\u00ed pues, nosotros crearemos nuestros propios certificados y los firmaremos nosotros mismos como si fu\u00e9ramos una CA aut\u00e9ntica para poder simular este escenario.</p> <p>Warning</p> <p>Esto provocar\u00e1 que cuando accedamos por HTTPS a nuestro sitio web por primera vez, nos salt\u00e9 el aviso de seguridad que se coment\u00e1bamos en la introducci\u00f3n. </p> <p>En este caso no habr\u00e1 peligro, puesto que estamos 100% seguros que ese certificado lo hemos emitido nosotros para esta pr\u00e1ctica, no hay dudas. </p> <p>Veamos pues el proceso para generar los certificados y las claves asociadas a ellos (privada/p\u00fablica). En primer lugar debemos crear el siguiente directorio: </p> <p><code>/etc/nginx/ssl</code></p> <p>Podemos crear el certificado y las claves de forma simult\u00e1nea con un \u00fanico comando, donde: </p> <ul> <li> <p><code>openssl</code>: esta es la herramienta por l\u00ednea de comandos b\u00e1sica para crear y administrar certificados, claves y otros archivos OpenSSL. </p> </li> <li> <p><code>req</code>: este subcomando se utiliza para generar una solicitud de certificados y tambi\u00e9n solicitudes de firma de certificados (CSR). </p> </li> <li> <p><code>-x509</code>: Esto modifica a\u00fan m\u00e1s el subcomando anterior al decirle a la herramienta que queremos crear un certificado autofirmado en lugar de generar una solicitud de firma de certificado, como suceder\u00eda normalmente. </p> </li> <li> <p><code>-nodes</code>: Esto le dice a OpenSSL que omita la opci\u00f3n de asegurar nuestro certificado con contrase\u00f1a. Necesitamos que Nginx pueda leer el archivo sin la intervenci\u00f3n del usuario cuando se inicia el servidor. Una contrase\u00f1a evitar\u00eda que esto sucediera ya que tendr\u00edamos que introducirla a mano despu\u00e9s de cada reinicio. </p> </li> <li> <p><code>-days 365</code>: esta opci\u00f3n establece el tiempo durante el cual el certificado se considerar\u00e1 v\u00e1lido. Lo configuramos para un a\u00f1o. </p> </li> <li> <p><code>-newkey rsa: 2048</code> : Esto especifica que queremos generar un nuevo certificado y una nueva clave al mismo tiempo. No creamos la clave necesaria para firmar el certificado en un paso anterior, por lo que debemos crearla junto con el certificado. La rsa:2048parte le dice que cree una clave RSA de 2048 bits de longitud. </p> </li> <li> <p><code>-keyout</code>: este par\u00e1metro le dice a OpenSSL d\u00f3nde colocar el archivo de clave privada generado que estamos creando. </p> </li> <li> <p><code>-out</code>: Esto le dice a OpenSSL d\u00f3nde colocar el certificado que estamos creando. </p> </li> </ul> <p>El comando completo ser\u00eda as\u00ed:</p> <pre><code>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/nginx/ssl/server.key -out /etc/nginx/ssl/server.crt\n</code></pre> <p></p> <p>Os solicitar\u00e1 que introduzc\u00e1is una serie de par\u00e1metros. Introduce los par\u00e1metros que se adecuen a nuestro contexto y, en concreto en los \u00faltimos:</p> <ul> <li>Organizational Unit Name:  <code>2DAW \u2013 DEAW</code></li> <li>Common Name: <code>Tu nombre</code></li> <li>Email Address: <code>Tu_email</code> </li> </ul> <p>Si no te ha dado ning\u00fan error comprueba los archivos creados en <code>etc/nginx/ssl</code> y el contenido de cada uno de ellos.</p>"},{"location":"Ud3%20Servidores%20web/P04/#configuracion-ssl-en-sitio-virtual-intranet","title":"Configuraci\u00f3n SSL en sitio virtual <code>intranet</code>","text":"<p>De la pr\u00e1ctica anterior, dentro del directorio <code>/etc/nginx/sites-available</code> ya deb\u00e9is tener el archivo de configuraci\u00f3n llamado <code>sitio1</code>. Es precisamente aqu\u00ed donde realizaremos la configuraci\u00f3n para que el acceso al sitio web se realice mediante SSL (HTTPS). </p> <p>Dentro del bloque <code>server {\u2026}</code> deb\u00e9is cambiar el puerto de escucha (<code>listen 80</code>) por lo que v\u00e9is en la imagen de abajo, a\u00f1adiendo las siguientes l\u00edneas de configuraci\u00f3n tambi\u00e9n, de tal forma que quede: </p> <pre><code>  listen 443 ssl;\n  ssl_certificate /etc/nginx/ssl/server.crt;\n  ssl_certificate_key     /etc/nginx/ssl/server.key;\n  ssl_ciphers 'TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384';\n  ssl_protocols TLSv1.2 TLSv1.3;\n  access_log /var/log/nginx/https_access.log;\n</code></pre> <p>Donde le est\u00e1is diciendo que: </p> <ul> <li> <p>Escuche en el puerto 443 \u2192 Puerto por defecto de HTTPS </p> </li> <li> <p>El directorio donde est\u00e1 el certificado que hab\u00e9is generado anteriormente </p> </li> <li> <p>El directorio donde est\u00e1 la clave que hab\u00e9is generado anteriormente </p> </li> <li> <p>Los protocolos y tipos de cifrados que se pueden utilizar \u2192 Estas son las versiones de protocolos y los tipos de cifrados considerados seguros a d\u00eda de hoy (hay muchos m\u00e1s pero no se consideran seguros actualmente) </p> </li> <li> <p>El archivo donde se guardan los logs cambia de nombre, ahora ser\u00e1 https_access.log </p> </li> </ul> <p>Recordad que tras modificar cualquier configuraci\u00f3n de un servicio, hay que reiniciar el servicio, en este caso Nginx. </p>"},{"location":"Ud3%20Servidores%20web/P04/#comprobaciones","title":"Comprobaciones","text":"<ul> <li> <p>Si acced\u00e9is ahora a <code>https://sitio1</code> os deber\u00eda saltar un aviso de seguridad debido a que nuestro certificado es autofirmado, como coment\u00e1bamos anteriormente. </p> </li> <li> <p>Si a\u00f1ad\u00eds una excepci\u00f3n podr\u00e9is acceder al sitio web mediante HTTPS. </p> </li> <li> <p>Para comprobar que los datos del certificado son, efectivamente, los vuestros pod\u00e9is comprobarlo as\u00ed. Pulsando en el candado de la barra de b\u00fasqueda: </p> </li> </ul> <p></p> <p>Con m\u00e1s informaci\u00f3n:</p> <p></p> <p>Info</p> <p>Aqu\u00ed tambi\u00e9n podr\u00e9is eliminar la excepci\u00f3n que hab\u00e9is a\u00f1adido en la p\u00e1gina de la advertencia de seguridad, por si necesit\u00e1is reiniciar las pruebas. </p> <p>Y por \u00faltimo, ver certificado: </p> <p></p> <p>Y podremos ver los detalles: </p> <p></p> <p>Si ahora intent\u00e1is acceder a <code>http://sitio1</code>, \u00bfdeber\u00edais poder acceder? Comprobadlo y describid qu\u00e9 pasa y por qu\u00e9. </p>"},{"location":"Ud3%20Servidores%20web/P04/#redireccion-forzosa-a-https","title":"Redirecci\u00f3n forzosa a HTTPS","text":"<p>Para que, indistintamente de la forma por la que accedamos al sitio web balanceo, siempre se fuerce a utilizar HTTPS, necesitaremos una configuraci\u00f3n adicional. </p> <p>Necesitamos a\u00f1adir un bloque \u201cserver\u201d adicional y separado del otro, al archivo de configuraci\u00f3n de \u201csitio1\u201d. Algo as\u00ed: </p> <pre><code>server {\n        listen 80;\n        server_name sitio1;\n        access_log /var/log/nginx/http_access.log;\n        return 301 https://sitio1$request_uri;\n}\n</code></pre> <p>Con esta configuraci\u00f3n le estamos diciendo que: </p> <ul> <li> <p>Escuche en el puerto 80 (HTTP) </p> </li> <li> <p>Que el nombre al que responder\u00e1 el servidor/sitio web es <code>sitio1</code> </p> </li> <li> <p>Que guarde los logs de este bloque en ese directorio y con ese nombre </p> </li> <li> <p>Cuando se recibe una petici\u00f3n con las dos condiciones anteriores, se devuelve un c\u00f3digo HTTP 301: </p> <ul> <li> <p>HTTP 301 Moved Permanently (Movido permanentemente en espa\u00f1ol) es un c\u00f3digo de estado de HTTP que indica que el host ha sido capaz de comunicarse con el servidor pero que el recurso solicitado ha sido movido a otra direcci\u00f3n permanentemente. Es muy importante configurar las redirecciones 301 en los sitios web y para ello hay diferentes m\u00e9todos y sintaxis para realizar la redirecci\u00f3n 301. </p> </li> <li> <p>La redirecci\u00f3n 301 es un c\u00f3digo o comando insertado por un Webmaster que permite redirigir a los usuarios y buscadores de un sitio web de un sitio a otro. </p> </li> </ul> <p>Aclaraci\u00f3n</p> <p>Es decir, lo que estamos haciendo es que cuando se reciba una petici\u00f3n HTTP (puerto 80) en <code>http://sitio1</code>, se redirija a <code>https://sitio1</code> (HTTPS) </p> </li> </ul> <p>Tarea</p> <ul> <li> <p>Eliminad del otro bloque <code>server{\u2026}</code> la l\u00edneas que hagan referencia a escuchar en el puerto 80 (listen 80\u2026). </p> </li> <li> <p>Reiniciad el servicio </p> </li> <li> <p>Comprobad ahora que cuando entr\u00e1is en <code>http://sitio1</code>, autom\u00e1ticamente os redirige a la versi\u00f3n segura de la web. </p> </li> <li> <p>Comprobad que cuando realiz\u00e1is una petici\u00f3n en el archivo de log <code>http_access.log</code> aparece la redirecci\u00f3n 301 y que, de la misma manera, aparece una petici\u00f3n GET en <code>https_access.log</code>. </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/P04/#cuestiones-finales","title":"Cuestiones finales","text":"<p>Cuesti\u00f3n 1</p> <p>Hemos configurado nuestro servidor con todo lo que nos hace falta pero no nos funciona y da un error del tipo <code>This site can't provide a secure connection, ERR_SSL_PROTOCOL_ERROR.</code></p> <p>Dentro de nuestro server block tenemos esto:</p> <pre><code>server {\n    listen 443;\n    ssl_certificate /etc/nginx/ssl/enrico-berlinguer/server.crt;\n    ssl_certificate_key /etc/nginx/ssl/enrico-berlinguer/server.key;\n    ssl_protocols TLSv1.3;\n    ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;\n    server_name enrico-berlinguer;\n    access_log /var/log/nginx/https_access.log;\n...\n\n}\n</code></pre> <p>Cuesti\u00f3n 2</p> <p>Imaginad que intentamos acceder a nuestro sitio web HTTPS y nos encontramos con el siguiente error:</p> <p></p> <p>Investigad qu\u00e9 est\u00e1 pasando y como se ha de solucionar.</p>"},{"location":"Ud3%20Servidores%20web/P04/#activacion-https-en-apache2","title":"Activaci\u00f3n HTTPS en Apache2","text":"<p>Como venimos haciendo en todas las pr\u00e1cticas anteriores vamos a hacer lo mismo pero en Apache2.</p> <p>As\u00ed que inica la m\u00e1quina virtual en AWS que llamamos \"servidorApache\" y en la que configuramos un sitio virtual que llamamos \"sitio1\".</p> <p>Para activar https deberemos generar un certificado autofirmado exactamente igual que hicimos en Nginx. En este caso crearemos el directorio <code>/etc/apache2/ssl</code> y generaremos los 2 ficheros en su interior como en el caso anterior.</p>"},{"location":"Ud3%20Servidores%20web/P04/#activacion-modulo-ssl-en-apache2","title":"Activaci\u00f3n m\u00f3dulo ssl en Apache2","text":"<p>Como ya vimos anteriormente Apache2 utiliza m\u00f3dulos para activar y desactivar funciones. </p> <p>El m\u00f3dulo que necesimatos activar es el m\u00f3dulo <code>ssl</code>. Comprueba si est\u00e1 activado con:</p> <pre><code>ls -la /etc/apache2/mods-enabled/ssl*\nlrwxrwxrwx 1 root root 26 Nov  6 19:34 /etc/apache2/mods-enabled/ssl.conf -&gt; ../mods-available/ssl.conf\nlrwxrwxrwx 1 root root 26 Nov  6 19:34 /etc/apache2/mods-enabled/ssl.load -&gt; ../mods-available/ssl.load\n</code></pre> <p>Si ambos enlaces est\u00e1n activos es que el m\u00f3dulo est\u00e1 activado. Sino deber\u00e1s activarlo y reinciar el servicio</p> <pre><code>sudo a2enmod ssl\nsudo systemctl restart apache2\n</code></pre> <p>Ahora hemos de modificar la configuraci\u00f3n de sitio1 para que se acceda por https. Modifica el fichero <code>/etc/apache2/sites-available/sitio1.conf</code></p> <pre><code>&lt;VirtualHost *:443&gt;\n    ServerName sitio1\n    DocumentRoot /var/www/sitio1\n\n    #Activa SSL\n    SSLEngine on\n    # Especifica la ruta a tu certificado SSL y clave privada\n    SSLCertificateFile /etc/apache2/ssl/server.crt\n    SSLCertificateKeyFile /etc/apache2/ssl/server.key\n\n    &lt;Directory /var/www/sitio1&gt;\n            AllowOverride All\n            Require all granted\n    &lt;/Directory&gt;\n&lt;/VirtualHost&gt;\n</code></pre> <p>Explicaci\u00f3n de las directivas principales:</p> <ul> <li>&lt;VirtualHost *:443&gt;: Ahora accedemos por el puerto 443 destinado a https en lugar del 80</li> <li>SSLEngine on: Activa el soporte SSL en este host virtual.</li> <li>SSLCertificateFile: Especifica la ruta al archivo del certificado SSL de tu dominio.</li> <li>SSLCertificateKeyFile: Ruta a la clave privada correspondiente al certificado.</li> </ul> <p>Reinicia apache 2 y accede a <code>https://sitio1</code>. Recuerda hacer los ajustes necesarios:</p> <ul> <li>Modifica el fichero /etc/hosts a la IP del nuevo servidor</li> <li>Accede en una ventana de navegaci\u00f3n privada para evitar que el navegador muestre la cach\u00e9.</li> </ul>"},{"location":"Ud3%20Servidores%20web/P04/#redireccion-forzosa-a-https_1","title":"Redirecci\u00f3n forzosa a HTTPS","text":"<p>Si ahora accedemos a <code>http://sitio1</code> veremos c\u00f3mo nos muestra la p\u00e1gina por defecto de apache. Antes nos ocurr\u00eda lo mismo en Nginx y dejamos como pregunta el motivo por el que ocurr\u00eda. Nuestro servidor virtual est\u00e1 configurado para responder solo a peticiones https. Si le pedimos el puerto 80, no tiene ning\u00fan servidor virtual para responder a una petici\u00f3n y entonces responde con el sitio por defecto.</p> <p>Vamos a hacer que cualquier petici\u00f3n a <code>http://sitio1</code> se redirija de forma forzosa a <code>https://sitio1</code>. A\u00f1ade al final del fichero <code>/etc/apache2/sites-available/sitio1.conf</code> un nuevo bloque \"VirtualHost\" como el siguiente</p> <pre><code>&lt;VirtualHost *:80&gt;\n    ServerName sitio1\n    Redirect permanent / https://sitio1/\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P05/","title":"Practica 3.5 - Instalaci\u00f3n de la pila LAMP","text":""},{"location":"Ud3%20Servidores%20web/P05/#introduccion","title":"Introducci\u00f3n","text":"<p>En la teor\u00eda hemos visto que el servidor web raramente funciona solo. Cada vez hay menos p\u00e1ginas web est\u00e1ticas y m\u00e1s servicios y aplicaciones que no solo necesitan el servidor web, sino que necesitan una plataforma web que contiene, adem\u00e1s, un gestor de base de datos y alg\u00fan lenguaje de programaci\u00f3n interpretado.</p> <p>Hoy en d\u00eda son muchos los servicios que necesitan una plataforma web corriendo en el servidor antes de poder instalarlos. Estamos hablando de entornos de aprendizaje virtual, como Moodle, o gestores de blogs y p\u00e1ginas web como Wordpress.</p> <p>Vimos en la teor\u00eda que existen distintas plataformas web libres, como LAMP y propietarias, como WISA. En esta pr\u00e1ctica instalaremos una plataforma web LAMP completa, formada por: </p> <ul> <li>Linux: sistema operativo. En nuestro caso usaremos Debian.</li> <li>Apache: servidor web.</li> <li>MySQL o MariaDB: gestor de bases de datos. Nosotros instalaremos MariaDb.</li> <li>PHP: lenguaje interpretado PHP, aunque a veces se sustituye por Perl o Python.</li> </ul>"},{"location":"Ud3%20Servidores%20web/P05/#prerrequisitos","title":"Prerrequisitos","text":"<p>Antes de empezar con la instalaci\u00f3n de los distintos componentes de la plataforma web necesitaremos:</p> <ul> <li>Crea en AWS Academy un EC2 Debian con los requisitos por defecto. Ll\u00e1male PracticaLAMP</li> <li>Crea un Grupo de seguridad y ll\u00e1male tambi\u00e9n PracticaLAMP. De momento abre los puertos para SSH, HTTP y HTTPS.</li> </ul> <p>Con\u00e9ctate por SSH al EC2 creado y actualiza el sistema.</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\n</code></pre> <p>Ahora ya podemos empezar a instalar los elementos de la plataforma uno a uno.</p>"},{"location":"Ud3%20Servidores%20web/P05/#instalacion-del-servidor-apache","title":"Instalaci\u00f3n del servidor Apache.","text":"<p>Como todo servidor LAMP, lo principal es la A de Apache. Para instalar Apache \u00fanicamente debemos de ejecutar:</p> <pre><code>sudo apt install apache2\n</code></pre> <p>Comprobamos que se ha instalado correctamente y el servicio est\u00e1 en ejecuci\u00f3n:</p> <pre><code>sudo systemctl status apache2\n</code></pre> <p>Si no estuviera arrancado recuerda que puedes usar <code>sudo systemctl enable apache2</code> para activarlo y que se arranque al inicio y <code>sudo systemctl start apache2</code> para arrancarlo.</p> <p>Y listo, ya tenemos servidor web instalado. Ahora desde nuestro navegador favorito escribimos la IP p\u00fablica de nuestro  servidor Debian (con http:// recuerda) y nos deber\u00eda de salir el index de Apache por defecto.</p> <p></p>"},{"location":"Ud3%20Servidores%20web/P05/#instalacion-de-mariadb","title":"Instalaci\u00f3n de MariaDB.","text":"<p>Ahora vamos a instalar un servidor de bases de datos para las aplicaciones que podamos instalar en nuestro servidor web, para ello instalaremos MariaDB que est\u00e1 basado en MySQL.</p> <pre><code>sudo apt install mariadb-server\n</code></pre> <p>Como antes, comprobamos que el servicio est\u00e1 en marcha. Como MariaDB est\u00e1 basado en Mysql mantiene el nombre de servicio <code>mysql</code>:</p> <pre><code>sudo systemctl status mysql\n</code></pre> <p>Una vez iniciado, no podremos iniciar sesi\u00f3n con MariaDB porque no hemos configurado a\u00fan el servidor para ello. Vamos a ejecutar este script que ayuda a securizar el servicio:</p> <pre><code>sudo mysql_secure_installation\n</code></pre> <p>Te har\u00e1 varias preguntas. Importante contestar:</p> <pre><code>Change the root password? [Y/n] Y\n</code></pre> <p>Y ponle de password a root: <code>ieselcaminas</code>.</p> <p>El resto de preguntas puedes mantener la base de datos en entorno de pruebas. Ten en cuenta que si fuera un entorno de producci\u00f3n las respuestas deber\u00edan ser distintas.</p> <p>Y finalmente:</p> <pre><code>Reload privilege tables now? [Y/n] y\n ... Success!\n\nCleaning up...\n\nAll done!  If you've completed all of the above steps, your MariaDB\ninstallation should now be secure.\n\nThanks for using MariaDB!\n</code></pre> <p>Ya hemos configurado MariaDB, ahora podemos conectarnos mediante terminal:</p> <p><pre><code># mysql -u root -p\nEnter password: \nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 35\nServer version: 10.11.4-MariaDB-1~deb12u1 Debian 12\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]&gt;\n</code></pre> Puedes conocer los distintos comandos con <code>help</code> o <code>\\h</code>. Para salir <code>\\q</code>.</p>"},{"location":"Ud3%20Servidores%20web/P05/#instalacion-de-php","title":"Instalaci\u00f3n de PHP","text":"<p>PHP es el componente de su configuraci\u00f3n que procesar\u00e1 c\u00f3digo para mostrar contenido din\u00e1mico. Puede ejecutar secuencias de comandos, establecer conexi\u00f3n con sus bases de datos de MariaDB para obtener informaci\u00f3n y entregar el contenido procesado a su servidor web para su visualizaci\u00f3n.</p> <p>Una vez m\u00e1s, utiliza el sistema apt-get para instalar PHP. Adem\u00e1s, incluye algunos paquetes de helper esta vez para que el c\u00f3digo de PHP pueda ejecutarse con el servidor Apache y comunicarse con su base de datos de MariaDB:</p> <p><pre><code>sudo apt-get install php libapache2-mod-php php-mysql\n</code></pre> Para que Apache aplique los cambios, es necesario reiniciar el servicio para que PHP est\u00e9 activo.</p> <pre><code>sudo systemctl restart apache2\n</code></pre> <p>A fin de verificar que tu sistema est\u00e9 configurado de forma adecuada para PHP, crearemos una secuencia de comandos PHP muy b\u00e1sica llamada <code>info.php</code>. Para que Apache encuentre este archivo y lo presente correctamente, debe guardarse en un directorio muy espec\u00edfico llamado web root. Este directorio se encuentra en /var/www/html/. Crea el archivo en esa ubicaci\u00f3n ejecutando lo siguiente:</p> <pre><code>sudo nano /var/www/html/info.php\n</code></pre> <p>Con esto se abrir\u00e1 un archivo vac\u00edo. A\u00f1ade el siguiente texto, que es el c\u00f3digo PHP v\u00e1lido, dentro del archivo <code>/var/www/html/info.php</code></p> <pre><code>&lt;?php\nphpinfo();\n?&gt;\n</code></pre> <p>Cuando termines, guarda y cierra el archivo.</p> <p>Ahora puedes probar si tu servidor web puede mostrar correctamente el contenido generado por esta secuencia de comandos PHP. Para probar esto, visita esta p\u00e1gina en tu navegador web. Necesitar\u00e1s de nuevo la direcci\u00f3n IP p\u00fablica de tu servidor Debian.</p> <p><code>http://IPservidorDebian/info.php</code></p> <p>La p\u00e1gina a la que llegues deber\u00eda tener un aspecto similar a este:</p> <p></p> <p>Una vez probada puedes borrar ese fichero que has creado.</p>"},{"location":"Ud3%20Servidores%20web/P05/#instalacion-de-phpmyadmin","title":"Instalaci\u00f3n de phpMyAdmin","text":"<p>En estos momentos ya tenemos la pila LAMP creada y operativa y ya podr\u00edamos instalar cualquier servicio sobre ella: Moodle, Wordpress, NextCloud...</p> <p>Pero vamos a instalar una cosa m\u00e1s que, no siendo imprescindible, si que nos ser\u00e1 muy \u00fatil para gestionar las bases de datos de forma gr\u00e1fica: phpMyAdmin.</p> <p>Para ello</p> <pre><code>sudo apt-get install phpmyadmin\n</code></pre> <p>La instalaci\u00f3n es bastante autom\u00e1tica, aunque nos har\u00e1 algunas preguntas. </p> <ul> <li> <p>Primero nos preguntar\u00e1 por el servidor web que tenemos instalado. L\u00f3gicamente le diremos que <code>apache2</code>.</p> <p></p> </li> <li> <p>Despu\u00e9s nos preguntar\u00e1 si gestionamos la configuraci\u00f3n de phpMyAdmin con \"dbconfig-common\". Le diremos que si.</p> </li> <li> <p>Y finalmente nos pedir\u00e1 la contrase\u00f1a de root de MySQL. Recuerda que le pusimos \"ieselcaminas\".</p> </li> </ul> <p>Ahora ya puedes acceder a la p\u00e1gina de phpMyAdmin con</p> <p><code>http://IPservidorDebian/phpmyadmin</code></p> <p>Te pedir\u00e1 el usuario y contrase\u00f1a. Recuerda usuario:<code>root</code> y pass:<code>ieselcaminas</code>.</p> <p></p> <p>Y si todo va bien estar\u00e1s dentro para poder gestionar las bases de datos de tu MariaDB.</p> <p></p> <p>Si con lo anterior no pudieras acceder a Phpmyadmin, a\u00f1ade este enlace simb\u00f3lico:</p> <pre><code>sudo ln -s /usr/share/phpmyadmin/ /var/www/html/phpmyadmin\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P05/#conclusion","title":"Conclusi\u00f3n","text":"<p>Hemos instalado la plataforma web LAMP completa con las \u00faltimas versiones de cada uno de sus elementos.</p> <p>Ahora ya podr\u00e1s instalar cualquier aplicaci\u00f3n o servicio que requiera dicha plataforma para funcionar.</p> <p>Recuerda al finalizar la pr\u00e1ctica parar el laboratorio AWS Academy para no seguir consumiendo recursos innecesariamente.</p>"},{"location":"Ud3%20Servidores%20web/P05/#referencias","title":"Referencias","text":"<ul> <li>Instalaci\u00f3n de servidor web LAMP en Debian 11</li> <li>C\u00f3mo instalar la pila Linux, Apache, MariaDB, PHP (LAMP) en Debian 9</li> <li>phpMyAdmin - Debian 11 Stable</li> </ul>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/","title":"Pr\u00e1ctica 3.6 - Instalaci\u00f3n pila LAMP dockerizada","text":""},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#introduccion","title":"Introducci\u00f3n","text":"<p>En esta pr\u00e1ctica vamos a instalar una pila LAMP dockerizada. Para comprobar que todos los contenedores trabajan conjuntamente desplegaremos una peque\u00f1a aplicaci\u00f3n PHP que consulta la base de datos instalada.</p> <p>\u00a1Atenci\u00f3n!</p> <p>En caso de que teng\u00e1is problemas, esta pr\u00e1ctica est\u00e1 comprobada y funcionando usando las siguientes versiones:</p> <ul> <li>Docker: Docker version 20.10.17, build 100c701</li> <li>Docker-compose: Docker Compose version v2.10.2</li> </ul>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#recordando-que-es-docker-compose","title":"Recordando qu\u00e9 es docker-compose","text":"<p>Como vimos en la parte de teor\u00eda para ejecutar nuestra aplicaci\u00f3n en docker creamos un fichero llamado <code>Dockerfile</code> y este fichero contiene una configuraci\u00f3n. Esta configuraci\u00f3n var\u00eda dependiendo de qu\u00e9 queremos poner en el contenedor, ya que no es lo mismo poner una p\u00e1gina web, que una base de datos.</p> <p>Este proceso, de crear todos los <code>Dockerfile</code> y ejecutarlos puede ser bastante tedioso, ya que debemos pensar que una aplicaci\u00f3n de tama\u00f1o mediano es probable que tenga un front end, un back end, quiz\u00e1 algunos background-workers as\u00ed como la base de datos, sistema de cach\u00e9, sistema de colas o de message-broker... por lo que cada uno de nuestros servicios ser\u00e1 un contenedor diferente.</p> <p>Por lo tanto, crear m\u00faltiples <code>Dockerfile</code> y ejecutarlos todo en un script queda largo y feo.</p> <p>Aqu\u00ed es donde entra <code>docker-compose</code> el cual es una herramienta que nos permite definir y correr m\u00faltiples contenedores en Docker. Estos m\u00faltiples contenedores se definen en un fichero denominado docker-compose con la extensi\u00f3n .yml. Luego, con un solo comando, crea e inicia todos los servicios desde su configuraci\u00f3n.</p> <p></p> <p>Compose funciona en todos los entornos: producci\u00f3n, puesta en escena, desarrollo, pruebas, as\u00ed como flujos de trabajo de CI.</p> <p>Usar Compose es b\u00e1sicamente un proceso de tres pasos:</p> <ul> <li> <p>Definir el entorno de nuestra aplicaci\u00f3n con un Dockerfile para que pueda reproducirse en cualquier lugar.</p> </li> <li> <p>Definir los servicios que componen la aplicaci\u00f3n <code>docker-compose.yml</code> para que puedan ejecutarse juntos en un entorno aislado.</p> </li> <li> <p>Ejecutar <code>docker-compose up</code> y Compose inicia y ejecuta toda su aplicaci\u00f3n.</p> </li> </ul> <p>Este proceso se denomina orquestaci\u00f3n de contenedores y se lleva a cabo de forma local al interior de los containers, quienes, adem\u00e1s, se encontrar\u00e1n unidos a trav\u00e9s de una red de Docker.</p>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#instalacion-de-docker-compose","title":"Instalaci\u00f3n de docker-compose","text":""},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#proceso-de-dockerizacion-de-nginxphpmysql","title":"Proceso de dockerizaci\u00f3n de Nginx+PHP+MySQL","text":""},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#1-estructura-de-directorios","title":"1. Estructura de directorios","text":"<p>Para que quede claro todo el proceso que vamos a seguir, la estructura de directorios que nos debe quedar en nuestra Debian al finalizar la pr\u00e1ctica es esta: <pre><code>/usuario/home/practica6-2/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 nginx\n\u2502   \u251c\u2500\u2500 default.conf\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 php\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 www\n    \u2514\u2500\u2500 html\n        \u2514\u2500\u2500 index.php\n</code></pre> Pod\u00e9is ir creando los directorios y archivos paso a paso o crearlo todo a la vez y luego ir rellenando los archivos vac\u00edos siguiendo un procedimiento como este:</p> <pre><code>mkdir practica6-2\ncd practica6-2\ntouch docker-compose.yml\nmkdir nginx\ntouch nginx/default.conf\n...\n</code></pre>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#2-creacion-de-un-contenedor-nginx","title":"2. Creaci\u00f3n de un contenedor Nginx","text":"<p>Paara empezar, necesitamos crear y correr un contendor Nginx que permita alojar nuestra aplicaci\u00f3n en PHP.</p> <p>Dentro de la carpeta /usuario/home/practica6-2/ debemos haber creado o crear ahora el archivo <code>docker-compose.yml</code></p> <p>Y editamos este archivo con el editor de texto que prefiramos, nano por ejemplo:</p> <pre><code>nano docker-compose.yml\n</code></pre> <p>Y a\u00f1adimos la siguientes l\u00edneas:</p> <pre><code>nginx:\n  image: nginx:latest\n  container_name: nginx-container\n  ports:\n    - 80:80\n</code></pre> <p>Y lo guardamos.</p> <p>El archivo que acabamos de crear ser\u00e1 el encargado de descargarse la \u00faltima versi\u00f3n de la imagen de Nginx, crear un contenedor con ella y publicar o escuchar en el puerto 80 del contenedor que tambi\u00e9n se corresponder\u00e1 con el 80 de nuestra m\u00e1quina (80:80).</p> <p>Iniciemos entonces este proceso:</p> <p><pre><code>docker-compose up -d\n</code></pre> Con la opci\u00f3n <code>-d</code> (de daemon), estamos indicando que el contenedor se ejecute en background o segundo plano:</p> <p></p> <p>Para comprobar que el contenedor est\u00e1 corriendo, podemos hacer:</p> <pre><code>docker ps\n</code></pre> <p>Y deber\u00edamos ver algo como:</p> <pre><code>CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                               NAMES\nc6641e4d5bbf   nginx:latest   \"/docker-entrypoint.\u2026\"   5 seconds ago   Up 3 seconds   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx-container\n</code></pre> <p>Adem\u00e1s, si abrimos el navegador de nuestra m\u00e1quina anfitri\u00f3n y accedemos a <code>http://IP_Maq_Virtual</code> deber\u00edamos ver la p\u00e1gina de bienvenida de Nginx:</p> <p></p>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#3-creacion-de-un-contenedor-php","title":"3. Creaci\u00f3n de un contenedor PHP","text":"<p>Creamos la carpeta y el documento pertinente dentro de ella, si no lo hab\u00edamos hecho antes:</p> <p><pre><code>mkdir -p /home/usuario/practica6-2/www/html\nnano /home/usuario/practica6-2/www/html/index.php\n</code></pre> Y dentro de <code>index.php</code> a\u00f1adimos el siguiente c\u00f3digo:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;head&gt;\n  &lt;title&gt;\u00a1Hola mundo!&lt;/title&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n  &lt;h1&gt;\u00a1Hola mundo!&lt;/h1&gt;\n  &lt;p&gt;&lt;?php echo 'Estamos corriendo PHP, version: ' . phpversion(); ?&gt;&lt;/p&gt;\n&lt;/body&gt;\n</code></pre> <p>Guardad el archivo y cread, si no lo hab\u00edais hecho antes, un directorio llamado nginx dentro del directorio del proyecto:</p> <p><pre><code>mkdir /home/usuario/practica6-2/nginx\n</code></pre> Ahora vamos a crear el archivo de configuraci\u00f3n por defecto para que Nginx pueda correr la aplicaci\u00f3n PHP:</p> <pre><code>nano /home/usuario/practica6-2/nginx/default.conf\n</code></pre> <p>Y dentro de ese archivo, colocaremos la siguiente configuraci\u00f3n:</p> <p><pre><code>server {\n\n     listen 80 default_server;\n     root /var/www/html;\n     index index.html index.php;\n\n     charset utf-8;\n\n     location / {\n      try_files $uri $uri/ /index.php?$query_string;\n     }\n\n     location = /favicon.ico { access_log off; log_not_found off; }\n     location = /robots.txt { access_log off; log_not_found off; }\n\n     access_log off;\n     error_log /var/log/nginx/error.log error;\n\n     sendfile off;\n\n     client_max_body_size 100m;\n\n     location ~ .php$ {\n      fastcgi_split_path_info ^(.+.php)(/.+)$;\n      fastcgi_pass php:9000;\n      fastcgi_index index.php;\n      include fastcgi_params;\n      fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n      fastcgi_intercept_errors off;\n      fastcgi_buffer_size 16k;\n      fastcgi_buffers 4 16k;\n    }\n\n     location ~ /.ht {\n      deny all;\n     }\n    }\n</code></pre> Guardamos el archivo y ahora crearemos el <code>Dockerfile</code> dentro del directorio nginx. En este archivo se copiar\u00e1 el archivo de configuraci\u00f3n de Nginx al contenedor correspondiente.</p> <p>As\u00ed pues:</p> <p><pre><code>nano /home/usuario/practica6-2/nginx/Dockerfile\n</code></pre> Y dentro de este archivo:</p> <pre><code>FROM nginx:latest\nCOPY ./default.conf /etc/nginx/conf.d/default.conf\n</code></pre> <p>Y ahora editamos nuestro archivo <code>docker-compose.yml</code>:</p> <p><pre><code>services:\n  nginx:\n    build: ./nginx/\n    container_name: nginx-container\n    ports:\n      - 80:80\n    links:\n      - php\n    volumes:\n      - ./www/html/:/var/www/html/\n\n  php:\n    image: php:7.0-fpm\n    container_name: php-container\n    expose:\n      - 9000\n    volumes:\n      - ./www/html/:/var/www/html/\n</code></pre> Ahora con este fichero <code>docker-compose.yml</code> se crear\u00e1 un nuevo contenedor PHP-FPM en el puerto 9000, enlazar\u00e1 el contenedor nginx con el contendor php, as\u00ed como usar\u00e1 el directorio local de la m\u00e1quina host ~/practica6-2/www/html y lo montar\u00e1 en el directorio <code>/var/www/html</code> de los contenedores.</p> <p>As\u00ed pues, ejecutaremos el nuevo contenedor volviendo a ejecutando compose. Cuidado pues se debe ejecutar el comando en el mismo directorio donde tengamos nuestro archivo <code>docker-compose.yml</code>:</p> <pre><code>cd /home/usuario/practica6-2\n\ndocker-compose up -d\n</code></pre> <p>Y comprobamos que los contenedores est\u00e1n corriendo:</p> <pre><code>docker ps\n</code></pre> <p>Debiendo ver algo como:</p> <pre><code>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                               NAMES\n82c8baf15221   docker-project_nginx   \"/docker-entrypoint.\u2026\"   23 seconds ago   Up 22 seconds   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx-container\n10778c6686d8   php:7.0-fpm            \"docker-php-entrypoi\u2026\"   25 seconds ago   Up 23 seconds   9000/tcp                            php-container\n</code></pre> <p>Y si ahora volvemos a acceder a <code>http://IP_Maq_Virtual</code>, veremos la p\u00e1gina <code>Hola mundo</code>.</p> <p>Question</p> <p>\u00bfLa directiva <code>links</code> es necesaria? \u00bfQu\u00e9 pasar\u00eda si la eliminamos?</p>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#4-creacion-de-un-contenedor-para-datos","title":"4. Creaci\u00f3n de un contenedor para datos","text":"<p>Como v\u00e9is, hemos montado el directorio <code>www/html</code> en ambos contenedores, el de nginx y el de php. Sin embargo, esta no es una forma adecuada de hacerlo. En este paso crearemos un contenedor independiente que se encargar\u00e1 de contener los datos y lo enlazaremos con el resto de contenedores.</p> <p>Warning</p> <p>Esta pr\u00e1ctica est\u00e1 sacada de aqu\u00ed. En esta pr\u00e1ctica usa un contenedor para guardar datos en lugar de usar un \"volumen\" docker. Mantenemos esta forma de hacerlo para que veas formas distintas de trabajo con docker que puedes encontrarte, aunque pensamos que no es la forma m\u00e1s adecuada. Piensa c\u00f3mo podr\u00edas hacer lo mismo con vol\u00famenes.</p> <p>Para llevar a cabo esta tarea, volvemos a editar el <code>docker-compose.yml</code>:</p> <p><pre><code>nano ~/practica6-2/docker-compose.yml\n</code></pre> Y a\u00f1adiremos un nuevo servicio a los que ya ten\u00edamos, quedando as\u00ed:</p> <pre><code>nginx:\n  build: ./nginx/\n  container_name: nginx-container\n  ports:\n    - 80:80\n  links:\n    - php\n  volumes_from:\n    - app-data\n\nphp:\n  image: php:7.0-fpm\n  container_name: php-container\n  expose:\n    - 9000\n  volumes_from:\n    - app-data\n\napp-data:\n  image: php:7.0-fpm\n  container_name: app-data-container\n  volumes:\n    - ./www/html/:/var/www/html/\n  command: \"true\"\n</code></pre> <p>As\u00ed que para recrear y lanzar todos los contenedores ejecutamos de nuevo (recordad, dentro del directorio donde se encuentra el archivo):</p> <pre><code>docker-compose up -d\n</code></pre> <p>Y volvemos a verificar que est\u00e1n corriendo todos:</p> <pre><code>docker ps -a\n</code></pre> <p>Debiendo ver algo como:</p> <pre><code>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS                      PORTS                               NAMES\n849315c7ffc0   docker-project_nginx   \"/docker-entrypoint.\u2026\"   27 seconds ago   Up 25 seconds               0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx-container\n59a0d7040fd8   php:7.0-fpm            \"docker-php-entrypoi\u2026\"   28 seconds ago   Up 27 seconds               9000/tcp                            php-container\nfbca95944234   php:7.0-fpm            \"docker-php-entrypoi\u2026\"   29 seconds ago   Exited (0) 28 seconds ago                                       app-data-container\n</code></pre> <p>Question</p> <p>\u00bfTiene sentido usar un contenedor cuya \u00fanica funci\u00f3n es alojar datos? \u00bfQu\u00e9 otra forma nos ofrece docker para este cometido? \u00bfC\u00f3mo podr\u00edas modificar el docker-compose.yaml para hacerlo?</p>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#5-creacion-de-un-contenedor-mysql","title":"5. Creaci\u00f3n de un contenedor MySQL","text":"<p>En esta secci\u00f3n crearemos un contenedor de una base de datos MySQL y lo enlazaremos con el resto de contenedores.</p> <p>Primero, modificaremos la imagen PHP e instalaremos la extensi\u00f3n PHP para MySQL, de tal forma que nos permita conectarnos desde nuestra aplicaci\u00f3n PHP a nuestra BBDD MySQL.</p> <p>Creamos, si no lo ten\u00edamos ya, nuestro directorio php y dentro de \u00e9l, el archivo <code>Dockerfile</code>:</p> <pre><code>mkdir /home/usuario/practica6-2/php\nnano /home/usuario/practica6-2/php/Dockerfile\n</code></pre> <p>Y dentro del <code>Dockerfile</code> ponemos:</p> <pre><code>FROM php:7.0-fpm\nRUN docker-php-ext-install pdo_mysql\n</code></pre> <p>Y una vez m\u00e1s, debemos editar <code>docker-compose.yml</code> con el objetivo de que se creen el contenedor para MySQL y el contenedor de los datos de MySQL que contendr\u00e1 la base de datos y las tablas:</p> <pre><code>services:\n  nginx:\n    build: ./nginx/\n    container_name: nginx-container\n    ports:\n      - 80:80\n    links:\n      - php\n    volumes_from:\n      - app-data\n  php:\n    build: ./php/\n    container_name: php-container\n    expose:\n      - 9000\n    links:\n      - mysql\n    volumes_from:\n      - app-data\n\n  app-data:\n    image: php:7.0-fpm\n    container_name: app-data-container\n    volumes:\n      - ./www/html/:/var/www/html/\n    command: \"true\"\n\n  mysql:\n    image: mysql:5.7\n    container_name: mysql-container\n    volumes_from:\n      - mysql-data\n    environment:\n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE: mydb\n      MYSQL_USER: myuser\n      MYSQL_PASSWORD: password\n\n  mysql-data:\n    image: mysql:5.7\n    container_name: mysql-data-container\n    volumes:\n      - /var/lib/mysql\n    command: \"true\"\n</code></pre> <p>Despu\u00e9s de guardar este archivo, editamos el archivo <code>index.php</code> y hacemos algunos cambios para comprobar la conexi\u00f3n a la base de datos.</p> <p>El archivo <code>index.php</code> debe quedar as\u00ed:</p> <pre><code>     &lt;!DOCTYPE html&gt;\n     &lt;head&gt;\n      &lt;title&gt;\u00a1Hola mundo!&lt;/title&gt;\n     &lt;/head&gt;\n\n     &lt;body&gt;\n      &lt;h1&gt;\u00a1Hola mundo!&lt;/h1&gt;\n      &lt;p&gt;&lt;?php echo 'Estamos corriendo PHP, version: ' . phpversion(); ?&gt;&lt;/p&gt;\n      &lt;?\n       $database =\"mydb\";\n       $user = \"myuser\";\n       $password = \"password\";\n       $host = \"mysql\";\n\n       $connection = new PDO(\"mysql:host={$host};dbname={$database};charset=utf8\", $user, $password);\n       $query = $connection-&gt;query(\"SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_TYPE='BASE TABLE'\");\n       $tables = $query-&gt;fetchAll(PDO::FETCH_COLUMN);\n\n        if (empty($tables)) {\n          echo \"&lt;p&gt;No hay tablas en la base de datos \\\"{$database}\\\".&lt;/p&gt;\";\n        } else {\n          echo \"&lt;p&gt;La base de datos \\\"{$database}\\\" tiene las siguientes tablas:&lt;/p&gt;\";\n          echo \"&lt;ul&gt;\";\n            foreach ($tables as $table) {\n              echo \"&lt;li&gt;{$table}&lt;/li&gt;\";\n            }\n          echo \"&lt;/ul&gt;\";\n        }\n        ?&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Guardad el archivo y lanzad los contenedores una vez m\u00e1s:</p> <pre><code>docker-compose up -d\n</code></pre> <p>Y verificamos que est\u00e1n ejecut\u00e1ndose:</p> <p><pre><code>docker ps -a\n</code></pre> Y veremos:</p> <pre><code>CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS                      PORTS                               NAMES\nd3e82747fe0d   mysql:5.7              \"docker-entrypoint.s\u2026\"   39 seconds ago   Up 38 seconds               3306/tcp, 33060/tcp                 mysql-container\n606320e5a7f8   mysql:5.7              \"docker-entrypoint.s\u2026\"   41 seconds ago   Exited (0) 39 seconds ago                                       mysql-data-container\nca4f63797d11   docker-project_php     \"docker-php-entrypoi\u2026\"   2 hours ago      Up 2 hours                  9000/tcp                            php-container\n849315c7ffc0   docker-project_nginx   \"/docker-entrypoint.\u2026\"   2 hours ago      Up 2 hours                  0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx-container\nfbca95944234   php:7.0-fpm            \"docker-php-entrypoi\u2026\"   2 hours ago      Exited (0) 39 seconds ago                                       app-data-\n</code></pre> <p>Question</p> <p>Nuevamente usa un contenedor para alojar datos. \u00bfTiene sentido usar un contenedor cuya \u00fanica funci\u00f3n es alojar datos? \u00bfQu\u00e9 otra forma nos ofrece docker para este cometido? \u00bfC\u00f3mo podr\u00edas modificar el docker-compose.yaml para hacerlo?</p>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#6-verificacion-de-conexion-a-la-base-de-datos","title":"6. Verificaci\u00f3n de conexi\u00f3n a la base de datos","text":"<p>Atenci\u00f3n</p> <p>Puede tardar un poco en arrancarse la base de datos desde que lances el contenedor. Espera un poco si te da error de conexi\u00f3n a la base de datos.</p> <p>Si ahora accedemos a <code>http://IP_Maq_Virtual</code>, deber\u00edamos obtener la siguiente pantalla:</p> <p></p> <p>Como pod\u00e9is ver, nos dice que no tenemos ninguna tabla en la base de datos mydb.</p> <p>Sin embargo, el hecho es que realmente s\u00ed existen algunas tablas, s\u00edmplemente no son visibles para un usuario normal. Si quisi\u00e9ramos verlas, debemos editar el archivo <code>index.php</code> y cambiar <code>$user</code> por <code>root</code> y <code>$password</code> a <code>secret</code>.</p> <p>Es decir:</p> <p><pre><code>nano /home/usuario/www/html/index.php\n</code></pre> Y cambiar las l\u00edneas:</p> <p><pre><code>$user = \"root\";\n$password = \"secret\";\n</code></pre> Guardad el archivo y refrescad la p\u00e1gina. Deber\u00edas obtener ahora una pantalla con todas las tablas de la base de datos, tal que as\u00ed:</p> <p></p> <p>Tarea</p> <p>Esta pr\u00e1ctica usa algunas cosas de docker que est\u00e1n obsoletas. Aunque la pr\u00e1ctica funciona podr\u00eda mejorarse usando pr\u00e1cticas m\u00e1s actuales. Te propongo que modifiques el <code>docker-compose.yaml</code> para hacerlo m\u00e1s limpio y mejorado.</p> <p>Algunas de las cosas que podr\u00edan mejorarse son:</p> <ul> <li>Uso de directiva <code>links</code></li> <li>Uso de <code>volumes_from</code></li> <li>Uso de vol\u00famenes en lugar de contenedores para almacenar los datos</li> </ul>"},{"location":"Ud3%20Servidores%20web/P06DockerizacionPHPNginx/#referencias","title":"Referencias","text":"<p>\u00bfQu\u00e9 es Docker Compose?</p> <p>\u00bfQu\u00e9 demonios es Docker y Docker-Compose? y c\u00f3mo Dockerizar Dotnet Core WebApi y SQL Server en un ambiente de desarrollo ideal</p> <p>Introducci\u00f3n a docker-compose</p> <p>How to Deploy a PHP Application with Nginx and MySQL Using Docker and Docker Compose</p>"},{"location":"Ud3%20Servidores%20web/PV01/","title":"Pr\u00e1ctica Voluntaria 3.1 \u2013 Proxy inverso con Nginx","text":""},{"location":"Ud3%20Servidores%20web/PV01/#requisitos-antes-de-comenzar-la-practica","title":"Requisitos antes de comenzar  la pr\u00e1ctica","text":"<p>Atenci\u00f3n, importante antes de comenzar</p> <ul> <li>La pr\u00e1ctica 2.1 ha de estar funcionando correctamente</li> <li>No comenzar la pr\u00e1ctica antes de tener la 2.1 funcionando y comprobada</li> </ul>"},{"location":"Ud3%20Servidores%20web/PV01/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"Ud3%20Servidores%20web/PV01/#que-es-un-servidor-proxy","title":"\u00bfQu\u00e9 es un servidor proxy?","text":"<p>Un proxy de reenv\u00edo, a menudo llamado proxy, servidor proxy o proxy web, es un servidor que se encuentra frente a un grupo de m\u00e1quinas cliente. Cuando esas m\u00e1quinas realizan solicitudes a sitios y servicios en Internet, el servidor proxy intercepta esas solicitudes y luego se comunica con los servidores web en nombre de esos clientes, como un intermediario. </p> <p>Por ejemplo, tomemos como ejemplo 3 m\u00e1quinas involucradas en una comunicaci\u00f3n t\u00edpica de proxy de reenv\u00edo: </p> <ul> <li> <p>A: Esta es la m\u00e1quina del hogar de un usuario. </p> </li> <li> <p>B: este es un servidor proxy de reenv\u00edo </p> </li> <li> <p>C: este es el servidor de origen de un sitio web (donde se almacenan los datos del sitio web) </p> </li> </ul> <p></p> <p>En una comunicaci\u00f3n est\u00e1ndar por Internet, la m\u00e1quina A se comunicar\u00eda directamente con la m\u00e1quina C, con el cliente enviando solicitudes al servidor de origen y el servidor de origen respondiendo al cliente. Cuando hay un proxy de reenv\u00edo, A enviar\u00e1 solicitudes a B, que luego reenviar\u00e1 la solicitud a C. C enviar\u00e1 una respuesta a B, que reenviar\u00e1 la respuesta a A. </p> <p>\u00bfPor qu\u00e9 agregar este intermediario adicional a nuestra actividad en Internet? </p> <p></p> <p>Hay algunas razones por las que uno podr\u00eda querer usar un proxy de reenv\u00edo: </p> <ul> <li> <p>Para evitar restricciones de navegaci\u00f3n estatales o institucionales: algunos gobiernos, escuelas y otras organizaciones usan firewalls para dar a sus usuarios acceso a una versi\u00f3n limitada de Internet. Se puede usar un proxy de reenv\u00edo para sortear estas restricciones, ya que permiten que el usuario se conecte al proxy en lugar de directamente a los sitios que est\u00e1 visitando. </p> </li> <li> <p>Para bloquear el acceso a cierto contenido: a la inversa, los proxies tambi\u00e9n se pueden configurar para bloquear el acceso de un grupo de usuarios a ciertos sitios. Por ejemplo, una red escolar puede estar configurada para conectarse a la web a trav\u00e9s de un proxy que habilita reglas de filtrado de contenido, neg\u00e1ndose a reenviar respuestas de Facebook y otros sitios de redes sociales. </p> </li> <li> <p>Para proteger su identidad en l\u00ednea: en algunos casos, los usuarios habituales de Internet simplemente desean un mayor anonimato en l\u00ednea, pero en otros casos, los usuarios de Internet viven en lugares donde el gobierno puede imponer graves consecuencias a los disidentes pol\u00edticos. Criticar al gobierno en un foro web o en las redes sociales puede dar lugar a multas o encarcelamiento para estos usuarios. Si uno de estos disidentes usa un proxy de reenv\u00edo para conectarse a un sitio web donde publica comentarios pol\u00edticamente sensibles, la direcci\u00f3n IP utilizada para publicar los comentarios ser\u00e1 m\u00e1s dif\u00edcil de rastrear hasta el disidente. Solo estar\u00e1 visible la direcci\u00f3n IP del servidor proxy. </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV01/#en-que-se-diferencia-un-proxy-inverso","title":"\u00bfEn qu\u00e9 se diferencia un proxy inverso?","text":"<p>Estar\u00edamos hablando del caso opuesto al anterior. </p> <p>Un proxy inverso es un servidor que se encuentra frente a uno o m\u00e1s servidores web, interceptando las solicitudes de los clientes. Esto es diferente de un proxy de reenv\u00edo, donde el proxy se encuentra frente a los clientes. Con un proxy inverso, cuando los clientes env\u00edan solicitudes al servidor de un sitio web, esas solicitudes son interceptadas en la frontera de la red por el servidor proxy inverso. El servidor proxy inverso enviar\u00e1 solicitudes y recibir\u00e1 respuestas del servidor del sitio web. </p> <p>La diferencia entre un proxy directo y inverso es sutil pero importante. Una forma simplificada de resumir ser\u00eda decir que un proxy de reenv\u00edo se encuentra frente a un cliente y garantiza que ning\u00fan servidor de origen se comunique nunca directamente con ese cliente espec\u00edfico. Por otro lado, un proxy inverso se encuentra frente a un servidor de origen y garantiza que ning\u00fan cliente se comunique nunca directamente con ese servidor de origen. </p> <p>Una vez m\u00e1s, ilustremos nombrando las m\u00e1quinas involucradas: </p> <ul> <li> <p>D: cualquier n\u00famero de ordenadores dom\u00e9sticos de los usuarios </p> </li> <li> <p>E: este es un servidor proxy inverso </p> </li> <li> <p>F: uno o m\u00e1s servidores de origen </p> </li> </ul> <p></p> <p>Normalmente, todas las solicitudes de D ir\u00edan directamente a F, y F enviar\u00eda respuestas directamente a D. Con un proxy inverso, todas las solicitudes de D ir\u00e1n directamente a E, y E enviar\u00e1 sus solicitudes ay recibir\u00e1 respuestas de F. E luego transmita las respuestas apropiadas a D. </p> <p>A continuaci\u00f3n se describen algunos de los beneficios de un proxy inverso: </p> <ul> <li> <p>Balanceo de carga: es posible que un sitio web popular que recibe millones de usuarios todos los d\u00edas no pueda manejar todo el tr\u00e1fico entrante del sitio con un solo servidor de origen. En cambio, el sitio se puede distribuir entre un grupo de servidores diferentes, todos manejando solicitudes para el mismo sitio. En este caso, un proxy inverso puede proporcionar una soluci\u00f3n de balanceo de carga que distribuir\u00e1 el tr\u00e1fico entrante de manera uniforme entre los diferentes servidores para evitar que un solo servidor se sobrecargue. En el caso de que un servidor falle por completo, otros servidores pueden intensificar para manejar el tr\u00e1fico. </p> </li> <li> <p>Protecci\u00f3n contra ataques: con un proxy inverso en su lugar, un sitio web o servicio nunca necesita revelar la direcci\u00f3n IP de su (s) servidor (es) de origen. Esto hace que sea mucho m\u00e1s dif\u00edcil para los atacantes aprovechar un ataque dirigido contra ellos, como un ataque DdoS. </p> </li> <li> <p>Almacenamiento en cach\u00e9: un proxy inverso tambi\u00e9n puede almacenar contenido en cach\u00e9 , lo que resulta en un rendimiento m\u00e1s r\u00e1pido. Por ejemplo, si un usuario en Par\u00eds visita un sitio web con proxy inverso con servidores web en Los \u00c1ngeles, el usuario podr\u00eda conectarse a un servidor proxy inverso local en Par\u00eds, que luego tendr\u00e1 que comunicarse con un servidor de origen en Los \u00c1ngeles. El servidor proxy luego puede almacenar en cach\u00e9 (o guardar temporalmente) los datos de respuesta. Los usuarios parisinos posteriores que naveguen por el sitio obtendr\u00e1n la versi\u00f3n en cach\u00e9 local del servidor proxy inverso parisino, lo que dar\u00e1 como resultado un rendimiento mucho m\u00e1s r\u00e1pido. </p> </li> <li> <p>Cifrado SSL - Cifrado y descifrado SSL (o TLS comunicaciones) para cada cliente pueden ser computacionalmente caro para un servidor de origen. Se puede configurar un proxy inverso para descifrar todas las solicitudes entrantes y cifrar todas las respuestas salientes, liberando valiosos recursos en el servidor de origen. </p> </li> </ul> <p></p>"},{"location":"Ud3%20Servidores%20web/PV01/#tarea","title":"Tarea","text":""},{"location":"Ud3%20Servidores%20web/PV01/#configuraciones","title":"Configuraciones","text":""},{"location":"Ud3%20Servidores%20web/PV01/#nginx-servidor-web","title":"Nginx servidor web","text":"<p>Vamos a configurar dos Debian con sendos servidores Nginx. Ten\u00e9is la m\u00e1quina virtual inicial y deb\u00e9is clonarla para tener una segunda: </p> <ul> <li> <p>Uno servir\u00e1 las p\u00e1ginas web que ya hemos configurado, as\u00ed pues utilizaremos el servidor que ya tenemos configurado de la Pr\u00e1ctica 2.1. </p> </li> <li> <p>El nuevo servidor clon Debian con Nginx configurado como proxy inverso</p> </li> <li> <p>Realizaremos las peticiones HTTP desde el navegador web de nuestra m\u00e1quina f\u00edsica/anfitri\u00f3n hacia el proxy clonado, que nos redirigir\u00e1 al servidor web original</p> </li> </ul> <p>Cuidado</p> <p>Ojo al clonar las m\u00e1quinas virtuales porque hay que darle a crear una nueva MAC, de lo contrario no tendr\u00e9is IP en esa m\u00e1quina.</p> <p>El diagrama de red quedar\u00eda as\u00ed: </p> <p></p> <p>Para que todo quede m\u00e1s diferenciado y os quede m\u00e1s claro que la petici\u00f3n est\u00e1 pasando por el proxy inverso y llega al servidor web destino, vamos a hacer que cada uno de los servidores escuche las peticiones en un puerto distinto. </p> <ol> <li> <p>En primer lugar, deb\u00e9is cambiar el nombre que tuviera vuestra web por el de <code>webserver</code>, ello implica: </p> <ul> <li> <p>Cambiar el nombre del archivo de configuraci\u00f3n de sitios disponibles par Nginx</p> </li> <li> <p>Cambiar el nombre del sitio web dentro de este archivo de configuraci\u00f3n donde haga falta </p> </li> <li> <p>No os olvid\u00e9is de eliminar el link simb\u00f3lico antiguo  con el comando <code>unlink nombre_del_link</code> dentro de la carpeta <code>sites-enabled</code> y crear el nuevo para el nuevo nombre de archivo. </p> </li> </ul> </li> <li> <p>En el archivo de configuraci\u00f3n del sitio web, en lugar de hacer que el servidor escuche en el puerto 80, cambiadlo al 8080. </p> </li> <li> <p>Reiniciar Nginx </p> </li> </ol>"},{"location":"Ud3%20Servidores%20web/PV01/#nginx-proxy-inverso","title":"Nginx proxy inverso","text":"<p>Ahora, cuando intentamos acceder a <code>http://ejemplo-proxy</code> (o el nombre que tuvier\u00e1is de vuestra web de las pr\u00e1cticas anteriores), en realidad estaremos accediendo al proxy, que nos redirigir\u00e1 a <code>http://webserver:8080</code>, el servidor web que acabamos de configurar para que escuche con ese nombre en el puerto 8080. </p> <p>Para ello: </p> <ul> <li> <p>Crear un archivo de configuraci\u00f3n en sites-available con el nombre <code>ejemplo-proxy</code> (o el que tuvier\u00e1is vosotros) </p> </li> <li> <p>Este archivo de configuraci\u00f3n ser\u00e1 m\u00e1s simple, tendr\u00e1 la siguiente forma </p> </li> </ul> <pre><code>server { \n    listen __; \n    server_name ____________; \n    location / { \n    proxy_pass http://_________:____; \n    } \n} \n</code></pre> <p>Donde, mirando el diagrama de red y teniendo en cuenta la configuraci\u00f3n hecha hasta ahora, deb\u00e9is completar: </p> <ul> <li> <p>El puerto donde est\u00e1 escuchando el proxy inverso </p> </li> <li> <p>El nombre de vuestro dominio o sitio web original al que accedemos en el proxy </p> </li> <li> <p>La directiva <code>proxy_pass</code> indica a d\u00f3nde se van a redirigir las peticiones, esto es, al servidor web. Por tanto, deb\u00e9is poner la IP y n\u00famero de puerto adecuados de vuestro sitio web configurado en el apartado anterior. </p> </li> <li> <p>Crear el link simb\u00f3lico pertinente </p> </li> </ul> <p>Esto es para simular la situaci\u00f3n en la que nosotros, como clientes, cuando accedamos a nuestro sitio web, no necesitemos saber c\u00f3mo est\u00e1 todo configurado, s\u00f3lo necesitamos saber el nombre de la web. </p> <p>\u00a1Atenci\u00f3n, muy importante!</p> <p>Deb\u00e9is modificar el archivo host que configurast\u00e9is en la pr\u00e1ctica 2.1. Si mir\u00e1is el diagrama de red, ahora el nombre de vuestro sitio web se corresponder\u00e1 con la IP de la nueva m\u00e1quina clon que hace de proxy. Ser\u00e1 \u00e9sta la encargada de redirigirnos autom\u00e1ticamente al verdadero sitio web.</p>"},{"location":"Ud3%20Servidores%20web/PV01/#comprobaciones","title":"Comprobaciones","text":"<p>Si acced\u00e9is a vuestro sitio web, deb\u00e9is poder seguir accediendo sin problemas. </p> <ul> <li> <p>Comprobad en los access.log de los dos servidores que llega la petici\u00f3n </p> </li> <li> <p>Comprobad adem\u00e1s la petici\u00f3n y respuesta con las herramientas de desarrollador de Firefox en Xubuntu. Pulsando F12 en el navegador os aparecer\u00e1n estas herramientas</p> </li> </ul> <p></p> <p>En la primera petici\u00f3n (marcada en rojo), utilizando el apartado \u201cRed\u201d (tambi\u00e9n marcado en rojo) y tambi\u00e9n en rojo est\u00e1 se\u00f1alado d\u00f3nde se puede ver la respuesta de la petici\u00f3n GET HTTP (200 OK). </p> <p>Tambi\u00e9n vemos las cabeceras que se incluyen en la petici\u00f3n (m\u00e9todo GET) y en la respuesta a esta petici\u00f3n. </p>"},{"location":"Ud3%20Servidores%20web/PV01/#anadiendo-cabeceras","title":"A\u00f1adiendo cabeceras","text":"<p>Adem\u00e1s de haber mirado los logs, vamos a demostrar a\u00fan de forma m\u00e1s clara que la petici\u00f3n est\u00e1 pasando por el proxy inverso y que est\u00e1 llegando al servidor web y que vuelve por el mismo camino. </p> <p>Si record\u00e1is de teor\u00eda, el servidor web es capaz de a\u00f1adir cabeceras en las respuestas a las peticiones. </p> <p>As\u00ed pues, vamos a configurar tanto el proxy inverso como el servidor web para que a\u00f1adan cada uno la cabecera \u201cHost\u201d que tambi\u00e9n vimos en teor\u00eda. </p> <p>Para a\u00f1adir cabeceras, en el archivo de configuraci\u00f3n del sitio web debemos a\u00f1adir dentro del bloque <code>location / { \u2026 }</code> debemos a\u00f1adir la directiva: </p> <pre><code>add_header Host nombre_del_host;\n</code></pre> <ol> <li> <p>A\u00f1adiremos primero esta cabecera \u00fanicamente en el archivo de configuraci\u00f3n del sitio web del proxy inverso. El Nombre_del_host ser\u00e1 Proxy_inverso_vuestronombre. </p> </li> <li> <p>Reiniciamos Nginx </p> </li> <li> <p>Comprobamos que podemos acceder al sitio web sin problemas </p> </li> <li> <p>Con las herramientas de desarrollador comprobamos que la petici\u00f3n ha pasado por el proxy inverso que ha a\u00f1adido la cabecera en la respuesta: </p> <p></p> </li> <li> <p>Hacemos lo propio con el servidor web. Esta vez el <code>Nombre_del_host</code> ser\u00e1 <code>servidor_web_vuestronombre</code>. </p> <p>Si todo est\u00e1 configurado correctamente, al examinar las peticiones y respuestas, os aparecer\u00e1n las dos cabeceras que han incluido en la respuesta tanto el proxy inverso como el servidor web. .</p> <p></p> </li> </ol> <p>Es muy importante que para realizar estas comprobaciones teng\u00e1is marcado el checkbox Desactivar cach\u00e9 o en una ventana privada del navegador.</p> <p></p> <p>Si no marc\u00e1is esto, la p\u00e1gina se guardar\u00e1 en la memoria cach\u00e9 del navegador y no estar\u00e9is recibiendo la respuesta del servidor sino de la cach\u00e9 del navegador, lo que puede dar lugar a resultados err\u00f3neos. </p>"},{"location":"Ud3%20Servidores%20web/PV01/#evaluacion","title":"Evaluaci\u00f3n","text":"Criterio Puntuaci\u00f3n Configuraci\u00f3n correcta y completa del servidor web 3 puntos Configuraci\u00f3n correcta y completa del proxy inverso 4 puntos Comprobaci\u00f3n del correcto funcionamento, incluyendo las cabeceras 1 puntos Se ha prestado especial atenci\u00f3n al formato del documento, utilizando la plantilla actualizada y haciendo un correcto uso del lenguaje t\u00e9cnico 2 puntos"},{"location":"Ud3%20Servidores%20web/PV02/","title":"Pr\u00e1ctica Voluntaria 3.2 \u2013 Balanceo de carga con proxy inverso en Nginx","text":""},{"location":"Ud3%20Servidores%20web/PV02/#requisitos-aantes-de-comenzar-la-practica","title":"Requisitos aantes de comenzar la pr\u00e1ctica","text":"<p>Atenci\u00f3n, muy importante antes de empezar</p> <ul> <li>La pr\u00e1ctica 2.3 debe estar funcionando correctamente</li> <li>No empezar la pr\u00e1ctica antes de tener la 2.3 funcionando y comprobada </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV02/#introduccion","title":"Introducci\u00f3n","text":"<p>Los servidores proxy inversos y los balanceadores de carga son componentes de una arquitectura inform\u00e1tica cliente-servidor. Ambos act\u00faan como intermediarios en la comunicaci\u00f3n entre los clientes y los servidores, realizando funciones que mejoran la eficiencia. </p> <p>Las definiciones b\u00e1sicas son simples: </p> <ul> <li> <p>Un proxy inverso     acepta una solicitud de un cliente, la reenv\u00eda a un servidor que puede cumplirla y devuelve la respuesta del servidor al cliente.  </p> </li> <li> <p>Un balanceador de carga     distribuye las solicitudes entrantes del cliente entre un grupo de servidores, en cada caso devolviendo la respuesta del servidor seleccionado al cliente apropiado. </p> </li> </ul> <p>Suenan bastante similares, \u00bfverdad? Ambos tipos de aplicaciones se ubican entre clientes y servidores, aceptando solicitudes del primero y entregando respuestas del segundo. No es de extra\u00f1ar que haya confusi\u00f3n sobre qu\u00e9 es un proxy inverso y un balanceador de carga. Para ayudar a diferenciarlos, exploremos cu\u00e1ndo y por qu\u00e9 normalmente se implementan en un sitio web. .</p>"},{"location":"Ud3%20Servidores%20web/PV02/#proxy-inverso","title":"Proxy inverso","text":"<p>Ya conocemos este concepto de la pr\u00e1ctica anterior. </p> <p>Mientras que implementar un balanceador de carga solo tiene sentido cuando se tienen varios servidores, a menudo tiene sentido implementar un proxy inverso incluso con un solo servidor web o servidor de aplicaciones. </p> <p>Se puede pensar en el proxy inverso como la \"cara p\u00fablica\" de un sitio web. Su direcci\u00f3n es la que se anuncia para el sitio web y se encuentra en la frontera de la red del sitio para aceptar solicitudes de navegadores web y aplicaciones m\u00f3viles para el contenido alojado en el sitio web. </p>"},{"location":"Ud3%20Servidores%20web/PV02/#balanceadores-de-carga","title":"Balanceadores de carga","text":"<p>Los balanceadores de carga se implementan con mayor frecuencia cuando un sitio necesita varios servidores porque el volumen de solicitudes es demasiado para que un solo servidor lo maneje de manera eficiente. </p> <p>La implementaci\u00f3n de varios servidores tambi\u00e9n elimina un solo punto de fallo, lo que hace que el sitio web sea m\u00e1s confiable. Por lo general, todos los servidores alojan el mismo contenido, y el trabajo del balanceador de carga es distribuir la carga de trabajo de  manera que se haga el mejor uso de la capacidad de cada servidor, evite la sobrecarga en cualquiera de ellos y d\u00e9 como resultado la respuesta m\u00e1s r\u00e1pida posible al cliente. . </p> <p>Un balanceador de carga tambi\u00e9n puede mejorar la experiencia del usuario al reducir la cantidad de respuestas de error que ve el cliente. Lo hace detectando cu\u00e1ndo los servidores caen y desviando las solicitudes de ellos a los otros servidores del grupo. En la implementaci\u00f3n m\u00e1s simple, el balanceador de carga detecta el estado del servidor al interceptar las respuestas de error a las solicitudes regulares. </p> <p>En esta pr\u00e1ctica tendremos el escenario donde Nginx har\u00e1 tanto de proxy inverso como de balanceador de carga al mismo tiempo.  </p> <p>Info</p> <p>En esta pr\u00e1ctica tendremos un escenario donde Nginx har\u00e1 tanto de proxy inverso como de balanceador de carga al mismo tiempo</p>"},{"location":"Ud3%20Servidores%20web/PV02/#tarea","title":"Tarea","text":"<p>Vamos a configurar dos servidores web Nginx con dos m\u00e1quinas Debian, adem\u00e1s de reutilizar el proxy inverso Nginx configurado en la pr\u00e1ctica anterior. Partiremos por tanto de la configuraci\u00f3n de la pr\u00e1ctica anterior, a\u00f1adiendo lo necesario: </p> <ul> <li> <p>Cada servidor web presentar\u00e1 un sitio web espec\u00edfico para esta pr\u00e1ctica </p> <ul> <li>El webserver2 debe tener la IP asignada de forma fija mediante la configuraci\u00f3n DHCP. </li> </ul> </li> <li> <p>El proxy inverso que ya ten\u00edamos configurado, habr\u00e1 ahora que configurarlo para que realice el balanceo de carga que deseamos </p> </li> <li> <p>Realizaremos las peticiones HTTP desde el navegador web de nuestra m\u00e1quina anfitriona. </p> </li> </ul> <p>El diagrama de red quedar\u00eda as\u00ed: </p> <p></p> <p>Haremos las peticiones web desde el navegador al proxy inverso, que las repartir\u00e1 entre los dos servidores web que tenemos. </p> <p>Accederemos a <code>http://balanceo</code> y debemos observar que las peticiones, efectivamente, se van repartiendo entre el servidor 1 y el 2. </p>"},{"location":"Ud3%20Servidores%20web/PV02/#configuraciones","title":"Configuraciones","text":"<p>Atenci\u00f3n</p> <p>Ya no vamos a utilizar los sitios web que hemos configurado en las pr\u00e1cticas anteriores. Por ello, para evitarnos una serie de problemas que pueden surgir, vamos a desactivarlos.</p> <p>Dentro de la carpeta <code>/etc/nginx/sites-enabled</code> debemos ejecutar <code>unlink nombre_archivo</code> para cada uno de los archivos de los sitios web que tenemos.</p> <p>Si no hac\u00e9is esto obtendr\u00e9is errores en todas las pr\u00e1cticas que quedan de este tema.</p>"},{"location":"Ud3%20Servidores%20web/PV02/#nginx-servidor-web-1","title":"Nginx Servidor Web 1","text":"<p>El primer servidor web ser\u00e1 el servidor principal que hemos venido utilizando hasta ahora durante el curso, el original, donde tenemos instalado ya el servicio Web. </p> <p>Debemos configurar este servidor web para que sirva el siguiente <code>index.html</code> que deb\u00e9is crear dentro de la carpeta <code>/var/www/webserver1/html</code>: </p> <p></p> <ul> <li> <p>El nombre del sitio web que deb\u00e9is utilizar en los archivos correspondientes (sites-available\u2026) que deb\u00e9is crear para Nginx es <code>webserver1</code>, as\u00ed como en sus configuraciones. Fij\u00e1os en las configuraciones que hicisteis en pr\u00e1cticas anteriores a modo de referencia. </p> </li> <li> <p>El sitio web debe escuchar en el puerto 8080. </p> </li> <li> <p>Deb\u00e9is a\u00f1adir una cabecera que se llame <code>Serv_Web1_vuestronombre</code>. </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV02/#nginx-servidor-web-2","title":"Nginx Servidor Web 2","text":"<p>Debe ser una m\u00e1quina Debian, clon del servidor web 1. </p> <p>En este servidor web debemos realizar una configuraci\u00f3n id\u00e9ntica al servidor web 1 pero cambiando <code>webserver1</code> por <code>webserver2</code> (tambi\u00e9n en el index.html), as\u00ed como el nombre de la cabecera a\u00f1adida, que ser\u00e1 <code>Serv_Web2_vuestronombre</code></p> <p>Warning</p> <p>Es importante que no quede ninguna referencia a webserver1 por ning\u00fan archivo, de otra forma os dar\u00e1 resultados err\u00f3neos y os dificultar\u00e1 mucho encontrar el error.</p>"},{"location":"Ud3%20Servidores%20web/PV02/#nginx-proxy-inverso","title":"Nginx Proxy Inverso","text":"<p>Ya disponemos de los dos servidores web entre los que se van a repartir las peticiones que realice el cliente desde el navegador. </p> <p>Vamos, por tanto, a configurar el proxy inverso para que realice este reparto de peticiones: </p> <ul> <li>En sites-available deb\u00e9is crear el archivo de configuraci\u00f3n con el nombre balanceo</li> </ul> <p>Este archivo tendr\u00e1 el siguiente formato:</p> <p><pre><code>    upstream backend_hosts {\n                random;\n                server ________:____;\n                server ________:____;\n    }\n            server {\n                listen 80;\n                server_name ________;      \n                location / {\n                    proxy_pass http://backend_hosts;\n                }\n            }\n</code></pre> Donde: </p> <ul> <li> <p>El bloque upstream \u2192 son los servidores entre los que se va a repartir la carga, que son los dos que hemos configurado anteriormente. </p> </li> <li> <p>Si mir\u00e1is el diagrama y ten\u00e9is en cuenta la configuraci\u00f3n que hab\u00e9is hecho hasta ahora, aqu\u00ed deber\u00e9is colocar la IP de cada servidor, as\u00ed como el puerto donde est\u00e1 escuchando las peticiones web. </p> </li> <li> <p>A este grupo de servidores le ponemos un nombre, que es <code>backend_hosts</code></p> </li> </ul> <p>Aclaraci\u00f3n</p> <p>En un sitio web, el backend se encarga de todos los procesos necesarios para que la web funcione de forma correcta. Estos procesos o funciones no son visibles pero tienen mucha importancia en el buen funcionamiento de un sitio web.</p> <ul> <li> <p>El par\u00e1metro random lo que hace es repartir las peticiones HTTP que llegan al proxy inverso de forma completamente aleatoria entre el grupo de servidores que se haya definido en el bloque upstream (en nuestro caso s\u00f3lo hay dos). </p> <ul> <li>Pondremos random porque es lo m\u00e1s f\u00e1cil para comprobar que todo funciona bien en la pr\u00e1ctica, pero hay diferentes formas de repartir la carga (las peticiones HTTP). </li> </ul> </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV02/#comprobaciones","title":"Comprobaciones","text":"<p>Si acced\u00e9is a vuestro sitio web, deb\u00e9is poder seguir accediendo sin problemas. </p> <ul> <li> <p>Comprobad d\u00e1ndole repetidamente a F5, que acced\u00e9is cada vez a uno de los servidores. Se os mostrar\u00e1 el contenido del index.html del servidor correspondiente cada vez. </p> <ul> <li>Para una doble comprobaci\u00f3n, utilizando las herramientas de desarrollador, mostrad que la web que se os muestra coincide con la cabecera que ha a\u00f1adido el servidor web en la respuesta HTTP. </li> </ul> </li> </ul> <p>Recordatorio</p> <p>Recordad que es muy importante que para realizar estas comprobaciones teng\u00e1is marcado el checkbox Desactivar cach\u00e9.  </p> <p></p> <p>Si no marc\u00e1is esto, la p\u00e1gina se guardar\u00e1 en la memoria cach\u00e9 del navegador y no estar\u00e9is recibiendo la respuesta del servidor sino de la cach\u00e9 del navegador, lo que puede dar lugar a resultados err\u00f3neos. </p> <p>Otra opci\u00f3n, si esto no funcionara, es hacer las pruebas con una nueva ventana privada del navegador.</p>"},{"location":"Ud3%20Servidores%20web/PV02/#comprobacion-del-balanceo-de-carga-cuando-cae-un-servidor","title":"Comprobaci\u00f3n del balanceo de carga cuando cae un servidor","text":"<p>Nuestro balanceador de carga est\u00e1 constantemente monitorizando \u201cla salud\u201d de los servidores web. De esta forma, si uno deja de funcionar por cualquier raz\u00f3n, siempre enviar\u00e1 las solicitudes a los que queden \u201cvivos\u201d. Vamos a comprobarlo: </p> <ul> <li> <p>Para el servicio Nginx en el servidor web 1 y comprueba, de la misma forma que en el apartado anterior, que todas las solicitudes se env\u00edan ahora al servidor web 2 </p> </li> <li> <p>Tras iniciar de nuevo Nginx en el servidor web 1, repite el proceso con el servidor web 2.  </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV02/#cuestiones-finales","title":"Cuestiones finales","text":"<p>Cuesti\u00f3n 1</p> <p>Busca informaci\u00f3n de qu\u00e9 otros m\u00e9todos de balanceo se pueden aplicar con Nginx y describe al menos 3 de ellos.</p> <p>Cuesti\u00f3n 2</p> <p>Si quiero a\u00f1adir 2 servidores web m\u00e1s al balanceo de carga, describe detalladamente qu\u00e9 configuraci\u00f3n habr\u00eda que a\u00f1adir y d\u00f3nde.</p> <p>Cuesti\u00f3n 3</p> <p>Describe todos los pasos que deber\u00edamos seguir y configurar para realizar el balanceo de carga con una de las webs de pr\u00e1cticas anteriores.</p> <p>Indicad la configuraci\u00f3n de todas las m\u00e1quinas (webservers, proxy...) y de sus servicios</p>"},{"location":"Ud3%20Servidores%20web/PV02/#evaluacion","title":"Evaluaci\u00f3n","text":"Criterio Puntuaci\u00f3n Configuraci\u00f3n correcta y completa del servidor web 1 2 puntos Configuraci\u00f3n correcta y completa del servidor web 2 2 puntos Configuraci\u00f3n correcta y completa del proxy inverso 3 puntos Cuestiones finales 1 puntos Se ha prestado especial atenci\u00f3n al formato del documento, utilizando la plantilla actualizada y haciendo un correcto uso del lenguaje t\u00e9cnico 2 puntos"},{"location":"Ud3%20Servidores%20web/PV03/","title":"Practica Voluntaria 3.3 - Proxy inverso y balanceo de carga con SSL en NGINX","text":""},{"location":"Ud3%20Servidores%20web/PV03/#requisitos-antes-de-comenzar-la-practica","title":"Requisitos antes de comenzar la pr\u00e1ctica","text":"<p>Atenci\u00f3n, muy importante antes de comenzar</p> <ul> <li>La pr\u00e1ctica 4.4 ha d'estar funcionant correctament</li> <li>No comenzar la pr\u00e1ctica antes de tener la 1.3 funcionant i comprovada</li> </ul>"},{"location":"Ud3%20Servidores%20web/PV03/#introduccion","title":"Introducci\u00f3n","text":"<p>A partir de las pr\u00e1cticas anteriores hemos llegado a un escenario donde un proxy inverso act\u00faa de intermediario entre dos servidores web Nginx, balanceando la carga entre ellos. </p> <p>Ya dijimos que una importante funci\u00f3n que pod\u00eda tener un proxy inverso era realizar el cifrado y descifrado de SSL para utilizar HTTPS en los servidores web. De esta forma se aliviaba la carga de trabajo de los servidores web, ya que es una tarea que consume recursos. </p> <p>En definitiva, tendr\u00edamos un esquema como este: </p> <p></p> <p>Podr\u00eda llegarse a pensar que en t\u00e9rminos de seguridad no es adecuado que el tr\u00e1fico de red entre el balanceador de carga y los servidores web vaya sin cifrar (HTTP). Sin embargo, pensando en un caso real, la red privada y el proxy inverso/balanceador de carga, adem\u00e1s de estar en la misma red privada, suelen estar administrados por las mismas personas de la misma empresa, por lo que no supone un peligro real que ese tr\u00e1fico vaya sin cifrar. </p> <p>Podr\u00eda cifrarse si fuera necesario, pero entonces pierde sentido que el proxy inverso se encargue del cifrado SSL para HTTPS, ya que har\u00edamos el mismo trabajo dos veces. </p> <p>As\u00ed las cosas, nos quedaremos con el esquema de la imagen de m\u00e1s arriba para la pr\u00e1ctica. </p>"},{"location":"Ud3%20Servidores%20web/PV03/#certificados","title":"Certificados","text":"<p>HTTPS se basa en el uso de certificados digitales. </p> <p>Grosso modo, cuando entramos en una web v\u00eda HTTPS, \u00e9sta nos presenta un certificado digital para asegurar que es qui\u00e9n dice ser. \u00bfC\u00f3mo sabemos que ese certificado es v\u00e1lido? Debemos consultar a la Autoridad de Certificaci\u00f3n (CA) que emiti\u00f3 ese certificado si es v\u00e1lido. </p> <p>Las CA son entidades que emiten certificados y su funcionamiento se basa en la confianza. Confiamos en que los certificados emitidos y firmados por esas entidades son reales y funcionales.  </p> <p></p> <p>Los navegadores web tienen precargadas las Autoridades de Certificaci\u00f3n en las que conf\u00edan por defecto a la hora de navegar por webs HTTPS: </p> <p></p> <p>Si accedemos a una web cuyo certificado no haya sido emitido y firmado por una de estas entidades, nos saltar\u00e1 el famoso aviso: </p> <p></p> <p>Ya que si el certificado no ha sido emitido y firmado por una CA de confianza, puede que se trate de una web maliciosa que nos suponga un riesgo de seguridad, como bien dice el aviso. </p>"},{"location":"Ud3%20Servidores%20web/PV03/#tarea","title":"Tarea","text":"<p>Partimos de la configuraci\u00f3n exacta de la pr\u00e1ctica anterior, que recordemos era esta: </p> <p></p> <p>Por lo que en esta pr\u00e1ctica simplemente debemos a\u00f1adir la configuraci\u00f3n SSL para el cifrado en el Proxy Inverso: </p> <p></p> <p>Tal y como quedar\u00e1 la configuraci\u00f3n, desde el cliente a\u00fan podr\u00edamos acceder a los dos servidores web con HTTP (pod\u00e9is probarlo) pero es algo que solucionaremos en siguientes temas, configurando un firewall para que s\u00f3lo la IP del proxy inverso pueda acceder por HTTP a los servidores web y nadie m\u00e1s. </p>"},{"location":"Ud3%20Servidores%20web/PV03/#creacion-de-certificado-autofirmado","title":"Creaci\u00f3n de certificado autofirmado","text":"<p>Nosotros no utilizaremos certificados de ninguna CA de confianza, b\u00e1sicamente porque: </p> <ul> <li> <p>Nuestros servicios no est\u00e1n publicados en Internet </p> </li> <li> <p>Estos certificados son de pago </p> </li> </ul> <p>As\u00ed pues, nosotros crearemos nuestros propios certificados y los firmaremos nosotros mismos como si fu\u00e9ramos una CA aut\u00e9ntica para poder simular este escenario.</p> <p>Warning</p> <p>Esto provocar\u00e1 que cuando accedamos por HTTPS a nuestro sitio web por primera vez, nos salt\u00e9 el aviso de seguridad que se comentaba en la introducci\u00f3n. </p> <p>En este caso no habr\u00e1 peligro puesto que estamos 100% seguros que ese certificado lo hemos emitido nosotros para esta pr\u00e1ctica, no hay dudas. </p> <p>Veamos pues el proceso para generar los certificados y las claves asociadas a ellos (privada/p\u00fablica). En primer lugar debemos crear el siguiente directorio: </p> <p><code>/etc/nginx/ssl</code></p> <p>Podemos crear el certificado y las claves de forma simult\u00e1nea con un \u00fanico comando, donde: </p> <ul> <li> <p><code>openssl</code>: esta es la herramienta por l\u00ednea de comandos b\u00e1sica para crear y administrar certificados, claves y otros archivos OpenSSL. </p> </li> <li> <p><code>req</code>: este subcomando se utiliza para generar una solicitud de certificados y tambi\u00e9n solicitudes de firma de certificados (CSR). </p> </li> <li> <p><code>-x509</code>: Esto modifica a\u00fan m\u00e1s el subcomando anterior al decirle a la herramienta que queremos crear un certificado autofirmado en lugar de generar una solicitud de firma de certificado, como suceder\u00eda normalmente. </p> </li> <li> <p><code>-nodes</code>: Esto le dice a OpenSSL que omita la opci\u00f3n de asegurar nuestro certificado con contrase\u00f1a. Necesitamos que Nginx pueda leer el archivo sin la intervenci\u00f3n del usuario cuando se inicia el servidor. Una contrase\u00f1a evitar\u00eda que esto sucediera ya que tendr\u00edamos que introducirla a mano despu\u00e9s de cada reinicio. </p> </li> <li> <p><code>-days 365</code>: esta opci\u00f3n establece el tiempo durante el cual el certificado se considerar\u00e1 v\u00e1lido. Lo configuramos para un a\u00f1o. </p> </li> <li> <p><code>-newkey rsa: 2048</code> : Esto especifica que queremos generar un nuevo certificado y una nueva clave al mismo tiempo. No creamos la clave necesaria para firmar el certificado en un paso anterior, por lo que debemos crearla junto con el certificado. La rsa:2048parte le dice que cree una clave RSA de 2048 bits de longitud. </p> </li> <li> <p><code>-keyout</code>: este par\u00e1metro le dice a OpenSSL d\u00f3nde colocar el archivo de clave privada generado que estamos creando. </p> </li> <li> <p><code>-out</code>: Esto le dice a OpenSSL d\u00f3nde colocar el certificado que estamos creando. </p> </li> </ul> <p>El comando completo ser\u00eda as\u00ed: </p> <p></p> <p>Os solicitar\u00e1 que introduzc\u00e1is una serie de par\u00e1metros, como v\u00e9is en el recuadro rojo de abajo de la imagen. Deb\u00e9is introducir los mismos par\u00e1metros que en la imagen excepto en el \u201cOrganizational Unit Name\u201d que v\u00e9is recuadrado en amarillo. Ah\u00ed deber\u00e9is poner <code>2DAW \u2013 DEAW - Vuestronombre</code> </p>"},{"location":"Ud3%20Servidores%20web/PV03/#configuracion-ssl-en-el-proxy-inverso","title":"Configuraci\u00f3n SSL en el proxy inverso","text":"<p>De la pr\u00e1ctica anterior, dentro del directorio <code>/etc/nginx/sites-available</code> ya deb\u00e9is tener el archivo de configuraci\u00f3n llamado \u201cbalanceo\u201d. Es precisamente aqu\u00ed donde realizaremos la configuraci\u00f3n para que el acceso  al sitio web se realice mediante SSL (HTTPS). </p> <p>Dentro del bloque <code>server {\u2026}</code> deb\u00e9is cambiar el puerto de escucha (<code>listen 80</code>) por lo que v\u00e9is en la imagen de abajo, a\u00f1adiendo las siguientes l\u00edneas de configuraci\u00f3n tambi\u00e9n, de tal forma que quede: </p> <p></p> <p>Donde le est\u00e1is diciendo que: </p> <ul> <li> <p>Escuche en el puerto 443 \u2192 Puerto por defecto de HTTPS </p> </li> <li> <p>El directorio donde est\u00e1 el certificado que hab\u00e9is generado anteriormente </p> </li> <li> <p>El directorio donde est\u00e1 la clave que hab\u00e9is generado anteriormente </p> </li> <li> <p>Los protocolos y tipos de cifrados que se pueden utilizar \u2192 Estas son las versiones de protocolos y los tipos de cifrados considerados seguros a d\u00eda de hoy (hay muchos m\u00e1s pero no se consideran seguros actualmente) </p> </li> <li> <p><code>server_name</code> ya lo ten\u00edais de la pr\u00e1ctica anterior, no hace falta tocarlo </p> </li> <li> <p>El archivo donde se guardan los logs cambia de nombre, ahora ser\u00e1 https_access.log </p> </li> </ul> <p>Recordad que tras modificar cualquier configuraci\u00f3n de un servicio, hay que reiniciar el servicio, en este caso Nginx. </p>"},{"location":"Ud3%20Servidores%20web/PV03/#comprobaciones","title":"Comprobaciones","text":"<ul> <li> <p>Si acced\u00e9is ahora a https://balanceo os deber\u00eda saltar un aviso de seguridad debido a que nuestro certificado es autofirmado, como coment\u00e1bamos anteriormente. </p> </li> <li> <p>Si a\u00f1ad\u00eds una una excepci\u00f3n podr\u00e9is acceder al sitio web y recargando repetidamente la p\u00e1gina con F5, ver\u00e9is que el balanceo de carga se hace correctamente accediendo mediante HTTPS. </p> </li> <li> <p>Para comprobar que los datos del certificado son, efectivamente, los vuestros pod\u00e9is comprobarlo as\u00ed. Pulsando en el candado de la barra de b\u00fasqueda: </p> </li> </ul> <p></p> <p>Con m\u00e1s informaci\u00f3n:</p> <p></p> <p>Info</p> <p>Aqu\u00ed tambi\u00e9n podr\u00e9is eliminar la excepci\u00f3n que hab\u00e9is a\u00f1adido en la p\u00e1gina de la advertencia de seguridad, por si necesit\u00e1is reiniciar las pruebas. </p> <p>Y por \u00faltimo, ver certificado: </p> <p></p> <p>Y podremos ver los detalles: </p> <p></p> <p>Si ahora intent\u00e1is acceder a <code>http://balanceo</code>, \u00bfdeber\u00edais poder acceder? Comprobadlo y describid qu\u00e9 pasa y por qu\u00e9. </p>"},{"location":"Ud3%20Servidores%20web/PV03/#redireccion-forzosa-a-https","title":"Redirecci\u00f3n forzosa a HTTPS","text":"<p>Para que, indistintamente de la forma por la que accedamos al sitio web balanceo, siempre se fuerce a utilizar HTTPS, necesitaremos una configuraci\u00f3n adicional. </p> <p>Necesitamos a\u00f1adir un bloque \u201cserver\u201d adicional y separado del otro, al archivo de configuraci\u00f3n de \u201cbalanceo\u201d. Algo as\u00ed: </p> <p></p> <p>Con esta configuraci\u00f3n le estamos diciendo que: </p> <ul> <li> <p>Escuche en el puerto 80 (HTTP) </p> </li> <li> <p>Que el nombre al que responder\u00e1 el servidor/sitio web es balanceo </p> </li> <li> <p>Que guarde los logs de este bloque en ese directorio y con ese nombre </p> </li> <li> <p>Cuando se recibe una petici\u00f3n con las dos condiciones anteriores, se devuelve un c\u00f3digo HTTP 301: </p> <ul> <li> <p>HTTP 301 Moved Permanently (Movido permanentemente en espa\u00f1ol) es un c\u00f3digo de estado de HTTP que indica que el host ha sido capaz de comunicarse con el servidor pero que el recurso solicitado ha sido movido a otra direcci\u00f3n permanentementeEs muy importante configurar las redirecciones 301 en los sitios web y para ello hay diferentes m\u00e9todos y sintaxis para realizar la redirecci\u00f3n 301. </p> </li> <li> <p>La redirecci\u00f3n 301 es un c\u00f3digo o comando insertado por un Webmaster que permite redirigir a los usuarios y buscadores de un sitio web de un sitio a otro. </p> </li> </ul> <p>Aclaraci\u00f3n</p> <p>Es decir, lo que estamos haciendo es que cuando se reciba una petici\u00f3n HTTP (puerto 80) en <code>http://balanceo</code>, se redirija a <code>https://balanceo</code> (HTTPS) </p> </li> </ul> <p>Tarea</p> <ul> <li> <p>Eliminad del otro bloque <code>server{\u2026}</code> la l\u00edneas que hagan referencia a escuchar en el puerto 80 (listen 80\u2026). </p> </li> <li> <p>Reiniciad el servicio </p> </li> <li> <p>Comprobad ahora que cuando entr\u00e1is en <code>http://balanceo</code>, autom\u00e1ticamente os redirige a la versi\u00f3n segura de la web. </p> </li> <li> <p>Comprobad que cuando realiz\u00e1is una petici\u00f3n en el archivo de log <code>http_access.log</code> aparece la redirecci\u00f3n 301 y que, de la misma manera, aparece una petici\u00f3n GET en <code>https_access.log</code>. </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/PV03/#cuestiones-finals","title":"Cuestiones finals","text":"<p>Cuesti\u00f3n 1</p> <p>Hemos configurado nuestro proxy inverso con todo lo que nos hace falta pero no nos funciona y da un error del tipo <code>This site can't provide a secure connection, ERR_SSL_PROTOCOL_ERROR.</code></p> <p>Dentro de nuestro server block tenemos esto:</p> <pre><code>server {\n    listen 443;\n    ssl_certificate /etc/nginx/ssl/enrico-berlinguer/server.crt;\n    ssl_certificate_key /etc/nginx/ssl/enrico-berlinguer/server.key;\n    ssl_protocols TLSv1.3;\n    ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;\n    server_name enrico-berlinguer;\n    access_log /var/log/nginx/https_access.log;\n\n    location / {\n        proxy_pass http://red-party;\n        }\n    }\n</code></pre> <p>Cuesti\u00f3n 2</p> <p>Imaginad que intentamos acceder a nuestro sitio web HTTPS y nos encontramos con el siguiente error:</p> <p></p> <p>Investigad qu\u00e9 est\u00e1 pasando y como se ha de solucionar.</p>"},{"location":"Ud3%20Servidores%20web/PV03/#evaluacion","title":"Evaluaci\u00f3n","text":"Criterio Puntuaci\u00f3n Creaci\u00f3n correcta del certificado 1 puntos Configuraci\u00f3n SSL correcta del proxy 3 puntos Comprobaciones 2 puntos Configuraci\u00f3n correcta de la redirecci\u00f3n forzosa a HTTPS y comprobaciones 1 puntos Cuestiones finales 2 puntos SSe ha prestado especial atenci\u00f3n al formato del documento, utilizando la plantilla actualizada y haciendo un correcto uso del lenguaje t\u00e9cnico 1 punto"},{"location":"Ud3%20Servidores%20web/T01/","title":"Implantaci\u00f3n de arquitecturas web","text":""},{"location":"Ud3%20Servidores%20web/T01/#aspectos-generales-de-arquitecturas-web","title":"Aspectos generales de arquitecturas web.","text":"<p>La arquitectura de aplicaciones en entornos web difiere bastante de la de aplicaciones de escritorio, en la cual un programa se ejecuta directamente sobre la m\u00e1quina en la que trabaja el usuario.</p> <p>El modelo de arquitectura b\u00e1sico que existe en toda aplicaci\u00f3n web es el modelo llamado cliente-servidor, en el cual entran en juego diversas m\u00e1quinas o plataformas, cada una de las cuales desarrolla un rol diferenciado en la ejecuci\u00f3n de la aplicaci\u00f3n. Seg\u00fan las necesidades y la complejidad de la aplicaci\u00f3n, este modelo b\u00e1sico de arquitectura puede complicarse m\u00e1s o menos para lograr una mejor distribuci\u00f3n de tareas, mejor rendimiento, fiabilidad, aumento de la capacidad de proceso, etc.</p>"},{"location":"Ud3%20Servidores%20web/T01/#arquitecturas-web-modelos","title":"Arquitecturas web. Modelos","text":"<p>Una aplicaci\u00f3n distribuida est\u00e1 compuesta por una colecci\u00f3n de ordenadores aut\u00f3nomos enlazados por una red de ordenadores y respaldados por un software que hace el conjunto act\u00fae como un servicio integrado.</p>"},{"location":"Ud3%20Servidores%20web/T01/#el-modelo-cliente-servidor","title":"El modelo cliente-servidor","text":"<p>El modelo cliente-servidor es un modelo de arquitectura de aplicaciones en el cual se definen o se asignan principalmente dos roles a los ordenadores, que son, como el nombre del modelo indica, los roles de cliente y de servidor.</p> <p> Imagen: Lubaochuan, CC BY-SA 4.0 Wikimedia Commons</p> <p>En el modelo cliente-servidor, existen dos tipos de componentes:</p> <ul> <li> <p>Clientes: realizan peticiones de servicio. Por lo general, los clientes inician la comunicaci\u00f3n con el servidor.</p> </li> <li> <p>Servidores: proveen servicios. Normalmente, los servidores esperan recibir peticiones. Una vez que han recibido una petici\u00f3n, la resuelven y devuelven el resultado al cliente.</p> </li> </ul> <p>El modelo cliente-servidor b\u00e1sico de la figura anterior es v\u00e1lido para aplicaciones web peque\u00f1as, simples y que no tengan una gran carga de trabajo, es decir, un n\u00famero reducido de clientes conectados simult\u00e1neamente.</p> <p>En entornos reales, es com\u00fan que estas tres caracter\u00edsticas no est\u00e9n presentes, por lo que es necesario implementar una arquitectura m\u00e1s compleja pero tambi\u00e9n basada en el modelo cliente-servidor. Esta arquitectura puede presentar diferencias o extensiones al modelo b\u00e1sico para garantizar un buen rendimiento de las aplicaciones web, su fiabilidad y/o la capacidad de atender un gran n\u00famero de peticiones de los clientes de forma simult\u00e1nea en aplicaciones web de tama\u00f1o mediano o grande, y con un nivel de complejidad medio/alto. De esta necesidad surge el modelo siguiente.</p>"},{"location":"Ud3%20Servidores%20web/T01/#modelo-cliente-servidor-con-servidores-encadenados","title":"Modelo Cliente-Servidor con Servidores Encadenados","text":"<p>Cuando en una aplicaci\u00f3n el servidor debe realizar tareas muy complejas o costosas de procesar, se pueden distribuir subtareas en varios servidores. De esta manera, un servidor puede actuar como cliente de otro servidor para delegar ciertas responsabilidades.</p> <p> Imagen: Michel Bakni, CC BY-SA 4.0 Wikimedia Commons</p> <p>Por ejemplo, cuando un cliente de una entidad bancaria accede a los servicios en l\u00ednea de su banco a trav\u00e9s de un navegador web (cliente), el cliente inicia una solicitud al servidor web del banco. Las credenciales de inicio de sesi\u00f3n del cliente se almacenan en una base de datos y el servidor web accede a la base de datos como cliente. Un servidor de aplicaciones interpreta los datos devueltos aplicando la l\u00f3gica de negocios del banco y proporciona la salida al servidor web. Finalmente, el servidor web devuelve el resultado al navegador web del cliente para su visualizaci\u00f3n.</p>"},{"location":"Ud3%20Servidores%20web/T01/#aplicaciones-basadas-en-la-web","title":"Aplicaciones Basadas en la Web","text":"<p>Un caso particular de aplicaciones cliente-servidor son las aplicaciones que se ejecutan aprovechando la arquitectura web. Estas aplicaciones se basan en tener toda la capacidad de procesamiento en un servidor web (o conjunto de servidores) al que se accede desde un navegador web.</p> <p>Cuando un usuario hace clic en un enlace en una p\u00e1gina web de su navegador, este genera una solicitud al servidor que contiene la informaci\u00f3n. Una vez que el servidor recibe la solicitud, devuelve el contenido. La comunicaci\u00f3n entre el cliente y el servidor se realiza a trav\u00e9s del protocolo HTTP.</p>"},{"location":"Ud3%20Servidores%20web/T01/#modelo-peer-to-peer-p2p","title":"Modelo Peer-to-Peer (P2P)","text":"<p>Existe un tipo de arquitectura en la cual todas las computadoras act\u00faan simult\u00e1neamente como clientes y servidores. Estas redes se conocen como redes peer-to-peer (igual a igual).</p> <p> Imagen: The 360 Degree, CC BY-SA 4.0 Wikimedia Commons</p> <p>Un sistema peer-to-peer se caracteriza por ser un sistema distribuido en el cual todos los nodos tienen las mismas capacidades y responsabilidades, es decir, todos son clientes y servidores al mismo tiempo, lo que implica que toda la comunicaci\u00f3n es sim\u00e9trica.</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-web-y-de-aplicaciones-instalacion-y-configuracion-basica","title":"Servidores web y de aplicaciones. Instalaci\u00f3n y configuraci\u00f3n b\u00e1sica","text":"<p>Durante las fases de desarrollo, puesta en producci\u00f3n y mantenimiento de una aplicaci\u00f3n web, nos encontramos con varios tipos de servidores que llevan a cabo tareas espec\u00edficas en el funcionamiento global.</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-web","title":"Servidores web","text":"<p>Un servidor web es un servidor que permite el acceso a recursos a trav\u00e9s del protocolo HTTP (Protocolo de Transferencia de Hipertexto) de internet.</p> <p>La definici\u00f3n original y estricta del concepto de servidor HTTP se refiere a aquellos servidores capaces de proporcionar acceso y permitir la gesti\u00f3n de un conjunto de recursos est\u00e1ticos como respuesta a las peticiones recibidas de los clientes. Es decir, que permiten consultar, cargar y eliminar recursos del servidor. Estos recursos suelen ser documentos HTML o variantes de este formato y contenidos adjuntos o relacionados con estos documentos, como im\u00e1genes, videos, etc.</p> <p>Estos recursos suelen estar guardados en forma de archivos en dispositivos de almacenamiento propios del servidor.</p> <p>El concepto original de servidor web no contempla la posibilidad de generar de forma din\u00e1mica los contenidos a partir de la ejecuci\u00f3n de c\u00f3digo como respuesta a las peticiones. Sin embargo, en la actualidad, la mayor\u00eda de los servidores web admiten la instalaci\u00f3n de m\u00f3dulos que permiten generar contenidos din\u00e1micos a partir de la ejecuci\u00f3n de programas escritos en diversos lenguajes de programaci\u00f3n (PHP, JavaScript, Python, Perl, etc.), aunque esta caracter\u00edstica es m\u00e1s propia de los servidores de aplicaciones.</p> <p>Algunos ejemplos de servidores web son Apache o Nginx, para sistemas operativos Linux, y Microsoft Internet Information Server, para Windows.</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-de-aplicaciones","title":"Servidores de aplicaciones","text":"<p>Un servidor de aplicaciones, en general, es un servidor que ofrece a los clientes un servicio de ejecuci\u00f3n de aplicaciones. Si nos centramos en las aplicaciones web, un servidor de aplicaciones es un software que controla la ejecuci\u00f3n de programas. Los clientes, desde un navegador (usando el protocolo HTTP), acceden a una interfaz web desde donde ejecutar\u00e1n la aplicaci\u00f3n. Normalmente, los servidores de aplicaciones se utilizan en aplicaciones web con un alto grado de complejidad.</p> <p>Un servidor de aplicaciones web se puede entender como un servidor orientado a la ejecuci\u00f3n de programas que puede recibir las peticiones de servicio y devolver los resultados utilizando los mismos protocolos (HTTP) y formatos de datos que los servidores web (HTML). Si el mismo servidor no tiene la capacidad de interactuar con estos protocolos, puede trabajar conjuntamente con el soporte de un servidor web que haga de intermediario entre el servidor de aplicaciones y el cliente. Los servidores de aplicaciones, adem\u00e1s, suelen proporcionar un amplio conjunto de servicios complementarios orientados a la persistencia de datos, seguridad, control de transacciones y concurrencia, entre otros.</p> <p>Algunos ejemplos de servidores de aplicaciones son GlassFish (servidor Java EE, Oracle), Tomcat o Microsoft Internet Information Server (servidor .NET).</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-de-bases-de-datos","title":"Servidores de bases de datos","text":"<p>Un servidor de bases de datos se utiliza para almacenar, recuperar y administrar los datos de una base de datos. El servidor gestiona las actualizaciones de datos, permite el acceso simult\u00e1neo de muchos servidores o usuarios web y garantiza la seguridad y la integridad de los datos.</p> <p>Entre sus funciones b\u00e1sicas, el software de servidores de bases de datos ofrece herramientas para facilitar y acelerar la administraci\u00f3n de bases de datos. Algunas funciones son la exportaci\u00f3n de datos, la configuraci\u00f3n del acceso de usuarios y el soporte de datos.</p> <p>Algunos ejemplos de servidores de bases de datos son Oracle Database, MySQL, Microsoft SQL Server, PostgreSQL, MongoDB o Firebase.</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-de-archivos","title":"Servidores de archivos","text":"<p>Un servidor de archivos es un servidor que permite gestionar a trav\u00e9s de red la carga, descarga, actualizaci\u00f3n y eliminaci\u00f3n de archivos almacenados en sus dispositivos desde computadoras cliente.</p> <p>En el \u00e1mbito de las aplicaciones web, los servidores de archivos se utilizan principalmente para implementar las aplicaciones en el servidor donde se ejecutar\u00e1n. La implementaci\u00f3n de una aplicaci\u00f3n web en los servidores de producci\u00f3n generalmente implica la carga de grandes cantidades de archivos en estos servidores. Dado que el desarrollo y mantenimiento de estas aplicaciones se realiza en las m\u00e1quinas de los programadores, se necesita un sistema de transferencia de archivos cada vez que se quiere actualizar la versi\u00f3n de producci\u00f3n de una aplicaci\u00f3n.</p> <p>Uno de los protocolos m\u00e1s utilizados para la transferencia de archivos en la implementaci\u00f3n de aplicaciones web es el protocolo FTP (Protocolo de Transferencia de Archivos), con sus variantes FTPS y SFTP para adaptarse a las necesidades actuales de seguridad.</p> <p>Algunos ejemplos de servidores de transferencia de archivos son ProFTPD o vsftpd, para sistemas operativos Linux, y Microsoft Internet Information Server, para Windows.</p>"},{"location":"Ud3%20Servidores%20web/T01/#servidores-de-directorio","title":"Servidores de directorio","text":"<p>Un servidor de directorio es un servidor que permite gestionar informaci\u00f3n administrativa sobre el entorno de una aplicaci\u00f3n web, como pueden ser, por ejemplo, los usuarios autorizados con sus roles o permisos, etc.</p> <p>La utilidad principal de los servidores de directorio es facilitar la gesti\u00f3n de informaci\u00f3n relacionada con la explotaci\u00f3n de aplicaciones web. La ventaja de gestionar esta informaci\u00f3n mediante este tipo de servidores es la centralizaci\u00f3n de datos y la facilidad de acceso mediante protocolos est\u00e1ndar como LDAP.</p> <p>Algunos ejemplos de servidores de directorio son OpenLDAP, para Linux, y Active Directory, para Windows.</p>"},{"location":"Ud3%20Servidores%20web/T01/#estructura-y-recursos-de-una-aplicacion-web","title":"Estructura y Recursos de una Aplicaci\u00f3n Web","text":"<p>Las aplicaciones web, adem\u00e1s de presentar una arquitectura cliente-servidor (hecho que no es necesario en el caso de las aplicaciones de escritorio), suelen estar estructuradas con una gran cantidad de archivos y recursos de diferentes tipos.</p> <p>Por esta raz\u00f3n, es necesario establecer directrices para organizar la ubicaci\u00f3n de estos componentes y su interrelaci\u00f3n durante la fase de desarrollo, as\u00ed como tambi\u00e9n al momento de poner la aplicaci\u00f3n en producci\u00f3n. De lo contrario, el desarrollo y mantenimiento de una aplicaci\u00f3n de tama\u00f1o mediano o grande se convertir\u00e1 en una tarea casi imposible de gestionar.</p> <p>Dejando de lado la organizaci\u00f3n o estructura impuesta por la elecci\u00f3n de ciertas herramientas de desarrollo o un servidor web o de aplicaciones espec\u00edfico, estas aplicaciones se pueden estructurar seg\u00fan varios modelos de organizaci\u00f3n de sus componentes y recursos. Algunos de los modelos de estructuraci\u00f3n de aplicaciones web que podemos encontrar m\u00e1s com\u00fanmente son los que se describen a continuaci\u00f3n.</p>"},{"location":"Ud3%20Servidores%20web/T01/#arquitectura-multinivel","title":"Arquitectura Multinivel","text":"<p>La arquitectura multinivel (multitier architecture) es un tipo espec\u00edfico de la arquitectura cliente-servidor en la cual los componentes y recursos de una aplicaci\u00f3n se separan seg\u00fan su funci\u00f3n. Una de las divisiones m\u00e1s utilizadas es la que separa el nivel de presentaci\u00f3n, el nivel de l\u00f3gica de aplicaci\u00f3n y el nivel de gesti\u00f3n de datos.</p> <p>En este caso, la estructura concreta ser\u00eda de tres niveles (3-tier architecture). El modelo se define como N-tier architecture (multinivel), ya que propone una divisi\u00f3n flexible de las aplicaciones en los niveles que sean necesarios para hacer m\u00e1s eficiente su desarrollo, mantenimiento y explotaci\u00f3n.</p> <p>En este modelo, la divisi\u00f3n por niveles se realiza de forma lineal: el nivel 1 interact\u00faa de forma directa y \u00fanica con el nivel 2, el nivel 2 interact\u00faa con el 3, y as\u00ed sucesivamente.</p> <p> Imagen: No machine-readable author provided. Master Will assumed (based on copyright claims)., Dominio p\u00fablico Wikimedia Commons</p> <p>Warning</p> <p>Es importante diferenciar entre el concepto de multinivel (multitier o N-tier) y multicapa (multilayer o N-layer). En el caso del modelo multinivel, se considera que cada nivel, adem\u00e1s de implementar una funci\u00f3n concreta, es ejecutado por un hardware diferente al del resto de los niveles. En el modelo multicapa, cada capa desarrolla una funci\u00f3n concreta que puede ser ejecutada por una misma computadora que se encarga tambi\u00e9n de la ejecuci\u00f3n de otras capas.</p>"},{"location":"Ud3%20Servidores%20web/T01/#arquitectura-modelo-vista-controlador","title":"Arquitectura Modelo-Vista-Controlador","text":"<p>La arquitectura Modelo-Vista-Controlador (Model-View-Controller o MVC) es una arquitectura que separa la representaci\u00f3n de la informaci\u00f3n y la l\u00f3gica de una aplicaci\u00f3n de la interacci\u00f3n del usuario.</p> <p>Los tres elementos que definen esta arquitectura son:</p> <ul> <li>Modelo: Contiene los datos de la aplicaci\u00f3n, las reglas de negocio o la l\u00f3gica de la aplicaci\u00f3n y sus funciones.</li> <li>Vista: Es la representaci\u00f3n visible de la aplicaci\u00f3n, la salida de los datos hacia el usuario, es decir, la interfaz.</li> <li>Controlador: Controla la interacci\u00f3n del usuario (entrada de datos) y convierte esta interacci\u00f3n en \u00f3rdenes o comandos para el modelo o la vista.</li> </ul> <p>La interrelaci\u00f3n entre los elementos de esta arquitectura no sigue un modelo lineal como el modelo multinivel, sino que se trata de un modelo circular.</p> <p> Imagen: Behnam Esfahbod, CC BY-SA 3.0 Wikimedia Commons</p> <p>Paralelamente a la estructura de la aplicaci\u00f3n, es necesario considerar que cada nivel, capa o m\u00f3dulo puede estar compuesto por un gran n\u00famero de componentes y recursos de diversos tipos: archivos HTML, CSS, im\u00e1genes, etc.</p> <p>Por ello, es conveniente establecer un sistema de organizaci\u00f3n coherente y eficiente para estructurar todos estos componentes que se generan durante el desarrollo de una aplicaci\u00f3n web. La mayor\u00eda de las plataformas de desarrollo avanzadas imponen mecanismos para organizar y describir de manera sistem\u00e1tica la ubicaci\u00f3n, caracter\u00edsticas y configuraci\u00f3n de los componentes y recursos de las aplicaciones.</p> <p>Entre estos mecanismos, se destacan dos:</p>"},{"location":"Ud3%20Servidores%20web/T01/#estructura-de-directorios","title":"Estructura de Directorios","text":"<p>Las plataformas avanzadas de desarrollo de aplicaciones web suelen definir una estructura de directorios m\u00ednima que toda aplicaci\u00f3n debe tener, a partir de la cual se despliegan los diferentes tipos de componentes. Los desarrolladores deben seguir las directrices de cada plataforma.</p>"},{"location":"Ud3%20Servidores%20web/T01/#descriptor-de-despliegue","title":"Descriptor de Despliegue","text":"<p>Existe un archivo de configuraci\u00f3n en el cual se puede especificar el nombre, ubicaci\u00f3n y par\u00e1metros de configuraci\u00f3n de los diferentes componentes que conforman una aplicaci\u00f3n. Esto permite tener dicha informaci\u00f3n centralizada, accesible y actualizable sin necesidad de modificar el c\u00f3digo fuente de la aplicaci\u00f3n. Este descriptor describe c\u00f3mo se debe desplegar la aplicaci\u00f3n en el servidor.</p>"},{"location":"Ud3%20Servidores%20web/T01/#plataformas-web-libres-y-propietarias","title":"Plataformas Web libres y propietarias","text":"<p>Una plataforma web es el entorno de desarrollo de software empleado para dise\u00f1ar y ejecutar un sitio web. En t\u00e9rminos generales, una plataforma web consta de cuatro componentes b\u00e1sicos:</p> <ol> <li>Sistema operativo: Bajo el cual opera el equipo donde se hospedan las p\u00e1ginas web y que representa la base misma del funcionamiento del computador. En ocasiones limita la elecci\u00f3n de otros componentes.</li> <li>Servidor web: El software que maneja las peticiones desde equipos remotos a trav\u00e9s de la Internet. En el caso de p\u00e1ginas est\u00e1ticas, el servidor web simplemente provee el archivo solicitado, el cual se muestra en el navegador. En el caso de sitios din\u00e1micos, el servidor web se encarga de pasar las solicitudes a otros programas que puedan gestionarlas adecuadamente.</li> <li>Gestor de bases de datos: Se encarga de almacenar sistem\u00e1ticamente un conjunto de registros de datos relacionados para ser usados posteriormente.</li> <li>Lenguaje de programaci\u00f3n interpretado: Controla las aplicaciones de software que corren en el sitio web.</li> </ol> <p>Diferentes combinaciones de los cuatro componentes se\u00f1alados, basadas en las distintas opciones de software disponibles en el mercado, dan lugar a numerosas plataformas web, aunque, sin duda, hay dos que sobresalen del resto por su popularidad y difusi\u00f3n: LAMP y WISA.</p>"},{"location":"Ud3%20Servidores%20web/T01/#plataforma-lamp","title":"Plataforma LAMP","text":"<p>La plataforma LAMP trabaja enteramente con componentes de software libre y no est\u00e1 sujeta a restricciones propietarias. El nombre LAMP surge de las iniciales de los componentes de software que la integran:</p> <ul> <li>Linux: sistema operativo.</li> <li>Apache: servidor web.</li> <li>MySQL: gestor de bases de datos.</li> <li>PHP: lenguaje interpretado PHP, aunque a veces se sustituye por Perl o Python.</li> </ul>"},{"location":"Ud3%20Servidores%20web/T01/#plataforma-wisa","title":"Plataforma WISA","text":"<p>La plataforma WISA est\u00e1 basada en tecnolog\u00edas desarrolladas por la compa\u00f1\u00eda Microsoft; se trata, por lo tanto, de software propietario. La componen los siguientes elementos:</p> <ul> <li>Windows: sistema operativo.</li> <li>Internet Information Services (IIS): servidor web.</li> <li>SQL Server: gestor de bases de datos.</li> <li>ASP o ASP.NET: como lenguaje para scripting del lado del servidor.</li> </ul>"},{"location":"Ud3%20Servidores%20web/T01/#otras-plataformas","title":"Otras plataformas","text":"<p>Existen otras plataformas, como por ejemplo la configuraci\u00f3n WAMP (Windows-Apache-MySQL-PHP), que es bastante com\u00fan pero s\u00f3lo como plataforma de desarrollo local. De forma similar, un servidor Windows puede correr con IIS y con MySQL y PHP. A esta configuraci\u00f3n se la conoce como plataforma WIMP.</p> <p>Entre los servidores web m\u00e1s utilizados hoy en d\u00eda, aparte de Apache e IIS, tenemos tambi\u00e9n a Nginx, un servidor web software libre que est\u00e1 demostrando un alto rendimiento. Nginx es capaz de atender una gran cantidad de peticiones simult\u00e1neas y tiene un mejor rendimiento que sus competidores al servir contenido est\u00e1tico. Sin embargo, su configuraci\u00f3n es menos flexible que otros.</p> <p>Nginx tambi\u00e9n puede integrarse con PHP, dando lugar a plataformas tipo LNMP (Linux + Nginx + MySQL o MariaDB + PHP). Esta opci\u00f3n es tambi\u00e9n posible en Windows, dando lugar a plataformas WNMP (Windows + Nginx + MySQL o MariaDB + PHP).</p> <p>Existen muchas otras plataformas que trabajan con distintos sistemas operativos (Unix, MacOS, Solaris), servidores web (incluyendo algunos que se han cobrado relativa popularidad como Lighttpd y LiteSpeed), bases de datos (MariaDB, PostgreSQL, MongoDB) y otros lenguajes de programaci\u00f3n.</p> <p>XAMPP: XAMPP es una forma f\u00e1cil de instalar y usar el servidor web Apache con un sistema gestor de bases de datos (MariaDB), PHP y Perl. Basta con descargarlo, extraerlo y comenzar. En este momento hay cuatro versiones de XAMPP para Linux, Windows, Mac OS X y Solaris.</p>"},{"location":"Ud3%20Servidores%20web/T01/#escalabilidad","title":"Escalabilidad","text":"<p>Las aplicaciones web se ejecutan en un entorno donde el n\u00famero de clientes que solicitan el servicio puede variar en gran medida en funci\u00f3n del momento. Es por ello que hay una caracter\u00edstica de esencial importancia como es la escalabilidad.</p> <p>En el entorno en que se ubican las aplicaciones web, uno de los principales factores que puede afectar al rendimiento de las mismas es el n\u00famero de usuarios, ya que este puede verse incrementado de forma vertiginosa en un periodo de tiempo relativamente corto. El \u00e9xito o el fracaso de un sitio web orientado al usuario com\u00fan vendr\u00e1 determinado, entre otros aspectos, por el dimensionamiento del sistema sobre el que se instala y soporta el software que sustenta dicho sitio. En consecuencia, uno de los requisitos fundamentales de una aplicaci\u00f3n web es que sea completamente escalable sin que un aumento de los recursos dedicados a la misma suponga modificaci\u00f3n alguna en su comportamiento o capacidades.</p>"},{"location":"Ud3%20Servidores%20web/T01/#escalabilidad-de-un-sistema-web","title":"Escalabilidad de un sistema web","text":"<p>La escalabilidad de un sistema web puede ser:</p> <ul> <li>Verticalmente: de manera ascendente \"upgrades\" a cada nodo.</li> <li>Horizontalmente: consiste en aumentar el n\u00famero de nodos.</li> <li>Cluster: consiste en crear agrupaciones de servidores.</li> </ul>"},{"location":"Ud3%20Servidores%20web/T01/#escalabilidad-vertical","title":"Escalabilidad vertical","text":"<p>Habitualmente, la separaci\u00f3n l\u00f3gica en capas se implementa de tal forma que se permita una separaci\u00f3n f\u00edsica de las mismas. Interponiendo elementos conectores que act\u00faen de \"middlewares\" es posible distribuir la aplicaci\u00f3n de forma vertical (una m\u00e1quina por cada capa del sistema), e incluso si esto no fuera suficiente, distribuyendo los elementos de una misma capa entre distintas m\u00e1quinas servidoras.</p>"},{"location":"Ud3%20Servidores%20web/T01/#escalabilidad-horizontal","title":"Escalabilidad horizontal","text":"<p>Se trata de clonar el sistema en otra m\u00e1quina de caracter\u00edsticas similares y balancear la carga de trabajo mediante un dispositivo externo. El balanceador de carga puede ser:</p> <ul> <li> <p>Balanceador Software: Por ejemplo, es com\u00fan encontrar un servidor web Apache junto con el m\u00f3dulo <code>mod_jk</code>, que permite redirigir las solicitudes HTTP configuradas entre las diferentes m\u00e1quinas que conforman la granja de servidores. Estos balanceadores examinan el paquete HTTP e identifican la sesi\u00f3n del usuario, registrando qu\u00e9 m\u00e1quina de la granja est\u00e1 atendiendo dicha sesi\u00f3n. Esto es crucial, ya que nos permite dise\u00f1ar la aplicaci\u00f3n teniendo en cuenta el objeto de sesi\u00f3n del usuario y almacenar informaci\u00f3n relevante de la sesi\u00f3n del mismo. Con esta garant\u00eda, todas las peticiones de una misma sesi\u00f3n HTTP se redirigen a la misma m\u00e1quina.</p> </li> <li> <p>Balanceador hardware: Son dispositivos que, siguiendo algoritmos de reparto de carga (como Round Robin, LRU - Menos Usado Recientemente, etc.), redirigen una solicitud HTTP del usuario a la m\u00e1quina que corresponde seg\u00fan dicho algoritmo. Estos son m\u00e1s r\u00e1pidos que los anteriores, ya que se basan en conmutaci\u00f3n de circuitos y no examinan ni interpretan el paquete HTTP. Sin embargo, no aseguran el mantenimiento de la misma sesi\u00f3n de usuario en la misma m\u00e1quina. Esto condiciona el dise\u00f1o, ya que obliga a almacenar la informaci\u00f3n de sesi\u00f3n del usuario por parte del desarrollador, en cookies o en una base de datos.</p> </li> <li> <p>Balanceador hardware HTTP: Son dispositivos hardware que examinan el paquete HTTP y mantienen la relaci\u00f3n entre el usuario y la m\u00e1quina servidora. Son m\u00e1s r\u00e1pidos que los balanceadores software, pero ligeramente menos que los balanceadores hardware. Hoy en d\u00eda, representan una de las soluciones m\u00e1s aceptadas en el mercado.</p> </li> </ul> <p>Cluster:</p> <p>Con la introducci\u00f3n de servidores de aplicaciones en cluster se abre una nueva capacidad de escalabilidad que puede clasificarse como vertical u horizontal, dependiendo de su implementaci\u00f3n. Un cluster de servidores de aplicaciones permite desplegar una aplicaci\u00f3n web convencional, distribuyendo su carga de trabajo entre la granja de servidores del cluster. Esto ocurre de manera transparente tanto para el usuario como para el administrador. Mediante el mecanismo de replicaci\u00f3n de sesi\u00f3n, el cluster garantiza que sin importar cu\u00e1l m\u00e1quina atienda la solicitud HTTP, esta tendr\u00e1 acceso a la sesi\u00f3n del usuario (objeto HttpSession en Java). Sin embargo, debido a la replicaci\u00f3n de sesi\u00f3n, este tipo de sistemas suele presentar problemas de rendimiento.</p>"},{"location":"Ud3%20Servidores%20web/T01/#referencias","title":"Referencias","text":"<p>IOC - Institut obert de Catalunya</p> <p>https://apuntes-daw.javiergutierrez.trade/despliegue-de-aplicaciones/ut1/recopila.html</p>"},{"location":"Ud3%20Servidores%20web/T02/","title":"Arquitectura Web. Implantaci\u00f3n y administraci\u00f3n de servidores web","text":""},{"location":"Ud3%20Servidores%20web/T02/#introducion","title":"Introduci\u00f3n","text":"<p>Con la evoluci\u00f3n y el acceso libre a Internet, uno de los principales alicientes que han surgido es la publicaci\u00f3n de p\u00e1ginas web donde se pueden mostrar contenidos atractivos que pueden ser consultados desde cualquier del mundo por cualquier persona. </p> <p>Cabe decir que, con la popularizaci\u00f3n de Internet, tanto empresas como usuarios han visto la necesidad de establecer un punto desde donde anunciar sus productos, o bien, a t\u00edtulo particular, dar publicidad a las aficiones o capacidades personales mediante la publicaci\u00f3n de p\u00e1ginas personales. </p> <p>Las p\u00e1ginas web, en su mayor\u00eda en formato HTML, requieren ser alojadas en m\u00e1quinas que dispongan de espacio en disco para almacenar archivos HTML, im\u00e1genes, bloques de c\u00f3digo o archivos de v\u00eddeo en directorios espec\u00edficos y, al mismo tiempo, deben ser capaces de entender todo tipo de extensi\u00f3n de los archivos que son enviados en ambos sentidos de la comunicaci\u00f3n. </p> <p></p> <p>Paralelamente, no podemos dejar de lado la importancia de las medidas de seguridad ante los peligros existentes en Internet. Para ello, las p\u00e1ginas deber\u00e1n estar dise\u00f1adas considerando la incorporaci\u00f3n de protocolos de comunicaci\u00f3n seguros como, por ejemplo, los desarrollados con el protocolo seguro de transferencia de hipertexto (HTTPS, Hyper Text Transfer Protocol secure) que utilizan claves y estrategias de cifrado propias de las herramientas del protocolo de capa de conexi\u00f3n segura (SSL, secure sockets layer). </p> <p>Las m\u00e1quinas que alojan las p\u00e1ginas web reciben la categor\u00eda de servidores web. Desde el punto de vista de los servidores, los requerimientos m\u00e1s relevantes son el espacio de disco necesario para poder almacenar la estructura de la p\u00e1gina web y una buena conexi\u00f3n de red. </p> <p>En cuanto a la capacidad de procesamiento, el funcionamiento de los servidores web es especial, ya que tienen consumos de recursos muy bajos durante un tiempo, porque pueden no estar recibiendo peticiones y, de repente, tener una avalancha de peticiones que les haga consumir muchos recursos puntualmente. Por eso se dice que tienen un consumo de recursos en forma de \"diente de sierra\". Esto hace que los servidores web suelan tener un n\u00famero bajo de procesos en espera. A medida que resultan necesarios, se van arrancando nuevos. </p> <p>Cabe decir que no todas las peticiones consumen lo mismo, y, por ejemplo, aquellas p\u00e1ginas web que ejecuten programas de interacci\u00f3n con el usuario o requieran cifrado (HTTPS) consumen m\u00e1s recursos que otras p\u00e1ginas web est\u00e1ticas. </p>"},{"location":"Ud3%20Servidores%20web/T02/#que-es-un-servidor-web","title":"\u00bfQu\u00e9 es un servidor web?","text":"<p>Los servidores web sirven para almacenar contenidos de Internet y facilitar su disponibilidad de forma constante y segura. Cuando visitas una p\u00e1gina web desde tu navegador, es en realidad un servidor web el que env\u00eda los componentes individuales de dicha p\u00e1gina directamente a tu ordenador. Esto quiere decir que para que una p\u00e1gina web sea accesible en cualquier momento, el servidor web debe estar permanentemente online. </p> <p></p> <p>Toda p\u00e1gina accesible en Internet necesita un servidor especial para sus contenidos web. A menudo, las grandes empresas y organizaciones cuentan con un servidor web propio para disponer sus contenidos en Intranet e Internet. Sin embargo, la mayor\u00eda de administradores recurren a los centros de datos de proveedores de alojamiento web para sus proyectos. Y cada vez m\u00e1s la tendencia es a usar servicios \"cloud\" que nos proporcionen los servicios requeridos sin necesidad de instalar, gestionar y mantener el HW asociado.</p> <p>Independientemente de si tienes un servidor web propio o de si alquilas uno externo, siempre necesitar\u00e1s un software para gestionar los datos de tu p\u00e1gina y mantenerla actualizada. En este sentido, tienes la posibilidad de elegir entre varias soluciones de software para servidores web dise\u00f1adas para diferentes aplicaciones y sistemas operativos. </p>"},{"location":"Ud3%20Servidores%20web/T02/#tecnologia-de-servidores-web","title":"Tecnolog\u00eda de servidores web","text":"<p>Principalmente, el software de un servidor HTTP es el encargado de proporcionar los datos para la visualizaci\u00f3n del contenido web. </p> <p>Para abrir una p\u00e1gina web, el usuario solo tiene que escribir el URL correspondiente en la barra de direcciones de su navegador web. El navegador env\u00eda una solicitud al servidor web, quien responde, por ejemplo, entregando una p\u00e1gina HTML. Esta puede estar alojada como un documento est\u00e1tico en el host o ser generada de forma din\u00e1mica, lo que significa que el servidor web tiene que ejecutar un c\u00f3digo de programa (p. ej., Java o PHP) antes de tramitar su respuesta. </p> <p>El navegador interpreta la respuesta, lo que suele generar autom\u00e1ticamente m\u00e1s solicitudes al servidor a prop\u00f3sito de, por ejemplo, im\u00e1genes integradas o archivos CSS (hojas de estilos). </p> <p></p> <p>El protocolo utilizado para la transmisi\u00f3n es HTTP (o su variante cifrada HTTPS), que se basa, a su vez, en los protocolos de red IP y TCP (y muy rara vez en UDP). Un servidor web puede entregar los contenidos simult\u00e1neamente a varios ordenadores o navegadores web. La cantidad de solicitudes (requests) y la velocidad con la que pueden ser procesadas depende, entre otras cosas, del hardware y la carga (n\u00famero de solicitudes) del host. Sin embargo, la complejidad del contenido tambi\u00e9n juega un papel importante: los contenidos web din\u00e1micos necesitan m\u00e1s recursos que los contenidos est\u00e1ticos. </p> <p></p> <p>La selecci\u00f3n del equipo adecuado para el servidor y la decisi\u00f3n de si este debe ser dedicado, virtual o en la nube, se debe hacer pensando siempre en evitar sobrecargas en el servidor. Aunque se haya encontrado un servidor web que se adapta perfectamente a las necesidades del proyecto, siempre se corre el riesgo de que se presenten fallos en \u00e9l como consecuencia de imprecisiones t\u00e9cnicas o cortes de energ\u00eda en el centro de datos del host. Aunque no es muy frecuente, durante un per\u00edodo de inactividad de este tipo (downtime), la web no estar\u00e1 disponible. </p>"},{"location":"Ud3%20Servidores%20web/T02/#otras-funciones-de-los-servidores-web","title":"Otras funciones de los servidores web","text":"<p>Aunque su principal funci\u00f3n es la transferencia de contenido web, muchos programas de servidor web ofrecen caracter\u00edsticas adicionales: </p> Seguridad Cifrado de la comunicaci\u00f3n entre el servidor web y el cliente v\u00eda HTTPS Autenticaci\u00f3n del usuario Autenticaci\u00f3n HTTP para \u00e1reas espec\u00edficas de una aplicaci\u00f3n web Redirecci\u00f3n Redirecci\u00f3n de una solicitud de documento por medio de Rewrite Engine Cach\u00e9 Almacenamiento en cach\u00e9 de documentos din\u00e1micos para la respuesta eficiente de solicitudes y para evitar una sobrecarga del servidor web Asignaci\u00f3n de cookies Env\u00edo y procesamiento de cookies HTTP <p>Adem\u00e1s del software del servidor, un host puede contener otro tipo de programas, como por ejemplo un servidor FTP para la carga de archivos o un servidor de base de datos para contenidos din\u00e1micos. En general, existen diferentes tipos de servidores web que pueden ser utilizados para numerosos prop\u00f3sitos, por ejemplo, los servidores de correo, los servidores de juegos o los servidores proxy. </p>"},{"location":"Ud3%20Servidores%20web/T03/","title":"3.3. Los protocolos HTTP y HTTPS","text":""},{"location":"Ud3%20Servidores%20web/T03/#el-protocolo-http","title":"El protocolo HTTP","text":""},{"location":"Ud3%20Servidores%20web/T03/#historia","title":"Historia","text":"<p>El protocolo de transferencia de hipertexto (HTTP, Hypertext Transfer Protocol) es el motor que da vida a Internet, ya que es la base para la web (www, world wide web). </p> <p>Desde un punto de vista hist\u00f3rico, la web fue creada en 1989 en el Consejo Europeo para la Investigaci\u00f3n Nuclear (CERN, Centro Europeene pour la Recherche Nucl\u00e9aire), con sede en Ginebra, justo en la frontera entre Suiza y Francia. Cabe decir que este organismo dispon\u00eda (y dispone) de una ampl*ia plantilla de cient\u00edficos de diferentes pa\u00edses de Europa que trabajan en sus aceleradores de part\u00edculas. En consecuencia, muchos equipos de trabajadores est\u00e1n integrados por miembros de nacionalidades diferentes. Adem\u00e1s, muchos de los experimentos que se realizan destacan por su complejidad y requieren a\u00f1os y a\u00f1os de planificaci\u00f3n y de construcci\u00f3n de equipamientos. </p> <p>Fue a ra\u00edz de la necesidad de disponer de m\u00faltiples grupos de cient\u00edficos repartidos por el mundo y colaborando entre ellos (envi\u00e1ndose informes, dibujos, esquemas, fotos y todo tipo de documentos) que naci\u00f3 la web. </p> <p></p> <p>Es en los inicios del protocolo HTTP, a mediados del a\u00f1o 1990, cuando encontramos la versi\u00f3n 0.9. Esta versi\u00f3n ten\u00eda como \u00fanica finalidad transferir datos por Internet en forma de p\u00e1ginas web escritas en lenguaje de marcado de hipertexto (HTML, HyperText Markup Language). A partir de la versi\u00f3n 1.0 del protocolo surgi\u00f3 la posibilidad de transferir mensajes con encabezados que describ\u00edan el contenido de los mensajes. </p>"},{"location":"Ud3%20Servidores%20web/T03/#versiones","title":"Versiones","text":""},{"location":"Ud3%20Servidores%20web/T03/#la-primera-version-http1","title":"La primera versi\u00f3n: HTTP/1","text":"<p>La historia de HTTP empez\u00f3 en 1989, cuando Tim Berners-Lee y su equipo del CERN (Suiza) empezaron a desarrollar la World Wide Web. La versi\u00f3n inicial de HTTP fue bautizada con el n\u00famero de versi\u00f3n 0.9, consist\u00eda en una sola l\u00ednea y solo permit\u00eda solicitar un archivo HTML del servidor cada vez. </p> <p>El servidor entonces no hac\u00eda m\u00e1s que transferir el archivo solicitado, de manera que esta versi\u00f3n del protocolo solo pod\u00eda manejar archivos HTML.</p>"},{"location":"Ud3%20Servidores%20web/T03/#el-primer-estandar-oficial-http11","title":"El primer est\u00e1ndar oficial: HTTP/1.1","text":"<p>HTTP/1.1 aclar\u00f3 ambig\u00fcedades y a\u00f1adi\u00f3 numerosas mejoras: </p> <ul> <li> <p>Una conexi\u00f3n pod\u00eda ser reutilizada, ahorrando as\u00ed el tiempo de re-abrirla repetidas veces. </p> </li> <li> <p>Enrutamiento('Pipelining' en ingl\u00e9s) se a\u00f1adi\u00f3 a la especificaci\u00f3n, permitiendo realizar una segunda petici\u00f3n de datos, antes de que fuera respondida la primera, disminuyendo de este modo la latencia de la comunicaci\u00f3n. </p> </li> <li> <p>Se permiti\u00f3 que las respuestas a peticiones, pod\u00edan ser divididas en sub-partes. </p> </li> <li> <p>La negociaci\u00f3n de contenido, incluyendo el lenguaje, el tipo de codificaci\u00f3n, o tipos, se a\u00f1adieron a la especificaci\u00f3n, permitiendo que servidor y cliente, acordasen el contenido m\u00e1s adecuado a intercambiarse. </p> </li> <li> <p>Gracias a la cabecera, Host, pudo ser posible alojar varios dominios en la misma direcci\u00f3n IP. </p> </li> </ul>"},{"location":"Ud3%20Servidores%20web/T03/#un-protocolo-de-mayor-rendimiento-http2","title":"Un protocolo de mayor rendimiento HTTP/2","text":"<p>Seg\u00fan pasaban los a\u00f1os, las p\u00e1ginas web se volv\u00edan cada vez m\u00e1s amplias y complejas. Para cargar una web moderna en el navegador, este tiene que solicitar muchos megabytes de datos y enviar hasta cien solicitudes HTTP. HTTP/1.1 est\u00e1 pensado para procesar solicitudes una tras otra en una misma conexi\u00f3n, de manera que cuanto m\u00e1s compleja sea una p\u00e1gina web, m\u00e1s tardar\u00e1 en cargarse y mostrarse. </p> <p>Por esta raz\u00f3n, Google desarroll\u00f3 un nuevo y experimental protocolo, el SPDY o Speedy, que despert\u00f3 un gran inter\u00e9s entre los desarrolladores y permiti\u00f3 que en 2015 se publicara la versi\u00f3n HTTP/2 del protocolo. Este est\u00e1ndar incluye m\u00faltiples mejoras que tienen como objetivo acelerar la carga de las p\u00e1ginas web. </p> <p>La versi\u00f3n HTTP/2 se extendi\u00f3 r\u00e1pidamente y las p\u00e1ginas web con mucho tr\u00e1fico fueron de las primeras en adoptarla. Actualmente (con fecha de enero de 2020), seg\u00fan W3Techs, un 42 % de las p\u00e1ginas web utilizan la versi\u00f3n HTTP/2. </p> <p></p>"},{"location":"Ud3%20Servidores%20web/T03/#el-futuro-http3","title":"El futuro: HTTP/3","text":"<p>Un punto d\u00e9bil de todas las versiones de HTTP usadas hasta ahora es el protocolo de control de transmisi\u00f3n (TCP) en el que se basan. Este protocolo requiere que el receptor de cada paquete de datos confirme la recepci\u00f3n antes de que pueda enviarse el siguiente paquete. De este modo, basta con que se pierda un paquete para que todos los dem\u00e1s tengan que esperar a que dicho paquete sea transmitido de nuevo. </p> <p>Para evitarlos, la nueva versi\u00f3n HTTP/3 no funcionar\u00e1 con TCP, sino con UDP, que no aplica este tipo de medidas correctivas. A partir de UDP, se ha creado el protocolo QUIC (Quick UDP Internet Connections), que ser\u00e1 la base de HTTP/3.</p>"},{"location":"Ud3%20Servidores%20web/T03/#funcionamiento-del-protocolo-http","title":"Funcionamiento del protocolo HTTP","text":"<p>Ya hemos comentado que el protocolo HTTP tiene un funcionamiento bastante sencillo basado en el env\u00edo de mensajes entre cliente y servidor. </p> <p>Gr\u00e1ficamente podemos resumir el proceso de comunicaci\u00f3n HTTP como sigue: </p> <p></p> <ol> <li> <p>Un usuario accede a una URL, seleccionando un enlace de un documento HTML o introduci\u00e9ndola directamente en el campo correspondiente del cliente Web. </p> </li> <li> <p>El cliente Web descodifica la URL, separando sus diferentes partes: el protocolo de acceso, la direcci\u00f3n DNS o IP del servidor, el posible puerto opcional (el valor por defecto es 80) y el objeto requerido del servidor. <code>http://direccion[:puerto][path]</code></p> <p><code>Ejemplo: http://www.miweb.com/documento.html</code></p> </li> <li> <p>Se abre una conexi\u00f3n TCP/IP con el servidor, llamando al puerto TCP correspondiente. En ese momento, se realiza la petici\u00f3n HTTP. Para ello, se env\u00eda el comando necesario (GET, POST, HEAD,...), la direcci\u00f3n del objeto requerido (el contenido de la URL que sigue a la direcci\u00f3n del servidor), la versi\u00f3n del protocolo HTTP empleada y un conjunto variable de informaci\u00f3n, que incluye datos sobre las capacidades del navegador (browser), datos opcionales para el servidor, etc. </p> </li> <li> <p>El servidor devuelve la respuesta al cliente. Consiste en un c\u00f3digo de estado y el tipo de dato MIME de la informaci\u00f3n de retorno, seguido de la propia informaci\u00f3n. </p> </li> <li> <p>Se cierra la conexi\u00f3n TCP. Este proceso se repite en cada acceso al servidor HTTP. Por ejemplo, si se recoge un documento HTML en cuyo interior est\u00e1n insertadas 2 im\u00e1genes y 1 v\u00eddeo, el proceso anterior se repite cuatro veces, una para el documento HTML y tres m\u00e1s para los recursos (la dos im\u00e1genes y el v\u00eddeo). </p> </li> </ol>"},{"location":"Ud3%20Servidores%20web/T03/#comandos-o-metodos-http","title":"Comandos o m\u00e9todos HTTP","text":"<p>HTTP define un conjunto de m\u00e9todos de petici\u00f3n para indicar la acci\u00f3n que se desea realizar para un recurso determinado. </p> <p></p> <p>El est\u00e1ndar HTTP/1.0 recoge \u00fanicamente tres comandos, que representan las operaciones de recepci\u00f3n y env\u00edo de informaci\u00f3n y chequeo de estado: </p> <ul> <li> <p>GET: se utiliza para solicitar cualquier tipo de informaci\u00f3n o recurso al servidor. Cada vez que se pulsa sobre un enlace o se teclea directamente a una URL se usa este comando. Como resultado, el servidor HTTP enviar\u00e1 el recurso correspondiente. </p> </li> <li> <p>HEAD: se utiliza para solicitar informaci\u00f3n sobre el recurso: su tama\u00f1o, su tipo, su fecha de modificaci\u00f3n\u2026 Es usado por los gestores de cach\u00e9s de p\u00e1ginas o los servidores proxy, para conocer cu\u00e1ndo es necesario actualizar la copia que se mantiene del recurso. Con HEAD se podr\u00e1 comprobar la \u00faltima fecha de modificaci\u00f3n de un recurso antes de traer una nueva copia del mismo. </p> </li> <li> <p>POST: sirve para enviar informaci\u00f3n al servidor, por ejemplo, los datos contenidos en un formulario. El servidor pasar\u00e1 esta informaci\u00f3n a un proceso encargado de su tratamiento. </p> </li> </ul> <p>La versi\u00f3n 1.1 del protocolo incorpora unos pocos comandos m\u00e1s como son: OPTIONS, PUT, DELETE, TRACE y CONNECT. Veamos algunos de ellos: </p> <ul> <li> <p>OPTIONS: Devuelve los m\u00e9todos HTTP que el servidor soporta para una URL espec\u00edfica. Esto puede ser utilizado para comprobar la funcionalidad de un servidor web mediante petici\u00f3n en lugar de un recurso espec\u00edfico. </p> </li> <li> <p>DELETE: sirve para eliminar un recurso especificado en la URL, aunque pocas veces sera permitido por un servidor web. </p> </li> <li> <p>TRACE: comando que permite hacer un sondeo para saber todos los dispositivos de la red por los que pasa nuestra petici\u00f3n. As\u00ed podremos descubrir si la petici\u00f3n pasa a trav\u00e9s dispositivos intermedios o proxys antes de llegar al servidor Web. </p> </li> <li> <p>PUT: puede verse como el comando inverso a GET. Nos permite escribir datos en el servidor o, lo que es lo mismo, poner un recurso en la URL que se especifique. Si el recurso no existe lo crea sino lo reemplaza. La diferencia con POST puede ser algo confusa; mientras que POST est\u00e1 orientado a la creaci\u00f3n de nuevos contenidos, PUT est\u00e1 m\u00e1s orientado a la actualizaci\u00f3n de los mismos (aunque tambi\u00e9n podr\u00eda crearlos). </p> </li> </ul> <p>HTTP/2 no incluye m\u00e9todos nuevos. </p>"},{"location":"Ud3%20Servidores%20web/T03/#ejemplo-de-peticion-y-respuesta","title":"Ejemplo de petici\u00f3n y respuesta","text":"<p>Una solicitud HTTP es un conjunto de l\u00edneas que el navegador env\u00eda al servidor. Incluye: </p> <ul> <li> <p>El recurso solicitado, el m\u00e9todo que se aplicar\u00e1 y la versi\u00f3n del protocolo utilizada. </p> </li> <li> <p>Los campos del encabezado de solicitud: es un conjunto de l\u00edneas opcionales que permiten aportar informaci\u00f3n adicional sobre la solicitud y/o el cliente (navegador, sistema operativo, etc.). Cada una de estas l\u00edneas est\u00e1 formada por un nombre que describe el tipo de encabezado, seguido de dos puntos (:) y el valor del encabezado. </p> </li> <li> <p>El cuerpo de la solicitud: es un conjunto de l\u00edneas opcionales que deben estar separadas de las l\u00edneas precedentes por una l\u00ednea en blanco y que, por ejemplo, permiten la transmisi\u00f3n de datos al servidor de un formulario a trav\u00e9s del m\u00e9todo POST. </p> </li> </ul> <p></p> <p>La sintaxis de una respuesta HTTP es un conjunto de l\u00edneas que el servidor env\u00eda al navegador. Incluye: </p> <ul> <li> <p>Una l\u00ednea de estado donde figura el versi\u00f3n del protocolo usada, un c\u00f3digo de estado/error y un texto con el significado de dicho c\u00f3digo. </p> </li> <li> <p>Los posibles c\u00f3digos de estado se identifican con n\u00fameros de tres cifras y se clasifican en cinco grupos seg\u00fan sean informativos (1xx), de \u00e9xito en la solicitud (2xx), para redireccionar la solicitud (3xx), por error generado en el cliente (4xx) o bien por errores generados en el servidor (5xx) \u2192 C\u00f3digos de estado/error </p> </li> <li> <p>Los campos del encabezado de la respuesta. Conjunto de lineas opcionales que aportan informaci\u00f3n adicional sobre la respuesta y/o el servidor. </p> </li> <li> <p>El cuerpo de la respuesta que contiene el recurso (objeto) solicitado</p> </li> </ul> <p></p>"},{"location":"Ud3%20Servidores%20web/T03/#cabeceras-http","title":"Cabeceras HTTP","text":"<p>Las cabeceras HTTP son los par\u00e1metros que se env\u00edan en una petici\u00f3n o respuesta HTTP al cliente o al servidor para proporcionar informaci\u00f3n esencial sobre la transacci\u00f3n en curso. Estas cabeceras proporcionan informaci\u00f3n mediante la sintaxis 'Cabecera: Valor' y son enviadas autom\u00e1ticamente por el navegador o el servidor Web.  \u2192 Cabeceras HTTP </p>"},{"location":"Ud3%20Servidores%20web/T03/#tipos-mime","title":"Tipos MIME","text":"<p>El protocolo HTTP fue dise\u00f1ado para transportar por red ficheros en formato ASCII, formados por texto plano. Con el paso del tiempo, surgi\u00f3 la necesidad de incluir diferentes tipos de ficheros no ASCII en las aplicaciones por Internet (im\u00e1genes, v\u00eddeos, sonidos, etc.) y, como consecuencia de ello, fue necesario buscar una soluci\u00f3n: hab\u00eda que transformar estos formatos a tipo ASCII (u otros juegos de caracteres compatibles) para su correcta recepci\u00f3n en el navegador web. </p> <p>Este problema ya hab\u00eda surgido en las aplicaciones de correo electr\u00f3nico, cuando se necesit\u00f3 enviar por MAIL ficheros no formados por texto plano, y por tanto, no compatibles con los juegos de caracteres permitidos. </p> <p>Para solucionar este problema se crearon los tipos MIME (Multipurpose Internet Mail Extensions), especificaciones para dar formato a mensajes no-ASCII, de forma que pudieran ser enviados por Internet e interpretados correctamente por los programas de correo locales. </p> <p>Tipos de medios de Internet, previamente conocido como \"tipos \" o \"tipos de contenido\", es un est\u00e1ndar dise\u00f1ado para indicar el tipo de informaci\u00f3n que presenta un archivo o un conjunto de datos. Este identificador puede ser \u00fatil para conocer el tipo de un archivo antes de descarcarglo y tener acceso a \u00e9l. Es una buena p\u0155actica proveer informaci\u00f3n de tipos de medios siempre que sea posible, como en el caso de los elementos que cuentan con atributos como type, enctype, formenctype y accept. </p> <p></p> <p>Todo identificador de tipo de medio de Internet debe ajustarse al siguiente formato: <code>tipo/subtipo</code></p> <p>Donde:</p> <p>tipo: Es la categor\u00eda general del recurso, como \"text\" (texto), \"image\" (imagen), \"audio\" (audio), \"video\" (video), etc.</p> <p>subtipo: Es una descripci\u00f3n m\u00e1s espec\u00edfica del formato del recurso dentro de la categor\u00eda de tipo. Por ejemplo, \"plain\" (texto sin formato), \"html\" (p\u00e1gina web HTML), \"jpeg\" (imagen JPEG), \"mp3\" (archivo de audio MP3), \"mp4\" (archivo de video MP4), etc.</p> <p>Algunos ejemplos de identificadores de tipo de medio comunes son:</p> <ul> <li>text/plain: Archivo de texto sin formato.</li> <li>text/html: P\u00e1gina web en formato HTML.</li> <li>image/jpeg: Imagen en formato JPEG.</li> <li>audio/mp3: Archivo de audio en formato MP3.</li> <li>video/mp4: Archivo de video en formato MP4.</li> </ul>"},{"location":"Ud3%20Servidores%20web/T03/#https","title":"HTTPS","text":"<p>El Protocolo seguro de transferencia de hipertexto (en ingl\u00e9s, Hypertext Transfer Protocol Secure o HTTPS) es un protocolo de aplicaci\u00f3n basado en el protocolo HTTP, destinado a la transferencia segura de datos de hipertexto, es decir, es la versi\u00f3n segura de HTTP. </p> <p>La web es insegura por naturaleza. Cuando se dise\u00f1aron los protocolos en los que est\u00e1 basada (TCP/IP) no se tuvieron en cuenta muchos de los problemas que tiene la Internet moderna. Y el protocolo HTTP, para transferir p\u00e1ginas web, no a\u00f1adi\u00f3 nada al respecto tampoco hasta mucho despu\u00e9s, con la introducci\u00f3n del protocolo HTTPS (la \"ese\" es de \"Seguro\") all\u00e1 por 1994 por la empresa Netscape. El protocolo HTTPS original utilizaba SSL (Secure Sockets Layer) como protocolo seguro de intercambio de claves y cifrado, pero en la actualidad est\u00e1 obsoleto y se emplea TLS (Transport Layer Security, que va por su versi\u00f3n 1.3). El est\u00e1ndar de HTTP sobre TLS, en realidad, no se configur\u00f3 hasta mayo del a\u00f1o 2000. </p> <p>Tradicionalmente, los navegadores le han indicado a sus usuarios que se estaban conectando a un sitio seguro utilizando un iconito, generalmente uno con un candado. </p> <p>Seg\u00fan el navegador el aspecto cambia un poco, pero todos muestran el proverbial \"candadito\" al lado de la direcci\u00f3n: </p> <p></p> <p>Es decir, lo importante aqu\u00ed es que hasta ahora los navegadores consideran HTTP como la norma, y HTTPS como la excepci\u00f3n, y por eso lo marcan de esta manera. </p>"},{"location":"Ud3%20Servidores%20web/T03/#funcionamiento-de-https","title":"Funcionamiento de HTTPS","text":"<p>El funcionamiento b\u00e1sico de HTTPS se muestra en la p\u00e1gina siguiente. Como se puede observar, utiliza conceptos de cifrado con clave sim\u00e9trica y asim\u00e9trica que vimos en la introducci\u00f3n del m\u00f3dulo.</p> <p></p>"},{"location":"Ud3%20Servidores%20web/T04/","title":"Servidores web: Nginx vs Apache","text":"<p>Cuando vamos a poner en marcha un servidor web, lo primero que necesitamos es utilizar un sistema operativo sobre el cual vamos a ejecutar los diferentes servicios, sistema operativo que en m\u00e1s del 95% de las ocasiones suele ser un sistema Linux. Sobre el S.O. se ha de instalar el servicio de servidor web, que es el que se encargara de recibir las peticiones de p\u00e1ginas y servirlas. Y actualmente con esto no suele ser suficiente, ya que raramente un servidor web se limitar\u00e1 a servir p\u00e1ginas est\u00e1ticas. Se har\u00e1 necesario un software que se encargue de la gesti\u00f3n de las bases de datos, MySQL habitualmente, y un software para gestionar los contenidos din\u00e1micos de las webs, que suele ser PHP. </p> <p>En este apartado vamos a centrarnos en el software del servidor web y aqu\u00ed es donde entran las dudas. </p> <p>Cuando buscamos montar una web podemos elegir una gran cantidad de servidores web diferentes, desde Apache y Nginx, los m\u00e1s conocidos y utilizados con m\u00e1s de un 85% de uso entre ambos, hasta otros servidores menos conocidos como Microsoft IIS (si usamos un servidor Windows), LiteSpeed, Node.js, etc. </p> <p>Los dos servidores m\u00e1s utilizados para montar p\u00e1ginas web hoy en d\u00eda son Apache y Nginx, sin embargo, es imposible decir que uno es mejor que otro ya que cada uno de ellos tiene sus propias fortalezas y debilidades y puede mejorar mejor bajo ciertas circunstancias o simplemente ser m\u00e1s sencillo de utilizar. </p> <p>Nginx est\u00e1 orientado a mejorar el rendimiento, soportando mayores cargas de tr\u00e1fico y usuarios que Apache (Problema C10K), adem\u00e1s de ofrecer otras funcionalidades como hacer de proxy. En sus or\u00edgenes era especialmente eficiente ofreciendo contenido est\u00e1tico.</p> <p> </p> <p>Despu\u00e9s de ser lanzado, Nginx fue usado principalmente para servir archivos est\u00e1ticos y como un balanceador de carga o proxy inverso en frente de instalaciones Apache.</p> <p>Ejemplos de servicios de despliegue de p\u00e1ginas est\u00e1ticas:</p> <ul> <li>Netlify</li> <li>Surge</li> <li>GitHub Pages</li> <li>GitLab Pages</li> <li>Firebase</li> <li>Vercel</li> <li>Neocities</li> </ul> <p>Mientras evolucionaba la red, y la necesidad de exprimir hasta la \u00faltima gota de la velocidad y eficiencia de uso de hardware con este, m\u00e1s sitios empezaron a reemplazar Apache con Nginx por completo, gracias a un software mucho m\u00e1s maduro.</p> <p></p>"},{"location":"Ud3%20Servidores%20web/T04/#razones-para-usar-nginx","title":"Razones para usar Nginx","text":"<ol> <li> <p>Es ligero</p> <p>Nginx reduce el consumo de RAM. </p> </li> <li> <p>Es multiplataforma y f\u00e1cil de instalar </p> <p>La mayor\u00eda de las grandes distribuciones de GNU/Linux, tienen Nginx en sus repositorios. </p> </li> <li> <p>\u00a1Se puede usar junto a Apache! </p> <p>S\u00ed, como lo lees, algunas empresas solo usan Nginx para servir contenido est\u00e1tico y Apache para el contenido din\u00e1mico. </p> </li> <li> <p>Cach\u00e9</p> <p>Puedes usar Nginx como cach\u00e9, con algo de configuraci\u00f3n, permitiendo mejorar la eficiencia de tu aplicaci\u00f3n sin tocar la programaci\u00f3n de la misma. </p> </li> <li> <p>Balanceador de carga </p> <p>Este servidor web puede funcionar como balanceador de carga, distribuyendo el tr\u00e1fico entre varios servidores, permitiendo mayor escalabilidad. </p> </li> <li> <p>Soporte comunitario y profesional </p> <p>Nginx, Inc est\u00e1 detr\u00e1s del desarrollo de Nginx, adem\u00e1s de la comunidad en general, permitiendo tener un soporte tanto profesional como comunitario. </p> </li> <li> <p>Compatibilidad con las aplicaciones web m\u00e1s populares</p> <p>Nginx es compatible con una gran cantidad de CMS existentes en el mercado, y hay un muchos tutoriales y documentaci\u00f3n para instalar estos bajo Nginx, como por ejemplo: Wordpress, Joomla, Drupal, phpBB \u00a1y m\u00e1s! </p> </li> </ol>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/","title":"Pr\u00e1ctica 1 - Configuraci\u00f3n de un servidor DNS","text":"<p>Nota importante</p> <p>Es muy importante que antes de empezar esta pr\u00e1ctica elimin\u00e9is las entradas que hab\u00e9is ido introduciendo hasta ahora en vuestro archivo <code>/etc/hosts</code> para asegurarnos que realmente la resoluci\u00f3n de nombres va a nuestro servidor DNS. Si no hac\u00e9is esto, resolver\u00e1 los nombres, pensar\u00e9is que est\u00e1 bien pero en realidad estar\u00e1 mal.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#creacion-de-la-maquina-virtual","title":"Creaci\u00f3n de la m\u00e1quina virtual","text":"<p>Para empezar, entra en AWS Academy y crea un nuevo EC2 Debian con estas caracter\u00edsticas. </p> <ul> <li>Ll\u00e1male P5ServidorDNS.</li> <li>Dale los recursos que te ofrece por defecto.</li> <li>Crea un Grupo de seguridad con el nombre P5ServidorDNS y abre los puertos necesarios para que una m\u00e1quina externa pueda consultarlo.</li> <li>Arranca la m\u00e1quina y actual\u00edzala para que cuente con las \u00faltimas versiones de todos los paquetes.</li> </ul> <p>Para esta pr\u00e1ctica es interesante que nuestro servidor DNS tenga una IP fija y no cambie cada vez que arranquemos nuestro servidor. </p> <p>En Amazon Web Services (AWS), las direcciones IP el\u00e1sticas se utilizan para proporcionar direcciones IP fijas a instancias de Amazon EC2 u otros recursos de AWS. Aqu\u00ed hay una gu\u00eda b\u00e1sica para asignar una direcci\u00f3n IP el\u00e1stica a una instancia de EC2 en AWS:</p> <ol> <li> <p>Inicia sesi\u00f3n en la Consola de AWS.</p> </li> <li> <p>Ve al panel de EC2.</p> </li> <li> <p>En el panel de navegaci\u00f3n izquierdo, haz clic en \"Direcciones IP el\u00e1sticas\" bajo \"Redes y Seguridad\".</p> </li> <li> <p>Asigna una nueva direcci\u00f3n IP el\u00e1stica:</p> <ol> <li>Haz clic en \"Asignar la direcci\u00f3n IP el\u00e1stica\".     Simplemente haz clic en \"Asignar\" para obtener una nueva.</li> </ol> </li> <li> <p>Asocia la direcci\u00f3n IP el\u00e1stica a una instancia:</p> <ol> <li> <p>Selecciona la direcci\u00f3n IP el\u00e1stica reci\u00e9n creada.</p> </li> <li> <p>Haz clic en \"Acciones\" y selecciona \"Asociar la direcci\u00f3n IP el\u00e1stica\".</p> </li> <li> <p>Selecciona la instancia a la que deseas asignar la direcci\u00f3n IP el\u00e1stica y haz clic en \"Associate\". As\u00edgnala a la instancia, no a la IP privada.</p> </li> </ol> </li> </ol> <p>Despu\u00e9s de estos pasos, la instancia de EC2 tendr\u00e1 una direcci\u00f3n IP el\u00e1stica asociada, proporcion\u00e1ndote una IP fija para esa instancia. Ten en cuenta que las direcciones IP el\u00e1sticas no son gratuitas cuando no est\u00e1n asociadas a una instancia en ejecuci\u00f3n, por lo que es una buena pr\u00e1ctica desasociarlas y liberarlas cuando no las est\u00e1s utilizando.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#herramientas-de-diagnostico-de-resolucion-de-nombres","title":"Herramientas de diagn\u00f3stico de resoluci\u00f3n de nombres.","text":"<p>Los programas <code>dig</code>, <code>host</code> y <code>nslookup</code> son herramientas de l\u00ednea de comandos para realizar consultas a servidores de nombres. </p> <ul> <li> <p><code>dig</code></p> <p><code>dig</code> es la herramienta m\u00e1s vers\u00e1til y completa de estas utilidades de consulta. Tiene dos modos: un modo interactivo simple para una sola consulta y un modo por lotes que ejecuta una consulta para cada l\u00ednea en una lista de varias l\u00edneas de consulta.</p> </li> <li> <p><code>host</code></p> <p>La utilidad <code>host</code> enfatiza la simplicidad y facilidad de uso. Por defecto, convierte entre nombres de host y direcciones de Internet-</p> </li> <li> <p><code>nslookup</code></p> <p><code>nslookup</code> tiene dos modos: interactivo y no interactivo. El modo interactivo permite al usuario consultar servidores de nombres para obtener informaci\u00f3n sobre varios hosts y dominios, o imprimir una lista de hosts en un dominio. El modo no interactivo se utiliza para imprimir solo el nombre y la informaci\u00f3n solicitada para un host o dominio.</p> </li> </ul> <p>Para instalar estas herramientas en nuestra Debian usaremos: </p> <pre><code>sudo apt-get install dnsutils \n</code></pre> <p>Comprobemos primero cu\u00e1l es el servidor de nombres que tenemos configurado en nuestra EC2. Podemos saberlo con: </p> <pre><code>$ cat /etc/resolv.conf \n...\n\nnameserver 172.31.0.2\nsearch .\n</code></pre> <p>Toma nota de la IP del \"nameserver\", es decir, la IP del equipo al que nuestra m\u00e1quina enviar\u00e1 las consultas de resoluci\u00f3n de nombres. En este caso nuestro DNS es 172.31.0.2.</p> <p>Vamos a probar con <code>host</code>.</p> <pre><code>$ host cisco.com\ncisco.com has address 72.163.4.185\ncisco.com has IPv6 address 2001:420:1101:1::185\ncisco.com mail is handled by 30 aer-mx-01.cisco.com.\ncisco.com mail is handled by 10 alln-mx-01.cisco.com.\ncisco.com mail is handled by 20 rcdn-mx-01.cisco.com.\n</code></pre> <p>La salida es simple. Nos responde con los registros. En muchos casos esta informaci\u00f3n es m\u00e1s que suficiente. Aunque no sabemos qu\u00e9 servidor DNS nos est\u00e1 dando la respuesta, si es autoritativa o no. Para nuestras pruebas se queda un poco corto.</p> <p>Probemos ahora con <code>dig</code>.</p> <pre><code>$ dig cisco.com\n\n; &lt;&lt;&gt;&gt; DiG 9.18.19-1~deb12u1-Debian &lt;&lt;&gt;&gt; cisco.com\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 57177\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;cisco.com.         IN  A\n\n;; ANSWER SECTION:\ncisco.com.      111 IN  A   72.163.4.185\n\n;; Query time: 3 msec\n;; SERVER: 172.31.0.2#53(172.31.0.2) (UDP)\n;; WHEN: Sat Nov 25 08:30:24 UTC 2023\n;; MSG SIZE  rcvd: 54\n</code></pre> <p>Vemos que obtenemos m\u00e1s informaci\u00f3n. No s\u00f3lo nos devuelve la respuesta de la IP sino que adem\u00e1s nos dice qu\u00e9 servidor DNS nos la est\u00e1 proporcionando.</p> <p>Y finalmente vamos a probar con nslookup:</p> <pre><code>$ nslookup cisco.com \nServer:     172.31.0.2 #(1)\nAddress:    172.31.0.2#53 #(2)\n\nNon-authoritative answer: #(3)\nName:   cisco.com\nAddress: 72.163.4.185 #(4)\nName:   cisco.com\nAddress: 2001:420:1101:1::185 #(5)\n</code></pre> <ol> <li> <p>Servidor DNS que nos est\u00e1 dando la respuesta</p> </li> <li> <p>IP y puerto del servidor DNS que nos da la respuesta</p> </li> <li> <p>El servidor DNS que nos contesta no tiene autoridad sobre la zona </p> </li> <li> <p>La IP de cisco.com en IPv4</p> </li> <li> <p>La IP de cisco. com en IPv6</p> </li> </ol> <p>F\u00edjate que en tu caso la IP de Server y Address pueden ser distintas si tu m\u00e1quina virtual pregunta a un servidor DNS diferente. Prueba a ejecutar el mismo comando desde tu ordenador anfitri\u00f3n (el de casa o el aula). \u00bfCoinciden los campos de Server y Address? \u00bfY la IP de Cisco.com?</p> <p>nslookup nos da una funcionalidad adicional. Podemos decirle cu\u00e1l es el servidor DNS al que queremos consultar. Prueba a realizar la consulta anterior a un DNS de Google y observa la diferencia en la respuesta. Esto nos ser\u00e1 muy \u00fatil para consultar a nuestro servidor DNS desde cualquier m\u00e1quina que no lo tenga configurado como servidor DNS principal.</p> <p><pre><code>$ nslookup cisco.com 8.8.8.8\nServer:     8.8.8.8\nAddress:    8.8.8.8#53\n\nNon-authoritative answer:\nName:   cisco.com\nAddress: 72.163.4.185\nName:   cisco.com\nAddress: 2001:420:1101:1::185\n</code></pre> Esta consulta lo que est\u00e1 haciendo es buscar la informaci\u00f3n de DNS para el dominio \"cisco.com\" utilizando el servidor DNS p\u00fablico de Google, que tiene la direcci\u00f3n IP 8.8.8.8.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#instalacion-de-servidor-dns","title":"Instalaci\u00f3n de servidor DNS","text":"<p>Bind es el est\u00e1ndar de facto para servidores DNS. Es una herramienta de software libre y se distribuye con la mayor\u00eda de plataformas Unix y Linux, donde tambi\u00e9n se le conoce con el sobrenombre de named (name daemon). Bind9 es la versi\u00f3n recomendada para usarse y es la que emplearemos.</p> <p>Para instalar el servidor DNS en un servidor Debian, usaremos los repositorios oficiales. Por ello, podremos instalarlo como cualquier paquete en Debian:</p> <pre><code>sudo apt-get install bind9 bind9utils bind9-doc \n</code></pre> <p>Comprueba si el servicio bind 9 ya est\u00e1 funcionando.</p> <p>Una vez instalado el servicio ya funcionar\u00e1 con las opciones b\u00e1sicas. </p> <p>En una prueba anterior hemos probado a preguntar al servidor DNS que tenemos configurado, pero lo que nos interesa ahora es preguntarle al que acabamos de instalar. Desde nuestro servidor Debian vamos a preguntarle al servidor bind9.</p> <pre><code>$ nslookup cisco.com 127.0.0.1 #(1)\nServer:     127.0.0.1\nAddress:    127.0.0.1#53\n\nNon-authoritative answer:\nName:   cisco.com\nAddress: 72.163.4.185\nName:   cisco.com\nAddress: 2001:420:1101:1::185\n</code></pre> <ol> <li>Inclu\u00edmos al final la IP del servidor al que queremos preguntar. Vemos como en Server y Address nos est\u00e1 contestando 127.0.0.1 que no es m\u00e1s que localhost, nuestra propia m\u00e1quina. Comprobamos c\u00f3mo nuestro servidor DNS y es capaz de darnos respuesta.</li> </ol> <p>Prueba ahora a consultar a nuestro servidor DNS desde tu m\u00e1quina anfitri\u00f3n. Para ello deber\u00e1s consultar a su IP p\u00fablica. \u00bfObtienes respuesta? \u00bfPor qu\u00e9 crees que obtienes esa respuesta? Lo veremos m\u00e1s adelante.</p> <p>Una vez comprobado que nuestro servidor DNS est\u00e1 funcionando correctamente vamos a cambiar el DNS al que consulta nuestro servidor Debian en <code>/etc/resolv.conf</code>. Sin embargo, este archivo puede ser gestionado autom\u00e1ticamente y sobrescrito por herramientas como <code>systemd-resolved</code> o <code>dhclient</code>. Para hacer cambios permanentes en los servidores DNS, es recomendable modificar la configuraci\u00f3n en el lugar correspondiente.</p> <p>Nuestro sistema usa <code>systemd-resolved</code>. Para cambiar la configuraci\u00f3n DNS de forma permanente, edita el archivo de configuraci\u00f3n <code>/etc/systemd/resolved.conf</code>. Dentro del archivo, busca la secci\u00f3n [Resolve] y agrega o modifica la l\u00ednea DNS= con tus servidores DNS preferidos, separados por espacios. En nuestro caso usaremos la propia m\u00e1quina 127.0.0.1.</p> <pre><code>[Resolve]\nDNS=127.0.0.1\n</code></pre> <p>Reinicia systemd-resolved para aplicar la nueva configuraci\u00f3n:</p> <pre><code>sudo systemctl restart systemd-resolved\n</code></pre> <p>Comprueba ahora que en <code>/etc/resolv.conf</code> tienes <code>nameserver=127.0.0.1</code> como primera opcion.</p> <p>Prueba ahora a consultar la IP de cisco.com con <code>dig</code> y <code>nslookup</code> y comprueba que servidor te responde.</p> <p>Es importante recordar aqu\u00ed que no tenemos configurada en ninguna parte la IP de ning\u00fan servidor DNS externo. Por tanto, \u00bfc\u00f3mo es capaz nuestro servidor de contestarnos cuando le preguntamos por la IP de cisco.com? Por defecto bind9 realizar\u00e1 una resoluci\u00f3n iterativa, preguntando primero a los servidores ra\u00edz de internet, si estos no tienen, preguntar\u00e1 a los servidores TLD y despu\u00e9s a los servidores autoritativos de dominio.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#configuracion-del-servidor","title":"Configuraci\u00f3n del servidor","text":"<p>El archivo de configuraci\u00f3n principal de Bind es:</p> <pre><code>/etc/bind/named.conf\n</code></pre> <p>Si lo consultamos veremos lo siguiente:</p> <pre><code>$ cat /etc/bind/named.conf\n// This is the primary configuration file for the BIND DNS server named.\n//\n// Please read /usr/share/doc/bind9/README.Debian for information on the\n// structure of BIND configuration files in Debian, *BEFORE* you customize\n// this configuration file.\n//\n// If you are just adding zones, please do that in /etc/bind/named.conf.local\n\ninclude \"/etc/bind/named.conf.options\";\ninclude \"/etc/bind/named.conf.local\";\ninclude \"/etc/bind/named.conf.default-zones\";\n</code></pre> <p>Este archivo sirve simplemente para aglutinar o agrupar a los archivos de configuraci\u00f3n que usaremos. Estos 3 includes hacen referencia a los 3 diferentes archivos donde deberemos realizar la verdadera configuraci\u00f3n, ubicados en el mismo directorio.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#configuracion-namedconfoptions","title":"Configuraci\u00f3n named.conf.options","text":"<p>Es una buena pr\u00e1ctica que hag\u00e1is siempre una copia de seguridad de un archivo de configuraci\u00f3n cada vez que vay\u00e1is a realizar alg\u00fan cambio:</p> <pre><code>sudo cp /etc/bind/named.conf.options /etc/bind/named.conf.options.backup\n</code></pre> <p>Recuerda que si preguntabas antes con nslookup desde el propio servidor obten\u00edamos respuesta pero si le hacemos la consulta desde nuestra m\u00e1quina local nos daba \"REFUSED\". Esto es porque BIND9 solo permite consultas locales por defecto. Para permitir todas las solicitudes a\u00f1adir\u00edamos la directiva:</p> <pre><code>allow-query { any; };\n</code></pre> <p>Puedes comprobar que el archivo de configuraci\u00f3n es correcto con:</p> <pre><code>sudo named-checkconf\n</code></pre> <p>Si no aparecen errores, entonces todo est\u00e1 en orden. Reinicia el servicio y prueba a consultar nuevamente desde tu m\u00e1quina anfitri\u00f3n. \u00bfRecibe ahora la respuesta esperada?</p> <p>Con esta configuraci\u00f3n b\u00e1sica ya hemos comprobado que nuestro servidor DNS est\u00e1 funcionando y respondiendo a peticiones de la propia m\u00e1quina y de otras externas.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#desactivar-la-recursividad","title":"Desactivar la recursividad","text":"<p>En la teor\u00eda vimos que cuando un servidor DNS tiene la recursividad activada dar\u00e1 una respuesta completa cuando le consulten. Si no tiene la respuesta buscar\u00e1 la forma de conseguirla para dar una respuesta al cliente. Este es el estado por defecto cuando instalamos bind9. Pero si queremos desactivar la recursividad incluiremos la siguiente directiva de configuraci\u00f3n en <code>/etc/bind/named.conf.options</code>:</p> <pre><code>recursion no;\n</code></pre> <p>Incluye la directiva, reinicia el servicio y haz una consulta por cualquier dominio, por ejemplo \"cisco.com\". Observa el resultado.</p> <p>Puedes comentar la directiva para dejar la recursividad activada de momento.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#configuracion-de-los-forwarder","title":"Configuraci\u00f3n de los forwarder","text":"<p>Hemos visto que por defecto nuestro servidor har\u00e1 consultas iterativas empezando por el servidor ra\u00edz. Para que realice consultas recursivas preguntando a un servidor DNS configurado por nosotros (forwarder), todo lo que se requiere es simplemente agregar los n\u00fameros de IP de los servidores DNS deseados en la secci\u00f3n \"forwarders\".</p> <p>Simplemente descomenta y edita lo siguiente en <code>/etc/bind/named.conf.options</code>:</p> <pre><code>    forwarders {\n            8.8.8.8;\n            8.8.4.4;\n    };\n</code></pre> <p>Aqu\u00ed hemos configurado los DNS de google. </p> <p>Reinicia el servicio para activarlos.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#comprobacion-del-funcionamiento-de-la-cache","title":"Comprobaci\u00f3n del funcionamiento de la cach\u00e9","text":"<p>Por defecto bind9 tiene la cach\u00e9 habilitada. Podemos probar su funcionamiento de una forma r\u00e1pida y sencilla.</p> <p>Haz un dig a un dominio que no hayas consultado nunca antes y f\u00edjate en el \"Query time\". Inmediatamente vuelve a realizar la misma consulta y comprubeba el \"Query time\" ahora. Deber\u00eda haber habido un descenso dr\u00e1stico debido al uso de la cach\u00e9. \u00bfEs as\u00ed?</p> <p>Podr\u00edamos configurar muchas otras cosas, pero para nuestros objetivos actuales es suficiente.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#configuracion-namedconflocal","title":"Configuraci\u00f3n named.conf.local","text":"<p>En este archivo configuraremos aspectos relativos a nuestras zonas. Vamos a declarar la zona \u201cdeaw.es\u201d. Por ahora simplemente indicaremos que el servidor DNS es maestro para esta zona y donde estar\u00e1 ubicado el archivo de zona que crearemos m\u00e1s adelante:</p> <pre><code>//\n// Do any local configuration here\n//\n\n// Consider adding the 1918 zones here, if they are not used in your\n// organization\n//include \"/etc/bind/zones.rfc1918\";\n\nzone \"deaw.es\" {\n        type master;\n        file \"/etc/bind/db.deaw.es\";  //Ruta donde ubicamos nuestro archivo de zona\n};\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#creacion-del-archivo-de-zona","title":"Creaci\u00f3n del archivo de zona","text":"<p>Vamos a crear el archivo de zona de resoluci\u00f3n directa justo en el directorio que hemos indicado antes y con el mismo nombre que hemos indicado antes.</p> <p>El contenido de <code>/etc/bind/db.deaw.es</code> ser\u00e1 algo as\u00ed (procurad respetar el formato):</p> <pre><code>$TTL 1d\n$ORIGIN deaw.es. ; base domain-name\n@   IN  SOA     ns1.deaw.es. admin.deaw.es. (\n                  2023112301  ; Serial\n                  8H          ; Refresh\n                  2H          ; Retry\n                  4W          ; Expire\n                  1D )        ; Minimum TTL\n; Name Servers\n    IN  NS      ns1.deaw.es.\n; A records\nns1 IN  A       3.85.104.173\nwww IN  A       3.85.104.173\n</code></pre> <p>Ojo, las \u00faltimas IP son la IP que tiene tu servidor Debian. C\u00e1mbiala por la que proceda.</p> <p>Explicaci\u00f3n de las partes del archivo:</p> <ul> <li> <p>$TTL: Tiempo de vida predeterminado para los registros de la zona. En este caso, se establece en 1 d\u00eda.</p> </li> <li> <p>SOA (Start of Authority): Indica informaci\u00f3n sobre la zona, como el nombre del servidor primario, el contacto del administrador y detalles de tiempo.</p> <ul> <li>Recuerda tambi\u00e9n incrementar el n\u00famero de serie cada vez que realices cambios para que las actualizaciones se propaguen correctamente.</li> </ul> </li> <li> <p>NS: Registra los servidores de nombres autoritativos para la zona.</p> </li> <li> <p>A: Registra la direcci\u00f3n IP asociada con un nombre de host espec\u00edfico.</p> </li> </ul> <p>Guarda el archivo. Comprueba que no hay errores con <code>named-checkconf</code> de una forma m\u00e1s avanzada. En este caso necesitar\u00e1 2 par\u00e1metros: el nombre de zona y el archivo de zona:</p> <pre><code>$ sudo named-checkzone deaw.es /etc/bind/db.deaw.es\nzone deaw.es/IN: loaded serial 2023112301\nOK\n</code></pre> <p>Vemos c\u00f3mo si va todo bien nos dir\u00e1 el n\u00famero de serie y Ok. Si hubiera alg\u00fan error nos dir\u00eda algo como </p> <pre><code>zone deaw.es/IN: NS 'ns1.deaw.es' has no address records (A or AAAA)\nzone deaw.es/IN: not loaded due to errors.\n</code></pre> <p>Si va todo bien reinicia el servicio.</p> <p>Prueba a preguntar por www.deaw.es o ns1.deaw.es a tu servidor.</p> <pre><code>nslookup www.deaw.es            //desde el propio servidor\nnslookup www.deaw.es IP_SERVER  //desde tu equipo local\n</code></pre> <p>Prueba a preguntar con <code>dig</code> por el dominio deaw.es:</p> <pre><code>$ dig deaw.es\n\n; &lt;&lt;&gt;&gt; DiG 9.18.19-1~deb12u1-Debian &lt;&lt;&gt;&gt; deaw.es\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31053\n;; flags: qr aa rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n; COOKIE: 535eb708a167a587010000006560f94758cba602eeb2f207 (good)\n;; QUESTION SECTION:\n;deaw.es.           IN  A\n\n;; AUTHORITY SECTION:\ndeaw.es.        86400   IN  SOA ns1.deaw.es. admin.deaw.es. 2023112301 28800 7200 2419200 86400\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1) (UDP)\n;; WHEN: Fri Nov 24 19:28:07 UTC 2023\n;; MSG SIZE  rcvd: 110\n</code></pre> <p>Observa los datos que te devuelve y comp\u00e1ralos con el fichero de configuraci\u00f3n de la zona. </p> <p>Task</p> <p>Haz un dig de otros dominios conocidos como cisco.com o google.com y analiza el resultado</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#creacion-del-archivo-de-zona-para-la-resolucion-inversa","title":"Creaci\u00f3n del archivo de zona para la resoluci\u00f3n inversa","text":"<p>Recordad que deben existir ambos archivos de zona, uno para la resoluci\u00f3n directa y otro para la inversa. Vamos pues a crear el archivo de zona inversa.</p> <p>En primer lugar, debemos a\u00f1adir las l\u00edneas correspondientes a esta zona inversa en el archivo <code>/etc/bind/named.conf.local</code>, igual que hemos hecho antes con la zona de resoluci\u00f3n directa:</p> <p><pre><code>zone \"104.85.3.in-addr.arpa\" {\n    type master;\n    file \"/etc/bind/db.3.85.104\";  # Ruta al archivo de zona inversa\n};\n</code></pre> Y la configuraci\u00f3n de la zona de resoluci\u00f3n inversa la realizaremos en el fichero descrito  \"/etc/bind/db.3.85.104\" :</p> <pre><code>$TTL 1d\n$ORIGIN 104.85.3.IN-ADDR.ARPA.\n@   IN  SOA     ns1.deaw.es. admin.deaw.es. (\n                  2023112301  ; Serial\n                  8H          ; Refresh\n                  2H          ; Retry\n                  4W          ; Expire\n                  1D )        ; Minimum TTL\n\n; Name Servers\n    IN  NS      ns1.deaw.es.\n\n; PTR record\n173 IN  PTR     ns1.deaw.es. ; fully qualified domain name (FQDN)\n</code></pre> <p>Vuelve a comprobar que la configuraci\u00f3n es correcta:</p> <pre><code>sudo named-checkzone 104.85.3.in-addr.arpa /etc/bind/db.3.85.104 \n</code></pre> <p>Reinicia el servicio y ejecuta los comandos de comprobaci\u00f3n.</p> <pre><code>nslookup 3.85.104.173           //desde el propio servidor\nnslookup 3.85.104.173 IP_SERVER //desde tu equipo local\n</code></pre> <p>Comprueba con <code>dig -x</code> la resoluci\u00f3n inversa:</p> <pre><code>$ dig -x 3.85.104.173\n\n; &lt;&lt;&gt;&gt; DiG 9.18.19-1~deb12u1-Debian &lt;&lt;&gt;&gt; -x 3.85.104.173\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 44375\n;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n; COOKIE: 727f64c781f9f648010000006560f9ee4cbddffde4f5df09 (good)\n;; QUESTION SECTION:\n;173.104.85.3.in-addr.arpa. IN  PTR\n\n;; ANSWER SECTION:\n173.104.85.3.IN-ADDR.ARPA. 86400 IN PTR ns1.deaw.es.\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1) (UDP)\n;; WHEN: Fri Nov 24 19:30:54 UTC 2023\n;; MSG SIZE  rcvd: 132\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P1DNS/#cuestiones-finales","title":"Cuestiones finales","text":"<p>Cuesti\u00f3n 1</p> <p>\u00bfQu\u00e9 pasar\u00e1 si un cliente de una red diferente a la tuya intenta hacer uso de tu DNS de alguna manera, le funcionar\u00e1?\u00bfPor qu\u00e9, en qu\u00e9 parte de la configuraci\u00f3n puede verse?</p> <p>Cuesti\u00f3n 2</p> <p>\u00bfPor qu\u00e9 tenemos que permitir las consultas recursivas en la configuraci\u00f3n?</p> <p>Cuesti\u00f3n 3</p> <p>El servidor DNS que acab\u00e1is de montar, \u00bfes autoritativo? \u00bfPor qu\u00e9?</p> <p>Cuesti\u00f3n 4</p> <p>\u00bfD\u00f3nde podemos encontrar la directiva $ORIGIN y para qu\u00e9 sirve?</p> <p>Cuesti\u00f3n 5</p> <p>\u00bfUna zona es id\u00e9ntico a un dominio? </p> <p>Cuesti\u00f3n 6</p> <p>\u00bfPueden editarse los archivos de zona de un servidor esclavo/secundario?</p> <p>Cuesti\u00f3n 7</p> <p>\u00bfPor qu\u00e9 podr\u00eda querer tener m\u00e1s de un servidor esclavo para una misma zona?</p> <p>Cuesti\u00f3n 8</p> <p>\u00bfCu\u00e1ntos servidores ra\u00edz existen?</p> <p>Cuesti\u00f3n 9</p> <p>\u00bfQu\u00e9 es una consulta iterativa de referencia?</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P2DNSDocker/","title":"Pr\u00e1ctica 2 - Dockerizaci\u00f3n de un servidor DNS","text":"<p>Ahora que ya sabemos c\u00f3mo instalar y configurar un servidor DNS vamos a dockerizarlo. A partir de ahora vamos a utilizar im\u00e1genes de docker ya existentes para ahorrarnos la tarea de instalar nuestro servidor.</p> <p>Nota</p> <p>La imagen oficial de Bind9 en Docker hub es internetsystemsconsortium/bind9</p> <p>Ah\u00ed puedes encontrar toda la informaci\u00f3n referente a esa imagen docker y c\u00f3mo usarla.</p> <p>Usaremos la versi\u00f3n BIND 9.18 que tiene \"extended support\"</p> <p>A la hora de dockerizar un servicio hemos visto que podemos seguir varias estrategias:</p> <ul> <li>Montar directorios del contenedor en directorios de nuestra m\u00e1quina host</li> <li>Copiar ficheros de nuestro host al interior del contenedor en el momento de crear la imagen mediante el fichero Dockerfile</li> <li>Crear el contenedor y una vez creado usar el comando \"docker cp\" para copiar ficheros del host a su interior (podemos hacerlo con el contenedor arrancado o parado)</li> <li>Crear el contenedor, arrancarlo, \"entrar a su interior\" con \"docker exec -it NOMBRECONTENEDOR /bin/sh\" y modificar los ficheros que necesitemos. Si usamos esta forma no podremos reiniciar el servicio desde el contenedor. Deberemos salir y reiniciarlo</li> </ul> <p>En esta ocasi\u00f3n vamos a optar por crear el contenedor y usar comandos \"docker cp\".</p> <p>Para crear el contenedor usaremos el comando:</p> <pre><code>docker run -d \\\n        --name=miserverdns \\\n        --publish 53:53/udp \\\n        --publish 53:53/tcp \\\n        internetsystemsconsortium/bind9:9.18\n</code></pre> <p>A estas alturas ya tenemos claro lo que hace este comando.</p> <p>Atenci\u00f3n</p> <p>Si estamos estamos corriendo docker en una EC2 en AWS puede que ya tenga el servicio <code>systemd-resolved</code> corriendo y utilizando el puerto 53, lo que nos dar\u00e1 un conflicto y evitar\u00e1 la creaci\u00f3n del contenedor. Si esto ocurre podemos pararlo con <code>sudo systemctl stop systemd-resolved</code> y ya lo reactivaremos al acabar la pr\u00e1ctica.</p> <p>Una vez arrancado el contenedor ya har\u00e1 consultas recursivas, as\u00ed que le podemos preguntar por cualquier dominio y comprobar que resuelve correctamente. Por ejemplo, desde el host:</p> <pre><code>nslookup cisco.com 127.0.0.1\n</code></pre> <p>La localizaci\u00f3n de los archivos en el contenedor es la misma que en una instalaci\u00f3n habitual e bind9. La \u00fanica particularidad que he encontrado es que el fichero <code>/etc/bind/named.conf</code> de la imagen es distinto al de una instalaci\u00f3n habitual y no tiene las directivas \"include\" habituales. As\u00ed que para poder trabajar como hemos hecho en nuestra instalaci\u00f3n lo sobreescribiremos.</p> <p>Para crear una zona igual que la de la pr\u00e1ctica anterior, nos crearemos una carpeta <code>miserverdns</code> y crearemos en su interior estos ficheros:</p> <pre><code>named.conf\nnamed.conf.options\nnamed.conf.local\ndb.deaw.es\ndb.3.85.104\n</code></pre> <p>Atenci\u00f3n</p> <p>Recuerda que tendr\u00e1s que cambiar <code>db.3.85.104</code> por el que corresponda a tu IP de resoluci\u00f3n inversa</p> <p>En cuanto al contenido de los ficheros ser\u00e1n todos iguales a los de la pr\u00e1ctica anterior, salvo <code>named.conf</code> que contendr\u00e1 lo siguiente:</p> <pre><code>include \"/etc/bind/named.conf.options\";\ninclude \"/etc/bind/named.conf.local\";\n</code></pre> <p>Cuando ya los tengamos todos creados los copiaremos uno a uno al interior del contenedor con:</p> <pre><code>docker cp named.conf miserverdns:/etc/bind\ndocker cp named.conf.options miserverdns:/etc/bind\n...\n</code></pre> <p>Una vez todos copiados al interior podemos parar y reiniciar el contenedor, si estaba en marcha, o arrancarlo si estaba parado.</p> <p>Ahora ya podemos interrogarlo, como hicimos en la pr\u00e1ctica anterior y comprobar que resuelve correctamente.</p> <p>Si hubiera alg\u00fan problema o queremos comprobar su correcta configuraci\u00f3n recuerda que tenemos los comandos <code>named-checkconf</code> y <code>named-checkzone</code>. Podemos lanzarlos al contenedor arrancado con:</p> <pre><code>docker exec miserverdns named-checkconf\ndocker exec miserverdns named-checkzone deaw.es /etc/bind/db.deaw.es\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P3LDAP/","title":"Pr\u00e1ctica 3 - Configuraci\u00f3n de un servidor LDAP","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P3LDAP/#creacion-de-la-maquina-virtual","title":"Creaci\u00f3n de la m\u00e1quina virtual","text":"<p>Para empezar, entra en AWS Academy y crea un nuevo EC2 Debian con estas caracter\u00edsticas. </p> <ul> <li>Ll\u00e1male ServidorLDAP.</li> <li>Dale los recursos que te ofrece por defecto.</li> <li>Crea un Grupo de seguridad con el nombre ServidorLDAP y abre los puertos necesarios para que una m\u00e1quina externa pueda consultarlo.</li> <li>Arranca la m\u00e1quina y actual\u00edzala para que cuente con las \u00faltimas versiones de todos los paquetes.</li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P3LDAP/#servidor-ldap","title":"Servidor LDAP","text":"<p>Un servidor LDAP es un servidor de datos optimizado para la realizaci\u00f3n r\u00e1pida de consultas de lectura y orientado al almacenamiento de datos de usuarios a modo de directorio.</p> <p>La principal utilidad de un directorio LDAP es como servidor de autentificaci\u00f3n para los distintos servicios de un sistema inform\u00e1tico como puedan ser: autentificaci\u00f3n para entrar en un PC, para entrar en una aplicaci\u00f3n web, para acceder a un servidor ftp, para acceder a servidores de correo entrante POP3 y saliente SMTP, etc...</p> <p></p> <p>Si en nuestra red disponemos de un servidor LDAP y configuramos todos los PCs y todos los servicios de la red para que se autentifiquen en \u00e9l, bastar\u00e1 con crear las cuentas de usuario y grupos de usuarios en nuestro servidor LDAP para que los usuarios puedan hacer uso del sistema y de sus servicios desde cualquier puesto de la red. Es un sistema ideal para centralizar la administraci\u00f3n de usuarios en un \u00fanico lugar.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P3LDAP/#instalacion-y-configuracion-de-openldap","title":"Instalaci\u00f3n y configuraci\u00f3n de OpenLDAP","text":"<p>Para simplificar la administraci\u00f3n de los usuarios del sistema es ideal utilizar una base de datos accesible mediante LDAP. Almacenar las cuentas de usuario de forma centralizada en un \u00fanico repositorio facilitar\u00e1 la creaci\u00f3n, modificaci\u00f3n y eliminaci\u00f3n de cuentas de usuario y grupos de usuarios. Ser\u00e1 necesario configurar los PCs de la red para que utilicen el servidor LDAP como servidor de autentificaci\u00f3n.</p> <p>El servidor OpenLDAP est\u00e1 disponible en el paquete slapd por tanto, lo instalaremos utilizando apt-get. Tambi\u00e9n nos conviene instalar el paquete ldap-utils que contiene utilidades adicionales:</p> <pre><code>sudo apt-get install slapd ldap-utils\n</code></pre> <p>Nos preguntar\u00e1 la password de administrador del servidor. Le pondremos \"ieselcaminas\"</p> <p></p> <p>Ahora comprobaremos si el servicio est\u00e1 en marcha con el comando habitual y recordando que el servicio se llama <code>slapd</code>.</p> <p>Vamos a ver qu\u00e9 informaci\u00f3n tiene ahora mismo la base de datos con el comando <code>slapcat</code></p> <pre><code>$sudo slapcat\ndn: dc=nodomain\nobjectClass: top\nobjectClass: dcObject\nobjectClass: organization\no: nodomain\ndc: nodomain\nstructuralObjectClass: organization\nentryUUID: 3d387392-2972-103e-985d-2d8a79039ae4\ncreatorsName: cn=admin,dc=nodomain\ncreateTimestamp: 20231207173146Z\nentryCSN: 20231207173146.118049Z#000000#000#000000\nmodifiersName: cn=admin,dc=nodomain\nmodifyTimestamp: 20231207173146Z\n</code></pre> <p>Como vemos solo est\u00e1 creado el nodo ra\u00edz y con dc=nodomain.</p> <p>Vamos a configurar nuestro directorio con el nodo ra\u00edz <code>dc=daw,dc=ieselcaminas</code> siguiendo estos pasos</p> <pre><code>sudo dpkg-reconfigure slapd\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Ejecutamos nuevamente slapcat para ver las modificaciones:</p> <pre><code>sudo slapcat\ndn: dc=daw,dc=ieselcaminas\nobjectClass: top\nobjectClass: dcObject\nobjectClass: organization\no: daw.ieselcaminas\ndc: daw\nstructuralObjectClass: organization\nentryUUID: 02508bf0-297e-103e-94fc-6953981852de\ncreatorsName: cn=admin,dc=daw,dc=ieselcaminas\ncreateTimestamp: 20231207185601Z\nentryCSN: 20231207185601.251149Z#000000#000#000000\nmodifiersName: cn=admin,dc=daw,dc=ieselcaminas\nmodifyTimestamp: 20231207185601Z\n</code></pre> <p>Ya tenemos nuestro directorio iniciado con el nodo ra\u00edz que quer\u00edamos. La configuraci\u00f3n de ldap con ficheros es compleja (puedes encontrar c\u00f3mo hacerlo en las referencias), as\u00ed que vamos a hacer uso de una herramienta web \"phpldapadmin\". La instalaremos con:</p> <pre><code>sudo apt-get install phpldapadmin\n</code></pre> <p>Y desde el navegador web de nuestro PC accederemos con la URL: \"http://IPSERVER/phpldapadmin\". Si todo va bien tendremos algo similar a esto:</p> <p></p> <p>Si pinchamos sobre login nos pedir\u00e1 los datos de acceso. Si recordamos la salida de slapd nuestro usuario no es el que nos ofrece, sino <code>cn=admin,dc=daw,dc=ieselcaminas</code>. Recuerda que la password que pusimos fue <code>ieselcaminas</code>.</p> <p></p> <p>Comprobamos como el login es correcto, pero el DIT o Directory Information Tree no es el correcto. El dn del nodo ra\u00edz en nuestro caso deber\u00eda ser dc=daw,dc=ieselcaminas, pero phpldapadmin, por defecto, intenta mostrar un DIT cuyo nodo principal es \"dc=example,dc=com\". </p> <p></p> <p>Vamos a solucionarlo editando el fichero de configuraci\u00f3n de phpldapadmin, <code>/etc/phpldapadmin/config.php</code>.</p> <pre><code>sudo nano /etc/phpldapadmin/config.php\n</code></pre> <p>Busca y sustituye las \u00fanicas 2 l\u00edneas donde aparece <code>dc=example,dc=com</code> y sustituyelo por <code>dc=daw,dc=ieselcaminas</code>. Lo encontrar\u00e1s en m\u00e1s l\u00edneas, pero f\u00edjate que en el resto la l\u00ednea est\u00e1 comentada. Las 2 l\u00edneas a sustituir son:</p> <pre><code>$servers-&gt;;setValue('server','base',array('dc=example,dc=com'));\n$servers-&gt;setValue('login','bind_id','cn=admin,dc=example,dc=com');\n</code></pre> <p>Que quedar\u00e1n as\u00ed:</p> <pre><code>$servers-&gt;setValue('server','base',array('dc=daw,dc=ieselcaminas'));\n$servers-&gt;setValue('login','bind_id','cn=admin,dc=daw,dc=ieselcaminas');\n</code></pre> <p>Si lees la descripci\u00f3n de esas l\u00edneas ver\u00e1s que tambi\u00e9n puedes borrarlas o comentarlas. En ese caso no te ofrecer\u00e1 valores por defecto al entrar y tendr\u00e1s que escribirlos tu.</p> <p>Refresca tu navegador y ahora ya deber\u00edas ver el DIT correcto.</p> <p></p> <p>Pincha sobre <code>dc=daw,dc=ieselcaminas</code>. La primera vez te saldr\u00e1n muchos mensajes, no te preocupes. Vuelve a pincharle.</p> <p>Vamos a crear 2 unidades organizativas, una para grupos y otra para usuarios. Seleccionamos \"Create a child entry\"</p> <p></p> <p></p> <p></p> <p>El siguiente paso no necesita captura de pantalla. Completalo y comprueba que la ou=grupos se ha creado correctamente.</p> <p>Crea tu mismo la ou=usuarios y comprueba ambas ou.</p> <p></p> <p>Ahora vamos a crear los grupos. Comprueba primero que el gid que vas asignar a tus grupos no existe en <code>/etc/group</code>. El 10000 puede ser una buena opci\u00f3n para profesores y el 10001 para alumnos.</p> <p>Para crear el grupo de profesores selecciona la ou=grupos y elige \"Create a child entry\". Selecciona \"Default\".</p> <p></p> <p>Ahora elige posixGroup.</p> <p></p> <p>Completa como en el ejemplo:</p> <p></p> <p>Completa el asistente y comprueba que se ha creado el grupo. Ahora crea un nuevo grupo para los alumnos con gid=10001 y comprueba que tienes ambos creados.</p> <p></p> <p>Ahora podemos pasar a crear los usuarios. Vamos primero a crear un \"profe01\" que pertenezca al grupo profesores.</p> <p>Selecciona la ou=usuarios. Pincha sobre \"Create a child entry\" y elige \"Default\" como antes. Ahora elige account y posixAccount (mat\u00e9n CTRL apretado para seleccionar ambos). </p> <p></p> <p></p> <p>Tras hacer clic sobre \"commit\" ya tendremos creado nuestro usuario.</p> <p>Crea un par de usuarios m\u00e1s. Por ejemplo un <code>alu01</code> y <code>alu02</code>.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P3LDAP/#recursos","title":"Recursos.","text":"<p>Sistemas Operativos en Red - Cap\u00edtulo 11. Instalar y configurar OpenLDAP</p> <p>Apache - Autenticaci\u00f3n LDAP en Active Directory </p> <p>Apache 2.2 autenticaci\u00f3n b\u00e1sica contra un LDAP </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/","title":"Pr\u00e1ctica 4 - Carga de datos en servidor LDAP mediante ficheros ldif","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#introduccion","title":"Introducci\u00f3n","text":"<p>Hasta ahora hemos creado usuarios y grupos de forma gr\u00e1fica. Vamos a ver c\u00f3mo podemos crearlos tambi\u00e9n en modo comando haciedo uso de archivos ldif. Esta forma ser\u00e1 mucho m\u00e1s r\u00e1pida cuando necesitemos crear gran cantidad de entradas.</p> <p>Para esta pr\u00e1ctica crearemos un nuevo servidor LDAP.</p> <p>Para empezar, entra en AWS Academy y crea un nuevo EC2 Debian con estas caracter\u00edsticas. </p> <ul> <li>Ll\u00e1male ServidorLDAP2.</li> <li>Dale los recursos que te ofrece por defecto.</li> <li>Puedes usar el grupo de seguridad de la pr\u00e1ctica anterior ServidorLDAP.</li> <li>Arranca la m\u00e1quina y actual\u00edzala para que cuente con las \u00faltimas versiones de todos los paquetes.</li> </ul> <p>Instala OpenLDAP igual que hicimos en la pr\u00e1ctica anterior y ejecuta el comando de reconfiguraci\u00f3n.</p> <pre><code>sudo dpkg-reconfigure slapd\n</code></pre> <p>En este caso usa <code>proyecto-empresa.local</code> para \"DNS Domanin Name\" y para \"Organization name\". Usa como password de administrador \"ieselcaminas\".</p> <p>Comprueba con slapcat que se ha creado la base de datos y podemos empezar a trabajar.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#creacion-de-objetos","title":"Creaci\u00f3n de objetos","text":"<p>Empezaremos creando 2 unidades organizativas \"ou\". Crea un archivo <code>estructura_basica.ldif</code> con el siguiente contenido:</p> <pre><code># Usuarios\ndn: ou=usuarios,dc=proyecto-empresa,dc=local\nobjectClass: organizationalUnit\nou: usuarios\n\n# Grupos\ndn: ou=grupos,dc=proyecto-empresa,dc=local\nobjectClass: organizationalUnit\nou: grupos\n</code></pre> <p>F\u00edjate en el contenido. Primero definimos en dn de cada unidad organizativa. Luego decimos el tipo de objectClass de que se trata y finalmente definimos el ou.</p> <p>Ahora vamos a incorporar esa informaci\u00f3n a la base de datos con el siguiente comando:</p> <pre><code>$ ldapadd -x -D cn=admin,dc=proyecto-empresa,dc=local -w ieselcaminas -f estructura_basica.ldif\nadding new entry \"ou=usuarios,dc=proyecto-empresa,dc=local\"\nadding new entry \"ou=grupos,dc=proyecto-empresa,dc=local\"`\n</code></pre> <p>Identifica los distintos par\u00e1metros del comando para saber lo que est\u00e1s haciendo.</p> <p>Podemos comprobar que se han a\u00f1adido despu\u00e9s de cada comando con <code>slapcat</code>. Tambi\u00e9n puedes instalar phpldapadmin e ir comprobando gr\u00e1ficamente lo que vas haciendo.</p> <p>Ya tenemos creadas nuestras 2 ou. Ahora vamos a crear los grupos dentro de la ou=grupos. Crea un fichero <code>grupos.ldif</code> con este contenido:</p> <pre><code>#Grupo profesores\ndn: cn=profesores,ou=grupos,dc=proyecto-empresa,dc=local\nobjectClass: posixGroup\ncn: profesores\ngidNumber: 10000\n\n#Grupo alumnos\ndn: cn=alumnos,ou=grupos,dc=proyecto-empresa,dc=local\nobjectClass: posixGroup\ncn: alumnos   \ngidNumber: 10001\n</code></pre> <p>Recuerda que antes de asignar el gid a los grupos hemos de comprobar en <code>/etc/group</code> que dicho uid no est\u00e1 ya asignado a alg\u00fan usuario local.</p> <p>Y los a\u00f1adimos mediante:</p> <pre><code>$ ldapadd -x -D cn=admin,dc=proyecto-empresa,dc=local -w ieselcaminas -f grupos.ldif\nadding new entry \"cn=profesores,ou=grupos,dc=proyecto-empresa,dc=local\"\n\nadding new entry \"cn=alumnos,ou=grupos,dc=proyecto-empresa,dc=local\"\n</code></pre> <p>Ahora crearemos los usuarios de los profesores. Crea el siguiente archivo y ll\u00e1male <code>profesores.ldif</code>.</p> <pre><code># Profe01\ndn: uid=profe01,ou=usuarios,dc=proyecto-empresa,dc=local\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nuid: profe01\ncn: profe01\nsn: DAW\nloginShell: /bin/bash\nuidNumber: 1001\ngidNumber: 10000\nhomeDirectory: /home/profe01\ngecos: Profe01 DAW\nuserPassword: 123456\n\n# Profe02\ndn: uid=profe02,ou=usuarios,dc=proyecto-empresa,dc=local\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nuid: profe02\ncn: profe02\nsn: DAW\nloginShell: /bin/bash\nuidNumber: 1002\ngidNumber: 10000\nhomeDirectory: /home/profe02\ngecos: Profe02 DAW\nuserPassword: 123456\n</code></pre> <p>Recuerda que antes de asignar el uid a los usuarios hemos de comprobar en <code>/etc/passwd</code> que dicho uid no est\u00e1 ya asignado a alg\u00fan usuario local.</p> <p>Los a\u00f1adiremos con:</p> <pre><code>$ ldapadd -x -D cn=admin,dc=proyecto-empresa,dc=local -w ieselcaminas -f profesores.ldif \nadding new entry \"uid=profe01,ou=usuarios,dc=proyecto-empresa,dc=local\"\n\nadding new entry \"uid=profe02,ou=usuarios,dc=proyecto-empresa,dc=local\"\n</code></pre> <p>Crea tu y a\u00f1ade ahora un par de alumnos. Ll\u00e1males alu01 y alu02. Dales uid a partir del 2001 y f\u00edjate que su gid debe ser el 10001.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#modificacion-de-objetos","title":"Modificaci\u00f3n de objetos","text":"<p>Tambi\u00e9n podemos modificar objetos ya creados con ficheros ldif. Vamos a cambiar la contrase\u00f1a de un usuario.</p> <p>Crea el fichero <code>cambiar_usuario.ldif</code> con el siguiente contenido.</p> <pre><code># Cambiar contrase\u00f1a Usuario\ndn: uid=alu01,ou=usuarios,dc=proyecto-empresa,dc=local\nchangetype: modify\nreplace: userPassword\nuserPassword: 654321\n</code></pre> <p>Y la cambiamos con:</p> <pre><code>$ ldapmodify -x -D cn=admin,dc=proyecto-empresa,dc=local -w ieselcaminas -f cambiar_usuario.ldif \nmodifying entry \"uid=alu01,ou=usuarios,dc=proyecto-empresa,dc=local\"\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#busqueda","title":"B\u00fasqueda","text":"<p>Tambi\u00e9n podemos hacer b\u00fasquedas en la base de datos de forma r\u00e1pida.</p> <p>Para buscar a todos los profesores:</p> <pre><code>ldapsearch -x -b dc=proyecto-empresa,dc=local \"(uid=*profe*)\"\n</code></pre> <p>O para buscar el profesor que tiene un uid concreto</p> <pre><code>$ ldapsearch -x -b dc=proyecto-empresa,dc=local \"(uidNumber=1002)\"\n</code></pre> <p>Para buscar profes con gid 10001 usar\u00edamos esta consulta. L\u00f3gicamente no encontrar\u00e1 ning\u00fan resultado.</p> <pre><code>$ ldapsearch -x -b dc=proyecto-empresa,dc=local \"(&amp;(uid=*profe*)(gidNumber=10001))\"\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#borrar-registros","title":"Borrar registros.","text":"<p>Podemos borrar registros con el comando <code>ldapdelete</code>.</p> <p>Borremos el usuario alu02</p> <pre><code>$ ldapdelete -x -D cn=admin,dc=proyecto-empresa,dc=local -w ieselcaminas uid=alu02,ou=usuarios,dc=proyecto-empresa,dc=local\n</code></pre> <p>Con esto ya hemos visto las acciones b\u00e1sicas que podemos hacer con comandos y ficheros ldif en un servidor OpenLDAP.</p> <p>Informaci\u00f3n</p> <p>Los comandos anteriores poseen la opci\u00f3n -h con la cual se puede indicar el host (nombre de dominio o IP) que identifica al servidor LDAP. Por ejemplo: ldapsearch -h 192.168.200.250 -x -b dc=proyecto-empresa,dc=local \"(objectclass=*)\" conectar\u00eda con el servidor LDAP en la IP 192.168.200.250 para buscar el DIT del dominio proyecto-empresa.local.</p> <p>Existe un paquete de nombre ldapscripts que contiene una serie de scripts para administrar de forma sencilla los usuarios y grupos almacenados en el servidor LDAP. Puedes encontrar plantillas de ejemplo, formato LDIF, situadas en /usr/share/doc/ldapscripts/examples/ cuando se instala el paquete ldapscripts.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P4LDAPFicheros/#referencias","title":"Referencias","text":"<p>Servicios de red implicados en el despliegue de una aplicaci\u00f3n web.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P5LDAPDockerizacion/","title":"Pr\u00e1ctica 5 - Dockerizaci\u00f3n de servidor LDAP","text":"<p>Para dockerizar la instalaci\u00f3n de OpenLDAP vamos a hacer uso de la imagen oficial de OpenLdap en Docker Hub, que se llama osixia/openldap </p> <p>Si vamos a la p\u00e1gina de ayuda, que est\u00e1 en GitHub, y buscamos la zona de \"Beninner Guide\" encontraremos este ejemplo:</p> <pre><code>docker run \\\n    --env LDAP_ORGANISATION=\"My Company\" \\\n    --env LDAP_DOMAIN=\"my-company.com\" \\\n    --env LDAP_ADMIN_PASSWORD=\"JonSn0w\" \\\n    --detach osixia/openldap:1.5.0\n</code></pre> <p>Lanza el contenedor y usa docker exec para comprobar si se ha creado correctamente la base de datos</p> <pre><code>$ docker exec NOMBRECONTENEDOR slapcat\ndn: dc=my-company,dc=com\nobjectClass: top\nobjectClass: dcObject\nobjectClass: organization\no: My Company\ndc: my-company\nstructuralObjectClass: organization\nentryUUID: 43981890-445c-103f-8edc-4796c2319b7e\ncreatorsName: cn=admin,dc=my-company,dc=com\ncreateTimestamp: 20241201181726Z\nentryCSN: 20241201181726.949230Z#000000#000#000000\nmodifiersName: cn=admin,dc=my-company,dc=com\nmodifyTimestamp: 20241201181726Z\n</code></pre> <p>Vemos, pues, que es muy r\u00e1pido y sencillo crear un contenedor LDAP. Borra el contenedor creado y crea uno nuevo, con la misma base de datos que creamos en la \"Pr\u00e1ctica 3 - Configuraci\u00f3n de un servidor LDAP\"</p> <pre><code>docker run \\\n    --name ldap-service \\\n    --env LDAP_ORGANISATION=\"daw.ieselcaminas\" \\\n    --env LDAP_DOMAIN=\"daw.ieselcaminas\" \\\n    --env LDAP_ADMIN_PASSWORD=\"ieselcaminas\" \\\n    --detach osixia/openldap\n</code></pre> <p>Y prueba si se ha creado la base de datos openldap correctamente</p> <pre><code>$ docker exec ldap-service slapcat\ndn: dc=daw,dc=ieselcaminas\nobjectClass: top\nobjectClass: dcObject\nobjectClass: organization\no: daw.ieselcaminas\ndc: daw\nstructuralObjectClass: organization\nentryUUID: 26a0e0d8-445b-103f-9969-692c79a37c92\ncreatorsName: cn=admin,dc=daw,dc=ieselcaminas\ncreateTimestamp: 20241201180928Z\nentryCSN: 20241201180928.856139Z#000000#000#000000\nmodifiersName: cn=admin,dc=daw,dc=ieselcaminas\nmodifyTimestamp: 20241201180928Z\n</code></pre> <p>Ahora ya podr\u00edamos rellenar la base de datos mediante ficheros ldif como vimos en la pr\u00e1ctica anterior. Pero si preferimos usar el interfaz gr\u00e1fico de phpldapadmin tenemos otro contenedor oficial a nuestra disposici\u00f3n https://hub.docker.com/r/osixia/phpldapadmin.</p> <p>Para seguir la pr\u00e1ctica borra el contenedor ldap-service porque lo volveremos a crear ligeramente modificado.</p> <p>Como el contenedor que contendr\u00e1 la base de datos de openldap y el que contendr\u00e1 phpldapadmin deben interactuar, podr\u00edamos hacer uso de la opci\u00f3n <code>--link</code> que hemos usado en otras ocasiones y que nos propone la ayuda del contenedor. Pero esa opci\u00f3n ya est\u00e1 obsoleta y es mejor usar redes docker. Es una buena excusa para introducirlas. Una red docker es una red virtual que pueden usar los contenedores para comunicarse entre ellos. Crearemos una red que llamaremos <code>ldap-netword</code> y que usar\u00e1n ambos contenedores. Adem\u00e1s, le daremos un <code>hostname</code> dentro de la red a cada uno para que puedan referirse uno al otro.</p> <pre><code>docker network create ldap-network\n\ndocker run \\\n    --net ldap-network \\\n    --hostname ldap-service \\\n    --name ldap-service \\\n    --env LDAP_ORGANISATION=\"daw.ieselcaminas\" \\\n    --env LDAP_DOMAIN=\"daw.ieselcaminas\" \\\n    --env LDAP_ADMIN_PASSWORD=\"ieselcaminas\" \\\n    --detach osixia/openldap\n\ndocker run \\\n    --net ldap-network \\\n    --name phpldapadmin-service \\\n    --publish 443:443 \\\n    --hostname phpldapadmin-service \\\n    --env PHPLDAPADMIN_LDAP_HOSTS=ldap-service \\\n    --detach osixia/phpldapadmin\n</code></pre> <p>El primer comando crear\u00e1 la red que usar\u00e1n ambos. Con <code>--net</code> les diremos que usen dicha red. Y con <code>--hostname</code> les asignaremos un nombre de red.</p> <p>Al crear el contenedor de <code>phpldapadmin-service</code> usaremos <code>--env PHPLDAPADMIN_LDAP_HOSTS=ldap-service</code> para decirle a phpldapadmin cu\u00e1l es el host que contiene el servidor ldap al que debe acceder.</p> <p>Si todo va bien podremos acceder a phpldapadmin desde el navegador con <code>https://IPSERVIDOR</code></p> <p>Tarea</p> <p>Hemos lanzado los 2 servicios usando comandos docker run. \u00bfPodr\u00edas crear ambos contenedores usando docker-compose para levantar todo el servicio en un solo comando?</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P6AutenticacionApacheLDAP/","title":"Pr\u00e1ctica 6 - Autenticaci\u00f3n Apache contra LDAP","text":"<p>Nota</p> <p>Para esta pr\u00e1ctica partiremos de la \"Pr\u00e1ctica 2 - Configuraci\u00f3n de un servidor LDAP y autenticaci\u00f3n en Apache\". Aseg\u00farate de tenerla funcionando antes de empezar.</p> <p>Arranca la m\u00e1quina que llamamos ServidorLDAP.</p> <p>Ya hemos instalado nuestro servidor OpenLDAP y hemos aprendido a crear usuarios. La utilidad real de esos usuarios ser\u00e1 usarlos para validarse al acceder a alg\u00fan sistema. Uno de los usos m\u00e1s habituales es para acceder al sistema operativo en distintos ordenadores. Pero como nosotros estamos en despliegue de aplicaciones web vamos a usarlo para acceder a una zona de un servidor web Apache. El motivo de usar Apache es que ya se instal\u00f3 al instalar phpldapadmin y que la autenticaci\u00f3n es muy sencilla de configurar.</p> <p>En primer lugar comprobaremos que el servicio <code>apache2</code> est\u00e1 funcionando.</p> <p>Habilita el m\u00f3dulo de autenticaci\u00f3n LDAP Apache2.</p> <pre><code>sudo a2enmod authnz_ldap\n</code></pre> <p>Vamos a solicitar la autenticaci\u00f3n a los usuarios que intentan acceder a un directorio denominado <code>test</code>.</p> <p>Crea un directorio denominado <code>test</code> y crea dentro un archivo index.html. Cambia el usuario y grupo del directorio <code>test</code> y su contenido a www-data.</p> <pre><code>sudo mkdir /var/www/html/test\nsudo nano /var/www/html/test/index.html\nsudo chown -R www-data:www-data /var/www/html/test \n</code></pre> <p>El fichero index.html podemos usar el siguiente:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Sitio LDAP!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Bienvendido al sitio validado por LDAP!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Ahora vamos a editar el archivo de configuraci\u00f3n Apache 000-default.conf. Antes haremos una copia de seguridad del mismo.</p> <p><pre><code>sudo cp /etc/apache2/sites-enabled/000-default.conf /etc/apache2/sites-enabled/000-default.conf.backup\nsudo nano /etc/apache2/sites-enabled/000-default.conf\n</code></pre> Inclu\u00edmos las l\u00edneas resaltadas:</p> <pre><code>&lt;VirtualHost *:80&gt;\n        ServerAdmin webmaster@localhost\n        DocumentRoot /var/www/html\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n        &lt;Directory \"/var/www/html/test\"&gt; \n        AuthType Basic\n        AuthName \"Apache LDAP authentication\"\n        AuthBasicProvider ldap \n        AuthLDAPURL \"ldap://127.0.0.1/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\" \n        AuthLDAPBindDN \"cn=admin,dc=daw,dc=ieselcaminas\"\n        AuthLDAPBindPassword ieselcaminas\n        Require valid-user\n        &lt;/Directory&gt;\n\n&lt;/VirtualHost&gt;\n</code></pre> <p>Veamos las distintas directivas para qu\u00e9 sirven:</p> <ul> <li>\"&lt;\"Directory \"/var/www/html/test\"&gt;\" : Directorio al que vamos a aplicar la autenticaci\u00f3n</li> <li>AuthType Basic : Define el m\u00e9todo de autenticaci\u00f3n: B\u00e1sica (Basic). Necesario para la autenticaci\u00f3n basada en LDAP</li> <li>AuthName \"Apache LDAP authentication\" : Especifica el texto que se mostrar\u00e1 en el cuadro de di\u00e1logo de autenticaci\u00f3n del navegador (aunque en mis pruebas no lo muestra)</li> <li>AuthBasicProvider ldap : Indica que el proveedor de autenticaci\u00f3n ser\u00e1 LDAP</li> <li>AuthLDAPURL \"ldap://127.0.0.1/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\" : Especifica c\u00f3mo Apache se conecta al servidor LDAP. Lo veremos en detalle a continuaci\u00f3n</li> <li>AuthLDAPBindDN \"cn=admin,dc=daw,dc=ieselcaminas\" : Especifica el DN del usuario que se autenticar\u00e1 en el servidor LDAP para buscar las entradas. Si en la configuraci\u00f3n del tu servidor LDAP se permiten b\u00fasquedas an\u00f3nimas no har\u00eda falta esta directiva</li> <li>AuthLDAPBindPassword ieselcaminas : Contrase\u00f1a asociada al AuthLDAPBindDN. Si en la configuraci\u00f3n del tu servidor LDAP se permiten b\u00fasquedas an\u00f3nimas no har\u00eda falta esta directiva</li> <li>Require valid-user : Permite el acceso solo a usuarios que proporcionen credenciales v\u00e1lidas (en este caso, autenticadas por LDAP).</li> </ul> <p>Las directivas AuthLDAPURL, AuthLDAPBindDN y AuthLDAPBindPassword son las que tendr\u00e9is que cambiar seg\u00fan la situaci\u00f3n. La sintaxis de AuthLDAPURL es la siguiente:</p> <p><pre><code>AuthLDAPURL ldap://host:port/basedn?attribute?scope?filter [NONE|SSL|TLS|STARTTLS]\n</code></pre> Si desmenuzamos la sintaxis:</p> <ul> <li> <p>host y port son evidentes</p> </li> <li> <p>basedn es la ruta en el DIT (recuerda, el \u00e1rbol) a partir de donde buscar los usuarios</p> </li> <li> <p>attribute, define el nombre atributo que contiene el nombre del usuario (normalmente uid)</p> </li> <li> <p>scope, puede ser one (para buscar en un subnivel a partir del basedn) o sub (para buscar en todos los subniveles)</p> </li> <li> <p>filter, filtro opcional de b\u00fasqueda, por ejemplo: (&amp;(objectClass=inetOrgPerson)(description=#test*))</p> </li> <li> <p>[NONE|SSL|TLS|STARTTLS], par\u00e1metro opcional definiendo el tipo de conexi\u00f3n, por defecto NONE.</p> </li> </ul> <p>Recuerda reiniciar <code>apache2</code> para que se apliquen los cambios.</p> <p>Ahora ya solo nos queda probar el funcionamiento. Abre una ventana privada de navegador en tu ordenador. Deber\u00e1s abrir una ventana privada para cada prueba.</p> <p>Accede a <code>http://IPSERVER/test</code>.</p> <p>Te deber\u00eda pedir un usuario y contrase\u00f1a. Prueba con <code>profe01</code> y la contrase\u00f1a que le pusiste antes. Luego abre una ventana privada y prueba con una contrase\u00f1a incorrecta.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P6AutenticacionApacheLDAP/#preparando-la-dockerizacion","title":"Preparando la dockerizaci\u00f3n","text":"<p>A la hora de levantar un servicio en docker sabemos que es m\u00e1s f\u00e1cil copiar archivos al interior del contenedor que modificar ficheros de cofiguraci\u00f3n que est\u00e1n dentro del mismo. </p> <p>Pensemos tambi\u00e9n que el fichero de configuraci\u00f3n del sitio lo tiene que actualizar el administrador, mientras que los ficheros del sitio los pueden modificar los propietarios del sitio, sin permisos de administrador. Por eso apache nos permite configurar algunas cosas mediante la inclusi\u00f3n de un fichero <code>.htaccess</code>, en este caso en <code>/var/www/html/test/</code>.</p> <p>Para ello el administrador solo deber\u00eda hacer lo siguiente. Recuperaremos el fichero de configuraci\u00f3n original:</p> <pre><code>sudo cp /etc/apache2/sites-enabled/000-default.conf.backup /etc/apache2/sites-enabled/000-default.conf\n</code></pre> <p>Dejaremos el bloque \"Directory\" as\u00ed:</p> <pre><code>    &lt;Directory \"/var/www/html/test\"&gt;\n            AllowOverride All\n    &lt;/Directory&gt;\n</code></pre> <p>Esto le indica a Apache que permita sobrecargar las configuraciones a trav\u00e9s de archivos <code>.htaccess</code> dentro de ese directorio. Aqu\u00ed acaba la tarea del administrador.</p> <p>Ahora el editor del sitio web creas un archivo <code>.htaccess</code> dentro de <code>/var/www/html/test</code> con este contenido:</p> <pre><code>    AuthType Basic\n    AuthName \"Apache LDAP authentication\"\n    AuthBasicProvider ldap\n    AuthLDAPURL \"ldap://127.0.0.1/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\"\n    AuthLDAPBindDN \"cn=admin,dc=daw,dc=ieselcaminas\"\n    AuthLDAPBindPassword ieselcaminas\n    Require valid-user\n</code></pre> <p>F\u00edjate que s\u00f3lo estamos trasladando las directivas que antes estaban en <code>/etc/apache2/sites-enabled/000-default.conf</code> a <code>.htaccess</code>. </p> <p>Ojo con los permisos de <code>.htaccess</code>. Se encuentra en un directorio con el resto de archivos html del sitio web y contiene usuario y password de acceso al servidor LDAP, que es informaci\u00f3n sensible. Por eso es mejor sacar la autenticaci\u00f3n Bind (es decir, el usuario y contrase\u00f1a de LDAP) del fichero .htaccess. Para ello sacamos las directivas AuthLDAPBindDN ni AuthLDAPBindPassword y las configuramos en <code>/etc/ldap/ldap.conf</code> (en sistemas basados en Debian/Ubuntu). Este fichero sirve para centralizar toda la configuraci\u00f3n de LDAP.</p> <p>Por tanto creamos <code>/etc/ldap/ldap.conf</code> con este contenido:</p> <pre><code>    # Opciones de conexi\u00f3n\n    BINDDN cn=admin,dc=daw,dc=ieselcaminas\n    BINDPW ieselcaminas\n</code></pre> <p>Y dejamos <code>/var/www/html/test/.htaccess</code> as\u00ed:</p> <pre><code>    AuthType Basic\n    AuthName \"Apache LDAP authentication\"\n    AuthBasicProvider ldap\n    AuthLDAPURL \"ldap://127.0.0.1/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\"\n    Require valid-user\n</code></pre> <p>Reinicia apache e intenta acceder nuevamente a la web. Comprueba nuevamente el correcto funcionamiento.</p> <p>Nota</p> <pre><code>Sacar la configuraci\u00f3n a los archivos `.htaccess` y `ldap.conf` es una alternativa que puede ser \u00fatil en ocasiones. No es mejor ni peor. Solo debemos conocerla y usar una u otra forma seg\u00fan las necesidades de cada caso.\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P7AutApacheLDAPDocker/","title":"Pr\u00e1ctica 7 - Autenticaci\u00f3n Apache contra LDAP dockerizada","text":"<p>Ya hemos aprendido a dockerizar OpenLDAP y tambi\u00e9n hemos aprendico a autenticar un Apache2 contra un servidor openLDAP. Ahora nos queda juntar ambas cosas.</p> <p>Atenci\u00f3n</p> <p>Antes de seguir hemos de asegurarnos que hemos hecho y tenemos corriendo el servidor OpenLDAP de la \"Pr\u00e1ctica 5 - Dockerizaci\u00f3n de servidor LDAP\". Adem\u00e1s, debemos haber creado en ese servidor OpenLDAP dockerizado los mismos usuarios que creamos en la pr\u00e1ctica \"Pr\u00e1ctica 3 - Configuraci\u00f3n de un servidor LDAP\" (al menos profe01)</p> <p>La imagen oficial de apache2 en Docker Hub (httpd), no tiene instalado el m\u00f3dulo ldap, as\u00ed que usaremos una imagen docker que si lo tiene instalado y es f\u00e1cil de activar.</p> <p>Vamos a reproducir en docker exactamente lo mismo que hicimos en la \"Pr\u00e1ctica 6 - Autenticaci\u00f3n Apache contra LDAP\"</p> <p>Empezaremos creando un fichero Dockerfile como este, que deber\u00e1s completar:</p> <pre><code>____ php:7-apache\n\n# Activamos el m\u00f3dulo LDAP de Apache ejecutando el siguiente comando\n____ a2enmod authnz_ldap\n\n# Creamos el directorio test como en la pr\u00e1ctica anterior\n____ mkdir -p /var/www/html/test\n\n# Copiamos los ficheros como los de la pr\u00e1ctica anterior\n____ index.html /var/www/html/test/index.html\n\n____ 000-default.conf /etc/apache2/sites-enabled/000-default.conf\n</code></pre> <p>El fichero index.html podemos usar el siguiente:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Sitio LDAP!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Bienvendido al sitio validado por LDAP!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Y el fichero 000-default.conf usaremos uno como este:</p> <pre><code>&lt;VirtualHost *:80&gt;\n        ServerAdmin webmaster@localhost\n        DocumentRoot /var/www/html\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n        &lt;Directory \"/var/www/html/test\"&gt; \n        AuthType Basic\n        AuthName \"Apache LDAP authentication\"\n        AuthBasicProvider ldap \n        AuthLDAPURL \"ldap://ldap-service/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\" \n        AuthLDAPBindDN \"cn=admin,dc=daw,dc=ieselcaminas\"\n        AuthLDAPBindPassword ieselcaminas\n        Require valid-user\n        &lt;/Directory&gt;\n\n&lt;/VirtualHost&gt;\n</code></pre> <p>F\u00edjate que es igual que el de la pr\u00e1ctica anterior salvo que hemos modificado la l\u00ednea <code>AuthLDAPURL \"ldap://ldap-service/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\"</code>. En la anterior usamos <code>AuthLDAPURL \"ldap://127.0.0.1/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub\"</code> porque el servidor ldap estaba en el mismo equipo. Ahora est\u00e1 en otro contenedor y nos referiremos a \u00e9l por su \"hostname\" que definimos en docker.</p> <p>Cuando ya lo tengamos todo podemos crear nuestra imagen particularizada. Ll\u00e1male my-apache2-</p> <p>Despu\u00e9s lanzamos el contenedor con:</p> <pre><code>docker run \\\n    --net ldap-network \\\n    --name apache2_server \\\n    -d \\\n    -p80:80 \\\n    my-apache2\n</code></pre> <p>F\u00edjate que usamos la misma red docker que usamos para el contenedor ldap en la pr\u00e1ctica anterior y que eso les permite comunicarse.</p> <p>Ahora accede desde un navegador a <code>http://IPSERVER/test</code> te deber\u00eda solicitar la autenticaci\u00f3n por ldap y al usar \"profe01\" nos deber\u00eda permitir el acceso.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P7AutApacheLDAPDocker/#pasando-informacion-al-contenedor-mediante-variables-de-entorno","title":"Pasando informaci\u00f3n al contenedor mediante variables de entorno","text":"<p>Si te fijas hemos incluido los datos del usuario ldap dentro del propio Dockerfile y al crear la imagen, estos quedan dentro de la misma. \u00bfY si quisi\u00e9ramos crear una imagen que nos permitiera autenticar contra cualquier servidor ldap pasando los datos del servidor en el \"docker run\" mediante variables de entorno?</p> <p>Vamos a borrar el contenedor \"apache2_server\" y la imagen \"my-apache2\". Modifiquemos el fichero <code>000-default.conf</code> as\u00ed:</p> <pre><code>PassEnv LDAP_BIND_ON\nPassEnv LDAP_PASSWORD\nPassEnv LDAP_URL\n&lt;VirtualHost *:80&gt;\n        ServerAdmin webmaster@localhost\n        DocumentRoot /var/www/html\n        ErrorLog ${APACHE_LOG_DIR}/error.log\n        CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n        &lt;Directory \"/var/www/html/test\"&gt;\n        AuthType Basic\n        AuthName \"Apache LDAP authentication\"\n        AuthBasicProvider ldap\n        AuthLDAPBindDN ${LDAP_BIND_ON}\n        AuthLDAPBindPassword ${LDAP_PASSWORD}\n        AuthLDAPURL ${LDAP_URL}\n        Require valid-user\n        &lt;/Directory&gt;\n\n&lt;/VirtualHost&gt;\n</code></pre> <p>En las primeras filas ahora definimos 3 variables, que ser\u00e1n las que recibir\u00e1 como variables de entorno en el \"docker run\" y m\u00e1s abajo incluimos con ${} donde se incluir\u00e1 el valor de dichas variables que recibamos del \"docker run\". Volvemos a crear la imagen y ahora lanzamos el contenedor as\u00ed:</p> <pre><code>docker build -t my-apache2 .\n\ndocker run -d \\\n    --name apache2_server \\\n    --net ldap-network \\\n    -d \\\n    -p80:80 \\\n    -e LDAP_BIND_ON='cn=admin,dc=daw,dc=ieselcaminas' \\\n    -e LDAP_PASSWORD='ieselcaminas' \\\n    -e LDAP_URL='ldap://ldap-service/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub' \\\n    my-apache2\n</code></pre> <p>Comprueba como sigues pudiendo acceder a http://IPSERVER/test autenticando con profe01.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P8AutenticandoNginxLDAP/","title":"Pr\u00e1ctica 8 - Autenticaci\u00f3n Nginx contra LDAP","text":"<p>En esta pr\u00e1ctica vamos a autenticar el acceso en Nginx usando un servidor LDAP.</p> <p>Partiremos de que tenemos configurado y ejecut\u00e1ndose el servidor LDAP que configuramos en la 'Pr\u00e1ctica 2 - Configuraci\u00f3n de un servidor LDAP y autenticaci\u00f3n en Apache'. Obt\u00e9n la IP p\u00fablica de dicho servidor que nos har\u00e1 falta para la configuraci\u00f3n</p> <p>Tambi\u00e9n necesitaremos un servidor Nginx instalado en otra EC2. Puedes usar la m\u00e1quina \"servidorNginx\" de la unidad de Servidores WEb o crear una nueva EC2 en AWS para instalar un servidor Nginx nuevo.</p> <p>Crearemos un sitio virtual \"sitioldap\" junto a los anteriores:</p> <pre><code>sudo mkdir -p /var/www/sitioldap\nsudo nano /var/www/sitioldap/index.html\n</code></pre> <p>Incluye lo siguient en index.html</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Sitio LDAP!&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Bienvendido al sitio validado por LDAP!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Ahora crea el sitio virtual</p> <pre><code>sudo nano /etc/nginx/sites-available/sitioldap\n</code></pre> <p>Contenido del archivo, de momento sin autenticaci\u00f3n:</p> <pre><code>server {\n    listen 80;\n    server_name sitioldap;\n    root /var/www/sitioldap;\n    index index.html;\n\n    location / {\n         try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Activamos el sitio virtual</p> <pre><code>sudo ln -s /etc/nginx/sites-available/sitioldap /etc/nginx/sites-enabled/\n</code></pre> <p>Verificamos la configuraci\u00f3n de nginx</p> <pre><code>sudo nginx -t\n</code></pre> <p>Reiniciamos el servicio</p> <pre><code>sudo systemctl restart nginx\n</code></pre> <p>Y accedemos a <code>http://sitioldap</code>. Recuerda que habr\u00e1s de modificar el fichero <code>/etc/hosts</code> para poder acceder. Comprueba que tienes acceso a la web sin aplicar la configuraci\u00f3n de LDAP antes de continuar.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P8AutenticandoNginxLDAP/#carga-del-modulo-de-autenticacion-ldap","title":"Carga del m\u00f3dulo de autenticaci\u00f3n LDAP.","text":"<p>Hay diversas formas de autenticar LDAP en NGINX. Si est\u00e1s utilizando una distribuci\u00f3n de Nginx que incluye soporte para m\u00f3dulos din\u00e1micos, verifica si tienes el m\u00f3dulo ngx_http_auth_ldap_module. Puedes comprobar si est\u00e1 el m\u00f3dulo en <code>/etc/nginx/modules-available</code>.</p> <p>Si no est\u00e1, como es el caso de nuestra Debian, tendremos que instalarlo. Este m\u00f3dulo est\u00e1 disponible en Github para descargarlo y compilarlo aqu\u00ed. Para simplificarte esta tarea puedes descargar el .deb ya compilado aqu\u00ed.</p> <p>Puedes instalarlo con</p> <pre><code>sudo dpkg -i libnginx-mod-http-auth-ldap_1.0.0-1_amd64.deb\n</code></pre> <p>Una vez instalado ver\u00e1s el m\u00f3dulo disponible en <code>/etc/nginx/modules-enabled</code>.</p> <pre><code>$ ls -la /etc/nginx/modules-enabled/\nlrwxrwxrwx 1 root root   58 Nov 27 19:01 50-mod-http-auth-ldap.conf -&gt; /usr/share/nginx/modules-available/mod-http-auth-ldap.conf\n</code></pre> <p>Ahora ya podemos proceder a activar la autenticaci\u00f3n. Primero a\u00f1ade un bloque ldap_server en la secci\u00f3n http de tu configuraci\u00f3n de Nginx. Este define c\u00f3mo se conecta Nginx al servidor LDAP para autenticar usuarios. En <code>/etc/nginx/nginx.conf</code> :</p> <pre><code>http {\n    ldap_server mi_servidor_ldap {\n        url ldap://IPSERVIDOR/ou=usuarios,dc=daw,dc=ieselcaminas?uid?sub;\n        binddn \"cn=admin,dc=daw,dc=ieselcaminas\";\n        binddn_passwd \"ieselcaminas\";\n        group_attribute member;\n        group_attribute_is_dn on;\n\n        require valid_user;\n    }\n\n    include /etc/nginx/sites-enabled/*;\n}\n</code></pre> <p>Cambia IPSERVIDOR por la IP externa de la m\u00e1quina virtual con el servidor LDAP.</p> <p>F\u00edjate que el bloque <code>ldap-server</code> ha de estar antes de la directiva <code>include /etc/nginx/sites-enabled/*</code> para que el servidor est\u00e9 configurado antes de hacer uso de \u00e9l en la configuraci\u00f3n del sitio virtual. Vamos a ella. Modifica <code>/etc/nginx/sites-available/sitioldap</code> as\u00ed:</p> <pre><code>server {\n    listen 80;\n    server_name sitioldap;\n    root /var/www/sitioldap;\n    index index.html;\n\n    # Configuraci\u00f3n LDAP\n    location / {\n        try_files $uri $uri/ =404;\n        auth_ldap \"Protected Area\";\n        auth_ldap_servers mi_servidor_ldap;\n    }\n}\n</code></pre> <p>Antes de nada prueba que las configuraciones son correctas con:</p> <pre><code>sudo nginx -t\n</code></pre> <p>Si no hay errores puedes recargar el servidor Nginx y acceder a <code>http://sitioldap</code> y comprobar si la autenticaci\u00f3n LDAP funciona. Recuerda que creamos varios usuarios como \"profe01/profe01\" para probar.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/P8AutenticandoNginxLDAP/#modulos-en-nginx","title":"M\u00f3dulos en NGINX","text":"<p>En esta pr\u00e1ctica hemos necesitado instalar un m\u00f3dulo adicional en NGINX.</p> <p>En esta p\u00e1gina puedes encontrar multitud de m\u00f3dulos para instalar. La mayor\u00eda de ellos se encuentran en git y deben ser descargados y compilados.</p> <p>Ya sabes usar git para clonar un repositorio remoto, as\u00ed que esa parte no deber\u00eda suponerte ning\u00fan problema. Para compilarlos sigue las instrucciones incluidas en cada uno de ellos.</p> <p>En el caso del m\u00f3dulo que hemos tenido que usar en esta pr\u00e1ctica, <code>nginx-auth-ldap</code>, puedes acceder en https://github.com/jessp01/nginx-auth-ldap.</p> <p>Este m\u00f3dulo ofrece la opci\u00f3n de compilarlo dentro del propio binario de nginx o, en el caso de Debian/Ubuntu, crear un paquete .deb y despu\u00e9s instalarlo. Nosotros hemos usado la segunda opci\u00f3n. Siguiendo las instrucciones del m\u00f3dulo lo hemos descargado con un <code>git clone</code>, hemos entrado en la carpeta que se ha creado y hemos ejecutado los comandos que nos indica:</p> <pre><code>sudo apt install build-essential dpkg-dev libssl-dev libldap2-dev\ncd /path/to/nginx-auth-ldap/source\ndpkg-buildpackage -b -uc\nsudo dpkg -i ../libnginx-mod-http-auth-ldap_1.0.0-1_amd64.deb\n</code></pre> <p>En nuestro debian, al ejecutar <code>dpkg-buildpackage -b -uc</code> obtenemos un error, debido a un problema de dependencias. Hemos de actualizar el sistema y verificar que tenemos los repositorios contrib y non-free habilitados en tu archivo /etc/apt/sources.list.</p> <pre><code>sudo apt update\n</code></pre> <p>Instala las herramientas de desarrollo y las dependencias faltantes:</p> <pre><code>sudo apt install -y build-essential debhelper dh-sequence-nginx\n</code></pre> <p>Despu\u00e9s de esto ya puedes continuar con el paso que daba error.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/","title":"Pr\u00e1ctica Voluntaria 1 - Despliegue de servidores web con usuarios autenticados mediante LDAP usando Docker y docker-compose","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#introduccion","title":"Introducci\u00f3n","text":"<p>Esta pr\u00e1ctica la dejamos como pr\u00e1ctica voluntaria. La principal novedad es que realiza la autenticaci\u00f3n en NGINX de forma distinta a c\u00f3mo la hemos hecho nosotros en la pr\u00e1ctica 8. Puede servir a quien le interese para aprender otra forma de trabajar en nginx.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#que-es-un-servicio-de-directorio-ldap","title":"\u00bfQu\u00e9 es un servicio de directorio LDAP?","text":"<p>LDAP (Lightweight Directory Access Protocol) o tambi\u00e9n conocido como \u00abProtocolo Ligero de Acceso a Directorios\u00bb es un protocolo de la capa de aplicaci\u00f3n TCP/IP que permite el acceso a un servicio de directorio ordenado y distribuido, para buscar cualquier informaci\u00f3n en un entorno de red.</p> <p>Aclaraci\u00f3n</p> <p>Un directorio es un conjunto de objetos con atributos que est\u00e1n organizados de manera l\u00f3gica y jer\u00e1rquica, es decir, est\u00e1 en forma de \u00e1rbol y perfectamente ordenado en funci\u00f3n de lo que nosotros queramos, ya sea alfab\u00e9ticamente, por usuarios, direcciones etc.</p> <p>Generalmente un servidor LDAP se encarga de almacenar informaci\u00f3n de autenticaci\u00f3n, es decir, el usuario y la contrase\u00f1a, para posteriormente dar acceso a otro protocolo o servicio del sistema. Adem\u00e1s de almacenar el nombre de usuario y la contrase\u00f1a, tambi\u00e9n puede almacenar otra informaci\u00f3n como datos de contacto del usuario, ubicaci\u00f3n de los recursos de la red local, certificados digitales de los propios usuarios y mucho m\u00e1s.</p> <p>LDAP es un protocolo que nos permite acceder a los recursos de la red local, sin necesidad de crear los diferentes usuarios en el sistema operativo, adem\u00e1s, es mucho m\u00e1s vers\u00e1til. Por ejemplo, LDAP permite realizar tareas de autenticaci\u00f3n y autorizaci\u00f3n a usuarios de diferentes softwares como Docker, OpenVPN, servidores de archivos como los usados por QNAP, Synology o ASUSTOR entre otros, y muchos m\u00e1s usos.</p> <p></p> <p>LDAP puede ser utilizado tanto por un usuario al que se pide unos  credenciales de acceso, como tambi\u00e9n por las aplicaciones para saber si tienen acceso a determinada informaci\u00f3n del sistema o no. Generalmente un servidor LDAP se encuentra en una red privada, es decir, redes de \u00e1rea local, para autenticar las diferentes aplicaciones y usuarios, pero tambi\u00e9n podr\u00eda funcionar sobre redes p\u00fablicas sin ning\u00fan problema.</p> <p>Info</p> <p>En definitiva, LDAP nos proporciona un serivicio de autenticaci\u00f3n y autorizaci\u00f3n para poder acceder a distintos recursos en red, como por ejemplo, a un sitio web. Si recordamos la pr\u00e1ctica de autenticaci\u00f3n en un servidor web, nuestro usuario se autenticaba utilizando usuarios creados en el mismo sistema operativo (Debian Linux) donde se hab\u00eda instalado el servidor web.</p> <p>Tenemos, por tanto, la posibilidad de utilizar otra autenticaci\u00f3n centralizada para el mismo cometido con LDAP.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#implementaciones-de-ldap","title":"Implementaciones de LDAP","text":"<p>Microsoft Active Directory utiliza internamente el protocolo LDAP para realizar todas las comunicaciones desde los clientes hasta el servidor o servidores, por lo tanto, se encarga de que los clientes puedan autenticarse y acceder a cualquier dato almacenado, adem\u00e1s, debemos tener en cuenta que este protocolo es multiplataforma, no solamente lo tenemos en sistemas operativos Windows sino que tambi\u00e9n es compatible con Linux, Unix y macOS, todo ello a trav\u00e9s del protocolo. Para que os hag\u00e1is una idea, los siguientes servicios de directorio usan este protocolo para su comunicaci\u00f3n:</p> <ul> <li>Active Directory de Microsoft</li> <li>Apache</li> <li>Servicio de directorio de Red Hat</li> <li>OpenLDAP</li> </ul> <p>Y muchos otros servicios tambi\u00e9n lo usan, sobre todo el \u00faltimo, OpenLDAP, el cual es una implementaci\u00f3n de c\u00f3digo abierto del protocolo y que se puede instalar en cualquier sistema, ya que est\u00e1 disponible el c\u00f3digo fuente para compilarlo. No obstante, en la mayor\u00eda de distribuciones de Linux lo tenemos disponible en sus repositorios.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#como-se-organiza-la-informacion-en-ldap","title":"\u00bfC\u00f3mo se organiza la informaci\u00f3n en LDAP?","text":"<p>En LDAP, las entradas est\u00e1n organizadas en una estructura jer\u00e1rquica en \u00e1rbol. Tradicionalmente, esta estructura reflejaba los l\u00edmites geogr\u00e1ficos y organizacionales.</p> <p>Las entradas que representan pa\u00edses aparecen en la parte superior del \u00e1rbol. Debajo de ellos, est\u00e1n las entradas que representan los estados y las organizaciones nacionales. Debajo de est\u00e1s, pueden estar las entradas que representan las unidades organizacionales, empleados, impresoras, documentos o todo aquello que pueda imaginarse. La siguiente figura muestra un ejemplo de un \u00e1rbol de directorio LDAP haciendo uso del nombramiento tradicional.</p> <p></p> <p>El \u00e1rbol tambi\u00e9n se puede organizar bas\u00e1ndose en los nombres de dominio de Internet. Este tipo de nombramiento es muy popular, ya que permite localizar un servicio de directorio haciendo uso de los DNS. La siguiente figura muestra un ejemplo de un directorio LDAP que hace uso de los nombres basados en dominios.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#como-se-referencia-la-informacion","title":"\u00bfC\u00f3mo se referencia la informaci\u00f3n?","text":"<p>Una entrada es referenciada por su nombre distinguido (DN), que es construido por el nombre de la propia entrada (llamado Nombre Relativo Distinguido o RDN) y la concatenaci\u00f3n de los nombres de las entradas que le anteceden. </p> <p>Por ejemplo, la entrada para Nuno Gon\u00e7alves en el ejemplo del nombramiento de Internet anterior tiene el siguiente RDN: uid=nuno y su DN ser\u00eda: uid=nuno,ou=estig,dc=ipb,dc=pt.  </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#como-se-accede-a-la-informacion","title":"C\u00f3mo se accede a la informaci\u00f3n?","text":"<p>LDAP define operaciones para interrogar y actualizar el directorio. Provee operaciones para a\u00f1adir y borrar entradas del directorio, modificar una entrada existente y cambiar el nombre de una entrada. La mayor parte del tiempo, sin embargo, LDAP se utiliza para buscar informaci\u00f3n almacenada en el directorio. Las operaciones de b\u00fasqueda de LDAP permiten buscar entradas que concuerdan con alg\u00fan criterio especificado por un filtro de b\u00fasqueda. La informaci\u00f3n puede ser solicitada desde cada entrada que concuerda con dicho criterio.</p> <p>Por ejemplo, imaginemos que queremos buscar en el sub\u00e1rbol del directorio que est\u00e1 por debajo de dc=ipb,dc=pt a personas con el nombre Nuno Gon\u00e7alves, obteniendo la direcci\u00f3n de correo electr\u00f3nico de cada entrada que concuerde. LDAP permite hacer esto f\u00e1cilmente. O tal vez preferimos buscar las organizaciones que posean la cadena IPB en su nombre, posean n\u00famero de fax y est\u00e9n debajo de la entrada st=Bragan\u00e7a,c=PT. LDAP permite hacer esto tambi\u00e9n.</p> <p>LDAP ofrece una autenticaci\u00f3n y autorizaci\u00f3n optimizadas y una b\u00fasqueda eficaz de datos de direcciones y de usuarios. Debido a sus muchas ventajas para las empresas. LDAP sirve a modo de un est\u00e1ndar de la industria y es compatible con la mayor\u00eda de los productos de software. Las ventajas principales son la rapidez de las consultas y conexiones, un lenguaje de consulta sencillo y un protocolo claramente estructurado</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#modulos-en-apache","title":"M\u00f3dulos en Apache","text":"<p>Un m\u00f3dulo es una parte independiente de un programa. La mayor parte de la funcionalidad de Apache est\u00e1 contenida en m\u00f3dulos que pueden incluirse o excluirse. Como decimos, existen una gran cantidad de M\u00f3dulos para utilizarse con Apache, algunos ejemplo son: \"Virtual Hosting\",\"Mod_JK(Java)\" y \"Rewrite\".</p> <p>Una de las principales razones de emplear m\u00f3dulos en Apache, es que no toda instalaci\u00f3n requiere de las mismas funcionalidades, esto es, una instalaci\u00f3n que utilice PHP probablemente no requiera de Tomcat (Java), o bien posiblemente no todas las instalaciones requieran de \"Virtual Hosting\".</p> <p>As\u00ed las cosas, para no incluir todas las funcionalidades de Apache, necesarias e innecesarias para cada ocasi\u00f3n, en un \u00fanico paquete de instalaci\u00f3n que lo har\u00eda demasiado grande en tama\u00f1o y pesado en recursos, se hace uso de los m\u00f3dulos, de tal forma que s\u00f3lo cargaremos en memoria los que nos hagan falta en cada ocasi\u00f3n.</p> <p>Los m\u00f3dulos le permiten a los administradores del servidor activar y desactivar funcionalidades adicionales. Apache tiene m\u00f3dulos de seguridad, almacenamiento en cach\u00e9, reescritura de URL, autenticaci\u00f3n de contrase\u00f1a y m\u00e1s.</p> <p>Info</p> <p>En Apache hay dos tipos de m\u00f3dulos:</p> <ul> <li>Est\u00e1ticos: Son a\u00f1adidos al compilar el servidor.</li> <li>Din\u00e1micos: Se cargan din\u00e1micamente al iniciar el servidor. </li> </ul> <p>Se puede habilitar cualquiera de los m\u00f3dulos de la lista con el comando <code>a2enmod (nombre del m\u00f3dulo)</code> (usando el <code>sudo</code> si no se es superusuario), y deshabilitar cualquiera de ellos previamente habilitado mediante el comando <code>a2dismod (nombre del m\u00f3dulo)</code>  (usando el <code>sudo</code> si no se es superusuario).</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#modulos-en-nginx","title":"M\u00f3dulos en Nginx","text":"<p>Los m\u00f3dulos est\u00e1ticos existen desde sus inicios en Nginx y los din\u00e1micos desde la versi\u00f3n 1.9.11 (Febrero de 2016).</p> <p>Nginx es, de hecho, una colecci\u00f3n de m\u00f3dulos. Incluso funciones b\u00e1sicas tales como HTTP o servir ficheros est\u00e1ticos dentro de HTTP, est\u00e1n implementadas por m\u00f3dulos.</p> <p>Se puede extender la funcionalidad de Nginx a\u00f1adiendo m\u00f3dulos propios. Esta arquitectura modular permite modificar f\u00e1cilmente Nginx.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#modulo-autenticacion-ldap-en-nginx","title":"M\u00f3dulo autenticaci\u00f3n LDAP en Nginx","text":"<p>La soluci\u00f3n aprovecha el m\u00f3dulo ngx_http_auth_request_module de Nginx, que reenv\u00eda las peticiones de autenticaci\u00f3n a un servicio externo. En la implementaci\u00f3n de referencia, ese servicio es un demonio que llamamos ldap-auth. Est\u00e1 escrito en Python y se comunica con un servidor de autenticaci\u00f3n del Protocolo Ligero de Acceso a Directorios (LDAP) - OpenLDAP por defecto, pero hemos probado el demonio ldap-auth tambi\u00e9n con configuraciones por defecto de Microsoft\u00ae Windows\u00ae Server Active Directory (tanto la versi\u00f3n 2003 como la 2012).</p> <p>Para realizar la autenticaci\u00f3n, el m\u00f3dulo http_auth_request realiza una subconsulta HTTP al demonio ldap-auth, que act\u00faa como intermediario e interpreta la subconsulta para el servidor LDAP - utiliza HTTP para la comunicaci\u00f3n con Nginx y la API apropiada para la comunicaci\u00f3n con el servidor LDAP.</p> <p></p> <p>A continuaci\u00f3n se describe paso a paso el proceso de autenticaci\u00f3n en la implementaci\u00f3n de referencia. Los detalles se determinan por los ajustes en el archivo de configuraci\u00f3n nginx-ldap-auth.conf; ver Configuraci\u00f3n de la implementaci\u00f3n de referencia m\u00e1s abajo. </p> <p>El diagrama de flujo debajo de los pasos resume el proceso.</p> <p></p> <ol> <li> <p>Un cliente env\u00eda una solicitud HTTP para un recurso protegido alojado en un servidor para el que Nginx est\u00e1 actuando como proxy inverso.</p> </li> <li> <p>Nginx (concretamente, el m\u00f3dulo http_auth_request) reenv\u00eda la solicitud al demonio ldap-auth, que responde con el c\u00f3digo HTTP 401 porque no se han proporcionado credenciales.</p> </li> <li> <p>Nginx reenv\u00eda la solicitud a <code>http://backend/login</code>, que corresponde al demonio del backend. Escribe el URI de la solicitud original en la cabecera X-Target de la solicitud reenviada.</p> </li> <li> <p>El demonio del backend env\u00eda al cliente un formulario de inicio de sesi\u00f3n (el formulario est\u00e1 definido en el c\u00f3digo Python del demonio). Tal y como se configura en la directiva error_page, NGINX establece el c\u00f3digo HTTP del formulario de inicio de sesi\u00f3n en 200.</p> </li> <li> <p>El usuario rellena los campos Nombre de usuario y Contrase\u00f1a en el formulario y hace clic en el bot\u00f3n Login. Seg\u00fan el c\u00f3digo del formulario, el cliente genera una petici\u00f3n HTTP POST dirigida a <code>/login</code>, que Nginx reenv\u00eda al demonio del backend.</p> </li> <li> <p>El demonio del backend construye una cadena con el formato nombre de <code>usuario:contrase\u00f1a</code>, aplica la codificaci\u00f3n Base64, genera una cookie llamada nginxauth con su valor establecido a la cadena codificada, y env\u00eda la cookie al cliente. Establece el flag httponly para evitar el uso de JavaScript para leer o manipular la cookie (protegiendo contra la vulnerabilidad cross-site scripting [XSS]).</p> </li> <li> <p>El cliente retransmite su solicitud original (del paso 1), esta vez incluyendo la cookie en el campo Cookie de la cabecera HTTP. Nginx reenv\u00eda la solicitud al demonio <code>ldap-auth</code> (como en el paso 2).</p> </li> <li> <p>El demonio <code>ldap-auth</code> decodifica la cookie y env\u00eda el nombre de usuario y la contrase\u00f1a al servidor LDAP en una solicitud de autenticaci\u00f3n.</p> </li> <li> <p>La siguiente acci\u00f3n depende de si el servidor LDAP autentifica con \u00e9xito al usuario:</p> <ul> <li> <p>Si la autenticaci\u00f3n tiene \u00e9xito, el demonio <code>ldap-auth</code> env\u00eda el c\u00f3digo HTTP 200 a Nginx. Nginx solicita el recurso al demonio del backend y \u00e9ste devuelve el c\u00f3digo del sitio web.</p> <p>El archivo <code>nginx-ldap-auth.conf</code> incluye directivas para el almacenamiento en cach\u00e9 de los resultados del intento de autenticaci\u00f3n.</p> </li> <li> <p>Si la autenticaci\u00f3n falla, el demonio <code>ldap-auth</code> env\u00eda el c\u00f3digo HTTP 401 a Nginx. Nginx reenv\u00eda la solicitud al demonio del backend de nuevo (como en el paso 3), y el proceso se repite.</p> </li> </ul> </li> </ol>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#despliegue-con-docker-de-nginx-demonio-de-autenticacion-ldap-openldap","title":"Despliegue con Docker de NGINX + demonio de autenticaci\u00f3n LDAP + OpenLDAP","text":"<p>Para esta pr\u00e1ctica nos crearemos un directorio que contendr\u00e1 nuestro index.html, con un texto muy simple:</p> <pre><code>$ mkdir app\n\n$ cat &lt;&lt; EOF &gt; app/index.html\n&lt;html&gt;\n&lt;body&gt;\n&lt;h1&gt;\u00a1Hola Mundo!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\nEOF\n</code></pre> <p>As\u00ed como otro directorio, con el contenido de la configuraci\u00f3n pertinente de Nginx:</p> <p><pre><code>$ mkdir conf\n\n$ cat &lt;&lt; EOF &gt; conf/ldap_nginx.conf\n    server {\n      listen 8080;\n\n      location = / {\n         auth_request /auth-proxy;\n      }\n\n      location = /auth-proxy {\n         internal;\n\n         proxy_pass http://nginx-ldap:8888;\n\n         # URL y puerto para conectarse al servidor LDAP\n         proxy_set_header X-Ldap-URL \"ldap://openldap:1389\";\n\n         # Base DN\n         proxy_set_header X-Ldap-BaseDN \"dc=example,dc=org\";\n\n         # Bind DN\n         proxy_set_header X-Ldap-BindDN \"cn=admin,dc=example,dc=org\";\n\n         # Bind password\n         proxy_set_header X-Ldap-BindPass \"adminpassword\";\n      }\n   }\nEOF\n</code></pre> En esta configuraci\u00f3n le decimos a Nginx:</p> <ul> <li>Que escuche en el puerto 8080 las peticiones HTTP</li> <li>Que cuando se acceda al sitio web, se solicite autorizaci\u00f3n en el directorio del sitio web llamado /auth-proxy</li> <li>Se crea un nuevo location para ese directorio /auth-proxy y que es donde se realizar\u00e1 la configuraci\u00f3n de c\u00f3mo conectarnos a nuestro openldap, de acuerdo con la documentaci\u00f3n oficial de Nginx a prop\u00f3sito de su m\u00f3dulo de autenticaci\u00f3n:</li> <li>Se indica la URL de nuestro openldap (es el nombre del contenedor que hemos levantado, ya que Docker tiene un DNS propio entre sus contenedores)</li> <li>El DN (Nombre distinguido) base sobre el que se realizar\u00e1n las b\u00fasquedas en openldap</li> <li>El usuario y contrase\u00f1a con el que nos conectaremos al openldap para realizar las consultas</li> </ul> <p>Y ahora, procedemos con el siguiente <code>docker-compose.yml</code>:</p> <pre><code>version: '2'\n\nservices:\n  nginx-ldap:  # (1)\n    image: bitnami/nginx-ldap-auth-daemon-archived # (2)\n    ports: # (3)\n      - 8888:8888\n  nginx: # (4)\n    image: bitnami/nginx\n    ports: \n     - 8080:8080\n    volumes: # (5)\n     - ./app:/app\n     - ./conf/ldap_nginx.conf:/opt/bitnami/nginx/conf/server_blocks/ldap_nginx.conf\n  openldap: # (6)\n    image: bitnami/openldap\n    ports:\n      - '1389:1389'    \n    environment: # (7)\n      - LDAP_ADMIN_USERNAME=admin\n      - LDAP_ADMIN_PASSWORD=adminpassword\n      - LDAP_USERS=customuser\n      - LDAP_PASSWORDS=custompassword\n</code></pre> <ol> <li>Nombre del contenedor</li> <li>Imagen que descargaremos del Dockerhub y a partir de la cual crearemos nuestro contenedor</li> <li>Puerto/s que se publicar\u00e1n para el contenedor</li> <li>Nombre del contenedor</li> <li>Vol\u00famenes o directorios compartidos entre nuestra m\u00e1quina y el contenedor</li> <li>Nombre del contenedor</li> <li>Variables de entorno utilizadas para la configuraci\u00f3n de este contenedor. Incluye credenciales del administrador de openldap, as\u00ed como un usuario que se crear\u00e1 en dicho openldap (pod\u00e9is cambiar usuario y contrase\u00f1a si quer\u00e9is, pero luego deb\u00e9is recordarlas)</li> </ol> <p>Tras esto s\u00f3lo queda ejecutar compose:</p> <pre><code>docker-compose up\n</code></pre> <p>Tarea</p> <p>Comprobar que puedes acceder a <code>http://IP_Maq_Virtual:8080</code> y loguearte en el servidor LDAP que acabas de desplegar.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#despliegue-con-docker-de-php-apache-con-autenticacion-ldap","title":"Despliegue con Docker de PHP + Apache con autenticaci\u00f3n LDAP","text":"<ol> <li> <p>Creamos un directorio que se llame <code>Practica7_3</code></p> </li> <li> <p>En primer lugar, como es obvio, dentro del directorio creado debemos crear el <code>index.php</code> de nuestra aplicaci\u00f3n:</p> <pre><code>  &lt;?php\n  echo 'Well, hello LDAP authenticated user!';\n  ?&gt;\n</code></pre> </li> <li> <p>Dentro de nuestro directorio de trabajo, creado anteriormente, crearemos otro directorio llamado <code>Docker</code> y dentro de \u00e9l, un Dockerfile (<code>./Docker/Dockerfile</code>)</p> <p>Nota</p> <p>En Linux, cuando queremos hacer referencia al directorio actual, lo hacemos con un punto <code>.</code> </p> <p>Si dentro de nuestro directorio actual tenemos una carpeta llamada <code>prueba</code>, podemos hacer referencia a ella como <code>./prueba</code>, ya que el <code>.</code> hace referencia precisamente al directorio donde nos encontramos.</p> <p>Para completar este Dockerfile con las opciones/directivas adecuadas, leed los comentarios y pod\u00e9is apoyaros en la teor\u00eda o en este cheatsheet:</p> <pre><code># ./Docker/Dockerfile --&gt; directorio donde se encuentra este archivo\n\n# Imagen base sobre la que vamos a trabajar\n____ php:7-apache\n\n# Activamos el m\u00f3dulo LDAP de Apache ejecutand el siguiente comando\n____ a2enmod authnz_ldap\n\n# A\u00f1adimos las reglas/configuraci\u00f3n de LDAP al directorio conf-enabled de Apache\n# (crearemos este archivo en el siguiente paso)\n____ Docker/ldap-demo.conf /etc/apache2/conf-enabled/\n\n# A\u00f1adimos ayuda de depuraci\u00f3n (debugging) en la configuraci\u00f3n de apache\n# En caso de necesitarlo, lo descomentamos para ejecutar el siguiente comando\n# ____ echo \"LogLevel debug\" &gt;&gt; apache2.conf\n\n# Establecemos el directorio de trabajo adecuado\n____ /var/www/html/demo\n\n\n# Configuramos Apache para usar la configuraci\u00f3n ldap definida arriba, la copiamos de nuestro ordenador al contenedor\n____ Docker/.htaccess ./.htaccess\n\n#  Copiamos los archivos del proyecto que necesitamos, al contenedor\n\n____ index.php ./\n</code></pre> <p>Tarea</p> <p>Completa el Dockerfile.</p> </li> <li> <p>Ahora crearemos el archivo <code>./Docker/ldap-demo.conf</code>, que es la configuraci\u00f3n LDAP. Aqu\u00ed establecemos los criterios de conexi\u00f3n con el contenedor de Openldap, password y URL.</p> <p>Las directivas <code>PassEnv</code> al principio del archivo nos permiten omitir nuestras credenciales y pasarlas luego como variables de entorno al correr la imagen del contenedor:</p> <pre><code># ./Docker/ldap-demo.conf\nPassEnv LDAP_BIND_ON\nPassEnv LDAP_PASSWORD\nPassEnv LDAP_URL\n&lt;AuthnProviderAlias ldap demo&gt;\n    AuthLDAPBindDN ${LDAP_BIND_ON}\n    AuthLDAPBindPassword ${LDAP_PASSWORD}\n    AuthLDAPURL ${LDAP_URL}\n&lt;/AuthnProviderAlias&gt; \n</code></pre> </li> <li> <p>Creamos el archivo .htaccess:</p> <pre><code># ./Docker/.htaccess\nAuthBasicProvider demo\nAuthType Basic\nAuthName \"Protected Area\"\nRequire valid-user\n</code></pre> </li> <li> <p>Dentro de nuestro directorio de trabajo, construimos la imagen con el siguiente comando:</p> <pre><code>docker build \\\n    -t docker-ldap \\\n    -f ./Docker/Dockerfile \\\n    .\n</code></pre> </li> <li> <p>Corremos el contenedor indicando las credenciales de nuestra cuenta LDAP mediante variables de entorno con la flag <code>-e</code>. Para este caso, vamos a probar un servidor LDAP externo, csimulando que tuvi\u00e9ramos que integrar nuestro despliegue con un servidor ya existente en la empresa. Utilizaremos un servidor p\u00fablico en Internet dedicado a pruebas: https://www.forumsys.com/2022/05/10/online-ldap-test-server/</p> <pre><code>docker run \\\n    -p 8080:80 \\\n    --name ldap_demo \\\n    -e LDAP_BIND_ON='cn=read-only-admin,dc=example,dc=com' \\\n    -e LDAP_PASSWORD='password' \\\n    -e LDAP_URL='LDAP://ldap.forumsys.com/dc=example,dc=com' \\\n    docker-ldap\n</code></pre> </li> <li> <p>No nos queda m\u00e1s que visitar <code>http://IP-M\u00e1q-Debian:8080/demo</code>. Si todo ha ido bien, nos solicitar\u00e1 nuestras credenciales para loguearnos contra el servidor openldap. Puedes acceder a https://www.forumsys.com/2022/05/10/online-ldap-test-server/ para obtener usuarios y sus passwords.</p> </li> </ol>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/PV1DockerizacionLDAP/#referencias","title":"Referencias","text":"<p>Para qu\u00e9 sirve el protocolo LDAP y c\u00f3mo funciona</p> <p>OpenLDAP conceptos te\u00f3ricos</p> <p>Using Nginx and NGINX to Authenticate Application Users with LDAP</p> <p>Simple Docker/Apache/PHP Authentication with LDAP</p> <p>bitnami/nginx-ldap-auth-daemon-archived</p> <p>nginxinc/nginx-ldap-auth</p> <p>Dockerfile cheatsheet</p> <p>Difference between RUN and CMD in a Dockerfile</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T01/","title":"Servicios de red implicados en el despliegue de aplicaciones web","text":"<p>En esta unidad vamos a estudiar 2 servicios de red implicados en el despliegue de aplicaciones web: el servicio de nombres de dominio o DNS y el servicio de directorio LDAP.</p> <p>Aunque estos 2 servicios no son imprescindibles para desplegar una aplicaci\u00f3n web (de hecho, hasta ahora no los hemos usado), si que son muy importantes para hacerlo de una forma amigable para el usuario y ayudar a los administradores en la gesti\u00f3n de los accesos a los servicios.</p> <p>El servicio DNS (Sistema de Nombres de Dominio) es una infraestructura que traduce nombres de dominio legibles por humanos en direcciones IP num\u00e9ricas, permitiendo la localizaci\u00f3n y acceso a recursos en Internet de manera m\u00e1s sencilla, actuando como un directorio distribuido para la resoluci\u00f3n de nombres.</p> <p></p> <p>Un servicio de directorio como LDAP (Protocolo Ligero de Acceso a Directorios) es una plataforma que organiza y almacena informaci\u00f3n de manera jer\u00e1rquica, facilitando la gesti\u00f3n centralizada y el acceso eficiente a datos de usuarios, dispositivos y recursos en una red.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/","title":"Servicio DNS (Domain Name System)","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#introduccion","title":"Introducci\u00f3n","text":"<p>El sistema de nombres de dominio DNS (Domain Name System) proporciona un mecanismo eficaz para llevar a cabo la resoluci\u00f3n de nombres de dominio a direcciones IP. Como usuarios (humanos) nos es m\u00e1s f\u00e1cil dirigirnos a un nombre de dominio (de host, de web, de servidor de correo, etc.) utilizando un texto identificativo (por ejemplo, www.gva.es) que a la direcci\u00f3n IP correspondiente (por ejemplo, 193.144.127.85). El servicio DNS no solo permite hacer la resoluci\u00f3n de nombres de dominio a direcciones IP, sino tambi\u00e9n la resoluci\u00f3n inversa. Es decir, a partir de una IP averiguar el nombre de dominio. </p> <p>El servicio DNS proporciona independencia del nombre de dominio respecto a la IP. As\u00ed un dominio puede cambiar de IP de forma transparente para los usuarios del dominio. Incluso es usual que un dominio se identifique con m\u00e1s de una IP como medida de redundancia contra la ca\u00edda del sistema o como balanceo de cargas. Otros servicios proporcionados por el DNS son la identificaci\u00f3n de los servidores de correo de un dominio, de cada uno de los hosts que pertenecen a la red, servidores de impresi\u00f3n, etc.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#sistemas-de-nombres-planos-y-jerarquicos","title":"Sistemas de nombres planos y jer\u00e1rquicos","text":"<p>El problema de la identificaci\u00f3n de equipos se produce desde el principio de la existencia de las redes de ordenadores y no es algo espec\u00edfico de TCP/IP. Hac\u00eda falta un lenguaje humano para realizar esta identificaci\u00f3n. </p> <p>En los albores de las redes, cuando ARPANET (la red predecesora de Internet), los nombres los equipos se centralizaban en un archivo llamado host.txt (/etc/hosts en Linux), que inclu\u00eda el nombre del equipo y su IP. Esto es lo que se conoce como un sistema de nombres plano. Puede ser adecuado para redes peque\u00f1as, pero no es escalable ni pr\u00e1ctico en redes grandes y mucho menos en Internet. </p> <p>Ejemplo de fichero de nombres plano: </p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#elementos-del-sistema-de-nombres-de-dominio","title":"Elementos del sistema de nombres de dominio","text":"<p>El espacio de nombres de dominio est\u00e1 formado por los nombres v\u00e1lidos utilizados para identificar servicios o m\u00e1quinas en una red. Se puede representar mediante una estructura jer\u00e1rquica de topolog\u00eda arb\u00f3rea, es decir, todos los nombres forman un \u00e1rbol invertido donde cada nodo se separa de los otros nodos por un punto <code>.</code>. </p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#nombres-de-dominio","title":"Nombres de dominio","text":"<p>Los nombres de dominio pueden estar formados por una o m\u00e1s cadenas de caracteres separadas por puntos y no se distingue entre may\u00fasculas y min\u00fasculas. Por ejemplo, www.deaw.es. es lo mismo que WWW.deaw.ES.. </p> <p></p> <p>Los nombres de dominio se expresan como secuencias de etiquetas (labels).</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#dominios-raiz","title":"Dominios ra\u00edz","text":"<p>En teor\u00eda, todos los dominios deben de terminar con un punto <code>.</code>. Es as\u00ed porque el \u00e1rbol de nombres de dominio (espacio de nombres de dominio) empieza con el dominio <code>.</code> que se conoce como dominio ra\u00edz (root). En realidad es un elemento nulo de 0 caracteres que se representa con un punto <code>.</code>. </p> <p>Un dominio se lee de derecha a izquierda, empezando por el punto <code>.</code>, aunque en la pr\u00e1ctica lo hacemos de izquierda a derecha. El punto inicial, generalmente se omite ya que los programas lo a\u00f1aden por defecto y es meramente formal, pero en ocasiones, como en los ficheros de configuraci\u00f3n de la zona, ser\u00e1 necesario que indiquemos el nombre de dominio completo incluyendo el dominio ra\u00edz, es lo que se conoce como nombres de dominio completos (Fully Qualified Domain Names, FQDN). </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#dominios-y-subdominios","title":"Dominios y subdominios","text":"<p>Como consecuencia de la organizaci\u00f3n jer\u00e1rquica del espacio de nombres de dominios, podemos utilizar los t\u00e9rminos dominio y subdominio. Por ejemplo, <code>deaw.es.</code> es un subdominio del dominio <code>es.</code> y <code>www.deaw.es</code>. es un subdominio del dominio <code>deaw.es.</code>. </p> <p>Los dominios o subdominios que cuelgan del dominio ra\u00edz <code>.</code> se conocen como dominios de primer nivel o dominios de nivel superior (Top Level Domains, TLD), los que cuelgan de los dominios TLD se denominan dominios de segundo nivel y as\u00ed sucesivamente</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#zonas","title":"Zonas","text":"<p>Atenci\u00f3n</p> <pre><code>Una zona es una porci\u00f3n del espacio de nombres de dominio en el DNS cuya responsabilidad administrativa recae sobre un \u00fanico responsable.\n</code></pre> <p>Los servidores que gestionan la zona tienen informaci\u00f3n completa sobre ella y se dice que son autorizados para esa zona. </p> <p>Las zonas se almacenan en archivos de texto o en bases de datos, seg\u00fan el tipo de software que se utilice para montar el servidor DNS y de como se configure. </p> <p>Tomemos como ejemplo el dominio deaw.es. y veamos parte de su archivo de zona </p> <p><pre><code>...\ndeaw.es.         IN NS      ns1.deaw.es.\nns1.deaw.es.     IN A       192.168.1.20\nnatos.deaw.es. IN   A       192.168.1.21\nwaor.deaw.es.    IN A       192.168.1.22\nwww.deaw.es.     IN CNAME   natos.deaw.es.\nftp.deaw.es.     IN CNAME   waor.deaw.es.\n...\n</code></pre> A cada una de las l\u00edneas del fichero se las conoce como registros de recurso (RR: Resource Records) y definen los tipos de datos en el Domain Name System (DNS). Se utilizan para almacenar datos sobre nombres de dominio y direcciones IP. Una base de datos o fichero de zona est\u00e1 formada por una serie de registros de recursos. Cada registro de recurso da informaci\u00f3n pertinente sobre un objeto determinado. Por ejemplo, los registros de tipo (A) asocian un nombre de host con una direcci\u00f3n IP, y los registros de puntero de b\u00fasqueda inversa (PTR) asocian una direcci\u00f3n IP con un nombre de host y un registro (NS) define un servidor DNS para la zona. El servidor DNS utiliza estos registros de recurso para resolver las consultas de los hosts de su zona. </p> <p>Cuando un servidor DNS es autorizado para una zona, es el responsable de los nombres de dominio para esa zona. En nuestro ejemplo, ns1.deaw.es es el servidor autorizado para la zona deaw.es. y en \u00e9l se definen los nombres que cuelgan de deaw.es como por ejemplo, www.deaw.es, ftp.deaw.es, natos.deaw.es, etc. </p> <p></p> <p>La organizaci\u00f3n que administra el servidor DNS y por lo tanto la zona, puede delegar o no alguno de sus subdominios. Supongamos que de deaw.es. cuelgan los subdominios teoria.deaw.es. y practicas.deaw.es. y se decide delegar solo el subdominio practicas.deaw.es.. Esto implica que existir\u00e1 otro servidor DNS autorizado para el dominio practicas.deaw.es., que almacenar\u00e1 el fichero de zona para dicho dominio.</p> <p>Atenci\u00f3n</p> <pre><code>Una zona no es lo mismo que un dominio. Un **dominio** es un **subarbol del espacio de nombres de dominio** y los datos asociados a los nombres de un **dominio** pueden estar almacenados en una o varias **zonas**, distribuidas en uno o varios **servidores DNS**.\n\nB\u00e1sicamente una zona es una porci\u00f3n de un dominio.\n</code></pre> <p>Un servidor DNS puede ser autorizado sobre varias zonas, por ejemplo, el mismo servidor DNS puede ser autorizado para la zona deaw.es. y para la zona seguridadinformatica.es..</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#tipos-de-rr-resource-record","title":"Tipos de RR (Resource Record)","text":"<p>En esta subsecci\u00f3n vamos a ver cu\u00e1les son los registros de recursos o RR m\u00e1s utilizados. Antes debemos aclarar algunos conceptos:</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#ttl-time-to-live","title":"$TTL (Time To Live)","text":"<p>El TTL o tiempo de vida determina, en segundos, durante cu\u00e1nto tiempo son validos los RR. Pueden indicarse en semanas (TTL 1W), d\u00edas (TTL 7D), horas (TTL 168H) o minutos (10080M).</p> <p>En otras palabras, el TTL indica cu\u00e1nto tiempo tardar\u00e1n en aplicarse los cambios que le hagamos a un RR desde que los hacemos. En el ejemplo del p\u00e1rrafo anterior, los servidores DNS comprobar\u00e1n cada semana si se ha producido alg\u00fan cambio en esos RR. Debe declararse al inicio del archivo de zona.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#origin","title":"$ORIGIN","text":"<p>La directiva $ORIGIN define el nombre del dominio que ser\u00e1 a\u00f1adido al final de cualquier nombre que no acabe en punto (nombres relativos o no cualificados) en los RR, para as\u00ed transformarlos en nombres FQDN (fully qualified domain name). Si un nombre acaba en punto, se considera un nombre FQDN y no se utilizar\u00eda $ORIGIN.</p> <p>Su sintaxis o forma de escribirlo ser\u00e1:</p> <pre><code>$ORIGIN nombre-dominio\n</code></pre> <p>Por ejemplo:</p> <pre><code>$ORIGIN deaw.es.\n;A partir de aqu\u00ed se a\u00f1ade deaw.es. a todos los nombres relativos\n...\n</code></pre>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#formato-general-de-los-rr","title":"Formato general de los RR","text":"<p>El formato con el que se introducen los RR en los archivos de zona es del siguiente estilo:</p> <p><pre><code>Nombre de dominio       [TTL]       Clase       Tipo        Tipo-Dato\n</code></pre> As\u00ed por ejemplo, un RR quedar\u00eda tal que as\u00ed:</p> <pre><code>profesor.deaw.es    7200        IN      A       192.168.10.254\n</code></pre> <p>Aclarados los puntos anteriores, ahora s\u00ed vamos a ver los principales tipos de registros.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#tipos-de-registros","title":"Tipos de registros","text":"<ul> <li> <p>Registro SOA (Start Of Authority): Especifica informaci\u00f3n autoritaria sobre una zona DNS, incluyendo el servidor de nombre primario, el email del administrador, el n\u00famero de serial o versi\u00f3n de la zona, y varios temporizadores.</p> <p>Ejemplo:</p> <pre><code>    deaw.es.   IN   SOA   ns1.deaw.es.   super.deaw.es. (\n                20190425001 ; serial\n                604800  ; refresh (7 d\u00edas)\n                86400   ; retry (1 d\u00eda)\n                2419200 ; expire (28 d\u00edas)\n                604800 )    ; TTL negativo (7 d\u00edas)\n    ...\n</code></pre> <ul> <li> <p>Nombre del dominio: deaw.es.</p> <ul> <li>Indica el dominio para el que aplica este registro SOA.</li> </ul> </li> <li> <p>Clase de registro: IN</p> <ul> <li>Especifica la clase de red, en este caso, \"Internet\".</li> </ul> </li> <li> <p>Tipo de registro: SOA</p> <ul> <li>Indica que es un registro de inicio de autoridad.</li> </ul> </li> <li> <p>Servidor principal (Primary NS): ns1.deaw.es.</p> <ul> <li>Nombre del servidor DNS principal que administra la zona.</li> </ul> </li> <li> <p>Correo del administrador: super.deaw.es.</p> <ul> <li>Representa el correo del administrador de la zona (convertido a super@deaw.es).</li> </ul> </li> <li> <p>Par\u00e1metros de control:</p> <ul> <li>Serial: 20190425001<ul> <li>N\u00famero de versi\u00f3n del registro, que se incrementa cuando se actualiza la zona.</li> <li>Formato: AAAAMMDDNN (a\u00f1o, mes, d\u00eda, n\u00famero de cambio).</li> </ul> </li> <li>Refresh: 604800 (7 d\u00edas)<ul> <li>Tiempo en segundos que los servidores secundarios esperan antes de consultar al primario por cambios.</li> </ul> </li> <li>Retry: 86400 (1 d\u00eda)<ul> <li>Intervalo en segundos para reintentar la conexi\u00f3n con el servidor primario si falla tras el tiempo de refresh.</li> </ul> </li> <li>Expire: 2419200 (28 d\u00edas)<ul> <li>Tiempo en segundos tras el cual los datos de la zona se consideran inv\u00e1lidos si no se ha podido contactar con el primario.</li> </ul> </li> <li>TTL Negativo: 604800 (7 d\u00edas)<ul> <li>Tiempo que un servidor cachear\u00e1 una respuesta negativa (por ejemplo, si un dominio no existe) antes de volver a consultar.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Registro NS (Name Server):Cuando se delega la administraci\u00f3n de subdominios en otros servidores, este registro indica cu\u00e1les son esos servidores autorizados.</p> <pre><code>...\ndeaw.es.    IN  NS  ns1.deaw.es.    ;Servidor DNS maestro\ndeaw.es.    IN  NS  ns2.deaw.es.    ;Servidor DNS esclavo\ndeaw.es.    IN  NS  dns.deaw.net.   ;Servidor DNS esclavo\n\nns1.deaw.es.    IN  A   192.168.10.20\nns2.deaw.es.    IN  A   192.168.10.21\n\n;DELEGACI\u00d3N\npracticas.deaw.es.  IN  NS  ns1.practicas.deaw.es.\nredes.deaw.es.      IN  NS  dns.deaw.net.\n</code></pre> </li> <li> <p>El registro A (Address), tambi\u00e9n conocido como registro de direcci\u00f3n, establece una correspondencia entre un nombre de dominio completamente cualificado (FQDN) y una direcci\u00f3n IP versi\u00f3n 4.</p> <pre><code>...\nns1.deaw.es.        IN  A   192.168.10.20\nns2.deaw.es.        IN  A   192.168.10.21\nnatos.deaw.es.      IN  A   192.168.10.22\n...\n</code></pre> </li> <li> <p>El registro CNAME (Canonical Name) permite crear alias para nombres de dominio especificados en registros A.</p> <pre><code>...\nnatos.deaw.es.      IN  A   192.168.1.22\nwww.deaw.es.        IN  CNAME   natos.deaw.es.\nftp.deaw.es.        IN  CNAME   natos.deaw.es.\n...\n</code></pre> <p>Un registro CNAME tambi\u00e9n puede apuntar a un nombre de otro dominio.</p> <pre><code>...\nwww.deaw.es.    IN  CNAME   www.deaw.com.\n...\n</code></pre> </li> <li> <p>El registro MX (Mail Exchange) permite definir los servidores encargados de la entrega de correo en el dominio y la prioridad entre ellos. Su sint\u00e1xis es la siguiente:</p> <pre><code>...\ndeaw.es.    IN  MX  10  mail1.deaw.es.\ndeaw.es.    IN  MX  20  mail2.deaw.es.\n\nmail1.deaw.es.  IN  A   192.168.1.100\nmail2.deaw.es.  IN  A   192.168.1.101\n...\n</code></pre> </li> <li> <p>El registro PTR (Pointer Record) establece una correspondencia entre direcciones IPv4 e IPv6 y nombres de dominio. Se utilizan en las zonas de resoluci\u00f3n inversa.</p> <p>En el caso de un bloque IPv4 de prefijo <code>/24</code>, por ejemplo el <code>192.168.1.0/24</code>, los registros PTR ser\u00edan los siguientes:</p> <pre><code>...\n20.1.168.192.in-addr.arpa.    IN    PTR    ns1.deaw.es.\n21.1.168.192.in-addr.arpa.    IN    PTR    ns2.deaw.es.\n22.1.168.192.in-addr.arpa.    IN    PTR    natos.deaw.es.\n...\n</code></pre> <p>o lo que es lo mismo:</p> <pre><code>...\n20    IN    PTR    ns1.deaw.es.\n21    IN    PTR    ns2.deaw.es.\n22    IN    PTR    natos.deaw.es.\n...\n</code></pre> </li> <li> <p>El registro TXT (plaint text) permite asociar informaci\u00f3n adicional a un dominio mediante m\u00faltiples cadenas de texto, con una longitud m\u00e1xima de 255 caracteres cada una de ellas. Por ejemplo, utilizado para almacenar claves de cifrado.</p> <pre><code>...\n@   IN  TXT     \"Servidor maestro de Servicios en Red\"\n@   IN  TXT     \"Servidor maestro de Servicios en Red\"\n</code></pre> </li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#tipos-de-servidores-dns","title":"Tipos de servidores DNS","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidor-maestro-o-primario","title":"Servidor maestro o primario","text":"<p>Un servidor maestro o primario, define una o varias zonas de las que es autorizado. Sus archivos de zona son de lectura y escritura y es en ellos donde el administrador del servidor a\u00f1ade, modifica o elimina nombres de dominio.</p> <ul> <li> <p>Si un cliente DNS u otro servidor DNS le pregunta por alg\u00fan nombre de dominio para el que es autorizado, consulta con los ficheros de zona y responde a la pregunta.</p> </li> <li> <p>Si un cliente DNS u otro servidor DNS le pregunta por alg\u00fan nombre de dominio para el que no es autorizado, tendr\u00e1 que preguntar a otros servidores DNS o responder que no conoce la respuesta.</p> </li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidor-esclavo-o-secundario","title":"Servidor esclavo o secundario","text":"<p>Un servidor esclavo o secundario define una o varias zonas para las que es autorizado. La diferencia con respecto a un servidor maestro es que los ficheros de zona los obtiene de otro servidor autorizado para la zona, normalmente, de un servidor maestro mediante un procedimiento denominado transferencia de zona. Los ficheros de zona de los servidores esclavos son de solo lectura y por lo tanto, el administrador no tiene que editarlos. La modificaci\u00f3n de los archivos de zona debe realizarla el servidor maestro que transfiere la zona.</p> <p></p> <p>El funcionamiento de como responden a los clientes DNS o a otros servidores DNS es similar al de un servidor maestro. Un servidor puede ser maestro para una o varias zonas y al mismo tiempo ser esclavo para otras.</p> <p>Pueden existir varios servidores esclavos para una misma zona. Las razones para esto suelen ser:</p> <ul> <li>Reducir y repartir la carga entre varios servidores DNS.</li> <li>Favorecer la tolerancia a fallos.</li> <li>Ofrecer mayor rapidez.</li> </ul> <p>Lo ideal es que los servidores DNS para una misma zona est\u00e9n ubicados en redes y localizaciones diferentes para evitar que, si ocurre alg\u00fan problema no les afecte simult\u00e1neamente y deje sin servicio de resoluci\u00f3n a los nombres de esa zona.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidor-cache","title":"Servidor cach\u00e9","text":"<p>Los servidores DNS se configuran como servidores cache para mejorar los tiempos de respuesta de las consultas, reducir la carga de los equipos y disminuir el tr\u00e1fico de red.</p> <p>Cuando un servidor DNS recibe una pregunta sobre un dominio para el cual no es autorizado, es decir, de un nombre del cual no tiene informaci\u00f3n, puede preguntar, si as\u00ed est\u00e1 configurado, a otros servidores para obtener la respuesta. Si el servidor act\u00faa como cache, guarda durante un tiempo (TTL: Time To Live) las respuestas a las \u00faltimas preguntas que ha realizado a otros servidores DNS. Cada vez que un cliente DNS u otro servidor DNS le formula una pregunta, comprueba si tiene la respuesta en su memoria cache, si la tiene, no tendr\u00e1 que preguntar a otro servidor DNS por la pregunta.</p> <p>Un servidor DNS es solo cache (cache only server) cuando:</p> <ul> <li>No tiene autoridad sobre ninguna zona.</li> <li>Pregunta a otros servidores DNS para resolver las preguntas de los clientes DNS y las guarda en su memoria cache.</li> </ul> <p>En el siguiente gr\u00e1fico se explica como dos clientes DNS hacen preguntas a un mismo servidor DNS que es autorizado para algunas zonas y adem\u00e1s act\u00faa como cach\u00e9.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidor-forwarder","title":"Servidor forwarder","text":"<p>Un forwarder es un servidor DNS que otros servidores DNS designan para reenviarle consultas. Son utilizados para minimizar las consultas y el tr\u00e1fico de peticiones DNS desde una red hacia Internet.</p> <p>Cuando a un servidor DNS se le hace una pregunta sobre un nombre de dominio del que no dispone informaci\u00f3n (no es autorizado), este tendr\u00e1 que preguntar a otros servidores DNS. Simplificando, existen dos formas de procesar las consultas:</p> <ul> <li> <p>El servidor no tiene un forwarder configurado, es decir, no tiene configurada la IP de otro servidor DNS, al que llamaremos forwarder al que reenviarle la consulta. Por tanto, intentar\u00e1 resolver la consulta por si mismo recurriendo al servidor ra\u00edz <code>.</code>. En este caso realiza una consulta iterativa que veremos en detalle m\u00e1s adelante.</p> <p></p> </li> <li> <p>El servidor tiene configurado un forwarder. Le trasladar\u00e1 la consulta a dicho forwarder. Y esperar\u00e1 la respuesta para trasladarla al cliente.</p> <p></p> </li> </ul> <p>En estas im\u00e1genes hay algunos textos que nos pueden llevar a confusi\u00f3n. Vamos a aclarar algunas cosas. Fij\u00e1ndonos siempre en el servidor DNS m\u00e1s hacia la izquierda, en la primera imagen dice \"Servidor DNS: no reenvia consultas a otro servidor (reenviador)\", quiere decir que no tiene un \"forwarder o reenviador\" configurado y que, por tanto, intentar\u00e1 \u00e9l obtener la resoluci\u00f3n. En la segunda imagen dice \"Servidor DNS: reenv\u00eda consultas\", por tanto, tiene configurado un \"forwarder\" y a \u00e9l le traslada la pregunta para que se la resuelva.</p> <p>Despu\u00e9s habla de que el primero \"tiene la recursividad activada\" y en la segunda imagen \"hace las consultas de forma recursiva\". Veremos esto en detalle m\u00e1s adelante, que no nos confunda ahora.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidor-solo-autorizado","title":"Servidor s\u00f3lo autorizado","text":"<p>Un Servidor solo autorizado (authoritative only) es aquel que es autorizado para una o varias zonas como servidor maestro y/o esclavo y no responde a preguntas que no sean relativas a sus zonas. Es decir, no tiene activada la recursividad, no es \"forwarder\" y no act\u00faa como cache.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#servidores-raiz","title":"Servidores ra\u00edz","text":"<p>En Internet existen un conjunto de servidores DNS autorizados para el dominio ra\u00edz <code>.</code>, conocidos como servidores ra\u00edz (root servers). Contienen el fichero de la zona <code>.</code> que contiene informaci\u00f3n sobre los servidores DNS autorizados para cada uno de los dominios TLD.</p> <p>Los servidores ra\u00edz son una parte fundamental de Internet, son el primer paso en la traducci\u00f3n (resoluci\u00f3n) de los nombres de host en direcciones IP, que se utilizan en la comunicaci\u00f3n entre los hosts de Internet. Son claves en el proceso de resoluci\u00f3n de nombres de dominio en Internet, y deben de ser conocidos por todos los servidores DNS que respondan a preguntas sobre nombres para los que no son autorizados.</p> <p>Existen 13 servidores ra\u00edz en toda Internet y cada uno de ellos tiene m\u00faltiples copias distribuidas por todo el mundo, es decir, que f\u00edsicamente no solo son 13 servidores. Cada conjunto de copias de uno de los 13 servidores se identifica por una misma IP. Cuando un cliente realiza una pregunta a una IP de un servidor ra\u00edz, los routers de Internet encaminan la pregunta hacia la copia m\u00e1s cercana mediante un procedimiento denominado anycasting.</p> <p>Los nombres de los servidores ra\u00edz son de la forma letra.root-servers.net, donde letra va desde la A a la M.</p> <p>Listado de Servidores ra\u00edz</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#tipos-de-consultas-recursivas-e-iterativas","title":"Tipos de consultas: recursivas e iterativas","text":"<p>La diferencia entre una consulta recursiva y una consulta iterativa en el contexto de DNS radica en c\u00f3mo se resuelven las peticiones y qui\u00e9n se encarga del proceso completo de resoluci\u00f3n.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#consultas-recursivas","title":"Consultas recursivas","text":"<p>Una consulta recursiva es aquella en la que el servidor DNS da una respuesta completa o exacta. Pueden darse tres tipos de respuesta:</p> <ul> <li>Positivas: se devuelve informaci\u00f3n sobre el dominio consultado</li> <li>Negativas: no se puede resolver el nombre de dominio</li> <li>Error: debido a un fallo en la red</li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#consultas-iterativas","title":"Consultas iterativas","text":"<p>Una consulta iterativa es aquella en la que el servidor DNS proporciona una respuesta parcial. Existen cuatro posibles respuestas:</p> <ul> <li>Positivas: se devuelve informaci\u00f3n sobre el dominio consultado</li> <li>Negativas: no se puede resolver el nombre de dominio</li> <li>Referencia: el servidor DNS indica a otros servidores a los que se le puede consultar para resolver la pregunta</li> <li>Error: debido a un fallo en la red</li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#ejemplos","title":"Ejemplos","text":"<p>Completando la informaci\u00f3n de la imagen del primer ejemplo del apartado del reenviador forwarder:</p> <p></p> <p>Completando la informaci\u00f3n de la imagen del segundo ejemplo del apartado del reenviador forwarder:</p> <p></p> <p>Ahora ya podemos definir m\u00e1s f\u00e1cilmente que significa que un servidor DNS tiene la recursividad activada. Significa simplemente que responde a preguntas recursivas, es decir, da una respuesta completa a una pregunta que se le hace. Si no la tiene activada solo responder\u00e1 a consultas iterativas.</p> <p>Y visto esto podemos volver a releer qu\u00e9 es un servidor s\u00f3lo autorizado para entenderlo mejor.</p> <p>En la imagen de la izquierda el Root DNS Server, el TLD DNS server y el Authoritative DNS server no tienen la recursividad activada. Por tanto, responder\u00e1n a consultas iterativas en este caso con respuestas tipo \"Referencia\". En la imagen de la derecha, los 3 servidores mencionados tienen la recursividad activada, por lo que contestar\u00e1n a respuestas recursivas proporcionando la resoluci\u00f3n completa.</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#resolucion-inversa","title":"Resoluci\u00f3n inversa","text":"<p>La resoluci\u00f3n inversa consiste en obtener informaci\u00f3n de un nombre de dominio preguntando por la direcci\u00f3n IP en vez de preguntar por el nombre de domino como hemos explicado en apartados anteriores.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#mapeo-de-direcciones-y-el-dominio-arpa","title":"Mapeo de direcciones y el dominio arpa","text":"<p>El funcionamiento de la resoluci\u00f3n de direcciones IP es igual al de la resoluci\u00f3n de nombrres de dominio. Las direcciones IP se tratan como nombres que cuelgan del dominio <code>in-addr.arpa</code> para las direcciones IPv4, y del dominio <code>ip6.arpa</code> para las direcciones IPv6.</p> <p></p> <p>Cuando usamos una direcci\u00f3n IP, por ejemplo <code>192.168.1.21</code>, para realizar una pregunta DNS inversa, en realidad estamos preguntando por el nombre de dominio <code>21.1.168.192.in-addr.arpa</code>. La estructura jer\u00e1rquica de la direcci\u00f3n IP, tratada como nombre de dominio, es de derecha a izquierda, comenzando por el dominio <code>in-addr.arpa</code>.</p> <p><code>.arpa (Address and Routing Parameter Area)</code> es un dominio de nivel superior gen\u00e9rico utilizado s\u00f3lo para la infraestructura de Internet. Los subdominios de .arpa o dominios de segundo nivel \u00abin-addr.arpa\u00bb e \u00abip6.arpa\u00bb son usados por los servidores DNS inversos para la obtenci\u00f3n de direcciones IPv4 e IPv6 respectivamente.</p> <p>Cuando mapeamos una direcci\u00f3n IP estamos asociando la direcci\u00f3n IP al nombre en el dominio .arpa. Por ejemplo la direcci\u00f3n <code>192.168.1.21</code> es mapeada al nombre <code>21.1.168.192.in-addr.arpa</code>.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#zonas-de-resolucion-inversa","title":"Zonas de resoluci\u00f3n inversa","text":"<p>Los servidores DNS almacenan zonas de resoluci\u00f3n inversa con registros de recursos (RR) que asocien nombres de dominio con direcciones IP. Las zonas de resoluci\u00f3n inversa pueden ser maestras o primarias y esclavas o secundarias.</p> <p>Las zonas de resoluci\u00f3n directa e inversa son independientes y es responsabilidad de los administradores de los servidores DNS que dichas zonas contengan informaci\u00f3n coherente y que no existan discrepancias.</p> <p>No es obligatorio que la entidad que administra una zona de resoluci\u00f3n directa de un dominio tenga que administrar la zona de resoluci\u00f3n inversa que se corresponda con las direcciones IPs asociadas a dicho dominio.</p> <pre><code>...\ndeaw.es.            IN  NS      ns1.deaw.es.\nns1.deaw.es.        IN  A       192.168.1.20\nnatos.deaw.es.  IN  A       192.168.1.21\nwaor.deaw.es.       IN  A       192.168.1.22\naltea.deaw.es.      IN  A       192.168.1.23\nwww.deaw.es.        IN  CNAME   natos.deaw.es.\nftp.deaw.es.        IN  CNAME   waor.deaw.es.\n...\n</code></pre> <p>Archivo de zona de resoluci\u00f3n directa del dominio deaw.es.</p> <pre><code>...\n1.168.192.in-addr.arpa.     IN  NS  ns1.deaw.es.\n20.1.168.192.in-addr.arpa.  IN  PTR ns1.deaw.es.\n21.1.168.192.in-addr.arpa.  IN  PTR natos.deaw.es.\n22.1.168.192.in-addr.arpa.  IN  PTR waor.deaw.es.\n23.1.168.192.in-addr.arpa.  IN  PTR altea.deaw.es.\n...\n</code></pre> <p>Archivo de zona de resoluci\u00f3n inversa <code>1.168.192.in-addr.arpa</code> que permite resolver consultas inversas sobre direcciones IP de la red <code>192.168.1.0/24</code></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#proceso-de-resolucion","title":"Proceso de resoluci\u00f3n","text":"<p>El proceso de resoluci\u00f3n inversa es similar al de resoluci\u00f3n directa. Las direcciones IP se tratan como nombres de dominio. Por lo tanto, existen consultas recursivas, iterativas, cache, TTL...</p> <p>Por ejemplo, si un cliente DNS realiza una consulta recursiva de la IP 192.168.1.21 a un servidor DNS, \u00e9ste, si no lo tiene en cache, iniciar\u00e1 una serie de consultas iterativas a los servidores DNS ra\u00edz, a los servidores autorizados para el dominio 192.in-addr.arpa y as\u00ed sucesivamente. </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#herramientas","title":"Herramientas","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#nslookup","title":"Nslookup","text":"<p>Es un programa para consultar servidores DNS. Se utiliza para saber si un servidor DNS resuelve correctamente los nombres DNS y las direcciones IP, para solucionar problemas frecuentes de los servidores DNS o, para diagnosticar problemas ocasionales de configuraci\u00f3n en los servidores DNS. </p> <p>Con nslookup podemos obtener la direcci\u00f3n IP asociada a un nombre DNS y viceversa, adem\u00e1s, podemos preguntar a los servidores de nombres informaci\u00f3n relativa a los registros de recursos (RR) de la/s zona/s de las que son autorizados.</p> <p>nslookup se usa de dos modos: interactivo y no interactivo. El modo interactivo permite al usuario consultar los servidores DNS para obtener informaci\u00f3n sobre varios hosts y dominios o para listar los hosts de un dominios. El modo no interactivo se usa para presentar solo el nombre y la informaci\u00f3n solicitada para un host o nombre DNS.</p> <p>Este comando funciona tanto en sistemas operativos UNIX/Linux como en Windows. En su momento se trat\u00f3 a nslookup como una aplicaci\u00f3n \u201cdeprecated\u201d u obsoleta, pero a d\u00eda de  hoy parece que ha vuelto a considerarse apta para su uso normal.</p> <p></p> <p></p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#dig","title":"Dig","text":"<p>Es un programa utilizado para preguntar a los servidores DNS.</p> <p>Herramienta utilizada para solucionar problemas de DNS gracias a su flexibilidad, facilidad de uso y claridad en la presentaci\u00f3n de la informaci\u00f3n. Normalmente, dig se usa pas\u00e1ndole argumentos desde la l\u00ednea de comandos (CLI), pero tambi\u00e9n tiene un modo de operar por lotes, leyendo las consultas desde un archivo.</p> <p>Este comando funciona tanto en sistemas operativos UNIX/Linux como en Windows</p> <p></p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#host","title":"Host","text":"<p>Host es una herramienta CLI sencilla y f\u00e1cil de usar para realizar consultas DNS, que traducen nombres de dominio a direcciones IP y viceversa. Tambi\u00e9n se utiliza para consultar los registros DNS de las zonas que almacenan los servidores DNS, probar y validar el servidor DNS y la conectividad a Internet, registros de correo no deseado y listas negras, diagn\u00f3stico de problemas en el servidor DNS...</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#whois","title":"Whois","text":"<p>Aunque no es una herramienta de diagn\u00f3stico DNS si que nos ofrece informaci\u00f3n sobre el registro del dominio.</p> <p>Whois es un protocolo que permite realizar consultas a bases de datos que contienen informaci\u00f3n; del usuario, empresa u organizaci\u00f3n que registra un nombre de dominio y/o una direcci\u00f3n IP en Internet. El protocolo whois se encapsula en TCP y solo especifica el intercambio de peticiones y respuestas, no el formato de datos a intercambiar. Por eso, los resultados de las consultas whois pueden variar dependiendo de la base de datos whois a la que se pregunte. </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T02/#referencias","title":"Referencias","text":"<p>Zeppelinux</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/","title":"Servicio de directorio LDAP","text":""},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#introduccion","title":"Introducci\u00f3n","text":"<p>Seguramente habr\u00e1s utilizado m\u00e1s de una vez alg\u00fan tipo de directorio o servicio de directorio, como por ejemplo: una gu\u00eda telef\u00f3nica impresa en papel o una revista con la programaci\u00f3n televisiva.</p> <p></p> <p>Los directorios, por lo tanto, permiten localizar informaci\u00f3n y para ello definen qu\u00e9 informaci\u00f3n se almacenar\u00e1 y en qu\u00e9 modo.</p> <p>Los directorios anteriormente comentados presentan una serie de problemas, en contra de los directorios electr\u00f3nicos, a saber:</p> <ul> <li> <p>Son est\u00e1ticos: Por contra, los directorios electr\u00f3nicos pueden ser consultados/actualizados en tiempo real, por lo que su fiabilidad es mucho mayor.</p> </li> <li> <p>Son inflexibles: en el contenido y en su organizaci\u00f3n. Por contra, los directorios electr\u00f3nicos pueden modificar cualquier contenido y \u00e9ste se ver\u00e1 reflejado al instante.</p> </li> <li> <p>Son inseguros: dificultad para controlar el acceso a la informaci\u00f3n. Los directorios electr\u00f3nicos s\u00ed permiten controlar el acceso a la informaci\u00f3n: solamente aquel que disponga de las claves de acceso obtendr\u00e1 la informaci\u00f3n.</p> </li> <li> <p>Dif\u00edcilmente configurable: \u00bfC\u00f3mo hacer en la gu\u00eda telef\u00f3nica para realizar una b\u00fasqueda solamente sobre un segundo apellido, de una zona urbana y con tel\u00e9fonos que poseen dos n\u00fameros que t\u00fa determines? Por contra, los directorios electr\u00f3nicos pueden establecer la informaci\u00f3n que recibe una persona en funci\u00f3n de sus necesidades.</p> </li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#utilidad-de-un-servicio-de-directorio","title":"Utilidad de un servicio de directorio.","text":"<p>Por lo visto anteriormente los directorios electr\u00f3nicos permiten, de forma eficiente:</p> <ul> <li> <p>Encontrar informaci\u00f3n:</p> <p>Los directorios electr\u00f3nicos a diferencia de los cl\u00e1sicos permiten acceder a la informaci\u00f3n contenida en los mismos de m\u00faltiples formas. As\u00ed, comparando con la gu\u00eda telef\u00f3nica tradicional, un directorio electr\u00f3nico permite realizar b\u00fasquedas, no solamente por orden alfab\u00e9tico, sino tambi\u00e9n por: apellido: direcci\u00f3n, tel\u00e9fono\u2026 \u00bfC\u00f3mo realizar\u00edas una b\u00fasqueda por tel\u00e9fono en una gu\u00eda telef\u00f3nica tradicional?</p> <p>Es m\u00e1s, podr\u00edas sumar campos de b\u00fasqueda, como por ejemplo: direcci\u00f3n y apellido.</p> </li> <li> <p>Gestionar informaci\u00f3n:</p> <p>En los directorios electr\u00f3nicos pueden existir varios usuarios que en tiempo real est\u00e9n realizando modificaciones, como agregar/editar/eliminar distintos usuarios con sus correspondientes campos. Adem\u00e1s, esta informaci\u00f3n ya estar\u00eda visible para todas aquellas aplicaciones que accedan a la misma. Centralizar as\u00ed los datos en un directorio evita tener que sincronizar varios directorios, con el consiguiente riesgo que esto provoca, pues: \u00bfqu\u00e9 pasar\u00eda si la sincronizaci\u00f3n no tuvo lugar y una aplicaci\u00f3n accede a los datos? Pues s\u00ed, obtendr\u00eda los datos no actualizados, o error en los mismos.</p> <p>Un caso muy com\u00fan es el de los servidores Web con autenticaci\u00f3n: si solamente dispones de un servidor web la soluci\u00f3n es sencilla, puesto que solamente se necesitar\u00eda actualizar una base de datos de usuarios, pero \u00bfy si dispones de m\u00e1s de un servidor web que debe acceder a la misma base de datos? Entonces, la cosa se complica, puesto que debes sincronizar a los distintos servidores. Es m\u00e1s, y si esa base de datos la quisi\u00e9ramos aprovechar para ofrecer otro servicio distinto del de los servidores web? Pues, todo el trabajo no ser\u00eda aprovechable, y por lo tanto ser\u00eda mejor desde un principio adaptar este sistema a los servicios de directorios.</p> </li> <li> <p>Control de seguridad:</p> <p>Los servicios de directorios no simplemente permiten delimitar el acceso a los usuarios, sino que tambi\u00e9n proporcionan una soluci\u00f3n al problema de gesti\u00f3n de certificados digitales. As\u00ed, permiten:</p> <ul> <li> <p>Su creaci\u00f3n: Incorporar a los certificados los datos contenidos en el directorio.</p> </li> <li> <p>Su distribuci\u00f3n: Tener accesibles mediante un protocolo est\u00e1ndar los certificados.</p> </li> <li> <p>Su destrucci\u00f3n: Revocar los certificados de forma sencilla simplemente borrando el certificado del directorio.</p> </li> <li> <p>Su ubicaci\u00f3n: Los usuarios pueden acceder a trav\u00e9s del directorio a los certificados de los restantes usuarios, de forma muy sencilla y f\u00e1cil de integrar con las aplicaciones.</p> </li> </ul> </li> </ul> <p>Por todo ello las aplicaciones pr\u00e1cticas que poseen los servicios de directorio son muy diversas y ventajosas, como por ejemplo:</p> <ul> <li>autenticaci\u00f3n de usuarios: en aplicaciones web, correo electr\u00f3nico, RADIUS..., </li> <li>sistemas de control de entradas a edificios, </li> <li>bases de datos comunes en organizaciones, </li> <li>en sistemas operativos: <ul> <li>gesti\u00f3n de cuentas de acceso, </li> <li>servidores de certificados, </li> <li>libretas de direcciones compartidas...</li> </ul> </li> </ul>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#directorio-vs-dns","title":"Directorio vs DNS","text":"<p>Tanto un servicio de directorio como un servicio DNS proporcionan acceso a una base de datos jer\u00e1rquica, pero difieren en:</p> <ul> <li> <p>Los servidores de directorio no est\u00e1n particularizados a una acci\u00f3n concreta sino orientados de forma m\u00e1s general, mientras que el servicio DNS est\u00e1 dedicado a la traducci\u00f3n de nombres de dominios a direcciones IP.</p> </li> <li> <p>La informaci\u00f3n almacenada en el servicio de directorio no es fija, mientras que en el servicio DNS tiene una estructura fija.</p> </li> <li> <p>El servicio de directorio permite actualizaciones, mientras que el servicio DNS no las permite, \u00bfo puedes actualizar a tu antojo los servidores ra\u00edz DNS?</p> </li> <li> <p>Los servicios de directorio suelen utilizar protocolos orientados a conexi\u00f3n (TCP), mientras que el servicio DNS opera con protocolos no orientados a conexi\u00f3n (UDP).</p> </li> </ul> <p>Pero, no por ello, poseen el impedimento de trabajar juntos, es m\u00e1s, usualmente los encontrar\u00e1s unidos de la mano en aplicaciones web con distintas funcionalidades, como: servidores de correo, gesti\u00f3n de proyectos e incidencias, servidores RADIUS, etc. </p> <p>As\u00ed, suele ser necesario acceder a las URL de las aplicaciones web mediante nombres de dominio DNS y una vez en ellas autenticarse por medio de LDAP.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#que-es-ldap","title":"\u00bfQu\u00e9 es LDAP?","text":"<p>LDAP es un protocolo que ofrece el acceso a un servicio de directorio implementado sobre un entorno de red, con el objeto de acceder a una determinada informaci\u00f3n. Puede ejecutarse sobre TCP/IP o sobre cualquier otro servicio de trasferencia orientado a la conexi\u00f3n.</p> <p>LDAP son las siglas en ingl\u00e9s de Lightweight Directory Access Protocol (Protocolo Ligero de Acceso a Directorios) y podemos considerarlo como un sistema de almacenamiento de red (normalmente construido como una base de datos) al que se pueden realizar consultas.</p> <p>El protocolo LDAP se cre\u00f3 originalmente en la Universidad de M\u00edchigan, que public\u00f3 un primer desarrollo en 1993. M\u00e1s tarde, Tim Howes y Steve Killela, dos de los dise\u00f1adores originales del proyecto comienzan a trabajar en una nueva versi\u00f3n bajo los auspicios de IETF (Internet Engineering Task Force) completando el desarrollo original.</p> <p>La nueva versi\u00f3n (LDAPv3) se public\u00f3 en 1997 e integraba mecanismos de autenticaci\u00f3n sencilla y capa de seguridad. Despu\u00e9s de esto, la IETF ha a\u00f1adido numerosas extensiones y especificaciones propias que le han ido incorporando nuevas capacidades.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#que-es-openldap","title":"\u00bfQu\u00e9 es OpenLDAP?","text":"<p>La respuesta es muy sencilla: OpenLDAP es un desarrollo del protocolo LDAP, implementado con la filosof\u00eda del software libre y c\u00f3digo abierto.</p> <p></p> <p>El proyecto OpenLDAP se inici\u00f3 en agosto de 1998 y est\u00e1 sustentado por una entidad sin \u00e1nimo de lucro llamada OpenLDAP Foundation, creada por el desarrollador estadounidense Kurt D. Zeilenga para coordinar las actividades del proyecto.</p> <p>Note</p> <p>OpenLDAP se publica bajo su propia licencia OpenLDAP Public License</p> <p>Como ocurr\u00eda en el caso de LDAP, OpenLDAP est\u00e1 muy optimizado para ofrecer los mejores resultados en situaciones que requieran operaciones de lectura intensivas. De esta forma, un directorio OpenLDAP arrojar\u00e1 unos resultados muy superiores a los que ofrece una base de datos relacional optimizada, cuando realicemos operaciones de consulta intensivas sobre ambas.</p> <p>Por el contrario, si utiliz\u00e1ramos un directorio OpenLDAP para guardar datos que sean actualizados de manera frecuente, los resultados obtenidos ser\u00edan muy inferiores a los ofrecidos por una base de datos relacional.</p> <p>No s\u00f3lo podemos encontrar OpenLDAP en la mayor\u00eda de de las distribuciones Linux, sino que tambi\u00e9n lo encontramos para Microsoft Windows, Apple OSX, Solaris, HP-UX, BSD, etc.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#como-funcionan-ldap-y-openldap","title":"\u00bfC\u00f3mo funcionan LDAP y OpenLDAP?","text":"<p>El modelo de informaci\u00f3n de LDAP se basa en entradas, entendiendo por entrada un conjunto de atributos identificados por un nombre global \u00fanico (Distinguished Name \u2013 DN), que se utiliza para identificarla de forma espec\u00edfica. Las entradas se organizan de forma l\u00f3gica y jer\u00e1rquica mediante un esquema de directorio, que contiene la definici\u00f3n de los objetos que pueden formar parte del directorio. Al esquema del directorio le llamamos DIT o Directory Information Tree.</p> <p></p> <p>Cada entrada del directorio DIT representa un objeto, que puede ser abstracto o real: una persona, un mueble o una funci\u00f3n en la estructura de una empresa, etc.</p> <p>Cada nodo del DIT podemos identificarlo de 2 formas</p> <ul> <li> <p>Relative Distinguished Name RDN, que es su nombre relativo, sin tener en cuenta en la posici\u00f3n del \u00e1rbol en que est\u00e1 respecto a sus nodos padres. Por ejemplo, el primero tiene de RDN dc=com. Este puede indicar lo que se desee, por ejemplo ou=usuarios significa \"unidad organizativa\".</p> </li> <li> <p>Distinguished Name DN que es la uni\u00f3n de su RDN con el de sus nodos padres. As\u00ed, Rompe Techos tiene como DN cn=Rompe Techos, ou=usuarios, I=Castellon, dc=san-gva, dc=com.</p> </li> </ul> <p>Cada nodo o entrada estar\u00e1 formado por varios atributos. Cada atributo tendr\u00e1 un tipo y un valor con el formato atributo/valor que permite caracterizar un aspecto del objeto que define la entrada. Estos atributos tienen nombres que hacen referencia a su contenido y pueden ser de dos tipos:</p> <ul> <li> <p>Atributos normales: Son los atributos que identifican al objeto (nombre, apellidos, etc.).</p> </li> <li> <p>Atributos operativos: Son los atributos que utiliza el servidor para administrar el directorio (fecha de creaci\u00f3n, tama\u00f1o, etc.).</p> </li> </ul> <p>Entre los atributos que suelen emplearse habitualmente, encontramos los siguientes, aunque puede haber muchos m\u00e1s:</p> <ul> <li>uid (user id): Identificaci\u00f3n \u00fanica de la entrada en el \u00e1rbol.</li> <li>objectClass: Indica el tipo de objeto al que pertenece la entrada.</li> <li>cn (common name): Nombre de la persona representada en el objeto.</li> <li>givenname: Nombre de pila.</li> <li>sn (surname): Apellido de la persona.</li> <li>o (organization): Entidad a la que pertenece la persona.</li> <li>u (organizational unit): El departamento en el que trabaja la persona.</li> <li>mail: direcci\u00f3n de correo electr\u00f3nico de la persona.</li> </ul> <p>Obviamente, los atributos anteriores hacen referencia a un tipo de objeto que representa a los miembros de una empresa. Para representar a otros tipos de objetos, necesitar\u00edamos atributos diferentes.</p> <p>De esta forma, una entrada almacenada en el directorio LDAP podr\u00eda tener el siguiente aspecto:</p> <pre><code>    dn: uid=Rompe Techos, ou=usuarios, I=Castellon, dc=san-gva\n    objectClass: person \n    cn: Rompe Techos\n    givenname: Rompe\n    sn: Techos\n    o: usuarios \n    u: Castellon\n    mail: rompetechos@san-gva.es\n</code></pre> <p>Como hemos dicho antes, las diferentes entradas se organizan a modo de \u00e1rbol jer\u00e1rquico que, normalmente, representa una estructura organizativa o geogr\u00e1fica en particular. As\u00ed, las entradas que representan comunidades aut\u00f3nomas aparecer\u00e1n en la parte superior del \u00e1rbol, debajo estar\u00e1n las que representan provincias, despu\u00e9s las ciudades, los departamentos, los usuarios, etc.</p> <p>En la actualidad, las implementaciones de LDAP suelen utilizar DNS (Domain Name Service) para la estructura de los niveles superiores del \u00e1rbol. En los niveles inferiores, sin embargo, las entradas representar\u00e1n otro tipo de unidades organizativas, usuarios o recursos.</p> <p>Por otra parte, gracias al uso de un atributo especial llamado objectClass, podemos controlar qu\u00e9 atributos son v\u00e1lidos y cu\u00e1les imprescindibles en una entrada. Los valores de objectClass establecen las reglas que debe seguir el valor de una entrada.</p> <p>L\u00f3gicamente, LDAP establece operaciones para consultar o actualizar el directorio. Estas nos permiten crear o eliminar entradas y modificar entradas existentes.</p> <p>La mayor parte del tiempo, LDAP se utiliza para diversas consultas sobre la informaci\u00f3n que contiene, por lo que es com\u00fan que la estructura de su base de datos se encuentre optimizada para la lectura en detrimento de la escritura.</p> <p>Como vemos, LDAP puede utilizarse para organizar de forma unificada el acceso a la informaci\u00f3n representativa de una red. Sin embargo, es muy frecuente que tambi\u00e9n almacene la informaci\u00f3n de autenticaci\u00f3n para los usuarios y/o recursos. De esta forma, se facilita el control de acceso sobre los datos contenidos en el servidor.</p> <p>Aunque ya hemos visto al principio un esquema de funcionamiento mucho m\u00e1s detallado, podr\u00edamos representar el funcionamiento de LDAP de una forma m\u00e1s abstracta con el siguiente esquema:</p> <p></p> <p>Por \u00faltimo, LDAP incluye servicios de integridad y confidencialidad de los datos que contiene.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#integracion-del-servicio-de-directorio-con-otros-servicios","title":"Integraci\u00f3n del servicio de directorio con otros servicios.","text":"<p>De lo expuesto anteriormente puede deducirse que el servicio de directorio es importante en s\u00ed mismo, pero es fundamental para aglutinar informaci\u00f3n que puede ser fuente de objeto para desplegar nuevos servicios basados en la cooperaci\u00f3n entre las distintas aplicaciones y el servicio de directorio.</p> <p>As\u00ed, el servicio de directorio puede actuar como servidor de autenticaci\u00f3n, proporcionando el servicio de contrase\u00f1a \u00fanica. Adem\u00e1s puede contener informaci\u00f3n necesaria para que los distintos servidores puedan decidir si un usuario puede acceder a determinada informaci\u00f3n.</p> <p>Puedes utilizar el servicio de directorio como repositorio en el cual almacenar la informaci\u00f3n que varios servidores deben compartir, por ejemplo: la configuraci\u00f3n, informaci\u00f3n sobre el control de acceso, etc.</p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#el-formato-de-intercambio-de-datos-ldif","title":"El formato de intercambio de datos LDIF","text":"<p>El formato LDIF es el est\u00e1ndar para representar entradas del directorio en formato texto ASCII, que posee la siguiente sintaxis:</p> <pre><code>dn: &lt;nombre distinguido&gt;\n&lt;nombre_atributo&gt;: &lt;valor&gt;\n&lt;nombre_atributo&gt;: &lt;valor&gt;\n&lt;nombre_atributo&gt;: &lt;valor&gt;\n</code></pre> <p>As\u00ed, una entrada del directorio en formato de intercambio de datos LDIF consiste en dos partes:</p> <ul> <li> <p>El DN que debe figurar en la primera l\u00ednea de la entrada y que se compone de la cadena dn: seguida del nombre distinguido (DN) de la entrada.</p> </li> <li> <p>Los atributos de la entrada.</p> <ul> <li>Cada atributo se compone de un nombre de atributo, seguido del car\u00e1cter dos puntos ':' y el valor del atributo. </li> <li>Si hay atributos multivaluados deben ponerse seguidos.</li> <li>No existe ning\u00fan orden preestablecido para la colocaci\u00f3n de los atributos, pero es conveniente listar primero el atributo objectclass, para mejorar la legibilidad de la entrada.</li> </ul> </li> </ul> <p>En un archivo LDIF puede haber mas de una entrada definida, cada entrada se separa de las dem\u00e1s por una l\u00ednea en blanco. A su vez, cada entrada puede tener una cantidad arbitraria de pares <code>&lt;nombre_atributo&gt;:&lt;valor&gt;</code>.</p> <p>Este formato es \u00fatil tanto para realizar copias de seguridad de los datos de un servidor LDAP, como para importar peque\u00f1os cambios que se necesiten realizar manualmente en los datos, siempre manteniendo la independencia de la implementaci\u00f3n LDAP y de la plataforma donde est\u00e9 instalada.</p> <p>A continuaci\u00f3n puedes observar un ejemplo de una entrada para describir una cuenta de usuario en un servidor:</p> <pre><code>dn: uid=upruebas,ou=People,dc=ejemplo,dc=com\nobjectclass: account\nobjectclass: posixAccount\nobjectclass: topuid: upruebas\ncn: Usuario Pruebas\nloginshell: /bin/bash\nuidnumber: 512\ngidnumber: 300\nhomedirectory: /home/upruebas\ngecos: Usuario Pruebas\nuserpassword: 123456\n</code></pre> <p>Crear\u00edamos un archivo de texto con la extensi\u00f3n ldif, por ejemplo <code>usuariopruebas.ldif</code> y lo a\u00f1adir\u00edamos con el comando <code>ldapadd</code>.</p> <p>Lo veremos en detalle en la pr\u00e1ctica. </p>"},{"location":"Ud4%20Servicios%20de%20red%20DNS%20y%20LDAP/T03/#referencias","title":"Referencias","text":"<p>Servicios de red implicados en el despliegue de una aplicaci\u00f3n web.</p> <p>Sistemas Operativos en Red - Cap\u00edtulo 11. Instalar y configurar OpenLDAP</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P01/","title":"Pr\u00e1ctica 1 - Acceso a un servidor FTP p\u00fablico ftp.rediris.es","text":""},{"location":"Ud5%20Servicios%20de%20red%20FTP/P01/#objetivo","title":"Objetivo.","text":"<p>Conectarse a un servidor p\u00fablico utilizando los comandos b\u00e1sicos de ftp y descargar un archivo.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P01/#acceso-en-modo-comando","title":"Acceso en modo comando.","text":"<p>Vamos a conectarnos a un servidor FTP p\u00fablico desde una ventana de comando de tu sistema operativo.</p> <ul> <li>Abre un terminal cmd en Linux</li> <li>PowerShell en Windows</li> <li>Terminal en Mac OS X</li> </ul> <p>Utiliza el comando ftp, esto har\u00e1 que entres dentro del servidor ftp de tu ordenador y visualiza los comandos ftp disponibles en tu m\u00e1quina con el comando help.</p> <p>Note</p> <p>Si en Mac OSX no tienes el comando <code>ftp`` disponible puedes instalarlo con</code>brew install lftp<code>y usar el comando</code>lftp` en su lugar.</p> <pre><code>ftp\n</code></pre> <pre><code>help\n</code></pre> <p></p> <p>Vamos a conectar con una red p\u00fablica como es ftp.rediris.es con el usuario an\u00f3nimo, por lo que no hace falta registrarse con ning\u00fan usuario, pulsamos intro cuando nos pida el usuario. </p> <p><pre><code>open ftp.rediris.es\n</code></pre> </p> <p>Posteriormente vamos listar el contenido de archivo y directorios y accederemos a la carpeta /debian/doc para descargar el archivo constitution.txt, para ello sigue las indicaciones siguientes </p> <p><pre><code>get constitution.txt\n</code></pre> </p> <p>Para comprobar que se ha descargado correctamente, salimos del servidor ftp y listamos los archivos de nuestra m\u00e1quina. Donde podemos observar que el archivo se ha descargado correctamente. <pre><code>quit\n</code></pre> </p> <p>Warning</p> <p>En definitiva los permisos del usuario an\u00f3nimo en un servidor ftp se establecer\u00e1n para que solamente pueda moverse por los directorios y descargar archivos, nunca subirlos, esto es, normalmente el usuario an\u00f3nimo no podr\u00e1 crear ni eliminar ficheros y directorios.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P01/#acceso-desde-cliente-grafico","title":"Acceso desde cliente gr\u00e1fico.","text":"<p>Vamos a ver ahora c\u00f3mo acceder a un servidor FTP desde un cliente gr\u00e1fico. Usaremos FileZilla por tratarse de un SW de c\u00f3digo abierto y disponible para todos los sistemas operativos m\u00e1s utilizados.</p> <p>Abre Filezilla y ver\u00e1s el entorno similar a este.</p> <p></p> <p>Ahora vamos a conectarnos a ftp.rediris.es. Prueba a hacer una conexi\u00f3n r\u00e1pida poniendo el servidor y usuario \"anonymous\" e intenta conectarte. Observa los mensajes que obtienes. \u00bfHas podido conectarte? \u00bfSabes por qu\u00e9 no puedes?</p> <p>Si miras bien los mensajes ver\u00e1s que has llegado al servidor, has autenticado pero obtienes un error que dice <code>Error: Se ha recibido una alerta TLS del servidor: Handshake failed (40)</code></p> <p>El motivo es que el FTP plano, sin cifrado, no es la opci\u00f3n por defecto y la conexi\u00f3n r\u00e1pida est\u00e1 intentando usar cifrado TSL.</p> <p>As\u00ed que vamos a crear una conexi\u00f3n avanzada.</p> <p></p> <p>Ahora crea un \"Nuevo sitio\" sin cifrado como en la imagen.</p> <p></p> <p>Acepta los mensajes que te previenen de usar FTP sin cifrado. Comprueba en los mensajes que has podido conectarte al servidor.</p> <p></p> <p>En la parte izquierda de la pantalla tendr\u00e1s un navegador que te permitir\u00e1 moverte por la estructura de directorios de tu equipo local. En la derecha podr\u00e1s moverte por el sitio remoto.</p> <p>Selecciona ahora en la izquierda donde quieres descargarte el archivo y en la derecha busca <code>/debian/doc/constitution.txt</code> como hicimos por comando.</p> <p>Haz doble clic sobre el archivo para descargarlo. Tambi\u00e9n puedes hacer clic con el bot\u00f3n derecho y \"Descargar\".</p> <p>Comprueba c\u00f3mo se descarga tu archivo.</p> <p>Para finalizar la conexi\u00f3n selecciona el icono de desconectar.</p> <p></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P01/#conclusion","title":"Conclusi\u00f3n","text":"<p>En esta pr\u00e1ctica has aprendido a conectarte a un servidor FTP y descargarte archivos tanto por comando como con un programa gr\u00e1fico.</p> <p>A partir de ahora configuraremos el servidor, pero necesitar\u00e1s hacer pruebas desde el cliente para probar las distintas configuraciones.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/","title":"Pr\u00e1ctica 2 - Instalar y Configurar el servidor vsFTPd sin cifrado.","text":"<p>En esta pr\u00e1ctica, aprenderemos c\u00f3mo instalar y configurar un servidor FTP usando vsFTPd en un servidor basado en Debian. En esta primera pr\u00e1ctica configuraremos el servidor como FTP sin cifrado. Es una manera de configuraci\u00f3n insegura que usaremos solo desde un punto de vista did\u00e1ctico.</p> <p>Informaci\u00f3n b\u00e1sica sobre el servidor vsFTPd (Very Secure FTP Daemon):</p> <p>Hoy en d\u00eda existe una amplia gama de servidores FTP de c\u00f3digo abierto, como FTPD, vsFTPd, PROFTPD y pureftpd. Entre todos ellos, vsFTPd es un protocolo muy seguro, r\u00e1pido y el m\u00e1s utilizado para transferir archivos entre dos sistemas. vsFTPd tambi\u00e9n se conoce como \u00abDemonio de Protocolo de Transferencia de Archivos Muy Seguro\u00bb con soporte de SSL, IPv6, FTPS expl\u00edcito e impl\u00edcito.</p> <p>Archivos y directorios que se crean en el sistema:</p> <ul> <li>El archivo <code>/etc/init.d/vsftpd</code> es el script de inicio en sistemas basados en Linux que permite administrar el servicio vsftpd, a trav\u00e9s de  tareas como iniciar, detener, reiniciar y administrar el servicio de FTP. Por ejemplo un comando para iniciar el servicio en Ubuntu ser\u00eda este: <code>systemctl start vsftpd</code> , entre otros (stop, restart, reload, status).</li> <li>El archivo <code>/usr/sbin/vsftpd</code> este archivo es el binario principal que se utiliza para iniciar y ejecutar el servidor vsFTPd. Es responsable de escuchar en el puerto FTP (por lo general, el puerto 21) y gestionar las conexiones de los clientes FTP. Este archivo lee la configuraci\u00f3n del archivo <code>/etc/vsftpd.conf</code> al iniciarse para personalizar el comportamiento del servidor FTP. </li> <li>El archivo <code>/etc/vsftpd.conf</code> es el archivo de configuraci\u00f3n principal del servidor vsFTPd donde se especifican numerosos par\u00e1metros de configuraci\u00f3n que controlan el comportamiento y la seguridad del servidor FTP.</li> <li>El directorio <code>/srv/ftp</code> este directorio ra\u00edz por defecto del servidor FTP, que se utiliza para organizar y administrar los archivos y directorios que est\u00e1n disponibles para los usuarios que se conectan al servidor FTP. Es donde se alojar\u00e1n los archivos para usuarios an\u00f3nimos (accesos an\u00f3nimos) sino se indica lo contrario en la configuraci\u00f3n.</li> <li>El archivo <code>/etc/ftpusers</code> tiene como funci\u00f3n denegar el acceso a ciertos usuarios, evitando que puedan autenticarse y utilizar los servicios de FTP.</li> <li>El archivo <code>/etc/vsftpd.user_list</code> se utiliza para controlar el acceso permitido a un grupo espec\u00edfico de usuarios. Este archivo no se instala, por lo cual hay que crearlo antes de comenzar a trabajar con la configuraci\u00f3n.</li> <li>El archivo <code>/etc/vsftpd.chroot_list</code> tiene como prop\u00f3sito principal controlar qu\u00e9 usuarios pueden ser \"encarcelados\" en sus respectivos directorios de inicio (chroot) cuando se conectan al servidor FTP.</li> <li>El archivo <code>/var/log/vsftpd.log</code> es un archivo de registro \u00fatil para el monitoreo, la soluci\u00f3n de problemas y la auditor\u00eda de actividades en el servidor FTP.</li> </ul> <p>Para m\u00e1s informaci\u00f3n puedes consultar la comunidad vsFTPd : https://help.ubuntu.com/community/vsftpd</p> <p>Vamos a empezar a trabajar. </p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#creamos-una-instancia-aws","title":"Creamos una instancia AWS","text":"<p>Vamos a instalar el servidor vsFTPd en una VM Debian en AWS. Crear una instancia nueva que llamar\u00e1s P4-vsFTPd</p> <p>A\u00f1ade una Regla de Entrada: En la pesta\u00f1a \"Reglas de entrada\", debes a\u00f1adir una regla para permitir el tr\u00e1fico en el puerto FTP que necesitas. </p> <ul> <li>Para FTP no cifrado (puerto 21), crea una regla con el protocolo TCP y el puerto 21.</li> <li>Para FTPS o SFTP con cifrado (puerto 22), tambi\u00e9n crea una regla con el protocolo TCP y el puerto 22.</li> </ul> <p>Aseg\u00farate de especificar la fuente del tr\u00e1fico, lo que puede ser tu propia direcci\u00f3n IP si deseas acceder al servidor FTP desde tu ubicaci\u00f3n actual o cualquier otra fuente si deseas permitir el acceso desde cualquier lugar (ten en cuenta que esto puede ser menos seguro).</p> <p></p> <p>Ahora vamos a instalar y configurar vsFTPd para el acceso de usuarios locales (es decir, usuarios que existen en el sistema operativo donde est\u00e1 instalado el servidor FTP), que solo podr\u00e1n acceder a su carpeta de usuarios (chroot). Adem\u00e1s les permitiremos subir ficheros.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#paso-1-instalacion-del-servidor-vsftpd","title":"Paso 1. Instalaci\u00f3n del servidor vsFTPd","text":"<p>En primer lugar, actualizaremos los repositorios de Ububtu y a continuaci\u00f3n instalaremos el servidor vsFTPd :</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\nsudo apt-get install vsftpd\n</code></pre> <p>Se crea el usuario ftp dentro del fichero /etc/passwd, y el grupo ftp en /etc/group del Servidor Linux. Puedes comprobarlo visualizando ambos ficheros.</p> <pre><code>cat /etc/passwd\ncat /etc/group\n</code></pre> <p>Para comprobar que el servidor se ha iniciado comprobamos que el servicio est\u00e1 en marcha:</p> <pre><code>systemctl status vsftpd\n</code></pre> <p>Tambi\u00e9n podr\u00edamos comprobar que el proceso vsftpd est\u00e1 funcionando.</p> <p><pre><code>ps -ef | grep vsftpd\n</code></pre> Vemos que aparecen el proceso con el archivo de configuraci\u00f3n  /etc/vsftpd.conf y el archivo ejecutable principal del servidor FTP vsFTPd /usr/sbin/vsftpd </p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#paso-2-configuramos-usuario-de-pruebas","title":"Paso 2. Configuramos usuario de pruebas.","text":"<p>Recordamos de la teor\u00eda que el servidor FTP puede configurarse para que lo usen 3 tipos distintos de usuarios:</p> <ol> <li>Usuario an\u00f3nimo</li> <li>Usuarios locales (del sistema)</li> <li>Usuarios virtuales (independientes de los del sistema y creados por el administrador)</li> </ol> <p>En este m\u00f3dulo de Despliegue de aplicaciones nos interesa usar FTP para subir nuestros ficheros al servidor donde est\u00e1 alojado nuestro servidor web o servidor de aplicaciones, as\u00ed que no nos interesa mucho configurar el usuario an\u00f3nimo. Nos centraremos en trabajar con usuarios locales, que nos ofrece la funcionalidad que necesitamos.</p> <p>Empezaremos por crear un usuario que llamaremos <code>userftp</code> y que utilizaremos el resto de la pr\u00e1ctica para transacciones FTP. Utilizando este usuario iniciaremos la sesi\u00f3n en el servidor FTP m\u00e1s adelante. Estableceremos como contrase\u00f1a \"ieselcaminas\".</p> <pre><code>sudo adduser userftp\n</code></pre>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#paso-3-configuracion-del-servidor-vsftpd","title":"Paso 3. Configuraci\u00f3n del servidor vsFTPd","text":"<p>Ahora repasaremos algunas configuraciones importantes para que vsFTPd funcione. Para ello buscamos el archivo de configuraci\u00f3n y guardamos una copia de \u00e9l por si acaso: </p> <p><pre><code>sudo cp /etc/vsftpd.conf /etc/vsftpd.conf.backup\n</code></pre> Comienza abriendo el archivo de configuraci\u00f3n.</p> <pre><code>sudo nano /etc/vsftpd.conf\n</code></pre> <p>Ahora vamos a ir probando distintas configuraciones y veremos c\u00f3mo afectan a la funcionalidad.</p> <p>1. Acceso FTP a usuarios locales</p> <p>En este tutorial, permitiremos el acceso FTP solo a los usuarios locales y deshabilitaremos cualquier acceso an\u00f3nimo. Esta es la configuraci\u00f3n por defecto cuando instalamos vsftpd. Comprueba estas 2 l\u00edneas en el fichero <code>/etc/vsftpd.conf</code></p> <pre><code>  anonymous_enable=NO #(1)\n  local_enable=YES #(2)\n</code></pre> <ol> <li>No permitimos el acceso an\u00f3nimo</li> <li>Permitimos el acceso de los usuarios del sistema</li> </ol> <p>Guarda el fichero, y reinicia el servicio vsftpd para habilitar la configuraci\u00f3n realizada.</p> <p><pre><code>sudo systemctl restart vsftpd\n</code></pre> A continuaci\u00f3n, aseg\u00farate de que el servicio vsftpd est\u00e1 en su estado de ejecuci\u00f3n ejecutando el siguiente comando en el Terminal:</p> <pre><code>sudo systemctl status vsftpd\n</code></pre> <p>Recuerda para volver al prompt , debes pulsar q  </p> <p>Prueba a conectarte con el usuario <code>userftp</code> con tu cliente FTP. </p> <p>Atenci\u00f3n</p> <p>Si tienes problemas con la conexi\u00f3n recuerda que FTP tiene 2 modos, activo y pasivo y que en funci\u00f3n de la configuraci\u00f3n del firewall de servidor y cliente puede ser m\u00e1s adecuado uno que otro.</p> <p>2. Habilitar modo de conexi\u00f3n activa/pasiva </p> <p>VSFTPD usa el modo activo de FTP de manera predeterminada, lo que puede causar problemas de conexi\u00f3n cuando los clientes de FTP usan el modo pasivo en su lugar. Lo que podemos hacer es habilitar en el Cliente FTP la opci\u00f3n de conexi\u00f3n activa o habilitar en nuestro servidor vsftpd el modo pasivo, como se realiza en la pr\u00e1ctica siguiente.</p> <p>Una vez ya te has conectado al servidor prueba a moverte por los distintos directorios del equipo  \u00bfTienes alguna restricci\u00f3n? \u00bfPuedes acceder a cualquier directorio? \u00bfHas probado a acceder a /root? \u00bfTe puedes descargar /etc/vsftpd.conf? \u00bfPuedes subir un archivo de tu equipo local a /home/userftp en el servidor?</p> <p>3. Habilitar la carga de archivos</p> <p>Lo m\u00e1s probable es que la respuesta a la \u00faltima pregunta fuera no. Por defecto la carga de ficheros al servidor est\u00e1 deshabilitada. El prop\u00f3sito singular m\u00e1s importante de FTP aqu\u00ed es poder escribir en el servidor. Descomenta la siguiente l\u00ednea para habilitar la carga de archivos eliminando # delante de ella.</p> <pre><code>  write_enable=YES\n</code></pre> <p>Reinicia nuevamente el servidor. Prueba a cargar en /home/userftp el archivo /etc/vsftpd.conf que intentaste descargaste antes. \u00bfAhora puedes? \u00bfY con qu\u00e9 permisos se carga el fichero en la carpeta?</p> <p>Prueba a cargarlo en /etc. \u00bfPuedes? \u00bfPor qu\u00e9 no?</p> <p>4. Permisos de los archivos subidos</p> <p>Al subir el fichero vsftpd.conf a /home/userftp los permisos son estos, \u00bfverdad?</p> <p><code>-rw-------</code> o dicho en octal <code>600</code>.</p> <p>Si buscas en el fichero de configuraci\u00f3n ver\u00e1s que habla de \"umask\" y dice esto</p> <pre><code># Default umask for local users is 077. You may wish to change this to 022,\n# if your users expect that (022 is used by most other ftpd's)\n#local_umask=022\n</code></pre> <p>Nos dice que umask es 077, pero los permisos del fichero que hemos subido son 600. \u00bfQu\u00e9 pasa aqu\u00ed? Los permisos por defecto al subir un fichero son 666 (rw-rw-rw- o 110110110) y a esos permisos se les hace un AND con la m\u00e1scara definida con umask \u00a1pero negada! Si la umask es 077 (---rwxrwx o 000111111) y la negamos obtenemos 700=111000000. Si hacemos el AND obtenemos:</p> <pre><code>110110110 = 666\n111000000 = 700\n---------\n110000000 = 600\n</code></pre> <p>Y aqu\u00ed tenemos el 600 o rw------- que nos hab\u00eda salido antes. </p> <p>En los servidores FTP lo habitual es que la umask sea 022. \u00bfQu\u00e9 permisos tendr\u00e1 un fichero al subirlo con esa m\u00e1scara?</p> <p>Prueba a descomentar esta l\u00ednea, reinicia el servicio, sube un fichero a <code>/home/userftp</code> y compru\u00e9ba sus permisos. Esto ser\u00e1 importante para cuando subas una p\u00e1gina web al servidor web usando FTP. Recuerda que los ficheros necesitaban unos permisos concretos para que pudieran visualizarse.</p> <p>5. C\u00e1rcel de Chroot para los usuarios locales</p> <p>Como vimos antes el usuario, al conectarse por FTP pod\u00eda navegar por todo el sistema de archivos. Esto no es muy recomendado y podemos hacer el usuario que est\u00e1 restringido a un directorio determinado.  El servidor vsFTPd logra eso usando chroot jails, de manera que cuando chroot est\u00e1 habilitado para usuarios locales, estos usuarios est\u00e1n restringidos a sus directorios de inicio de forma predeterminada. Para lograr esto, cambiamos la configuraci\u00f3n con las propiedades siguientes:</p> <p><pre><code>chroot_local_user=YES\n</code></pre> Para evitar cualquier vulnerabilidad de seguridad, cuando chroot est\u00e1 habilitado, no funcionar\u00e1 si el directorio ra\u00edz al que se conectan los usuarios es escribible. Por tanto, si no hacemos nada m\u00e1s e intentamos conectarnos veremos que no nos deja, ya que <code>userftp</code> si puede escribir en su directorio home: <code>/home/userftp</code>. Para sortear esta limitaci\u00f3n, tenemos varias opciones de configuraci\u00f3n:</p> <ul> <li>Opci\u00f3n 1 \u2013 Simplemente permitir que el directorio ra\u00edz al que nos conectamos s\u00ed pueda ser escribible.</li> </ul> <p>En ese caso, agregamos la siguiente l\u00ednea. Haz la prueba, reinicia vsftpd e intenta conectarte. Despu\u00e9s deshabilita esta opci\u00f3n, ya que no es la que usaremos.</p> <pre><code>allow_writeable_chroot=YES\n</code></pre> <ul> <li>Opci\u00f3n 2 \u2013 Definir un directorio de acceso por FTP distinto al home del usuario y sin permisos de escritura.</li> </ul> <p>Se debe utilizar un directorio diferente para cargas FTP. Crearemos un directorio <code>/home/userftp/ftp</code> al que quitaremos los permisos de escritura para todo el mundo que servir\u00e1 como chroot. Pero antes de quitarle los permisos de escritura, crearemos un segundo directorio <code>/home/userftp/ftp/upload</code> para la carga de archivos, este s\u00ed tendr\u00e1 permisos de escritura. Para configurar esta opci\u00f3n de chroot, agregamos las siguientes l\u00edneas al fichero de configuraci\u00f3n.</p> <p><pre><code>user_sub_token=userftp\nlocal_root=/home/userftp/ftp\n</code></pre> Prueba a conectarte por ftp con el usuario <code>userftp</code> y comprueba que su directorio ra\u00edz ahora es <code>/home/userftp/ftp</code> y que ah\u00ed no puedes subir ning\u00fan fichero. Prueba a subir a <code>upload</code> y comprueba que en este directorio s\u00ed puedes.</p> <p>En el caso anterior servir\u00e1 solo para el usuario <code>userftp</code>. Si lo queremos hacer para todos los usuarios del sistema usaremos estas directivas en su lugar :</p> <pre><code>user_sub_token=$USER\nlocal_root=/home/$USER/ftp\n</code></pre> <p>Ahora crea un segundo usuario, por ejemplo <code>user2</code>. Crea los directorios <code>/home/user2/ftp</code> sin permiso de escritura y <code>/home/user2/ftp/upload</code> con permiso de escritura. Con\u00e9ctate con <code>user2</code> y comprueba lo dicho anteriormente.</p> <p>Elimina las directivas <code>user_sub_token</code> y <code>local_root</code> para probar la opci\u00f3n 3.</p> <ul> <li>Opci\u00f3n 3 \u2013 Enjaular al usuario en otra carpeta distinta, por ejemplo /var/www</li> </ul> <p>Suele ser normal querer que el usuario pueda ver un directorio distinto al de su home, como por ejemplo la carpeta www o la de un servidor virtual concreto de apache, para ello, la soluci\u00f3n m\u00e1s r\u00e1pida es cambiar el directorio home del usuario de la siguiente forma. Para hacer esta prueba, antes instala APACHE si no estaba instado.</p> <pre><code>sudo usermod --home /var/www userftp\n</code></pre> <p>Comprobamos con:</p> <pre><code>su userftp\ncd\npwd\n</code></pre> <p>Vuelve al usuario admin con <code>exit</code>.</p> <p>Con esto habremos cambiado el directorio home del usuario y cada vez que se conecte tanto por FTP como por SSH entrar\u00e1 al directorio /var/www. Compru\u00e9balo. Si quisieramos subir archivos a la web s\u00f3lo nos quedar\u00eda, para este caso, a\u00f1adir el usuario al grupo de apache o www-data dependiendo del sistema operativo o el usuario apache configurado.</p> <pre><code>sudo adduser userftp www-data\n</code></pre> <p>6. Restricci\u00f3n de usuarios</p> <p>Para permitir que s\u00f3lo ciertos usuarios inicien sesi\u00f3n en el servidor FTP, agregamos las siguientes l\u00edneas en la parte inferior. Con esta opci\u00f3n habilitada, debemos especificar qu\u00e9 usuarios deber\u00edan poder usar FTP y agregar sus nombres de usuario en el archivo <code>/etc/vsftpd.userlist</code>.</p> <pre><code>userlist_enable=YES #(1)\nuserlist_file=/etc/vsftpd.userlist #(2)\nuserlist_deny=NO #(3)\n</code></pre> <ol> <li>Hace que solo puedan conectarse o impide que se puedan conectar los usuarios de la lista</li> <li>Lista donde se definen qu\u00e9 usuarios pueden conectarse o no conectarse</li> <li>Si el valor es YES a los usuarios de la lista se les deniega el acceso. Si es NO se les permite</li> </ol> <p>Agregamos el nuevo usuario <code>userftp</code> a la lista de usuarios de FTP permitidos, con este comando o con nano.</p> <pre><code>echo \"userftp\" | sudo tee -a /etc/vsftpd.userlist\n</code></pre> <p>Guarda y cierra el archivo. Reinicia el servidor e intenta conectarte con <code>userftp</code>. Comprueba que funciona. Intenta conectarte ahora con <code>user2</code>. \u00bfTe lo permite?</p> <p>Despu\u00e9s de todas estas pruebas vamos a dejarlo de la siguiente manera para las comprobaciones finales:</p> <ol> <li>Deja que s\u00f3lo puedan conectarse los usuarios locales.</li> <li>Habilita la carga de archivos.</li> <li>Haz que los archivos se suban con umask 022.</li> <li>Habilita chroot con la opci\u00f3n 2, es decir, que cada usuario del sistema se conecte a <code>/home/$USER/ftp</code></li> <li>Restringe para que solo <code>userftp</code> pueda conectarse por FTP</li> <li>Agrega un archivo <code>pruebaftp.txt</code> en <code>/home/userftp/ftp/upload/</code> para usar en las pruebas.</li> </ol> <pre><code>echo \"esto es una prueba con vsftpd\" | sudo tee /home/userftp/ftp/upload/pruebaftp.txt\n</code></pre>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#paso-4-comprobacion-del-acceso-ftp","title":"Paso 4: Comprobaci\u00f3n del acceso FTP","text":"<p>Nuestro servidor FTP es completamente funcional en este momento. Podemos hacer una peque\u00f1a prueba antes de continuar.</p> <p>Intentemos iniciar sesi\u00f3n como un usuario an\u00f3nimo. Vemos que funciona seg\u00fan lo previsto, es decir, no se permiten usuarios an\u00f3nimos.</p> <p></p> <p>Ahora vamos a conectarnos como usuario de prueba <code>userftp</code> que creamos para acceder al servidor FTP. </p> <p></p> <p>Cambiemos al directorio de carga y usemos el comando get para transferir el archivo de prueba a nuestra m\u00e1quina local.</p> <p></p> <p>A continuaci\u00f3n, subamos el archivo con un nuevo nombre usando el comando put para probar los permisos de escritura del archivo.</p> <p></p> <p>Cierra la conexi\u00f3n. <pre><code>ftp&gt; bye\n</code></pre></p> <p>Finalmente comprobaci\u00f3n que la descarga se ha producido.</p> <p>Comprobamos que el archivo se ha descargado correctamente en nuestra m\u00e1quina local. La descarga la dejar\u00e1 en la misma carpeta donde se haya producido la conexi\u00f3n ftp. En nuestro caso, la misma carpeta que nos encontremos al salir con el quit.</p> <p></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P02/#referencias","title":"Referencias","text":"<ul> <li>vsftpd - Ubuntu documentation</li> <li>VSFTPD: Instalaci\u00f3n y chroot a una carpeta de usuario.</li> <li>How To Set Up vsftpd for a User's Directory on Ubuntu 16.04</li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/","title":"Pr\u00e1ctica 3. Configuraci\u00f3n de servidor FTP con Cifrado","text":"<p>En esta pr\u00e1ctica, aprenderemos c\u00f3mo asegurar la conexi\u00f3n usando el protocolo SSL/TLS, de esta forma se podr\u00e1n transferir datos encriptados a trav\u00e9s de FTP.</p> <p>Recuerda de la teor\u00eda que hay 2 modos de conexi\u00f3n cifrada de FTP, FTPS y SFTP y que no tienen nada que ver en cuanto a configuraci\u00f3n y funcionamiento.</p> <ul> <li>FTPS (File Transfer Protocol Secure) - Es a FTP lo que HTTPS a HTTP. Es el servidor FTP quien define sus claves p\u00fablica y privada. Comparte su clave p\u00fablica con el cliente que quiere conectarse a \u00e9l para establecer el canal privado. Por tanto requiere de la generaci\u00f3n de dichas claves en el servidor y la configuraci\u00f3n en vsftpd.conf. Adem\u00e1s tiene 2 formas de conexi\u00f3n<ul> <li>FTPS Expl\u00edcito (FTPES): En este modo, la seguridad SSL/TLS se inicia despu\u00e9s de que el cliente se conecta al servidor y emite un comando espec\u00edfico (por ejemplo, AUTH TLS o AUTH SSL) para solicitar una conexi\u00f3n segura. Por tanto la primera conexi\u00f3n del cliente al servidor es por el puerto habitual de comandos de FTP, el 21.</li> <li>FTPS Impl\u00edcito (FTPIS): En este modo, la seguridad SSL/TLS se establece autom\u00e1ticamente cuando el cliente se conecta al servidor en un puerto espec\u00edfico (generalmente el puerto 990 para FTPS impl\u00edcito).</li> </ul> </li> <li>SFTP (SSH File Transfer Protocol) - Aqu\u00ed primero se establece un canal SSH entre cliente y servidor SSH (no vsftpd) a trav\u00e9s del puerto habitula ssh, el 22.. Una vez establecido el canal el cliente ftp y vsftpd intercambian mensajes cifrados dentro de ese canal. Por tanto, vsftpd no necesita ninguna configuraci\u00f3n especial</li> </ul> <p>En esta pr\u00e1ctica veremos las 2 formas de funcionamiento y conexi\u00f3n.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#instancia-en-aws","title":"Instancia en AWS","text":"<p>Primero abriremos la instancia AWS P4-vsftpd creada en la pr\u00e1ctica anterior, donde ya ten\u00edamos instalado el servidor vsftpd y usuarios con permisos a FTP.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#servidor-vsftpd","title":"Servidor vsftpd","text":"<p>Comprobamos el estado del servicio y en caso de que no est\u00e9 habilita el servicio al inicio.</p> <pre><code>sudo systemctl status vsftpd\n</code></pre> <p>En caso de que no est\u00e9 iniciado el servicio, realizar estos pasos;</p> <pre><code>sudo systemctl start vsftpd\nsudo systemctl enable vsftpd.service\n</code></pre>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#ftps-file-transfer-protocol-secure","title":"FTPS (File Transfer Protocol Secure)","text":"<p>Veamos primero la configuraci\u00f3n y conexi\u00f3n a trav\u00e9s de FTPS.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#generar-un-certificado-autofirmado-con-openssl","title":"Generar un certificado autofirmado con OpenSSL","text":"<p>Ya hemos visto que el servidor vsftpd admite FTPS (FTP sobre SSL/TLS), es decir que cifra las comunicaciones entre el cliente y el servidor. As\u00ed que para poder transferir datos encriptados a trav\u00e9s de FTP, necesitaremos crear un certificado SSL y habilitar la conexi\u00f3n SSL/TLS. Por ello vamos a utilizar OpenSSL con el siguiente comando;</p> <p><pre><code>sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/vsftpd.pem -out /etc/ssl/private/vsftpd.pem\n</code></pre> Tenemos que tener en cuenta que nos pedir\u00e1 que ingresemos cierta informaci\u00f3n, como el pa\u00eds, el estado/provincia y el nombre com\u00fan. Puede ingresar los valores que desee o dejarlos en blanco.</p> <p>Este comando genera un certificado SSL autofirmado v\u00e1lido por 365 d\u00edas y guarda la clave privada y el certificado en <code>/etc/ssl/private/vsftpd-cert.pem</code></p> <p>Podemos comprobarlo con el comando  <pre><code>sudo ls -l /etc/ssl/private\n</code></pre></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#configurar-el-servidor-vsftpd","title":"Configurar el servidor vsftpd","text":"<p>1. Habilitar el cifrado SSL</p> <p>Una vez que tengamos el certificado SSL y la clave privada, tendremos que modificar el archivo /etc/vsftpd.conf. Para ello buscamos el archivo de configuraci\u00f3n y guardamos una copia de \u00e9l por si acaso: </p> <p><pre><code>sudo cp /etc/vsftpd.conf /etc/vsftpd.conf.backup2\n</code></pre> Pasamos a modificar el archivo de configuraci\u00f3n utilizando un editor.</p> <p><pre><code>sudo nano /etc/vsftpd.conf\n</code></pre> En primer lugar, buscaremos las siguientes l\u00edneas del archivo y las eliminaremos o comentaremos con #:</p> <p><pre><code>rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nrsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nssl_enable=NO\n</code></pre> Tras ello, a\u00f1adiremos estas l\u00edneas en su lugar;</p> <pre><code>rsa_cert_file=/etc/ssl/private/vsftpd.pem\nrsa_private_key_file=/etc/ssl/private/vsftpd.pem\nssl_enable=YES\n\nallow_anon_ssl=NO\nforce_local_data_ssl=YES\nforce_local_logins_ssl=YES\nssl_tlsv1=YES\nssl_sslv2=NO\nssl_sslv3=NO\nrequire_ssl_reuse=NO\nssl_ciphers=HIGH\n</code></pre> <p>Al conectarnos utilizando FTPS el servidor forzar\u00e1 al cliente a realizar una conexi\u00f3n pasiva por segurida, como vimos en la teor\u00eda. Si no hacemos nada m\u00e1s, tras el primer intercambio de \u00f3rdenes a trav\u00e9s del puerto 21, la conexi\u00f3n no podr\u00e1 establecerse por el puerto de datos y obtendremos un mensaje similar a este \"El servidor envi\u00f3 una respuesta pasiva con una direcci\u00f3n no enrutable. Usando en su lugar la direcci\u00f3n del servidor.\"</p> <p>2. Habilitar el modo pasivo</p> <p>Para evitar que esto ocurra, definiremos los puertos que puede abrir el servidor para el canal de datos en la conexi\u00f3n pasiva en el fichero /etc/vsftpd.conf con las siguientes \u00f3rdenes:</p> <p><pre><code>pasv_enable=YES\npasv_min_port=1027  # Puerto m\u00ednimo de conexi\u00f3n pasiva (reemplaza XXXX con un n\u00famero)\npasv_max_port=1030  # Puerto m\u00e1ximo de conexi\u00f3n pasiva (reemplaza XXXX con un n\u00famero)\npasv_address=X.X.X.X  # Direcci\u00f3n IP p\u00fablica o accesible desde el cliente (reemplaza X.X.X.X con la direcci\u00f3n IP)\n</code></pre> En este caso hemos elegido los puertos 1027 a 1030, pero puedes elegir otros que est\u00e9n libres. Ten en cuenta que deber\u00e1s abrir esos puertos en el firewall de AWS para permitir conexiones a esos puertos.</p> <p>La \u00faltima l\u00ednea pasv_address=X.X.X.X es opcional y si la pones debes poner la IP p\u00fablica de tu servidor. Si no la pones, cuando te conectes con el cliente recibir\u00e1s un mensaje similar a \"El servidor envi\u00f3 una respuesta pasiva con una direcci\u00f3n no enrutable. Usando en su lugar la direcci\u00f3n del servidor.\", pero funcionar\u00e1 igual. Si la pones ten en cuenta que cada vez que cambie la IP p\u00fablica de tu servidor deber\u00e1s cambiar esta l\u00ednea en la configuraci\u00f3n.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#reinicia-el-servicio","title":"Reinicia el servicio","text":"<p>Finalmente reiniciamos el servicio vsftpd para que coja la nueva configuraci\u00f3n realizada en todos estos pasos.</p> <pre><code>sudo systemctl restart --now vsftpd\n</code></pre>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#comprobar-la-conexion-ftp-al-servidor-vsftpd","title":"Comprobar la Conexi\u00f3n FTP al servidor vsftpd","text":""},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#acceso-con-cliente-ftp-de-consola","title":"Acceso con Cliente FTP de consola","text":"<ol> <li>Abre una terminal en tu sistema. </li> <li>Desde Linux/Mac, abre el terminal del sistema</li> <li> <p>Desde Windows, abre el \"S\u00edmbolo del sistema\" o \"PowerShell\". Puedes hacerlo buscando \"cmd\" o \"PowerShell\" en el men\u00fa de inicio o escribiendo \"cmd\" en la barra de b\u00fasqueda.</p> </li> <li> <p>En la terminal, escribe el siguiente comando para iniciar una sesi\u00f3n FTP. Debes reemplazar nombre_de_host_ftp con la direcci\u00f3n IP P\u00daBLICA o el nombre de dominio del servidor FTP al que deseas conectarte:</p> </li> </ol> <pre><code>ftp nombre_de_host_ftp\n</code></pre> <ol> <li>Una vez que ingreses el comando, el cliente FTP intentar\u00e1 establecer una conexi\u00f3n con el servidor. Si la conexi\u00f3n es exitosa, ver\u00e1s un mensaje similar a este:</li> </ol> <pre><code>Connected to nombre_de_host_ftp.\n220 (nombre_del_servidor_ftp) FTP server ready\nName (nombre_de_host_ftp:tu_nombre_de_usuario_ftp):\n</code></pre> <ol> <li>A continuaci\u00f3n, el cliente FTP te pedir\u00e1 que ingreses un usuario (en nuestro caso recuerda que era userftp)  y presiona \"Enter\". Luego, se te pedir\u00e1 que ingreses la contrase\u00f1a (recuerda que era ieselcaminas). Si las credenciales son correctas, deber\u00edas obtener acceso al servidor FTP. Verifica que el prompt a cambiado a ftp&gt; (quiere decir que has conectado correctamente). Es posible que si el cliente ftp no conoce el certificado del servidor no te permita la conexi\u00f3n. Si esto ocurre no te preocupes e intenta la conexi\u00f3n con el cliente gr\u00e1fico, que suele solucionar ese inconveniente.</li> </ol>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#acceso-con-cliente-ftp-grafico","title":"Acceso con Cliente FTP gr\u00e1fico","text":"<p>Vamos a utilizar como cliente FTP con entorno gr\u00e1fico a Filezilla, que dispone de versiones para GNU/Linux, Mac OS X y Windows. Tras descargar el cliente FTP en nuestro ordenador vamos a crear una conexi\u00f3n para usarla m\u00e1s adelante. Lo haremos siguiendo los pasos de la pr\u00e1ctica 4.1 Acceso a un servidor FTP p\u00fablico con los siguientes datos:</p> <p></p> <p>F\u00edjate que usamos FTP y no SFTP, que usamos FTPS Expl\u00edcito y que el puerto est\u00e1 vac\u00edo, porque usar\u00e1 el 21, que es el puerto por defecto. Puedes ponerlo y ver\u00e1s que funciona igual.</p> <p>Tras darle al bot\u00f3n de Conectar, nos saltar\u00e1 un aviso a prop\u00f3sito del certificado, le damos a aceptar puesto que no entra\u00f1a peligro ya que lo hemos generado nosotros mismos:</p> <p></p> <p>Nos conectaremos directamente a la carpeta que le hab\u00edamos indicado en el archivo de configuraci\u00f3n <code>/home/userftp/ftp</code></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#sftp-ssh-file-transfer-protocol","title":"SFTP (SSH File Transfer Protocol)","text":"<p>Ahora vamos a probar la conexi\u00f3n por SFTP. Recuerda que para esta no necesitamos configurar vsftp de ninguna forma especial, as\u00ed que vamos a recuperar el fichero de configuraci\u00f3n antes de configurar FTPS. Antes guardaremos el fichero de configuraci\u00f3n con ftps activado por si queremos usarlo despu\u00e9s.</p> <pre><code>sudo cp /etc/vsftpd.conf /etc/vsftpd.conf.ftps\nsudo cp /etc/vsftpd.conf.backup2 /etc/vsftpd.conf\n</code></pre> <p>Ahora recuerda que aqu\u00ed primero se establece una conexi\u00f3n ssh entre el usuario y el servidor ssh usando las claves p\u00fablica y privada del usuario. Vamos a usar en este caso el usuario <code>user2</code>. Puedes crear un par de claves p\u00fablica y privada para este usuario como hicimos en la pr\u00e1ctica 1.3 y configurar el servidor ssh en la m\u00e1quina virtual en AWS para que user2 pueda conectarse con ssh usando su clave privada. </p> <p>Cuando lo tengas, lo primero es probar que funciona antes de intentar la conexi\u00f3n SFTP.</p> <pre><code>ssh -i clave user2@ipserver\n</code></pre> <p>Recuerda cambiar clave por el nombre y ruta del fichero de clave privada generado y ipserver por la ip p\u00fablica de tu servidor en AWS. </p> <p>Una vez comprobado que funciona ya podemo intentar conectar por sftp.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#conexion-en-modo-comando","title":"Conexi\u00f3n en modo comando","text":"<p>Probamos a conectarnos en modo comando.</p> <p></p> <p>Si todo va bien se establecer\u00e1 la conexi\u00f3n sin pedirnos usuario ni contrase\u00f1a.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P03/#conexion-en-modo-grafico","title":"Conexion en modo gr\u00e1fico.","text":"<p>Si lo que quisi\u00e9ramos es conectarnos con Filezilla mediante la conexi\u00f3n r\u00e1pida, bastar\u00e1 con seleccionar el puerto 22, que recordemos es el de ssh. Para que esto funcione el archivo de clave privada deber\u00e1 estar en la ubicaci\u00f3n donde el sistema espera encontrarlo, en caso contrario no lo encontrar\u00e1 y nos dar\u00e1 error.</p> <p></p> <p>Si tenemos nuestro fichero con la clave privada de <code>user2</code> en otro sitio podemos crear una conexi\u00f3n nueva as\u00ed:</p> <p></p> <p>Fij\u00e1os que al utilizar las claves de SSH no se debe introducir la contrase\u00f1a, \u00fanicamente el nombre de usuario.</p> <p>Puesto que nos estamos conectando usando las claves FTP, nos sale el mismo aviso que nos sal\u00eda al conectarnos por primera vez por SSH a nuestra Debian, que aceptamos porque sabemos que no entra\u00f1a ning\u00fan peligro en este caso:</p> <p></p> <p>Y vemos que al ser una conexi\u00f3n SSH, nos conecta al <code>home</code> del usuario, en lugar de a la carpeta <code>ftp</code>. A partir de aqu\u00ed ya proceder\u00edamos igual que en el otro caso.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P04/","title":"Pr\u00e1ctica 4. Dockerizar un servidor FTP","text":"<p>Si buscamos vsftpd en Docker Hub encontraremos que la imagen m\u00e1s utilizada es fauria/vsftpd</p> <p>En la p\u00e1gina de Docker Hub tenemos toda la informaci\u00f3n necesaria para usar este contenedor. Tendr\u00e1s que consultarla as\u00ed que \u00e9chale un primer vistazo.</p> <p>Intentar usar un contenedor usando todas sus opciones desde el principio es garant\u00eda de no conseguirlo. Vamos a ir poco a poco. Nuestro objetivo final ser\u00e1 crear un contenedor dockerizado con las mismas caracter\u00edsticas que el contenedor de la pr\u00e1ctica 2, que recordamos era:</p> <ol> <li>Deja que s\u00f3lo puedan conectarse los usuarios locales.</li> <li>Habilita la carga de archivos.</li> <li>Haz que los archivos se suban con umask 022.</li> <li>Habilita chroot con la opci\u00f3n 2, es decir, que cada usuario del sistema se conecte a <code>/home/$USER/ftp</code></li> <li>Restringe para que solo <code>userftp</code> pueda conectarse por FTP</li> <li>Agrega un archivo <code>pruebaftp.txt</code> en <code>/home/userftp/ftp/upload/</code> para usar en las pruebas.</li> </ol> <p>Info</p> <p>La imagen docker <code>fauria/vsftpd</code> est\u00e1 configurada para usar \"usuarios virtuales\" en lugar de usuarios locales. Pero como la configuraci\u00f3n ya est\u00e1 hecha en el contenedor no nos preocupar\u00e1. Simplemente hemos de saberlo para cuando veamos ciertas configuraciones en vsftpd.conf que no conozcamos.</p> <p>Vamos a empezar por intentar correr un contentedor que permita un acceso FTP activo simple. Viendo las opciones que nos da la p\u00e1gina de \"fauria/vsftpd\" probaremos esto:</p> <pre><code>docker run \\\n    --rm \\\n    -p 21:21 -p 20:20 \\\n    -d \\\n    --name pruebavsftpd \\\n    fauria/vsftpd\n</code></pre> <p>La opci\u00f3n -rm borrar\u00e1 el contenedor al pararlo. Como estamos en pruebas nos interesa esa opci\u00f3n. Corre el contenedor y luego, siguiendo las instrucciones del contenedor, ejecuta lo siguiente para obtener el usuario y contrase\u00f1a de acceso:</p> <pre><code>$ docker logs pruebavsftpd \n    *************************************************\n    *                                               *\n    *    Docker image: fauria/vsftpd                *\n    *    https://github.com/fauria/docker-vsftpd    *\n    *                                               *\n    *************************************************\n\n    SERVER SETTINGS\n    ---------------\n    \u00b7 FTP User: admin\n    \u00b7 FTP Password: nfcf4ZoxNRsV2c3L\n    \u00b7 Log file: /var/log/vsftpd/vsftpd.log\n    \u00b7 Redirect vsftpd log to STDOUT: No.\n</code></pre> <p>Ahora abre Filezilla y establece un conexi\u00f3n con el contenedor. Recuerda que si est\u00e1 corriendo en una EC2 de AWS habr\u00e1s de tener abiertos los puertos 20 y 21. Y en Filezilla tendr\u00e1s que establecer una conexi\u00f3n FTP (no FTPS ni sFTP) y en opciones de transferencia establecer el modo \"Activo\".</p> <p>Una vez establecida la conexi\u00f3n, \u00bfesta activo el chroot (puedes moverte por todos los directorios del servidor)? \u00bfPuedes subir archivos al servidor?</p> <p>Bueno, ya tenemos algunas cosas claras. Pero se trata de un servidor FTP. No nos interesa que los archivos a descargar o subir est\u00e9n dentro del contenedor y se borren cuando este se elimine. As\u00ed que vamos a pararlo pero montando el directorio de datos en un directorio de nuestro host. Crearemos un directorio <code>datosftp</code> y lo montaremos como dicen las instrucciones del contenedor.</p> <pre><code>mkdir datosftp\ndocker run \\\n    --rm \\\n    -p 21:21 -p 20:20 \\\n    -d \\\n    --name pruebavsftpd \\\n    -v /home/admin/datosftp:/home/vsftpd \\\n    fauria/vsftpd\n</code></pre> <p>Vuelve a conectarte con Filezilla. Recuerda recuperar la nueva contrase\u00f1a de admin. Observa en la m\u00e1quina host como se crea un directorio <code>/home/admin/datosftpd/admin</code> que alojar\u00e1 los datos. Con filezilla env\u00eda un fichero al directorio ra\u00edz donde te has conectado. Comprueba en el host que aparece dicho fichero en <code>/home/admin/datosftpd/admin</code>. Ya podemos parar nuevamente el contenedor.</p> <p>Vamos ahora con una configuraci\u00f3n m\u00e1s completa en la que crearemos un usuario ftp y activaremos el modo pasivo:</p> <pre><code>docker run \\\n    --rm \\\n    -e FTP_USER=userftp \\\n    -e FTP_PASS=ieselcaminas \\\n    -e PASV_MIN_PORT=21100 \\\n    -e PASV_MAX_PORT=21110 \\\n    -p 21:21 -p 21100-21110:21100-21110 \\\n    -d \\\n    --name pruebavsftpd \\\n    -v /home/admin/datosftp:/home/vsftpd \\\n    fauria/vsftpd\n</code></pre> <p>Atenci\u00f3n</p> <p>Antes de probarlo, f\u00edjate que hemos abierto en el servido los puertos 21100 a 21110. Por tanto, si nuestro docker corre en una EC2 de AWS deberemos modificar el grupo de seguridad para permitir el acceso a dicho rango de puertos.</p> <p>Prueba ahora a conectarte con <code>userftp</code> password <code>ieselcaminas</code> y modo pasivo desde Filezilla. Si todo va bien, prueba a enviar un fichero y despu\u00e9s comprueba en el host que existe dicho fichero en <code>/home/admin/datosftp/userftp/</code>. Comprueba sus permisos. \u00bfQu\u00e9 permisos tiene?</p> <p>Con esto ya tenemos \"casi\" todo lo que dijimos en un principio. Y digo casi, porque no hemos tenido en cuenta los permisos con los que se suben los archivos. En la pregunta anterior comprobar\u00edamos que los permisos del fichero subido son -rw------- . Veamos por qu\u00e9. Si revisamos la documentaci\u00f3n del contenedor vemos que hay 2 variables para definir los permisos de los archivos subidos: </p> <ul> <li>Variable name: FILE_OPEN_MODE</li> <li>Default value: 0666</li> <li>Accepted values: File system permissions.</li> <li> <p>Description: The permissions with which uploaded files are created. Umasks are applied on top of this value. You may wish to change to 0777 if you want uploaded files to be executable.</p> </li> <li> <p>Variable name: LOCAL_UMASK</p> </li> <li>Default value: 077</li> <li>Accepted values: File system permissions.</li> <li>Description: The value that the umask for file creation is set to for local users. NOTE! If you want to specify octal values, remember the \"0\" prefix otherwise the value will be treated as a base 10 integer!</li> </ul> <p>Es decir, el fichero subido se crea con permisos 0666 \u00f3 rw-rw-rw. Y luego se hace un AND con la LOCAL_UMASK negada. Como LOCAL_UMASK=077, la negada es 700 \u00f3 111000000. Por tanto, el resultado de rw-rw-rw AND 11100000000 = rw-------</p> <p>Pero nosotros quer\u00edamos que nuestra UMASK fuera 022, as\u00ed que pasaremos la siguiente variable:</p> <pre><code>docker run \\\n    -e FTP_USER=userftp \\\n    -e FTP_PASS=ieselcaminas \\\n    -e PASV_MIN_PORT=21100 \\\n    -e PASV_MAX_PORT=21110 \\\n    -e LOCAL_UMASK=022 \\\n    -p 21:21 -p 21100-21110:21100-21110 \\\n    -d \\\n    --name vsftpdsincifrado \\\n    -v /home/admin/datosftp:/home/vsftpd \\\n    fauria/vsftpd\n</code></pre> <p>Comprueba ahora que si subes un fichero sus permisos ser\u00e1n rw-r--r-- y con esto ya tenemos todo lo que hicimos en el servidor vsftp sin cifrado pero dockerizado. F\u00edjate que le he quitado el <code>-rm</code> y le he cambiado el nombre al contenedor por <code>vsftpdsincifrado</code>.</p> <p>Warning</p> <p>En esta pr\u00e1ctica hemos creado un usuario en el docker run usando variables de entorno. Pero podr\u00eda ocurrir que quisi\u00e9ramos a\u00f1adir m\u00e1s usuarios una vez el contenedor ya creado. En la p\u00e1gina del contenedor fauria/vsftpd en Docker Hub ten\u00e9is la forma de hacerlo usando un comando <code>docker exec</code></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/P04/#dockerizando-servidor-vsftpd-con-cifrado","title":"Dockerizando servidor vsftpd con CIFRADO","text":"<p>Si recordamos de la \"Pr\u00e1ctica 3. Configuraci\u00f3n de servidor FTP con Cifrado\" para activar FTPS en vsftpd deb\u00edamos hacer 2 cosas:</p> <ul> <li>Generar un certificado autofirmado que se guarda en un fichero .pem (le llamaremos vsftpd.pem)</li> <li>Modificar el fichero de configuraci\u00f3n <code>vsftpd.conf</code> con las directivas que activan el cifrado SSL</li> </ul> <p>Para hacer esto en un contenedor podr\u00edamos plantearnos varias estrategias partiendo de que tenemos los ficheros vsftpd.pem y vsftpd.conf en el host y los queremos copiar al interior del contenedor</p> <ol> <li>Crear un contenedor como el anterior. Despu\u00e9s copiar en su interior los 2 ficheros con comandos <code>docker cp vsftpd.conf vsftpdconcifrado:/etc/vsftpd/vsftpd.conf</code> y <code>docker cp vsftpd.pem vsftpdconcifrado:/etc/vsftpd/vsftpd.pem</code></li> <li>Crear un Dockerfile que genere una imagen copiando esos 2 ficheros a su interior. Despu\u00e9s crear el contenedor, con los mismos par\u00e1metros a partir de la imagen creada</li> </ol> <p>Warning</p> <p>Aunque ambas soluciones parecen v\u00e1lidas pod\u00e9is comprobar que la primera no funciona. Una vez copiados los archivos al interior el contenedor no arranca correctamente.  No es la primera vez que comprobamos que algunas im\u00e1genes docker solo nos permiten hacer ciertas cosas si antes creamos nuestra propia imagen con un <code>docker build</code>. As\u00ed que ahora y en lo sucesivo usaremos esa estrategia.</p> <p>Por tanto, vamos a crear primero una imagen propia a partir de <code>fauria/vsftpd</code> copiando en su interior los ficheros que necesitemos. Crearemos un directorio <code>practicavsftpd</code> y entraremos dentro.</p> <p>Primero crearemos el fichero vsftpd.pem con el certificado:</p> <pre><code>openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout vsftpd.pem -out vsftpd.pem\n</code></pre> <p>Luego copiaremos el vsftpd.conf del contenedor sin cifrado en el host para despu\u00e9s modificarlo:</p> <pre><code>docker cp vsftpdsincifrado:etc/vsftpd/vsftpd.conf .\nsudo nano vsftpd.conf \n</code></pre> <p>A\u00f1adimos las l\u00edneas que vimos en la \"Pr\u00e1ctica 3. Configuraci\u00f3n de servidor FTP con Cifrado\" que habilitaban el cifrado</p> <pre><code>rsa_cert_file=/etc/vsftpd/vsftpd.pem\nrsa_private_key_file=/etc/vsftpd/vsftpd.pem\nssl_enable=YES\n\nallow_anon_ssl=NO\nforce_local_data_ssl=YES\nforce_local_logins_ssl=YES\nssl_tlsv1=YES\nssl_sslv2=NO\nssl_sslv3=NO\nrequire_ssl_reuse=NO\nssl_ciphers=HIGH\n</code></pre> <p>F\u00edjate que las vamos a copiar en <code>/etc/vsftpd/</code> en lugar de la ruta donde la copi\u00e1bamos en la Pr\u00e1ctica3. Da igual d\u00f3nde siempre que el COPY que hagamos en el Dockerfile sea coherente.</p> <p>Ahora creamos el Dockerfile con este contenido</p> <pre><code>FROM fauria/vsftpd\n\n# Copia tu archivo vsftpd.conf y los certificados\nCOPY vsftpd.conf /etc/vsftpd/vsftpd.conf\nCOPY --chown=root:root vsftpd.pem /etc/vsftpd/vsftpd.pem\n</code></pre> <p>F\u00edjate que hemos usado una opci\u00f3n en COPY para que vsftpd.pem se copie al interior del contenedor siendo el propietario root del grupo root. Esto es necesario para el certificado.</p> <p>Creamos nuestra imagen</p> <pre><code>docker build -t mivsftpd .\n</code></pre> <p>Y creamos nuestro contenedor a partir de la imagen creada:</p> <pre><code>docker run \\\n    -e FTP_USER=userftp \\\n    -e FTP_PASS=ieselcaminas \\\n    -e PASV_MIN_PORT=21100 \\\n    -e PASV_MAX_PORT=21110 \\\n    -e LOCAL_UMASK=022 \\\n    -p 21:21 -p 21100-21110:21100-21110 \\\n    -d \\\n    --name vsftpdconcifrado \\\n    -v /home/admin/datosftp:/home/vsftpd \\\n    mivsftpd\n</code></pre> <p>Comprueba ahora el acceso con Filezilla. Recuerda que tendr\u00e1s que usar \"Cifrado: Requiere FTP expl\u00edcito sobre TLS\" y el \"Modo de transferencia: Pasivo\"</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/","title":"1. Servidor de Transferencia de Ficheros","text":""},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#introduccion","title":"Introducci\u00f3n","text":"<p>Las aplicaciones de transferencia de ficheros fueron una de las primeras herramientas al desarrollarse en la expansi\u00f3n de las redes de internet. La necesidad de poder acceder a diferentes sistemas e intercambiar informaci\u00f3n origin\u00f3 uno de los sistemas que actualmente se usan.</p> <p>Actualmente hay diferentes formas de intercambio de informaci\u00f3n de forma distribuida en formato fichero:</p> <ul> <li>Sistemas de ficheros en redes</li> <li>Software de mensajer\u00eda</li> <li>Software de distribuciones de ficheros P2P (peer-to-peer)</li> </ul> <p>El FTP (File transfer protocol) o protocolo de transferencia de ficheros es un protocolo que proporciona el servicio de transferencia de ficheros entre sistemas de diferente naturaleza, es decir, se podr\u00e1n interconectar clientes de Linux hacia un sistema de Microsoft u otros.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#funcionalidad-del-servicio-de-transferencia-de-ficheros","title":"Funcionalidad del servicio de transferencia de ficheros","text":"<p>La funcionalidad que aporta este servicio es esencial en numerosos escenarios y aplicaciones, y desempe\u00f1a un papel crucial en la gesti\u00f3n y compartici\u00f3n de datos. Estas son algunas de las principales funcionalidades del servicio de transferencia de archivos:</p> <ul> <li>Transferencia de Archivos</li> <li>Copia de Seguridad</li> <li>Compartici\u00f3n de Archivos</li> <li>Despliegue de Software de actualizaciones y parches.</li> <li>Acceso Remoto</li> <li>Intercambio de Datos entre Aplicaciones</li> <li>Automatizaci\u00f3n de tareas </li> <li>Seguridad, como el cifrado de datos (a trav\u00e9s de protocolos como SFTP o FTPS) y la autenticaci\u00f3n</li> <li>Control de Acceso</li> <li>Monitorizaci\u00f3n y Registro</li> </ul> <p>En resumen, la funcionalidad del servicio de transferencia de archivos es facilitar la transferencia segura y eficiente de datos entre sistemas y dispositivos. Estas capacidades son fundamentales en numerosos escenarios, desde la gesti\u00f3n de archivos personales hasta la administraci\u00f3n de sistemas empresariales y la colaboraci\u00f3n en equipo.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#un-poco-de-historia","title":"Un poco de historia","text":"<p>La implementaci\u00f3n de la FTP se remonta en el a\u00f1o 1971, cuando se desarroll\u00f3 un sistema de transferencia de ficheros, definido dentro de la RFC (request for comments) 141, entre equipos del Instituto Tecnol\u00f3gico de Massachusetts (MIT, Massachusetts Institute of Technology). Durante los a\u00f1os posteriores se hicieron diferentes innovaciones al protocolo b\u00e1sico, que se incluyeron en 1973.</p> <p>El protocolo FTP, tal como se conoce actualmente como est\u00e1ndar, se especifica dentro de la RFC 959 en 1985 y define el funcionamiento del protocolo. Posteriormente, el protocolo FTP se ha ido revisando con algunas nuevas caracter\u00edsticas, pero su base de funcionamiento ha sido mantenida.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#el-modelo-ftp-como-funciona","title":"El modelo FTP. \u00bfC\u00f3mo funciona?","text":"<p>El protocolo FTP emplea una arquitectura cliente/servidor, siendo el cliente FTP quien solicita la transferencia de archivos y el servidor FTP quien ofrece los archivos. Pertenece a la familia de protocolos de red TCP y por lo tanto es un protocolo orientado a conexi\u00f3n, esto es, el cliente ftp necesita establecer una conexi\u00f3n con el servidor para empezar la transferencia de ficheros. Si no se establece la conexi\u00f3n \u00e9sta no tiene lugar.</p> <p>Puesto que FTP es un protocolo que no utiliza una autenticaci\u00f3n de usuarios y contrase\u00f1a cifrada, se considera un protocolo inseguro y no se deber\u00eda utilizar a menos que sea absolutamente necesario. Ver\u00e1s que existen otras alternativas al FTP, como por ejemplo el protocolo FTPS, para mantener comunicaciones cifradas. A\u00fan as\u00ed, el protocolo FTP est\u00e1 muy extendido en Internet ya que a menudo los usuarios necesitan transferir archivos entre m\u00e1quinas sin importar la seguridad.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#canales-o-puertos-de-comunicacion","title":"Canales o puertos de comunicaci\u00f3n","text":"<p>El protocolo FTP requiere de dos puertos TCP en el servidor para su funcionamiento, a diferencia de la mayor\u00eda de los protocolos utilizados en Internet que solamente requieren un puerto en el servidor. </p> <p>Estos dos puertos o canales de comunicaci\u00f3n dentro del protocolo FTP son:</p> <ul> <li>El canal de control env\u00eda todas las \u00f3rdenes de comunicaci\u00f3n, como pueden ser iniciar la sesi\u00f3n de trabajo y \u00f3rdenes de ejecuci\u00f3n como leer, escribir, listar, borrar, etc.</li> <li>El canal de datos env\u00eda el contenido de aquellos ficheros a trabajar, que puede ser tanto para leer el contenido del fichero como para hacer la escritura del fichero.</li> </ul> <p>Los puertos TCP del servidor en cuesti\u00f3n, suelen ser un puerto para el control de la conexi\u00f3n y otro puerto para los datos, a determinar seg\u00fan el modo de conexi\u00f3n, que podr\u00eda ser el 20 o incluso uno mayor de 1024. Normalmente se utilizan el puerto 21 como puerto de control o comandos y el puerto 20 como puerto de datos.  Hay que tener en cuenta que estos puertos pueden ser modificados en la configuraci\u00f3n del servidor, as\u00ed no es obligatorio que los puertos 21 y 20 sean los asignados al servidor FTP, pero s\u00ed son los que \u00e9ste maneja por defecto. </p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#procesos-dtp-y-pi-en-el-servidor-y-en-el-cliente","title":"Procesos DTP y PI en el Servidor y en el Cliente","text":"<p>Tanto el cliente como el servidor gestionan dos procesos:</p> <ul> <li>Proceso DTP (Data Transfer Protocol, o proceso de transferencia de datos): es el encargado de establecer la conexi\u00f3n y administrar el canal de datos. Tanto el cliente como el servidor tienen su propio DTP.</li> <li>Proceso PI (Protocol Interpret, int\u00e9rprete del protocolo): interpreta el protocolo y permite que el DTP pueda ser controlado mediante \u00f3rdenes recibidas a trav\u00e9s del canal de control.</li> </ul> <p></p> <p></p> <p>El proceso PI en el servidor:</p> <ul> <li>Escucha las \u00f3rdenes que provienen del proceso PI del usuario mediante el canal de control por un puerto de datos (puerto 20).</li> <li>Establece la conexi\u00f3n del canal de control.</li> <li>Recibe las \u00f3rdenes FTP del proceso PI del usuario, las responde y ejecuta el proceso DTP del servidor.</li> </ul> <p>El proceso PI en el cliente:</p> <ul> <li>Es el responsable de establecer la conexi\u00f3n con el servidor FTP.</li> <li>Env\u00eda \u00f3rdenes FTP.</li> <li>Recibe las respuestas del servidor PI.</li> <li>Controla el DTP del usuario.</li> </ul> <p>El modo de funcionamiento es el siguiente; Cuando un cliente conecta al servidor FTP, la PI del usuario inicia la conexi\u00f3n con el servidor con el protocolo  Telnet (RFC 854). El cliente env\u00eda \u00f3rdenes FTP al servidor, el servidor las interpreta, ejecuta el DTP y responde con un formato est\u00e1ndar. Una vez establecida la conexi\u00f3n, el proceso PI del servidor proporciona el puerto por el cual se enviar\u00e1n los datos al DTP del cliente, por donde escuchar\u00e1 y recibir\u00e1 los datos del servidor.</p> <p>Toda la comunicaci\u00f3n que se hace en el canal de control sigue las recomendaciones del protocolo Telnet.  Los canales de control deben permanecer abiertos durante la transferencia de datos. De este modo, un servidor puede detener una transmisi\u00f3n si el canal de control es interrumpido durante la transmisi\u00f3n.</p> <p></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#modos-de-conexion-del-cliente-ftp","title":"Modos de conexi\u00f3n del cliente FTP","text":"<p>Dentro del protocolo FTP se definen dos modos de conexi\u00f3n que se configuran dentro del servicio. Estos modos se refieren a la forma en que se establecen las conexiones de datos entre el cliente y el servidor. </p> <p>El modo ftp Activo (o Est\u00e1ndar, o PORT, debido a que el cliente env\u00eda comandos tipo PORT al servidor por el canal de control al establecer la conexi\u00f3n) y el modo ftp Pasivo (o PASV, porque en este caso env\u00eda comandos tipo PASV). Tanto en el modo Activo como en el modo Pasivo, el cliente establece una conexi\u00f3n con el servidor mediante el puerto 21, que establece el canal de control.</p> <p>Aqu\u00ed hay una explicaci\u00f3n de las diferencias entre ambos modos:</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#modo-ftp-activo","title":"Modo FTP activo","text":"<p>Para establecer una conexi\u00f3n FTP activa, se siguen estos pasos:</p> <ul> <li>En el modo FTP activo, el cliente conecta desde un puerto aleatorio m\u00e1s grande de 1024 (denominemos N) hacia el puerto 21 de control del servidor. </li> <li>El cliente inicia la escucha en el puerto (N+1).</li> <li>El servidor establece la conexi\u00f3n desde el puerto 20 al cliente por el puerto de datos especificado por parte del cliente, que es el puerto N+1.</li> </ul> <p>Cuando se trabaja en modo activo puede haber problemas con el cortafuegos del sistema. El cortafuegos tiene que tener los puertos de trabajo abiertos del servidor y del cliente, para poder establecer las comunicaciones. En este modo es el cliente el que inicia la comunicaci\u00f3n en el canal de control, pero es el servidor el que inicia la comunicaci\u00f3n en el canal de datos.</p> <p>Ve\u00e1moslo con un ejemplo:</p> <p></p> <p>Puertos que se abrir\u00e1n en modo activo dentro del servidor:</p> <ol> <li>El cliente conectar\u00e1 al puerto 21 del servidor FTP con un puerto m\u00e1s grande de 1024 del cliente. (Iniciaci\u00f3n de la conexi\u00f3n del cliente)</li> <li>El puerto 21 del servidor FTP conectar\u00e1 a un puerto m\u00e1s grande de 1024. (El servidor responde al puerto de control del cliente)</li> <li>El puerto 20 del servidor FTP conectar\u00e1 a un puerto m\u00e1s grande de 1024. (El servidor inicia la conexi\u00f3n de datos hacia el puerto de datos del cliente FTP)</li> <li>El cliente conectar\u00e1 con un puerto m\u00e1s grande de 1024 hacia el puerto 20 del servidor FTP. (El cliente env\u00eda la confirmaci\u00f3n de conexi\u00f3n al puerto de datos del servidor FTP.)</li> </ol> <p>En resumen, en modo Activo, el servidor siempre crea el canal de datos en su puerto 20, mientras que en el lado del cliente el canal de datos se asocia a un puerto aleatorio mayor que el 1024. Para ello, el cliente manda un comando PORT al servidor por el canal de control indic\u00e1ndole ese n\u00famero de puerto, de manera que el servidor pueda abrirle una conexi\u00f3n de datos por donde se transferir\u00e1n los archivos y los listados, en el puerto especificado.</p> <p>Ver otro ejemplo de \"modo activo\".</p> <p></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T01/#modo-ftp-pasivo","title":"Modo FTP pasivo","text":"<p>Para evitar que el servidor inicie la conexi\u00f3n al cliente, lo que impedir\u00eda la comunicaci\u00f3n si hay un cortafuegos, hay otro m\u00e9todo de conexi\u00f3n denominado pasivo.</p> <p>En el m\u00e9todo FTP pasivo el cliente inicia las dos conexiones al servidor (control y datos), resolviendo el problema de control del cortafuego o configuraciones NAT en el filtraje del puerto de datos del servidor hacia el cliente. En caso de no existir cortafuegos no habr\u00eda problema, pero si existe, al intentar el servidor devolver la respuesta a un puerto diferente, el cortafuegos bloquear\u00eda la conexi\u00f3n. Como contrapartida hay que tener m\u00e1s rango de puertos abiertos en el servidor.</p> <ul> <li>El cliente, al iniciar la conexi\u00f3n FTP, coge un puerto aleatorio m\u00e1s grande de 1024, que llamaremos N y el siguiente como N + 1.</li> <li>El primer puerto N hace la conexi\u00f3n hacia el puerto 21 del servidor y evita hacer la conexi\u00f3n al puerto de datos 20. El cliente har\u00e1 uso de una orden PASV. </li> <li>El servidor abre un puerto aleatorio P m\u00e1s grande de 1024 y le devuelve al cliente con la orden PASV. </li> <li>El cliente inicia el canal de datos del puerto (N + 1) al puerto P.</li> </ul> <p>Ve\u00e1moslo con un ejemplo:</p> <p></p> <p>Para controlar el cortafuegos en el servidor FTP en modo pasivo abriremos los puertos siguientes:</p> <ol> <li>El cliente conectar\u00e1 al puerto 21 del servidor FTP con un puerto m\u00e1s grande de 1024 del cliente pidiendo una conexi\u00f3n pasiva con la orden PASV. (Iniciaci\u00f3n de la conexi\u00f3n del cliente)</li> <li>El puerto 21 del servidor FTP conectar\u00e1 a un puerto m\u00e1s grande de 1024 del cliente. (El servidor responde al puerto de control del cliente).</li> <li>Un puerto m\u00e1s grande de 1024 del cliente conectar\u00e1 a un puerto m\u00e1s grande de 1024 del servidor. (El cliente inicia el canal de datos a un puerto aleatorio del servidor).</li> <li>Un puerto m\u00e1s grande de 1024 del servidor conectar\u00e1 a un puerto m\u00e1s grande de 1024 del cliente. (El servidor confirma la conexi\u00f3n al puerto de datos)</li> </ol> <p>En la figura, al paso 1 el cliente contacta con el servidor por el puerto 21 pidiendo una conexi\u00f3n pasiva con la orden PASV. El servidor responde en el paso 2 con un puerto aleatorio, en el ejemplo 1024, pidiendo al cliente qu\u00e9 puerto es el que usar\u00e1 para abrir el canal de datos. En el paso 3 el cliente inicia el canal de datos del puerto de datos del cliente 1027 al puerto que ha abierto el servidor 1024. En el paso 4 el servidor confirma la conexi\u00f3n.</p> <p>Ver otro ejemplo de \"modo pasivo\"</p> <p></p> <p>Con el modo pasivo se resuelven muchos problemas del cliente, pero se ampl\u00edan los problemas del servidor. Uno de los principales problemas es la apertura de un gran rango de puertos en el servidor para poder iniciar canales de datos.</p> <p>Una de las ventajas actualmente es que las implementaciones de servidores FTP permiten escoger el rango de puertos que se usar\u00e1n.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/","title":"2. Servidores y clientes FTP","text":"<p>Actualmente hay muchas aplicaciones que implementan el protocolo FTP tanto por el lado del cliente como por el lado del servidor. </p> <p>La decisi\u00f3n de utilizar una aplicaci\u00f3n u otra que implemente el protocolo FTP viene dada por las posibilidades que ofrece y el sistema operativo en uso. En el caso del despliegue de aplicaciones web, cualquier servidor o cliente FTP se ajusta a las necesidades del despliegue web. </p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/#servidores-ftp","title":"Servidores FTP","text":"<p>Algunos de los servidores FTP populares en este momento son vsFTPd, ProFTPD, Pure-FTPd, y FileZilla Server, entre otros.  La elecci\u00f3n del servidor FTP adecuado depender\u00e1 de las necesidades espec\u00edficas, como la seguridad, la facilidad de configuraci\u00f3n, la compatibilidad con tu sistema, el soporte de protocolos, y otras consideraciones. </p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/#servidor-vsftpd","title":"Servidor vsFTPd","text":"<p>En esta unidad usaremos el servidor FTP llamado vsFTPd (Very Secure FTP Daemon). Es un software utilizado para implementar servidores de archivos a trav\u00e9s del protocolo FTP en sistemas Linux.</p> <p>vsFTPd se distingue principalmente porque sus valores predeterminados son muy seguros y por su sencillez en la configuraci\u00f3n, comparado con otras alternativas como Pure-ftpd, ProFTPD y Wu-ftpd tambi\u00e9n para sistemas Linux.</p> <p>Actualmente se presume que vsFTPd podr\u00eda ser quiz\u00e1 el servidor FTP m\u00e1s seguro del mundo.</p> <p>A continuaci\u00f3n, se enumeran algunas de las caracter\u00edsticas destacadas de vsFTPd:</p> <ul> <li>Seguridad: vsFTPd se enfoca en la seguridad y se esfuerza por ser uno de los servidores FTP m\u00e1s seguros disponibles. Ofrece soporte para FTPS (FTP sobre SSL/TLS) y puede cifrar las comunicaciones entre el cliente y el servidor.</li> <li>Modo Pasivo y Activo: Admite tanto el modo pasivo como el modo activo para las conexiones de transferencia de datos.</li> <li>Aislamiento de Usuarios: Permite el aislamiento de usuarios para que cada usuario acceda a su propio directorio ra\u00edz de forma predeterminada, lo que mejora la seguridad.</li> <li>Control de Acceso y Permisos: Proporciona opciones avanzadas para controlar el acceso de usuarios y administrar permisos en los archivos y directorios.</li> <li>Logging Avanzado: Ofrece un sistema de registro (logging) completo que registra actividades y eventos del servidor para facilitar el seguimiento y la soluci\u00f3n de problemas.</li> <li>Rendimiento: Es conocido por su eficiencia y su bajo consumo de recursos, lo que lo hace adecuado para servidores con una alta carga.</li> <li>Modo An\u00f3nimo: Admite el acceso de usuarios an\u00f3nimos y ofrece opciones de configuraci\u00f3n para controlar qu\u00e9 puede hacer un usuario an\u00f3nimo en el servidor.</li> <li>Reglas de Firewall Integradas: vsFTPd incluye funcionalidades de cortafuegos incorporadas para ayudar a los administradores a configurar reglas de firewall espec\u00edficas.</li> <li>Soporte IPv6: Es compatible con IPv6, lo que facilita la transici\u00f3n a protocolos de red modernos.</li> <li>Funciones Avanzadas de PAM: Utiliza Pluggable Authentication Modules (PAM) para una mayor flexibilidad en la autenticaci\u00f3n de usuarios.</li> <li>Funciones de Virtual Hosting: Permite a un servidor vsFTPd alojar varios sitios web FTP en una sola instancia.</li> <li>Tolerancia a Errores y Recuperaci\u00f3n: Ofrece capacidades de recuperaci\u00f3n y tolerancia a errores para garantizar un servicio FTP continuo.</li> <li>Configuraci\u00f3n Detallada: Proporciona numerosas opciones de configuraci\u00f3n avanzada para personalizar el comportamiento del servidor seg\u00fan las necesidades del administrador.</li> <li>Gran Comunidad de Usuarios: vsFTPd tiene una gran comunidad de usuarios y es ampliamente documentado, lo que facilita la obtenci\u00f3n de soporte y recursos en l\u00ednea.</li> </ul> <p>En resumen, vsFTPd se ha ganado su reputaci\u00f3n como un servidor FTP muy seguro debido a su enfoque en la seguridad y su conjunto de caracter\u00edsticas de seguridad avanzadas. Sin embargo, es importante destacar que la seguridad de un servidor depende no solo del software del servidor en s\u00ed, sino tambi\u00e9n de la configuraci\u00f3n y el mantenimiento adecuados del servidor y de las pr\u00e1cticas de seguridad en todo el entorno en el que opera.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/#clientes-ftp","title":"Clientes FTP","text":"<p>Un cliente FTP (File Transfer Protocol) es una aplicaci\u00f3n de software que se utiliza para conectarse a servidores FTP y realizar operaciones de transferencia de archivos entre el cliente y el servidor. Los clientes FTP permiten a los usuarios:</p> <ul> <li>Conexi\u00f3n a Servidores FTP: Los clientes FTP se utilizan para establecer conexiones con servidores FTP a trav\u00e9s de Internet o redes locales.</li> <li>Autenticaci\u00f3n: Los usuarios pueden iniciar sesi\u00f3n en el servidor FTP proporcionando su nombre de usuario y contrase\u00f1a. Algunos clientes FTP tambi\u00e9n admiten autenticaci\u00f3n an\u00f3nima para acceder como usuario an\u00f3nimo si el servidor lo permite.</li> <li>Transferencia de Archivos: Descargar archivos desde el servidor al cliente: Los usuarios pueden descargar archivos o directorios completos del servidor a su propia computadora local. Cargar archivos desde el cliente al servidor: Los usuarios pueden cargar archivos desde su computadora local al servidor FTP para su almacenamiento o distribuci\u00f3n.</li> <li>Navegaci\u00f3n por Directorios: Los clientes FTP permiten a los usuarios navegar por la estructura de directorios en el servidor, lo que les permite acceder a diferentes archivos y carpetas.</li> <li>Renombrar y Eliminar Archivos: Los usuarios pueden renombrar archivos en el servidor, eliminar archivos no deseados y realizar operaciones de administraci\u00f3n de archivos.</li> <li>Gesti\u00f3n de Permisos: Algunos clientes FTP permiten cambiar los permisos de archivos y directorios en el servidor si se tiene el permiso adecuado.</li> <li>Gesti\u00f3n de Sesiones: Los clientes FTP gestionan sesiones de transferencia de archivos, lo que facilita la transferencia de m\u00faltiples archivos de forma eficiente.</li> <li>Seguridad: Los clientes FTP pueden ofrecer funciones de seguridad, como FTPS (FTP sobre SSL/TLS) o SFTP (SSH File Transfer Protocol) para cifrar las comunicaciones entre el cliente y el servidor.</li> <li>Registro de Actividad: Algunos clientes FTP registran las actividades realizadas durante la sesi\u00f3n, lo que facilita la soluci\u00f3n de problemas y la auditor\u00eda.</li> <li>Configuraci\u00f3n de Opciones: Los usuarios pueden configurar diversas opciones, como la gesti\u00f3n de contrase\u00f1as, la elecci\u00f3n entre modos activos y pasivos, y otros ajustes espec\u00edficos del cliente.</li> </ul> <p>En resumen, un cliente FTP es una herramienta que facilita a los usuarios la transferencia de archivos entre la computadora y un servidor FTP. Puede ser \u00fatil en una variedad de escenarios, como la administraci\u00f3n de sitios web, la copia de archivos de respaldo, la distribuci\u00f3n de software y la colaboraci\u00f3n en l\u00ednea. </p> <p>Por defecto la mayor\u00eda de sistemas operativos llevan un cliente FTP gr\u00e1fico o terminal, para poder acceder remotamente a los servidores externos.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/#herramientas-graficas","title":"Herramientas gr\u00e1ficas","text":"<p>Existen numerosos clientes FTP gr\u00e1ficos (clientes FTP con interfaces de usuario basadas en ventanas y gr\u00e1ficos) disponibles para diferentes sistemas operativos que facilitan la transferencia de archivos mediante FTP, SFTP y otros protocolos relacionados. A continuaci\u00f3n, te presento una lista de algunos de los clientes FTP gr\u00e1ficos populares para distintas plataformas:</p> <p>Clientes FTP para Windows:</p> <ul> <li>FileZilla: es uno de los clientes FTP m\u00e1s populares y ampliamente utilizados. Ofrece una interfaz f\u00e1cil de usar, es de c\u00f3digo abierto y es compatible con FTP, FTPS y SFTP. Tambi\u00e9n est\u00e1 disponible en MacOS y Linux.</li> <li>WinSCP: es un cliente SFTP y SCP gratuito para Windows. Adem\u00e1s de la transferencia de archivos segura, tambi\u00e9n permite la administraci\u00f3n de archivos en servidores remotos.</li> <li>Core FTP: es un cliente FTP con una interfaz gr\u00e1fica atractiva y muchas caracter\u00edsticas \u00fatiles. Ofrece soporte para FTP, FTPS y SFTP.</li> <li>Cyberduck: Aunque inicialmente se dise\u00f1\u00f3 para macOS, Cyberduck tambi\u00e9n est\u00e1 disponible para Windows. Es un cliente FTP/SFTP de c\u00f3digo abierto con una interfaz f\u00e1cil de usar.</li> </ul> <p>Clientes FTP para macOS:</p> <ul> <li>Cyberduck: es una opci\u00f3n popular tanto para macOS como para Windows. Ofrece una interfaz intuitiva y es compatible con una variedad de protocolos, incluyendo FTP, SFTP, WebDAV y m\u00e1s.</li> <li>Transmit: es un cliente FTP y SFTP exclusivo para macOS con una interfaz pulida. Ofrece caracter\u00edsticas avanzadas y herramientas de administraci\u00f3n de archivos.</li> <li>Fetch: es un cliente FTP para macOS, conocido por su simplicidad y facilidad de uso. Ofrece soporte para FTP, SFTP y FTP con seguridad.</li> </ul> <p>Clientes FTP para Linux:</p> <ul> <li>FileZilla: Aunque se desarroll\u00f3 inicialmente para Windows, tambi\u00e9n est\u00e1 disponible para Linux. Es uno de los clientes FTP m\u00e1s populares y es compatible con FTP, FTPS y SFTP.</li> <li>gFTP: es un cliente FTP de c\u00f3digo abierto para sistemas Linux. Ofrece una interfaz gr\u00e1fica sencilla y soporta FTP, SFTP y HTTP.</li> <li>KDE Konqueror: El navegador de archivos Konqueror en el entorno de escritorio KDE de Linux incluye funciones de cliente FTP. Puedes usarlo para acceder a servidores FTP de manera sencilla.</li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T02/#comandos-basicos-ftp","title":"Comandos B\u00e1sicos FTP","text":"<p>Los comandos FTP son instrucciones que un cliente FTP emite al servidor FTP para realizar diversas operaciones, como conectarse al servidor, listar directorios, cargar y descargar archivos, cambiar permisos y m\u00e1s. </p> <p>Si usamos un cliente gr\u00e1fico podemos no necesitar conocerlos, ya que el cliente los usar\u00e1 de forma transparente para nosotros. Pero si usamos una conexi\u00f3n por comando deberemos conocerlos en detalle.</p> <p>Estos son algunos comandos FTP comunes junto con ejemplos de uso:</p> <p>Conexi\u00f3n al Servidor FTP:</p> <ul> <li><code>open</code> o <code>open [hostname]</code>: Establece una conexi\u00f3n con un servidor FTP. Ejemplo: <code>open ftp.example.com</code></li> <li><code>user [nombre de usuario] [contrase\u00f1a]</code>: Inicia sesi\u00f3n en el servidor FTP. Ejemplo: <code>user myuser mypassword</code></li> </ul> <p>Operaciones de Archivos y Directorio:</p> <p>Ver\u00e1s que son igual que los comandos de linux para funciones equivalentes.</p> <ul> <li><code>cd [directorio]</code>: Cambia el directorio en el servidor FTP. Ejemplo: <code>cd public_html</code></li> <li><code>pwd</code>: Muestra el directorio de trabajo actual en el servidor. Ejemplo: <code>pwd</code></li> <li><code>ls</code> o <code>dir</code>: Lista los archivos y directorios en el directorio actual en el servidor. Ejemplo: <code>ls</code></li> <li><code>ls -l [archivo]</code>: Algunos servidores FTP pueden admitir el comando ls -l para mostrar los permisos de un archivo o directorio. Ejemplo: <code>ls -l myfile.txt</code></li> <li><code>chmod [permisos] [archivo]</code>: Cambia los permisos de un archivo en el servidor FTP. Ejemplo: <code>chmod 644 myfile.txt</code></li> <li><code>delete [archivo]</code>: Elimina un archivo en el servidor FTP. Ejemplo: <code>delete unwanted.txt</code></li> <li><code>rmdir [directorio]</code>: Elimina un directorio vac\u00edo en el servidor. Ejemplo: <code>rmdir old_directory</code></li> <li><code>rmd [directorio]</code>: Elimina un directorio y su contenido de forma recursiva en el servidor FTP. No todos los servidores FTP admiten este comando. Ejemplo: <code>rmd old_directory</code></li> <li><code>mkdir [directorio]</code>: Crea un nuevo directorio en el servidor. Ejemplo: <code>mkdir new_directory</code></li> <li><code>rename [nombre original] [nuevo nombre]</code>: Cambia el nombre de un archivo o directorio en el servidor FTP. Ejemplo: <code>rename oldfile.txt newfile.txt</code></li> </ul> <p>Transferencia de Archivos:</p> <ul> <li><code>get [archivo remoto] [archivo local]</code>: Descarga un archivo del servidor FTP al sistema local. Ejemplo: <code>get example.txt</code></li> <li><code>put [archivo local] [archivo remoto]</code>: Carga un archivo desde el sistema local al servidor FTP. Ejemplo: <code>put localfile.txt remotefile.txt</code></li> </ul> <p>Modo Activo y Pasivo:</p> <ul> <li><code>PASV</code>:Este comando es enviado por el cliente al servidor FTP para solicitar que el servidor cambie a modo pasivo y abra un puerto para la conexi\u00f3n de datos.</li> <li><code>PORT</code>: cuando te conectas a un servidor FTP en modo activo, puedes utilizar el comando PORT para especificar el puerto en el cual el cliente estar\u00e1 escuchando para la conexi\u00f3n de datos.</li> </ul> <p>Ayuda y Salida:</p> <ul> <li><code>help</code> o <code>?</code>: Muestra la lista de comandos FTP disponibles. Ejemplo: <code>help</code></li> <li><code>quit</code>: Cierra la sesi\u00f3n FTP y sale del cliente. Ejemplo: <code>quit</code></li> </ul> <p>Hay que tener en cuenta que la disponibilidad de comandos y su sintaxis puede variar seg\u00fan el servidor FTP y la implementaci\u00f3n. </p> <p>Adem\u00e1s, es importante recordar que FTP no es un protocolo seguro, ya que las credenciales y los datos se transmiten sin cifrar. </p> <p>Warning</p> <p>Si se requiere seguridad, se recomienda utilizar FTPS (FTP con SSL/TLS) o SFTP (SSH File Transfer Protocol), que cifran las comunicaciones y proporcionan un nivel adicional de seguridad.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/","title":"3. Autenticaci\u00f3n, control de acceso y cuotas.","text":""},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#usuarios-y-niveles-de-acceso-al-servicio-ftp","title":"Usuarios y niveles de acceso al servicio ftp","text":"<p>A continuaci\u00f3n veremos los diferentes tipos de usuarios y sus niveles de acceso en el servidor FTP.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#acceso-anonimo-anonymous","title":"Acceso an\u00f3nimo (anonymous)","text":"<p>Los servidores pueden ofrecer servicio libremente a todos los usuarios, acceder sin tener un identificador de usuario, leer y navegar por el contenido de los directorios libremente, indiferentemente de quienes acceden y del lugar donde lo hace.</p> <p>El acceso an\u00f3nimo es una forma c\u00f3moda de permitir que todos los clientes tengan acceso a cierta informaci\u00f3n sin que el administrador del servicio tenga que controlar las cuentas de usuarios.</p> <p>La informaci\u00f3n que se usa en el acceso an\u00f3nimo es de car\u00e1cter p\u00fablico y se pueden leer los contenidos de los directorios pero no eliminarlos ni modificarlos. Normalmente, el contenido suele ser software de dominio p\u00fablico o de libre distribuci\u00f3n, im\u00e1genes, sonido, videos, etc.</p> <p>Ejemplos de servidores p\u00fablicos con acceso an\u00f3nimo: ftp://ftp.rediris.es y ftp://cdimage.ubuntu.com.</p> <p>El requisito para acceder por acceso an\u00f3nimo es mediante un nombre predefinido que existe en el servicio FTP y que tiene que estar configurado previamente.</p> <p>Este usuario que permite el acceso an\u00f3nimo se llama anonymous. Cuando se valida la conexi\u00f3n, el nombre del usuario que ponemos es anonymous, y sin contrase\u00f1a (aunque pida una contrase\u00f1a, no es necesario escribir nada o, si lo pide obligatoriamente, se puede poner cualquier correo electr\u00f3nico como contrase\u00f1a v\u00e1lida).</p> <p>Warning</p> <p>El acceso an\u00f3nimo es un tipo de acceso que es inviable en el caso del despliegue web, donde el control de acceso de los usuarios es importante, puesto que es de car\u00e1cter privado, confidencial y depende tambi\u00e9n nuestra aplicaci\u00f3n web. Permitir un acceso al directorio ra\u00edz de la aplicaci\u00f3n web con un acceso an\u00f3nimo mediante FTP es una falta grave de seguridad y puede tener consecuencias desastrosas.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#acceso-por-usuario-identificado-cuentas","title":"Acceso por usuario identificado (cuentas)","text":"<p>Se da cuando la necesidad de privilegios y la informaci\u00f3n con la cual se trabaja es de \u00edndole privada. Se tiene que acceder al servicio mediante usuarios identificados dentro del servidor FTP, llamadas cuentas.</p> <p>Las cuentas de usuario pueden ser:</p> <ul> <li>Usuario de sistema o autenticado (Local): ser\u00e1 un usuario definido dentro del sistema operativo donde se ofrece el servicio.</li> <li>Usuario virtual: no tiene una relaci\u00f3n directa con el sistema operativo. Utilizar este tipo de usuarios es \u00fatil en entornos donde la seguridad y el control de acceso son una preocupaci\u00f3n, o cuando se necesita una gesti\u00f3n m\u00e1s eficiente de m\u00faltiples cuentas de usuario FTP, ya que este tipo de usuarios proporcionan un nivel adicional de control y seguridad en el acceso al sistema.</li> </ul> <p>Todos estos usuarios tendr\u00e1n configurado una serie de permisos dependiendo de la implicaci\u00f3n que tengan los usuarios, por ejemplo dentro del proyecto web. Os pueden interesar usuarios que solo puedan leer la informaci\u00f3n del proyecto y otros que puedan actualizar los ficheros, todo esto gestionando la jerarqu\u00eda del equipo del proyecto que est\u00e1 haciendo la aplicaci\u00f3n web.</p> <p>De manera resumida podemos ver los usuarios y sus accesos</p> Usuario An\u00f3nimo Autenticado (Local) Virtual Acceso Este tipo de usuario no requiere autenticaci\u00f3n; cualquiera puede acceder de forma an\u00f3nima. Estos usuarios deben autenticarse con un nombre de usuario y contrase\u00f1a v\u00e1lidos en el servidor FTP. Los usuarios virtuales se autentican en el servidor FTP, pero no corresponden a cuentas de usuario reales en el sistema operativo del servidor. Nivel de Acceso Los usuarios an\u00f3nimos suelen tener acceso limitado y solo pueden ver y descargar archivos p\u00fablicos en un directorio espec\u00edfico. No pueden cargar ni modificar archivos en el servidor. Los usuarios autenticados pueden tener diferentes niveles de acceso seg\u00fan la configuraci\u00f3n del servidor. Pueden cargar, descargar y administrar archivos en el servidor, y su acceso se basa en las pol\u00edticas de seguridad y permisos configurados por el administrador. Los usuarios virtuales tienen un acceso limitado y controlado por el administrador del servidor. Pueden tener acceso a directorios espec\u00edficos, y sus permisos se gestionan de manera independiente de las cuentas de usuario del sistema."},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#permisos","title":"Permisos","text":"<p>Dentro de un servicio FTP, uno de los pasos importantes es el de conceder permisos determinados para controlar el acceso al servidor o a los diferentes directorios. El protocolo FTP sigue los permisos establecidos en entornos de tipo UNIX y sus similares GNU/Linux.</p> <p>Por otro lado, los permisos tambi\u00e9n son una parte importante de la configuraci\u00f3n del servicio FTP para poder restringir la lectura y escritura a usuarios que entran al sistema desde el exterior, dando siempre los m\u00ednimos permisos a los usuarios y siempre a carpeta concretas para que no puedan acceder a informaci\u00f3n a la que no est\u00e1n autorizados.</p> <p>La configuraci\u00f3n de niveles de acceso y tipos de permisos en un servidor FTP es igual que en un sistema operativo unix/linux.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#nivel-de-acceso","title":"Nivel de acceso","text":"<p>En Linux existen tres niveles de acceso a ficheros y carpetas:</p> <ul> <li>Propietario(user=u): permisos asignados al propietario del archivo o directorio.</li> <li>Grupo(group=g): permisos asignados a los grupos de usuarios.</li> <li>Otros(others=o): permisos asignados a otros usuarios existentes en el sistema operativo que no son ni propietarios ni pertenecen a un grupo.</li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#tipos-de-permisos","title":"Tipos de permisos","text":"<p>Cada fichero a su vez puede tener tres permisos:</p> <ul> <li>Lectura (r): se puede ver el contenido, visualizar un fichero o un directorio. </li> <li>Escritura (w): se puede modificar el contenido del archivo o directorio.</li> <li>Ejecuci\u00f3n (x): se puede ejecutar el archivo.</li> <li>La ausencia de permiso es identificada con el car\u00e1cter '-'. </li> </ul> <p>Cada permiso tiene un equivalente num\u00e9rico en el sistema octal, as\u00ed por ejemplo: r=4, w=2, x=1 y -=0. Por ejemplo: rw- identifica permiso de lectura y escritura o lo que es lo mismo 4+2+0=6</p> <p>En un sistema operativo tipo GNU/Linux mediante el comando <code>ls -l</code> puedes ver los permisos asignados a ficheros y directorios.</p> <p>El modo octal relacionado con los permisos es el siguiente:</p> <p></p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#veamos-un-ejemplo","title":"Veamos un ejemplo:","text":"<p>Estos tres permisos se pueden aplicar a los tres niveles anteriores, en la siguiente pantalla se puede ver un ejemplo.</p> <p></p> <p>El primer car\u00e1cter indica el tipo de archivo de la siguiente manera:</p> <ul> <li>d: directorio.</li> <li>gui\u00f3n (-): fichero.</li> <li>l: enlace (link).</li> <li>b: archivo binario.</li> <li>p: archivo especial de tuber\u00eda (pipe).</li> <li>c: archivo de caracteres especiales (por ejemplo una impresora).</li> </ul> <p>El resto son 9 caracteres, indican los permisos en cada uno de los grupos, por ejemplo: rwxr-xr-x en tres grupos.</p> <ul> <li>Primer grupo son los permisos del Propietario (user) del directorio o archivo.</li> <li>Segundo grupo son los permisos del Grupo (group).</li> <li>Tercer grupo son los permisos del resto u Otros (others) usuarios del sistema operativo.</li> <li>Despu\u00e9s aparece un n\u00famero que indica el n\u00famero de enlaces al archivo.</li> <li>La siguiente columna es el nombre de usuario propietario del archivo o directorio.</li> <li>La siguiente es el nombre del grupo al que pertenece el archivo.</li> <li>Las siguientes columnas son el tama\u00f1o y la fecha y hora de la \u00faltima modificaci\u00f3n del archivo o directorio.</li> <li>La \u00faltima columna es el nombre del directorio o archivo.</li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#comando-chmod","title":"Comando chmod","text":"<p>Para asignar permisos en Linux se usa el comando chmod que puede modificar los permisos siguientes:</p> <ul> <li>Propietario (u) </li> <li>Grupos (g)</li> <li>Otros (o)</li> </ul> <p>La sintaxis general es:  <code>chmod [opciones] modo-octal fichero</code></p> <p>Por ejemplo, si se quiere asignar permisos de lectura (r) y escritura (w) al fichero prueba1.txt solamente al usuario propietario podemos utilizar cualquiera de los dos comandos siguientes:</p> <ul> <li><code>chmod 600 prueba1.txt</code> </li> <li><code>chmod u+rw prueba1.txt</code></li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#comando-chown","title":"Comando chown","text":"<p>Este comando se utiliza para cambiar el propietario del archivo o directorio se usa el comando chown. La sintaxis general es: </p> <p><code>chown [opciones] [usuario] [:grupo] ficheros</code></p> <p>Por ejemplo, si se quiere hacer propietario a usuario1 del fichero prueba.txt el comando a utilizar ser\u00eda: </p> <p><code>chown usuario1 prueba.txt</code></p> <p>Warning</p> <p>Por otro lado en un sistema GNU/Linux, en principio, no todos los usuarios del sistema tienen acceso por ftp, as\u00ed existe un fichero /etc/ftpusers que contiene una lista de usuarios que no tienen permiso de acceso por FTP. Por razones de seguridad al menos los siguientes usuarios deber\u00edan estar listados en este fichero: root, bin, uucp, news. Ten en cuenta que las l\u00edneas en blanco y las l\u00edneas que comiencen por el car\u00e1cter '#' ser\u00e1n ignoradas.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T03/#cuotas","title":"Cuotas","text":"<p>Las cuotas de FTP se refieren a la limitaci\u00f3n de espacio en disco que se impone a los usuarios en un servidor FTP. </p> <p>El establecer cuotas FTP permite realizar un control del recurso y gestionar el uso del espacio en disco y priorizar los recursos a los usuarios, entre otras razones, especialmente en entornos compartidos o en servidores FTP p\u00fablicos.</p> <p>Las cuotas de FTP permiten a los administradores de servidores FTP asignar un l\u00edmite de espacio en disco a cada usuario o grupo de usuarios. Esto puede ser beneficioso por varias razones:</p> <ol> <li>Control de Recursos: Las cuotas evitan que un usuario o grupo utilice todo el espacio en disco disponible, lo que garantiza que haya recursos disponibles para otros usuarios.</li> <li>Gesti\u00f3n de Espacio: Ayudan a mantener organizado y gestionado el espacio en disco del servidor, evitando que se sature y se vuelva inmanejable.</li> <li>Prioridad de Recursos: Las cuotas pueden usarse para dar prioridad a ciertos usuarios o grupos, permiti\u00e9ndoles disponer de m\u00e1s espacio que otros.</li> <li>Seguridad: Limitan el da\u00f1o potencial que un usuario malicioso podr\u00eda causar si tuviera acceso ilimitado al espacio en disco del servidor.</li> <li>Evitar el Abuso: Evitan el abuso del servidor FTP, como la carga excesiva de archivos o la acumulaci\u00f3n de datos innecesarios.</li> </ol> <p>La forma en que se implementan las cuotas de FTP puede variar seg\u00fan el servidor FTP que se utilice. En algunos servidores, las cuotas se configuran en el nivel de usuario, lo que permite asignar un l\u00edmite de espacio en disco individualmente a cada usuario. En otros servidores, las cuotas pueden configurarse en el nivel de grupo, lo que permite definir l\u00edmites de espacio para grupos de usuarios.</p> <p>Las cuotas generales del servidor permiten configurar:</p> <ul> <li>Restringir la velocidad de subida y de descarga dentro del servidor FTP.</li> <li>Restringir el m\u00e1ximo de espacio de almacenamiento de un fichero al servidor FTP.</li> <li>Restringir el m\u00e1ximo de la medida del fichero que podemos descargar del servidor.</li> </ul> <p>Las cuotas de usuario o grupos de trabajo permiten:</p> <ul> <li>Restringir la velocidad de subida y de descarga del usuario o el grupo de trabajo.</li> <li>Restringir el m\u00e1ximo de espacio de almacenamiento de un fichero por parte del usuario o del grupo de trabajo.</li> <li>Restringir el m\u00e1ximo de la medida del fichero que puede descargar el usuario o el grupo de trabajo.</li> <li>Restringir de espacio propio para almacenar datos en el directorio de configuraci\u00f3n del usuario o del grupo de trabajo.</li> </ul> <p>Es importante se\u00f1alar que las cuotas de FTP no son una caracter\u00edstica est\u00e1ndar de FTP en s\u00ed mismo, sino una funcionalidad adicional proporcionada por el servidor FTP que se est\u00e9 utilizando. Si desamos configurar cuotas de FTP en el servidor, tendremos que consultar la documentaci\u00f3n espec\u00edfica del servidor FTP o las opciones de configuraci\u00f3n para conocer los detalles sobre c\u00f3mo implementarlas.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T04/","title":"4. Protocolo de transferencia de ficheros seguro","text":"<p>Cuando se redact\u00f3 el protocolo FTP dentro de la RFC 959 la seguridad no era un tema cr\u00edtico. Con la evoluci\u00f3n de las redes y la transferencia masiva de datos dentro de las redes p\u00fablicas, ha cambiado mucho respecto a las ideas originales en los a\u00f1os 70 y 80. Esta evoluci\u00f3n hace que enviar datos sin encriptar sea muy arriesgado y que protocolos antiguos tengan que evolucionar para garantizar que la remisi\u00f3n de datos sea segura.</p> <p>Con la evoluci\u00f3n de las redes, el protocolo FTP hizo que se originar\u00e1n nuevas revisiones para paliar las deficiencias de seguridad y en 1997 se redact\u00f3 la actualizaci\u00f3n del protocolo FTP que da como resultado el SFTP.</p> <p>Los autores de la RFC listaron en 1999 las diferentes vulnerabilidades FTP:</p> <ul> <li>Ataques Spoofing</li> <li>Ataques de fuerza bruta</li> <li>Ataques rebote (bounce attacks)</li> <li>Captura de paquetes (sniffing)</li> <li>Robo de puertos (puerto stealing)</li> <li>Claves de usuario y datos no cifrados</li> </ul> <p>Las soluciones a estas vulnerabilidades son:</p> <ul> <li>FTPS (cifrado SSL/TLS entre Cliente y Servidor)</li> <li>SFTP (SSH File Transfer Protocol)</li> </ul>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T04/#ftps-cifrado-ssltls-entre-cliente-y-servidor","title":"FTPS (cifrado SSL/TLS entre Cliente y Servidor)","text":"<p>FTPS (File Transfer Protocol Secure) es un protocolo de transferencia de archivos que agrega una capa de seguridad a FTP (File Transfer Protocol) mediante el uso de SSL/TLS (Secure Sockets Layer/Transport Layer Security) para cifrar las comunicaciones entre el cliente y el servidor. El objetivo principal de FTPS es proporcionar una transferencia de archivos segura y proteger la confidencialidad y la integridad de los datos durante la transferencia.</p> <p>Si hacemos una analog\u00eda con la transferencia de p\u00e1ginas web podemos decir que FTPS es a FTP lo que HTTPS es a HTTP. Dicho de otra forma, si recordamos del tema de servidores web, para la trasferencia de p\u00e1ginas web en modo seguro se desarroll\u00f3 HTTPS. Para transferir p\u00e1ginas por https, el servidor debe tener un certificado instalado y, cuando el cliente pide una p\u00e1gina por https, el servidor le env\u00eda un certificado que contiene su clave p\u00fablica. El cliente genera una clave sim\u00e9trica, que cifra con la p\u00fablica del servidor y se la env\u00eda. El servidor la desencripta con su clave privada y a partir de ah\u00ed intercambian la informaci\u00f3n de forma encriptada usando la clave aleatoria que ambos conocen.</p> <p></p> <p>Pues en FTPS es similar. El servidor debe tener un par de claves p\u00fablica privada y el establecimiento del canal es similar al visto anteriormente. Por tanto, para poder usar FTPS, vemos claramente que el servidor deber\u00e1 tener el par de claves y habr\u00e1 que configurarlo para que soporte este tipo de conexi\u00f3n.</p> <p>Hay dos modos de trabajo con FTPS :</p> <ul> <li> <p>FTPS Expl\u00edcito (FTPES): En este modo, la seguridad SSL/TLS se inicia despu\u00e9s de que el cliente se conecta al servidor y emite un comando espec\u00edfico (por ejemplo, AUTH TLS o AUTH SSL) para solicitar una conexi\u00f3n segura. Por tanto la primera conexi\u00f3n del cliente al servidor es por el puerto habitual de comandos de FTP, el 21.</p> </li> <li> <p>FTPS Impl\u00edcito (FTPIS): En este modo, la seguridad SSL/TLS se establece autom\u00e1ticamente cuando el cliente se conecta al servidor en un puerto espec\u00edfico (generalmente el puerto 990 para FTPS impl\u00edcito).</p> </li> </ul> <p>Atenci\u00f3n</p> <p>La mayor\u00eda de las conexiones FTPS utilizan el \"Modo Pasivo\" por seguridad. As\u00ed que al configurar un servidor FTPS deber\u00e1s configurar los puertos que se usar\u00e1n en el modo pasivo y abrir esos puertos en el firewall. Al realizar una conexi\u00f3n a un servidor por FTPS selecciona \"Modo pasivo\"</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T04/#sftp-ssh-file-transfer-protocol","title":"SFTP (SSH File Transfer Protocol)","text":"<p>Hay otro tipo de servicio seguro con FTP denominado SFTP.</p> <p>SFTP suele ser confundido con el servicio FTPS y viceversa, y realmente no tienen nada que ver mutuamente. Excepto por la seguridad en la remisi\u00f3n de ficheros, el procedimiento interno es diferente. SFTP est\u00e1 basado en SSH (secure shell), protocolo conocido para proveer seguridad a los terminales remotos.</p> <p>No hace uso de canales de \u00f3rdenes y de datos. Los dos canales que usamos en SFTP se env\u00edan en paquetes con formato dentro de un mismo canal, es decir, el canal de datos y de \u00f3rdenes es \u00fanico.  Por lo general, SFTP utiliza el puerto 22, que es el puerto predeterminado para las conexiones SSH. Sin embargo, este puerto puede configurarse de manera diferente si es necesario.</p> <p>Todos los datos enviados y recibidos son encriptados mediante un algoritmo de encriptaci\u00f3n previamente acordado. Las sesiones est\u00e1n protegidas mediante claves p\u00fablicas y privadas, que ofrecen un sistema de autenticaci\u00f3n conocido como autenticaci\u00f3n de clave p\u00fablica que se puede usar como alternativa o uni\u00f3n de los sistemas de autenticaci\u00f3n tradicionales de nombres de usuario y contrase\u00f1as.</p> <p>Dicho de otro modo, al establecer una conexi\u00f3n por SFTP, primero se establecer\u00e1 un canal SSH entre el cliente y el servidor, igual que en una conexi\u00f3n de consola, y una vez establecida todo en intercambio de mensajes de control y datos entre el cliente y el servidor ftp se realiza dentro de ese canal encriptado, normalmente el puerto 22.</p> <p></p> <p>Por tanto, deberemos haber configurado en el servidor SSH con la clave p\u00fablica del usuario que se va a conectar con la clave privada, exactamente igual que hicimos en la pr\u00e1ctica \"P0.3. Conceder acceso a un segundo administrador\". F\u00edjate que no hablamos del servidor ftp, sino del servidor ssh. En este caso el servidor ftp no necesita de ninguna configuraci\u00f3n adicional; no necesita generar claves p\u00fablica y privadas propias, ya que la encriptaci\u00f3n se realiza usando las claves p\u00fablica/privada de cada usuario por parte del servidor ssh.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/","title":"5. Utilizaci\u00f3n del servicio de transferencia de ficheros en el proceso de despliegue de la aplicaci\u00f3n web","text":"<p>El servicio de transferencia de archivos, como FTP (File Transfer Protocol) o SFTP (SSH File Transfer Protocol), desempe\u00f1a un papel importante en el proceso de despliegue de una aplicaci\u00f3n web. A continuaci\u00f3n, se detallan algunos escenarios en los que se utiliza el servicio de transferencia de archivos en el despliegue de aplicaciones web:</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#transferencia-de-archivos-al-servidor-web","title":"Transferencia de archivos al servidor web:","text":"<p>Para desplegar una aplicaci\u00f3n web, es necesario transferir archivos, como archivos HTML, CSS, JavaScript, im\u00e1genes y otros recursos, desde el entorno de desarrollo o el sistema local al servidor web en el que se ejecutar\u00e1 la aplicaci\u00f3n. Las conexiones FTP o SFTP son comunes para cargar estos archivos en el servidor.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#actualizaciones-y-parches","title":"Actualizaciones y parches:","text":"<p>Durante la vida \u00fatil de una aplicaci\u00f3n web, es probable que se requieran actualizaciones peri\u00f3dicas, correcciones de errores y parches de seguridad. El servicio de transferencia de archivos se utiliza para enviar estas actualizaciones y parches al servidor web sin interrumpir el funcionamiento del sitio.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#gestion-de-contenido","title":"Gesti\u00f3n de contenido:","text":"<p>En sistemas de gesti\u00f3n de contenido (CMS) y sitios web din\u00e1micos, la transferencia de archivos es esencial para cargar contenido nuevo o actualizar contenido existente. Los administradores del sitio web suelen utilizar FTP o SFTP para cargar y gestionar archivos, bases de datos y recursos multimedia.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#copia-de-seguridad-y-restauracion","title":"Copia de seguridad y restauraci\u00f3n:","text":"<p>Las copias de seguridad regulares son una parte fundamental de la gesti\u00f3n de aplicaciones web. Los servicios de transferencia de archivos facilitan la copia de seguridad de archivos y bases de datos cr\u00edticos y permiten la restauraci\u00f3n de un sitio en caso de problemas.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#automatizacion-de-despliegues","title":"Automatizaci\u00f3n de despliegues:","text":"<p>En entornos de desarrollo y despliegue continuo (CI/CD), se pueden usar herramientas de automatizaci\u00f3n para desplegar autom\u00e1ticamente aplicaciones web. Estas herramientas pueden utilizar protocolos de transferencia de archivos para enviar nuevas versiones de la aplicaci\u00f3n al servidor de producci\u00f3n.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#carga-de-recursos-de-terceros","title":"Carga de recursos de terceros:","text":"<p>Algunas aplicaciones web utilizan recursos externos, como bibliotecas JavaScript, fuentes, im\u00e1genes, etc. Estos recursos a menudo se almacenan en servidores externos y se acceden a trav\u00e9s de FTP o SFTP.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#actualizaciones-de-plugins-o-extensiones","title":"Actualizaciones de plugins o extensiones:","text":"<p>Si una aplicaci\u00f3n web utiliza plugins, extensiones o m\u00f3dulos adicionales, las actualizaciones de estos componentes a menudo se entregan mediante transferencias de archivos.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#configuracion-y-archivos-de-servidor","title":"Configuraci\u00f3n y archivos de servidor:","text":"<p>Los archivos de configuraci\u00f3n del servidor web, como archivos de configuraci\u00f3n de Apache o NGINX, tambi\u00e9n se pueden actualizar y transferir mediante servicios de transferencia de archivos.</p> <p>Al utilizar servicios de transferencia de archivos en el proceso de despliegue de una aplicaci\u00f3n web, es fundamental garantizar la seguridad de las conexiones y proteger los datos transmitidos. SFTP (SSH File Transfer Protocol) es una opci\u00f3n m\u00e1s segura en comparaci\u00f3n con FTP, ya que cifra la transferencia de datos y autentica a los usuarios de manera m\u00e1s s\u00f3lida. Tambi\u00e9n es importante seguir pr\u00e1cticas de seguridad, como limitar los permisos de acceso y realizar copias de seguridad antes de cualquier despliegue o actualizaci\u00f3n.</p>"},{"location":"Ud5%20Servicios%20de%20red%20FTP/T05/#utilizacion-del-servicio-de-transferencia-de-ficheros-desde-el-navegador-web","title":"Utilizaci\u00f3n del servicio de transferencia de ficheros desde el navegador web.","text":"<p>El servicio de transferencia de archivos desde el navegador web se refiere a la capacidad de cargar y descargar archivos directamente desde un navegador web sin la necesidad de utilizar un cliente FTP u otras herramientas de transferencia de archivos externas. Esto es posible gracias a las tecnolog\u00edas web y los protocolos que permiten la transferencia de archivos a trav\u00e9s de una interfaz web. </p> <p>Este servicio es especialmente \u00fatil para sitios web que ofrecen compartir archivos, como plataformas de almacenamiento en la nube, servicios de intercambio de archivos y sitios de transferencia de archivos temporales.</p> <p>En resumen, el servicio de transferencia de archivos desde el navegador web proporciona una forma conveniente y segura de gestionar tus archivos y compartirlos con otros usuarios a trav\u00e9s de una interfaz web intuitiva, eliminando la necesidad de herramientas de transferencia de archivos externas.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/","title":"Pr\u00e1ctica 1: Instalaci\u00f3n de Tomcat","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#introduccion","title":"Introducci\u00f3n","text":"<p>Recordamos que estamos en el apartado de \"Despliegue de aplicaciones Java\" y, com ya vimos en la teor\u00eda, Tomcat es una de las opciones para este tipo de despliegues.</p> <p>En esta pr\u00e1ctica vamos a instalar el servidor de aplicaciones Apache Tomcat en su \u00faltima versi\u00f3n disponible.</p> <p>Si consultamos el apartado de versiones de Tomcat en su p\u00e1gina oficial, nos daremos cuenta de que la \u00faltima versi\u00f3n estable disponible en el momento de redacci\u00f3n de esta pr\u00e1ctica es la 10.1.15 que soporta versiones de Java 11 y posteriores. Esto podr\u00eda hacer que algunos despliegues que realicemos con ficheros .war desarrollados en versiones anteriores de java planteen problemas. Esto nos servir\u00e1 para ver la importancia de usar las mismas versiones en fase de desarrollo y fase de despliegue y acordar entre desarrolladores y encargados de despliegue cualquier actualizaci\u00f3n antes de llevarla a cabo.</p> <p>En Java 9 se introdujeron novedades como un nuevo sistema de m\u00f3dulos (Jigsaw), entre otras.</p> <p>En Java 11 se dio un paso m\u00e1s al haber renombrado completamente las rutas de paquetes \"javax.*\" a \"jakarta.*\". Oracle, a pesar de haber hecho p\u00fablico el desarrollo de Java, no hizo lo mismo con su nombre. Por tanto, si el paquete a desplegar ya est\u00e1 compilado, poco podemos hacer. Pero si disponemos del c\u00f3digo fuente y nos da un error de complilaci\u00f3n, podemos mirar si los paquetes que est\u00e1 usando son los \"javax.*\" y sustituirlos por \"jakarta.*\" e intentar complilar de nuevo.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#instalacion-de-tomcat","title":"Instalaci\u00f3n de Tomcat","text":"<p>Esta pr\u00e1ctica es muy sencilla y va a consistir en realizar la instalaci\u00f3n del servidor de aplicaciones Tomcat, en una m\u00e1quina virtual Debian.</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#creacion-de-la-maquina-virtual","title":"Creaci\u00f3n de la m\u00e1quina virtual","text":"<p>Para empezar, entra en AWS Academy y crea un nuevo EC2 Debian con estas caracter\u00edsticas. </p> <ul> <li>Ll\u00e1male PTomcat.</li> <li>Dale los recursos que te ofrece por defecto.</li> <li>El acceso al servidor Tomcat se realiza por el puerto TCP 8080. Puedes modificar el Grupo de seguridad ahora para permitir el acceso por http, https y TCP 8080 ahora o editarlo m\u00e1s tarde.</li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#instalacion-de-java","title":"Instalaci\u00f3n de Java","text":"<p>Una vez creada, entra como administrador y vamos a instalar Java en primer lugar.</p> <ol> <li> <p>Comprobar si est\u00e1 instalado:</p> <pre><code>java --version\n</code></pre> <p>En caso de no estarlo lo indicar\u00e1</p> </li> <li> <p>De no estar instalado lo haremos con:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\nsudo apt-get install default-jdk\nsudo apt-get install default-jre\n</code></pre> <p>Volver a comprobar: <code>java --version</code></p> <p>Deber\u00eda aparecer una pantalla como esta:</p> <p></p> </li> </ol> <p>Una vez Java instalado pasamos a la instalaci\u00f3n del servidor TOMCAT propiamente dicho.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#instalacion-de-apache-tomcat","title":"Instalaci\u00f3n de Apache Tomcat","text":"<p>Se puede hacer tanto con el administrador de paquetes <code>apt</code> como de forma manual. La forma m\u00e1s recomendable por su sencillez es la primera.</p> <p>Ejecutamos</p> <pre><code>sudo apt-get install -y tomcat10 tomcat10-admin\n</code></pre> <p>Comprobamos si est\u00e1 instalado</p> <pre><code>systemctl status tomcat10\n</code></pre> <p>Y comproblamos que est\u00e1 correctamente instalado.</p> <p></p> <p>Presionaremos la tecla q para volver al prompt.</p> <p>Ahora comprueba que tienes acceso al servidor escribiendo en un navegador en tu equipo local <code>http://IP_SERVIDOR:8080</code> debe aparecer la siguiente pantalla. F\u00edjate que estamos accediendo por http (no https) y por el puerto 8080. Si no modificaste el Grupo de Seguridad en AWS para permitir el acceso a este puerto, hazlo ahora.</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P01-TomcatInstalacion/#gestionar-de-forma-grafica-tomcat-y-creacion-de-usuario-de-tomcat","title":"Gestionar de forma gr\u00e1fica Tomcat y creaci\u00f3n de usuario de Tomcat.","text":"<p>Para gestionar Tomcat de forma gr\u00e1fica, tenemos un interfaz gr\u00e1fico al que se accede mediante <code>http://IP_SERVIDOR:8080/manager</code>. </p> <p>Si intentas acceder ver\u00e1s que te pide un usuario y una contrase\u00f1a y no podr\u00e1s acceder. Hemos de crear un usuario de Tomcat con esos permisos. </p> <p>Vamos a crearlo modificando el archivo <code>/etc/tomcat10/tomcat-users.xml</code> (con el editor que quieras).</p> <p>Merece la pena dedicarle un tiempo a leer ese fichero. Ver\u00e1s que Tomcat tiene una serie de roles administrativos predefinidos. Hemos de activar aquellos que queramos y luego asignarlos a los usuarios que deseemos.  Para poder tener acceso al:</p> <ul> <li>\"Gestor de Aplicaciones Web de Tomcat\" deberemos activar el rol \"manager-gui\".</li> <li>\"Gestor de M\u00e1quina Virtual de Tomcat\" necesitaremos activar el rol \"admin-gui\".</li> </ul> <p><pre><code>sudo nano /etc/tomcat10/tomcat-users.xml\n</code></pre> A\u00f1ade las siguientes l\u00edneas antes del cierre .</p> <p><pre><code>  &lt;role rolename=\"manager-gui\"/&gt;\n  &lt;role rolename=\"admin-gui\"/&gt;\n  &lt;user username=\"admin\" password=\"ieselcaminas\" roles=\"admin-gui,manager-gui\"/&gt;\n</code></pre> As\u00ed pues, crearemos un usuario llamado \"admin\" con password \"ieselcaminas\" al que le asignaremos esos dos roles, admin-gui y manager-gui. </p> <p>Reinicia tomcat: <code>sudo systemctl restart tomcat10</code></p> <p>Comprueba el estado: <code>sudo systemctl status tomcat10</code></p> <p>Accede ahora a <code>http://IP_SERVIDOR:8080/manager</code>, introduce el usuario y contrase\u00f1a creado y deber\u00edas acceder al \"Gestor de Aplicaciones Web de Tomcat\".</p> <p></p> <p>Accede ahora a <code>http://IP_SERVIDOR:8080/host-manager</code>, introduce el usuario y contrase\u00f1a creado y deber\u00edas acceder al \"Gestor de M\u00e1quina Virtual de Tomcat\".</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/","title":"Pr\u00e1ctica 2: Despliegue de aplicaciones con Tomcat.","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#despliegue-manual-mediante-gestor-de-aplicaciones-web-de-tomcat","title":"Despliegue manual mediante Gestor de Aplicaciones Web de Tomcat","text":"<p>Realizaremos el despliegue manual de una aplicaci\u00f3n ya previamente empaquetada en formato WAR. Para ello accedemos al \"Gestor de Aplicaciones Web de Tomcat\" como vimos en la pr\u00e1ctica anterior.</p> <ol> <li> <p>Nos logueamos con el usuario previamente creado.</p> </li> <li> <p>Descargamos el archivo de muestra sample.war</p> </li> <li> <p>Buscamos la secci\u00f3n que nos permite desplegar un WAR manualmente, seleccionamos nuestro archivo y lo desplegamos. </p> <p></p> <p>Tras estos pasos, se nos listar\u00e1 la aplicaci\u00f3n ya desplegada como un directorio m\u00e1s y podremos acceder a ella. </p> <p></p> <p>Al lado de cada una de las aplicaciones instaladas aparecen varios comandos:</p> <ul> <li>Replegar es para desinstalarla.</li> <li>Reiniciar es muy \u00fatil si en alg\u00fan momento no se est\u00e1n reflejando los cambios que estamos realizando, por ejemplo al cambiar el contenido de alguna clase.</li> </ul> </li> <li> <p>Comprobamos el funcionamiento. Entrar en <code>http://IP_SERVIDOR:8080/sample</code> ver\u00e1s esto:</p> <p></p> <p>Si haces clic sobre \"JSP page\" ver\u00e1s esto.</p> <p></p> <p>Pero si haces clic sobre \"servlet\"</p> <p></p> <p>No se est\u00e1 ejecutando el Servlet y si ves los mensajes ha encontrado un problema. Recuerda que al principio hablamos de los problemas de versiones de java y que a partir de la versi\u00f3n 11 de Java se renombraron las librer\u00edas java a jakarka. Este .war se complil\u00f3 en una versi\u00f3n anterior y ahora no podemos desplegarlo. Aqu\u00ed el problema de las versiones.</p> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#crear-una-aplicacion-nueva-paso-a-paso","title":"Crear una aplicaci\u00f3n nueva paso a paso","text":"<p>En el apartado anterior hemos desplegado una aplicaci\u00f3n de la que dispon\u00edamos del fichero .war. Ahora vamos a crear una aplicaci\u00f3n nueva. Esto asemejar\u00eda un entorno en el que al departamento de despliegue le facilitan directamente el c\u00f3digo fuente de la aplicaci\u00f3n en lugar de la aplicaci\u00f3n ya compilada.</p> <p>Tomcat guarda las aplicaciones que despleguemos dentro de la carpeta <code>/var/lib/tomcat10/webapps</code>. Si hacemos un listado largo de dicha carpeta observaremos lo siguiente:</p> <p><pre><code>ls -la /var/lib/tomcat10/webapps\ntotal 24\ndrwxrwxr-x 4 tomcat tomcat 4096 Sep 10 10:00 .\ndrwxr-xr-x 5 root   root   4096 Sep 10 15:24 ..\ndrwxr-xr-x 3 root   root   4096 Sep 10 09:24 ROOT\ndrwxr-x--- 5 tomcat tomcat 4096 Sep 10 10:00 sample\n-rw-r----- 1 tomcat tomcat 4606 Sep 10 10:00 sample.war\n</code></pre> Observa un par de cosas. </p> <ul> <li>Las aplicaciones desplegadas pertenecen al usuario <code>tomcat</code>.</li> <li>La aplicaci\u00f3n \"sample\" que desplegamos anteriormente tiene el fichero <code>sample.war</code> que subimos y una carpeta <code>sample</code> que corresponde a la aplicaci\u00f3n ya desplegada</li> </ul> <p>Recordamos pues que la estructura de un Archivo WAR es la siguiente:</p> <ul> <li>/  : Este directorio base contiene los elementos que com\u00fanmente son utilizados en un sitio, Documentos en HTML , JSP's , CSS(\"Cascading Style Sheets\") y otros elementos. </li> <li>/WEB-INF/web.xml : Contiene elementos de seguridad de la aplicaci\u00f3n as\u00ed como detalles sobre los Servlets que ser\u00e1n utilizados dentro de la misma.</li> <li>/WEB-INF/classes/ : Contiene las clases Java adicionales a las del JDK que ser\u00e1n empleadas en los JSP's y Servlets</li> <li>/WEB-INF/lib/ : Contiene los JAR's que ser\u00e1n utilizados por su aplicaci\u00f3n.</li> </ul> <p>Y comprobamos que nuestra aplicaci\u00f3n sample cumple con esa estructura: <pre><code>ls -l /var/lib/tomcat10/webapps/sample\ntotal 20\ndrwxr-x--- 2 tomcat tomcat 4096 Nov  5 18:07 META-INF\ndrwxr-x--- 4 tomcat tomcat 4096 Nov  5 18:07 WEB-INF\n-rw-r----- 1 tomcat tomcat  376 Jul 30  2007 hello.jsp\ndrwxr-x--- 2 tomcat tomcat 4096 Nov  5 18:07 images\n-rw-r----- 1 tomcat tomcat  636 Jul 30  2007 index.html\n\nls -l /var/lib/tomcat10/webapps/sample/WEB-INF/\ntotal 12\ndrwxr-x--- 3 tomcat tomcat 4096 Nov  5 18:07 classes\ndrwxr-x--- 2 tomcat tomcat 4096 Nov  5 18:07 lib\n-rw-r----- 1 tomcat tomcat  813 Jul 30  2007 web.xml\n</code></pre></p> <p>Por tanto, para desplegar nuevas aplicaciones manualmente deberemos :</p> <ol> <li>Primero logearnos como usuario <code>tomcat</code> </li> <li>Segundo generar una estructura de carpetas para la aplicaci\u00f3n a desplegar similar a la de \"sample\", que es la estructura que necesita Tomcat.</li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#1-usuario-tomcat","title":"1. Usuario Tomcat","text":"<p>Para entrar como usuario <code>tomcat</code> veamos primero c\u00f3mo est\u00e1 creado en el fichero <code>/etc/passwd</code>:</p> <pre><code>cat /etc/passwd\n</code></pre> <p>Y buscamos la l\u00ednea:</p> <p><code>tomcat:x:994:994:Apache Tomcat:/var/lib/tomcat:/usr/sbin/nologin</code></p> <p>El \u00faltimo campo indica la ruta del shell asignado al usuario. Vemos que tiene <code>/usr/sbin/nologin</code> lo nos indica que es un usuario que no puede shell asignado y, por tanto, no puede logarse en el sistema. Como nosotros necesitamos logarnos cambiaremos el shell por:</p> <p><code>tomcat:x:994:994:Apache Tomcat:/var/lib/tomcat:/bin/bash</code></p> <p>Como desconocemos la password del usuario <code>tomcat</code> le asignaremos una nueva. Vamos a ponerle password <code>ieselcaminas</code>.</p> <pre><code>sudo passwd tomcat\n</code></pre> <p>Ahora entraremos en el sistema como usuario <code>tomcat</code></p> <pre><code>su tomcat\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#2-estructura-de-carpetas","title":"2. Estructura de carpetas","text":"<p>Ahora ya podemos empezar a desplegar nuestra aplicaci\u00f3n a la que llamaremos \"prueba\". Crearemos la siguiente estructura de carpetas dentro de <code>/var/lib/tomcat10/webapps</code>.</p> <p></p> <p>Podemos hacerlo en un solo comando con: <pre><code>mkdir -p /var/lib/tomcat10/webapps/prueba/WEB-INF/classes\n</code></pre></p> <p>Si comprobamos en nuestro Gestor de Aplicaciones Web de Tomcat veremos que aparece nuestra nueva aplicaci\u00f3n llamada \"prueba\" en la lista de aplicaciones. Aunque si intentamos hacer algo nos dar\u00e1 error al no contener nada todav\u00eda.</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#creamos-los-archivos-java-y-class","title":"Creamos los archivos .java y .class","text":"<p>Dentro de la carpeta <code>prueba</code> crea el archivo <code>hola1.java</code> con el c\u00f3digo siguiente:</p> <pre><code>import javax.servlet.*;\nimport javax.servlet.http.*;\nimport java.io.*;\npublic class hola1 extends HttpServlet {\n public void init(ServletConfig conf)\n    throws ServletException {\n    super.init(conf);\n }\n\npublic void service(HttpServletRequest req, HttpServletResponse res)\n throws ServletException, IOException {\n    res.setContentType(\"text/html\");\n    PrintWriter out = res.getWriter();\n    out.println(\"&lt;html&gt;\");\n    out.println(\"&lt;body&gt;\");\n    out.println(\"&lt;h1&gt;servlet hola 1&lt;/h1&gt;\");\n    out.println(\"&lt;/body&gt;\");\n    out.println(\"&lt;/html&gt;\");\n    }\n}\n</code></pre> <p>Desde el directorio prueba ejecuta el comando para compilar la aplicaci\u00f3n java: </p> <pre><code>javac -classpath /usr/share/tomcat10/lib/servlet-api.jar hola1.java\n</code></pre> <p>\u00bfSe ha podido complilar? Probablemente no, \u00bfverdad? Mira en los errores y recuerda lo que hemos hablado ya sobre las versiones de Java. \u00bfSe te ocurre d\u00f3nde puede estar el error? </p> <p>Atenci\u00f3n</p> <p>Recuerda que comentamos que a partir de Java 11 las rutas de paquetes javax. pasaron a jakarta.. Prueba a cambiar las rutas en <code>hola1.java</code> y vuelve a complilar. \u00bfSe ha compilado bien ahora? Nuevamente, comprueba la importancia de usar las mismas versiones en desarrollo y despliegue.</p> <p>Si no hay ning\u00fan problema el fichero <code>hola1.java</code> se compilar\u00e1 y aparecer\u00e1 un fichero <code>hola1.class</code>.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#configura-el-servlet","title":"Configura el servlet","text":"<p>La principal diferencia de un servlet Java respecto a una aplicaci\u00f3n Java normal, es que una aplicaci\u00f3n (una vez compilada) ya la podr\u00edamos ejecutar, mientras que el servlet lo tendremos que a\u00f1adir al contenedor de servlets.  Para ello mueve <code>hola1.class</code> a la carpeta <code>webapps/prueba/WEB-INF/classes</code>.</p> <pre><code>  mv hola1.class ./WEB-INF/classes\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#configura-el-servidor-de-aplicaciones","title":"Configura el servidor de aplicaciones","text":"<p>Ahora hay que configurar el servidor de aplicaciones (hay que decir d\u00f3nde est\u00e1 el nuevo servlet). Para ello crea el fichero <code>web.xml</code> en el directorio WEB-INF (en \u00e9l se indica donde est\u00e1 el servlet y como mapearlo en una llamada) con el siguiente c\u00f3digo:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt;\n&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\"&gt;\n&lt;web-app&gt;\n    &lt;display-name&gt;Ejemplos tutorial&lt;/display-name&gt;\n    &lt;description&gt;Servlets de ejemplos del tutorial de Servlets y JDBC.&lt;/description&gt;\n    &lt;servlet&gt;\n        &lt;servlet-name&gt;hola1&lt;/servlet-name&gt;\n        &lt;servlet-class&gt;hola1&lt;/servlet-class&gt;\n    &lt;/servlet&gt;\n    &lt;servlet-mapping&gt;\n        &lt;servlet-name&gt;hola1&lt;/servlet-name&gt;\n        &lt;url-pattern&gt;/hola1&lt;/url-pattern&gt;\n    &lt;/servlet-mapping&gt;\n&lt;/web-app&gt;\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#otros-ficheros-necesarios","title":"Otros ficheros necesarios","text":"<p>Para el ejemplo vamos a necesitar 2 ficheros m\u00e1s dentro de la carpeta \"prueba\":</p> <ul> <li>index.html</li> <li>hola1.jsp</li> </ul> <p>El fichero <code>index.html</code> contendr\u00e1 lo siguiente:</p> <pre><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Actividad de prueba con Tomcat&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body bgcolor=white&gt;\n        &lt;div style=\" width:100% text-align:center\"&gt;\n            &lt;img width=\"200\" src=\"tomcat.gif\"&gt;\n            &lt;br&gt;\n            &lt;h1&gt;Actividad con Tomcat&lt;/h1&gt;\n            &lt;p&gt;Despliegue de aplicaciones web&lt;/p&gt;\n        &lt;/div&gt;\n        &lt;div style=\"background:#ffc; margin-top:30px; padding:30px; text-align:center\"&gt;\n            Ir a &lt;a href=\"hola1.jsp\"&gt;JSP page&lt;/a&gt;\n            &lt;br&gt;\n            Ir al &lt;a href=\"hola1\"&gt;servlet&lt;/a&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Y el contenido de hola1.jsp:</p> <pre><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Ejemplo p\u00e1gina JSP&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body bgcolor=white&gt;\n        &lt;div style=\" width:100%; text-align:center\"&gt;\n            &lt;img width=\"150\" src=\"tomcat.gif\"&gt;\n            &lt;br&gt;\n            &lt;h1&gt;Ejemplo JSP hola1&lt;/h1&gt;\n            &lt;br&gt;\n            &lt;%= new String(\"Hola 1\") %&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Observa c\u00f3mo estamos usando una imagen <code>tomcat.gif</code>. Puedes copiarla del proyecto \"sample\"</p> <p>Ya podemos probar nuestra aplicaci\u00f3n de prueba desde el navegador de nuestro equipo accediendo a <code>http://IPSERVIDOR:8080/prueba/</code> o directamente desde el Gestor de Aplicaciones Web de Tomcat.</p> <p>Probablemente hemos llegado hasta aqu\u00ed copiando y pegando pero sin saber demasiado bien qu\u00e9 hemos hecho ni como hacer modificaciones.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#el-fichero-indexhtml","title":"El fichero index.html","text":"<p>Como en toda p\u00e1gina web, el fichero <code>index.html</code> es el que se mostrar\u00e1 al acceder a la URL de la aplicaci\u00f3n <code>http://IPSERVIDOR:8080/prueba/</code>. Comprueba su contenido y lo que se muestra en el navegador.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#el-fichero-hola1jsp","title":"El fichero <code>hola1.jsp</code>","text":"<p>Un fichero JSP (JavaServer Pages) es un tipo de archivo utilizado en el desarrollo web que combina c\u00f3digo Java con contenido HTML para crear p\u00e1ginas web din\u00e1micas. Los archivos JSP permiten a los desarrolladores mezclar l\u00f3gica de programaci\u00f3n en Java con la presentaci\u00f3n de p\u00e1ginas web de una manera m\u00e1s sencilla y organizada.</p> <p>Una caracter\u00edstica clave de los archivos JSP es la integraci\u00f3n de Java: Los archivos JSP permiten la inclusi\u00f3n de fragmentos de c\u00f3digo Java directamente en el contenido HTML utilizando etiquetas especiales &lt;% %&gt; para encerrar el c\u00f3digo Java. Esto permite la ejecuci\u00f3n de c\u00f3digo en el servidor antes de que se env\u00ede la p\u00e1gina al navegador del cliente.</p> <p>Observa como nuestro fichero hola1.jsp contiene la l\u00ednea <code>&lt;%= new String(\"Hola 1\") %&gt;</code> que es un fragmento de c\u00f3digo java que ejecurar\u00e1 nuestro servidor Tomcat antes de entregar la p\u00e1gina al usuario, sustituy\u00e9ndolo por el resultado de ejecutar ese fragmento de c\u00f3digo, que en este caso no es m\u00e1s que sacar una cadena de texto. Comprueba el resultado en el navegador.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#el-servlet","title":"El servlet","text":"<p>El servlet es el primer fichero que hemos creado, llamado <code>hola1.java</code> y que despu\u00e9s hemos compilado. Solo contiene un texto dentro de una etiqueta <code>&lt;h1&gt;</code>, su contenido se mostrar\u00e1 al hacer clic en <code>Ir al servlet</code> desde la p\u00e1gina principal.</p> <p>Observa c\u00f3mo para mapear el servlet hemos tenido que hacerlo en el fichero <code>web.xml</code>.</p> <p>Task</p> <p>Para ver si has entendido bien qu\u00e9 hace cada cosa realiza lo siguiente:</p> <ul> <li>Cambia el texto que muestra el fragmento de c\u00f3digo java en hola1.jsp</li> <li>Crea un segundo servlet que llamaremos <code>hola2</code> y haz que en la p\u00e1gina index.html tengas una l\u00ednea adicional que diga <code>Ir a servlet2</code> que ejecute dicho servlet.</li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P02-TomcatDespliegue/#crea-el-host-virtual-voluntario","title":"Crea el Host Virtual - Voluntario","text":"<p>En la pr\u00e1ctica 1 vimos c\u00f3mo pod\u00edamos acceder al Tomcat Web Application Manager y al  Tomcat Virtual Host Manager.</p> <p>Un host virtual en Tomcat nos permitir\u00e1 acceder a una aplicaci\u00f3n desplegada a trav\u00e9s de un nombre de dominio de esa aplicaci\u00f3n, sin necesidad de acceder al ra\u00edz del servidor tomcat y poner al final /app (sustituyendo app por el nombre de la aplicaci\u00f3n). Es como los host virtuales que configuramos en Nginx en el tema anterior.</p> <p>Llegados a este punto, ya tienes un par de aplicaciones desplegadas. Busca en internet c\u00f3mo crear un web virtual y crea uno para una de ellas. Recuerda que tendr\u00e1s que modificar el fichero /etc/hosts para acceder al host virtual creado.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/","title":"Pr\u00e1ctica 3: Despliegue en Tomcat con Maven","text":"<p>Apache Maven es una herramienta de gesti\u00f3n de proyectos ampliamente utilizada en el desarrollo de software. Proporciona una forma eficiente de administrar la construcci\u00f3n, el ciclo de vida y las dependencias de proyectos Java y otros lenguajes de programaci\u00f3n. Con Maven, los desarrolladores pueden automatizar la compilaci\u00f3n, la prueba y la distribuci\u00f3n de sus proyectos, lo que simplifica el proceso de desarrollo y garantiza la consistencia en la gesti\u00f3n de proyectos a lo largo del tiempo. Adem\u00e1s, Maven facilita la colaboraci\u00f3n en proyectos de c\u00f3digo abierto al proporcionar una forma est\u00e1ndar de compartir y gestionar bibliotecas y dependencias.</p> <p>Al integrar Maven con Tomcat, se obtiene una forma eficiente de administrar y desplegar aplicaciones web Java en un servidor Tomcat. Maven facilita la gesti\u00f3n de dependencias, la construcci\u00f3n de proyectos y la automatizaci\u00f3n de tareas de despliegue, lo que agiliza el ciclo de desarrollo y garantiza una gesti\u00f3n m\u00e1s consistente de las aplicaciones web en el servidor Tomcat.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#instalacion-de-maven","title":"Instalaci\u00f3n de Maven","text":"<p>Para instalar Maven en nuestro Debian tenemos, de nuevo, dos opciones:</p> <ul> <li> <p>Instalaci\u00f3n mediante gestor de paquetes APT</p> </li> <li> <p>Instalaci\u00f3n manual</p> </li> </ul> <p>La primera, recomendada,  es mucho m\u00e1s sencilla y automatizada (establece todos los paths y variables de entorno), aunque con la segunda se podr\u00eda conseguir un paquete m\u00e1s actualizado.</p> <p>Ambos m\u00e9todos vienen explicados aqu\u00ed</p> <p>Si decidimos seguir el primer m\u00e9todo, el m\u00e1s sencillo, vemos que es tan simple como actualizar los repositorios:</p> <pre><code>sudo apt-get update\n</code></pre> <p>E instalar Maven</p> <p><pre><code>sudo apt-get install maven\n</code></pre> Para comprobar que todo ha ido correctamente, podemos ver la versi\u00f3n instalada de Maven:</p> <pre><code>mvn --v\n</code></pre> <p>Pero antes de pasar a integrar Tomcat con Maven hemos de tener algunos conocimientos b\u00e1sicos de Maven. Para ello realizaremos esta breve pr\u00e1ctica: Maven in 5 minutes. Aqu\u00ed aprenderemos conceptos b\u00e1sicos c\u00f3mo:</p> <ul> <li>C\u00f3mo crear un proyecto </li> <li>La estructura de carpetas de un proyecto </li> <li>El fichero POM</li> <li>Compilar un proyecto</li> <li>Las fases de un proyecto</li> </ul> <p>No intentes seguir la pr\u00e1ctica sin haber comprendido antes todo lo anterior o no sabr\u00e1s qu\u00e9 est\u00e1s haciendo</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#configuracion-de-maven","title":"Configuraci\u00f3n de Maven","text":"<p>Para poder realizar despliegues en nuestro Tomcat previamente instalado, necesitamos realizar la configuraci\u00f3n adecuada para Maven. Ya sabemos que esto en Linux significa editar los archivos de configuraci\u00f3n adecuados. Vamos a ello.</p> <p>1.Creaci\u00f3n de usuario para Maven</p> <p>En primer lugar necesitamos asegurarnos de que en el apartado anterior de la pr\u00e1ctica hemos a\u00f1adido todos los usuarios necesarios, as\u00ed como sus respectivos roles. Ahora debemos a\u00f1adir el rol de <code>manager-script</code> para permitir que Maven se autentique contra Tomcat y pueda realizar el despliegue.</p> <p>Los roles utilizados por Tomcat vienen detallados en su documentaci\u00f3n, que merece ser consultada:</p> <p></p> <p>En dicha documentaci\u00f3n se nos indica que, por temas de seguridad, es recomendable no otorgar los roles de manager-script o manager-jmx al mismo usuario que tenga el rol de manager-gui. </p> <p>Info</p> <pre><code>Tendremos dos usuarios, uno para la GUI y otro exclusivamente para hacer los deploys de Maven.\n</code></pre> <p>As\u00ed las cosas, modificamos el archivo <code>/etc/tomcat10/tomcat-users.xml</code> acorde a nuestras necesidades. A\u00f1adiremos un usuario \"despliegues\" con password \"ieselcaminas\":</p> <pre><code>     &lt;role rolename=\"admin-gui\"/&gt;\n     &lt;role rolename=\"manager-gui\"/&gt;\n     &lt;role rolename=\"manager-script\"/&gt;\n     &lt;user username=\"admin\" password=\"ieselcaminas\" roles=\"admin-gui,manager-gui\"/&gt;\n     &lt;user username=\"despliegues\" password=\"ieselcaminas\" roles=\"manager-script\"/&gt;\n</code></pre> <p>Como hemos hecho cambios en la configuraci\u00f3n de Tomcat deberemos reiniciarlo</p> <pre><code>     sudo systemctl restart tomcat10.service\n</code></pre> <p>2.Indicar a Maven sobre el servidor que vamos a desplegar (en nuestro caso TOMCAT)</p> <p>Editar el archivo <code>/etc/maven/settings.xml</code>  para indicarle a Maven un identificador para el servidor sobre el que vamos a desplegar. No es m\u00e1s que un nombre, le pondremos DesplieguesTomcat, pero podr\u00eda ser cualquier cosa. El usuario y password ser\u00e1n los que definimos antes en <code>tomcat-users.xml</code>. Todo esto se har\u00e1 dentro del bloque servers del XML:</p> <pre><code>    &lt;server&gt;\n      &lt;id&gt;DesplieguesTomcat&lt;/id&gt;\n      &lt;username&gt;despliegues&lt;/username&gt;\n      &lt;password&gt;ieselcaminas&lt;/password&gt;\n    &lt;/server&gt;\n</code></pre> <p>Ya tenemos Maven y Tomcat preparados para trabajar juntos. Veamos c\u00f3mo desplegar ahora un proyecto.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#despliegue-de-un-proyecto-ya-preparado","title":"Despliegue de un proyecto ya preparado.","text":"<p>Empezaremos desplegando un proyecto que ya est\u00e1 preparado para ser desplegado con Maven. Para ello clonaremos el proyecto \"rock-paper-scissors\" de GitHub. Col\u00f3cate en un directorio de tu elecci\u00f3n y ejecuta lo siguiente. Igual tienes que instalar git antes, pero ya sabes c\u00f3mo hacerlo.</p> <pre><code>git clone https://github.com/cameronmcnz/rock-paper-scissors.git\ncd rock*\ngit checkout patch-1\n</code></pre> <p>Como ya vimos en el taller de Git, estamos clonando un proyecto de GitHub y coloc\u00e1ndonos en la rama patch-1. Ten en cuenta el comando para cambiar a la rama <code>patch-1</code>. La rama <code>master</code> compilar\u00e1 en un archivo JAR integrado, lo cual no es lo que deseamos aqu\u00ed. En su lugar, queremos que el proyecto compile en un archivo WAR para implementarlo en Tomcat con Maven.</p> <p>Ahora debemos modificar el <code>POM</code> del proyecto para que haga referencia a que el despliegue se realice con el plugin de Maven para Tomcat. </p> <p>Info</p> <p>No existen plugins oficiales para Tomcat m\u00e1s all\u00e1 de la versi\u00f3n 7 del servidor. No obstante, el plugin para  Tomcat 7 sigue funcionando correctamente con Tomcat 9. </p> <p>Otra opci\u00f3n ser\u00eda utilizar el plugin Cargo</p> <p>Donde lo que a\u00f1adimos es el bloque <code>&lt;plugin&gt;</code> dentro del bloque <code>&lt;plugins&gt;</code>.</p> <pre><code>&lt;build&gt;\n    &lt;finalName&gt;roshambo&lt;/finalName&gt; #(1)\n    &lt;plugins&gt; \n        &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;\n        &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;\n        &lt;version&gt;2.2&lt;/version&gt;\n        &lt;configuration&gt;\n            &lt;url&gt;http://localhost:8080/manager/text&lt;/url&gt; #(2)\n            &lt;server&gt;DesplieguesTomcat&lt;/server&gt; #(3)\n            &lt;path&gt;/rps&lt;/path&gt; #(4)\n        &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <ol> <li> <p>Nombre final del ejecutable que se va a generar. No has de cambiarlo</p> </li> <li> <p>URL del servidor Tomcat donde se har\u00e1 el despliegue. Como en nuestro caso Maven y Tomcat est\u00e1n en el mismo servidor, la URL corresponde a localhost. Esta URL debe ir seguida por <code>/manager/text</code>, tal y como leemos en la documentaci\u00f3n del plugin. Esto no hemos de modificarlo.</p> </li> <li> <p>Nombre del server donde se va a desplegar la aplicaci\u00f3n. El nombre debe ser consistente con lo que hayamos puesto en el <code>settings.xml</code> del paso anterior.</p> </li> <li> <p>Nombre que la aplicaci\u00f3n utilizar\u00e1 en el path de la URL</p> </li> </ol> <p>El paso final consiste en ejecutar un \"build\" de Maven mientras tambi\u00e9n invocas la funci\u00f3n de implementaci\u00f3n del complemento Tomcat-Maven, lo cual puedes hacer con el siguiente comando:</p> <p><code>mvn tomcat7:deploy</code></p> <p>Si todo va bien responder\u00e1 algo as\u00ed:</p> <pre><code>[INFO] Deploying war to http://localhost:8080/rps  \nUploading: http://localhost:8080/manager/text/deploy?path=%2Frps\nUploaded: http://localhost:8080/manager/text/deploy?path=%2Frps (11 KB at 2586.4 KB/sec)\n\n[INFO] tomcatManager status code:200, ReasonPhrase:\n[INFO] OK - Deployed application at context path [/rps]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  6.256 s\n[INFO] Finished at: 2023-09-10T18:41:06Z\n[INFO] ------------------------------------------------------------------------\n</code></pre> <p>F\u00edjate que informe que est\u00e1 desplegando el war. Y que es un BUIL SUCCESS.</p> <p>Despu\u00e9s de ejecutar el comando de instalaci\u00f3n de Maven, notar\u00e1s que sucedieron dos cosas muy interesantes:</p> <ol> <li>Se ha guardado un archivo llamado \"rps.war\" en el directorio webapps de Tomcat <code>/var/lib/tomcat10/webapps</code>.</li> <li>La carpeta webapps tiene un nuevo subdirectorio llamado \"rps\".</li> </ol> <p>La nueva aplicaci\u00f3n te aparecer\u00e1 en el Gestor de Aplicaciones Web de Tomcat.</p> <p></p> <p>Y si la ejecutamos podremos comprobar su funcionamiento. Se trata del famoso juego piedra-papel-tijeras.</p> <p></p> <p>Como referencia, los comandos que se utilizan en Maven para desplegar, volver a desplegar o replegar una aplicaci\u00f3n, son:</p> <ul> <li><code>mvn tomcat7:deploy</code></li> <li><code>mvn tomcat7:redeploy</code></li> <li><code>mvn tomcat7:undeploy</code></li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#despliegue-de-un-proyecto-nuevo","title":"Despliegue de un proyecto nuevo","text":"<p>En el paso anterior hemos desplegado un proyecto que hemos descargado de GitHub y que ya estaba preparado para ser desplegado con Maven. Ahora vamos a crear una una aplicaci\u00f3n Java de prueba desde cero para ver si podemos desplegarla sobre la arquitectura que hemos montado. </p> <p>Para ello col\u00f3cate en el directorio en el que quieras crear la estructura de carpetas de Maven y ejecuta el comando:</p> <pre><code>    mvn archetype:generate -DgroupId=IESElCaminas -DartifactId=miapp -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false\n</code></pre> <p>Pod\u00e9is sustituir los valores de <code>groupID</code> (nombre organizaci\u00f3n) y <code>artifactId</code> (nombre de la aplicaci\u00f3n) por lo que quer\u00e1is.</p> <p>Comprueba que se ha creado un directorio <code>miapp</code> donde hab\u00edas ejecutado el comando. Entra dentro y comprueba que tienes el archivo <code>pom.xml</code> y el directorio <code>src</code>. Edita el POM e incluye la secci\u00f3n del plugin de tomcat7-maven en la secci\u00f3n de <code>&lt;plugins&gt;</code> como en el caso anterior. En este caso, adem\u00e1s, deberemos incluir el plugin \"maven-war\" que nos permitir\u00e1 compilar un archivo .war compatible con el plugin tomcat7-maven. Por tanto, incluiremos 2 bloques <code>&lt;plugin&gt;</code> dentro de la secci\u00f3n <code>&lt;plugins&gt;</code>:</p> <pre><code>  &lt;build&gt;\n    &lt;finalName&gt;miapp&lt;/finalName&gt;\n    &lt;plugins&gt;  \n        &lt;plugin&gt;\n            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n            &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;\n            &lt;version&gt;3.4.0&lt;/version&gt;\n        &lt;/plugin&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;\n            &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;2.2&lt;/version&gt;\n            &lt;configuration&gt;\n                &lt;url&gt;http://localhost:8080/manager/text&lt;/url&gt;\n                &lt;server&gt;DesplieguesTomcat&lt;/server&gt;\n                &lt;path&gt;/miapp&lt;/path&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <p>Ya puedes desplegar la aplicaci\u00f3n con </p> <p><code>mvn tomcat7:deploy</code></p> <p>Comprueba nuevamente que puedes verla en el Gestor de Aplicaciones Web de Tomcat y que puedes ejecutarla. En este caso es un simple \"Hello world!\". Navega la estructura de directorios que Maven ha creado en el directorio <code>miapp</code>. F\u00edjate c\u00f3mo es la misma que creamos manualmente en la pr\u00e1ctica anterior. Y compara el proceso que seguimos en la anterior pr\u00e1ctica creando y editando el fichero index.html, web.xml, compilando la aplicaci\u00f3n para generar el .war, etc. Maven ha hecho todo eso por nosotros con un solo comando <code>mvn tomcat7:deploy</code>.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#para-saber-mas","title":"Para saber m\u00e1s","text":"<p>Hemos usado el plugin tomcat7-maven para realizar los despliegues. Pero no es el \u00fanico. Otro plugin, de funcionamiento parecido es \"cargo\".</p> <p>En este enlace tienes un ejemplo de c\u00f3mo realizar un despliegue utilizando \"cargo\":</p> <p>How to deploy the java application to Tomcat 9 webserver using Maven</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#cuestiones","title":"Cuestiones","text":"<p>Hab\u00e9is visto que los archivos de configuraci\u00f3n que hemos tocado contienen contrase\u00f1as en texto plano, por lo que cualquiera con acceso a ellos obtendr\u00eda las credenciales de nuestras herramientas. </p> <p>En principio esto representa un gran riesgo de seguridad, \u00bfsabr\u00edas razonar o averig\u00fcar por qu\u00e9 esto est\u00e1 dise\u00f1ado de esta forma?</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P03-TomcatMaven/#referencias","title":"Referencias","text":"<p>Tutorial Tomcat I</p> <p>Tutorial Tomcat II</p> <p>Tutorial Tomcat para Ubuntu</p> <p>Instalaci\u00f3n Maven</p> <p>JSF 3.0 en Tomcat 10 con Java 11</p> <p>Migraci\u00f3n de Java 8 a Java 11</p> <p>Install and configure jdk11 + Tomcat + Maven under Linux system</p> <p>Step-by-step Maven Tomcat WAR file deploy example</p> <p>How to Install Apache Maven on Debian 11 Bullseye</p> <p>How to Deploy a WAR File to Tomcat</p> <p>Migrate Maven Projects to Java 11</p> <p>How to configure Tomcat 9.0 in Maven</p> <p>Github: cameronmcnz/rock-paper-scissors</p> <p>Why are plain text passwords in the config files?</p> <p>How to avoid storing passwords in the clear for tomcat's server.xml Resource definition of a DataSource?</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/","title":"Pr\u00e1ctica 4: Despliegue de aplicaciones con Node Express","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#introduccion","title":"Introducci\u00f3n","text":"<p>En esta pr\u00e1ctica vamos a realizar el despliegue de aplicaciones Node.js sobre un servidor Node Express. Lo curioso de este caso es que el despliegue aqu\u00ed cambia un poco puesto que no se hace sobre el servidor, sino que la aplicaci\u00f3n es el servidor.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#creacion-de-la-maquina-virtual","title":"Creaci\u00f3n de la m\u00e1quina virtual","text":"<p>Para empezar, entra en AWS Academy y crea un nuevo EC2 Debian con estas caracter\u00edsticas.</p> <ul> <li>Ll\u00e1male P3NodeJs. </li> <li>Dale los recursos que te ofrece por defecto. </li> <li>El acceso al servidor se realiza por el puerto TCP 3000. Puedes modificar el Grupo de seguridad ahora para permitir el acceso por http, https y TCP 3000 ahora o editarlo m\u00e1s tarde.</li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#instalacion-de-nodejs-express-y-test-de-la-primera-aplicacion","title":"Instalaci\u00f3n de Node.js, Express y test de la primera aplicaci\u00f3n","text":"<p>La primera parte de la pr\u00e1ctica es muy sencilla. </p> <p>Consistir\u00e1 en instalar sobre nuestra Debian tanto Node.js como Express y tras ello crear un archivo <code>.js</code> de prueba para comprobar que nuestro primer despliegue funciona correctamente.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#instalacion-de-nodejs","title":"Instalacion de Node.js","text":"<p>Seguiremos las instrucciones de instalaci\u00f3n que encontramos aqu\u00ed.</p> <ol> <li> <p>Descargar e importar la clave GPG de Nodesource</p> <p><pre><code>sudo apt-get update\nsudo apt-get install -y ca-certificates curl gnupg\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n</code></pre> 2. Crear el repositorio deb</p> <pre><code>NODE_MAJOR=20\necho \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n</code></pre> <p>Opcional: Puedes cambiar NODE_MAJOR dependiendo de la versi\u00f3n que necesites.</p> <ul> <li>NODE_MAJOR=16</li> <li>NODE_MAJOR=18</li> <li>NODE_MAJOR=20</li> <li>Ejecutar la actualizaci\u00f3n e instalaci\u00f3n</li> </ul> <p><pre><code>sudo apt-get update\nsudo apt-get install nodejs -y\n</code></pre> 4. Para comprobar que Node.js est\u00e1 correctamente instalado ejecuta:    <pre><code> $ node --version\n v20.7.0\n $ npm --version\n 10.1.0\n</code></pre></p> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#instalacion-de-express","title":"Instalaci\u00f3n de Express","text":"<p>Ejecutamos el siguiente comando</p> <pre><code>sudo npm install -g express\n</code></pre> <p>Obtendremos una salida similar a esta:</p> <pre><code>$ sudo npm install -g express\n\nadded 58 packages in 3s\n\n8 packages are looking for funding\n  run `npm fund` for details\nnpm notice \nnpm notice New major version of npm available! 9.8.1 -&gt; 10.1.0\nnpm notice Changelog: https://github.com/npm/cli/releases/tag/v10.1.0\nnpm notice Run npm install -g npm@10.1.0 to update!\nnpm notice \n</code></pre> <p>Si leemos con atenci\u00f3n nos dice que hay una versi\u00f3n m\u00e1s actual y que actualicemos. Pues lo haremos seg\u00fan lo que nos indique, en el caso de arriba:</p> <pre><code>sudo npm install -g npm@10.1.0\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#creacion-del-primer-proyecto","title":"Creaci\u00f3n del primer proyecto","text":"<p>Vamos a probar que la instalaci\u00f3n funciona creando un sencillo proyecto.</p> <p>Crea la carpeta del proyecto:</p> <p><pre><code>mkdir proyecto\ncd proyecto\n</code></pre> Inicializa el proyecto</p> <p><pre><code>npm init -y\n</code></pre> Instala Express.js para este proyecto de manera local:</p> <p><pre><code>npm install express\n</code></pre> Ahora crea un archivo de muestra:</p> <pre><code>sudo nano app.js\n</code></pre> <p>Y agrega lo siguiente:</p> <pre><code>const express = require('express')\nconst app = express()\nconst port = 3000\n\napp.get('/', (req, res) =&gt; {\n    res.send('Hello. Welcome to this blog')\n})\n\napp.listen(port, () =&gt; {\n    console.log(`Example app listening at http://localhost:${port}`)\n})\n</code></pre> <p>Ahora ejecuta el proyecto con el siguiente comando:</p> <pre><code>node app.js\n</code></pre> <p>Obtendr\u00e1s la siguiente salida.</p> <pre><code>Example app listening at http://localhost:3000\n</code></pre> <p>Abre un navegador web y ve a la direcci\u00f3n indicada o la direcci\u00f3n de tu servidor. En nuestro caso deber\u00e1s sustituir <code>localhost</code> por la IP p\u00fablica de nuestra EC2. Si tienes problemas para acceder recuerda que debiste permitir el acceso al puerto TCP 3000 en el Grupo de Seguridad de AWS.</p> <p>Recordad parar el servidor (CTRL+C en el terminal conectado a la m\u00e1quina virtual) al acabar la pr\u00e1ctica.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#despliegue-de-una-nueva-aplicacion","title":"Despliegue de una nueva aplicaci\u00f3n","text":"<p>Vamos ahora a realizar el despliegue de una aplicaci\u00f3n de terceros para ver c\u00f3mo es el proceso.</p> <p>Se trata de un \"prototipo\" de una especie de CMS que pod\u00e9is encontrar en este repositorio de Github. </p> <p>Tal y como indican las instrucciones del propio repositorio, los pasos a seguir son, en primer lugar, clonar el repositorio a nuesta m\u00e1quina:</p> <p><pre><code>git clone https://github.com/contentful/the-example-app.nodejs.git\n</code></pre> Movernos al nuevo directorio:</p> <pre><code>cd the-example-app.nodejs\n</code></pre> <p>Instalar las librer\u00edas necesarias (paciencia, este proceso puede tardar un buen rato):</p> <pre><code>npm install\n</code></pre> <p>Y, por \u00faltimo, iniciar la aplicaci\u00f3n:</p> <pre><code>npm run start:dev\n</code></pre> <p>Warning</p> <p>No te preocupes por el contenido o si salen errores. Lo importante es ver c\u00f3mo en unos pocos comandos hemos desplegado una aplicaci\u00f3n de terceros, no el contenido de la misma.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#cuestiones","title":"Cuestiones","text":"<p>Cuando ejecut\u00e1is el comando <code>npm run start:dev</code>, lo que est\u00e1is haciendo es ejecutar un script:</p> <ul> <li> <p>\u00bfDonde podemos ver que script se est\u00e1 ejecutando?</p> </li> <li> <p>\u00bfQu\u00e9 comando est\u00e1 ejecutando?</p> </li> </ul> <p>Como ayuda, pod\u00e9is consultar esta informaci\u00f3n.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P04-NodeJS-Express/#referencias","title":"Referencias","text":"<p>How to install ExpressJS on Debian 11?</p> <p>Node.js installation</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/","title":"Pr\u00e1ctica 5 - Dockerizaci\u00f3n del despliegue de una aplicaci\u00f3n Node.js","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/#introduccion","title":"Introducci\u00f3n","text":"<p>En este caso vamos a Dockerizar la aplicaci\u00f3n que ya desplegamos en la Pr\u00e1ctica 4 - Despliegue de aplicaciones con Node Express.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/#por-que-dockerizar","title":"\u00bfPor qu\u00e9 dockerizar?","text":"<p>Si uno trata de informarse, encontrar\u00e1 m\u00faltiples y variadas razones para dockerizar nuestras aplicaciones y servicios.</p> <p>Por citar s\u00f3lo algunas:</p> <p>1. Configuraci\u00f3n r\u00e1pida del entorno en local para el equipo de desarrollo: si todos los servicios est\u00e1n implementados con contenedores, es muy r\u00e1pida la configuraci\u00f3n de dicho entorno.</p> <p>2. Evita el cl\u00e1sico \"en mi m\u00e1quina funciona\": gran parte de los problemas de desarrollo provienen de la propia configuraci\u00f3n que los integrantes del equipo de desarrollo tienen de su entorno. Con los servicios en contenedores, esto queda solucionado en gran medida.</p> <p>3. Despliegues m\u00e1s r\u00e1pidos</p> <p>4. Mejor control de versiones: como ya sab\u00e9is, se puede etiquetar (tags), lo que ayuda en el CONTROL DE VERSIONES.</p> <p>5. Rollbacks m\u00e1s f\u00e1ciles: puesto que se tienen las cosas mas controladas por la versi\u00f3n, es m\u00e1s f\u00e1cil revertir el c\u00f3digo. A veces, simplemente apuntando a su versi\u00f3n de trabajo anterior.</p> <p>6. F\u00e1cil configuraci\u00f3n de m\u00faltiples entornos: como hacen la mayor\u00eda de los equipos de desarrollo, se establece un entorno local, de integraci\u00f3n, de puesta en escena (preprod) y de producci\u00f3n. Esto se hace m\u00e1s f\u00e1cil cuando los servicios est\u00e1n en contenedores y, la mayor\u00eda de las veces, con s\u00f3lo un cambio de VARIABLES DE ENTORNO.</p> <p>7. Apoyo de la comunidad: existe una fuerte comunidad de ingenieros de software que continuamente contribuyen con grandes im\u00e1genes que pueden ser reutilizadas para desarrollar un gran software. \u00bfPor qu\u00e9 reinventar la rueda, no?</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/#despliegue-con-docker","title":"Despliegue con Docker","text":"<p>En primer lugar, si eliminast\u00e9is el repositorio en su momento, deb\u00e9is volver a clonarlo en vuestra Debian, en caso contrario obviad este paso:</p> <p><pre><code>git clone https://github.com/contentful/the-example-app.nodejs.git\n</code></pre> Ahora, puesto que la aplicaci\u00f3n ya viene con el <code>Dockerfile</code> necesario dentro del directorio para construir la imagen y correr el contenedor, vamos a estudiar su contenido.</p> <p>Tarea</p> <p>Completa este Dockerfile con las opciones/directivas adecuadas, leed los comentarios y pod\u00e9is apoyaros en la teor\u00eda, en este cheatsheet, en este otro o en cualquiera que encontr\u00e9is.</p> <pre><code>_____ node #(1) \n\n_____ /app #(2)\n\n_____ npm install -g contentful-cli #(3)\n\n_____ package.json . #(4)\n_____ npm install #(5)\n\n_____ . . #(6)\n\n_____ node #(7)\n_____ 3000 #(8)\n\n_____ [\"npm\", \"run\", \"start:dev\"] #(9)\n</code></pre> <ol> <li>Con <code>_____</code> indicamos que vamos a utilizar la imagen de Docker Hub oficial de Node. En el Dockerfile pone node:9 para usar la versi\u00f3n 9, pero as\u00ed no funciona. Deja solo \"node\" para que use la versi\u00f3n \"latest\". </li> <li><code>_____</code> define el directorio sobre el que se ejecutar\u00e1n las subsiguientes instrucciones del <code>Dockerfile</code> </li> <li><code>_____</code> ejecuta un comando en una nueva capa de la imagen (podemos tener varios comandos <code>_____</code>)</li> <li><code>_____</code> como su nombre indica, copia los archivos que le indiquemos dentro del contenedor, en este caso <code>package.json</code>      !!!info         Recordemos que <code>package.json</code> cumpl\u00eda ciertas funciones importantes:            * Centraliza la forma de interactuar con la aplicaci\u00f3n por medio de definici\u00f3n de scripts (indica comandos que podemos correr dentro de nuestro proyecto, asoci\u00e1ndolos a una palabra clave para que npm (o yarn) los reconozca cuando queramos ejecutarlos.)            * Gestiona de una forma clara y sencilla las dependencias necesarias para que la aplicaci\u00f3n pueda funcionar correctamente.</li> <li>Con otro <code>_____</code> ejecutamos el ya conocido comando que nos instala las dependencias que se indican en el archivo que hemos copiado en el paso anterior, el <code>package.json</code></li> <li>Copiamos todos los archivos de nuestro directorio de trabajo al contenedor</li> <li>Con <code>_____</code> le indicaremos el usuario con el que correr\u00e1 el contenedor</li> <li><code>_____</code> nos permite documentar que puertos est\u00e1n expuestos o a la escucha en el contenedor (s\u00f3lo ser\u00e1 accesible desde otros contenedores)</li> <li>Y finalmente <code>_____</code> nos permite ejecutar un comando dentro del contenedor. En este caso iniciamos la aplicaci\u00f3n.</li> </ol> <p>Nota</p> <p>En Linux, cuando queremos hacer referencia al directorio actual, lo hacemos con un punto <code>.</code> </p> <p>Si dentro de nuestro directorio actual tenemos una carpeta llamada <code>prueba</code>, podemos hacer referencia a ella como <code>./prueba</code>, ya que el <code>.</code> hace referencia precisamente al directorio donde nos encontramos</p> <p>As\u00ed pues, tener nuestra aplicaci\u00f3n corriendo es cuesti\u00f3n de un par de comandos.</p> <p>Hacemos un build de la imagen de Docker. Le indicamos que \u00e9sta se llama <code>the-example-app.nodejs</code> y que haga el build con el contexto del directorio actual de trabajo, as\u00ed como del Dockerfile que hay en \u00e9l:</p> <pre><code>docker build -t the-example-app.nodejs .\n</code></pre> <p>Y por \u00faltimo, iniciamos el contenedor con nuestra aplicaci\u00f3n. Ahora s\u00ed, con la opci\u00f3n <code>-p</code>, le indicamos que escuche conexiones entrantes de cualquier m\u00e1quina en el puerto 3000 de nuestra m\u00e1quina anfitri\u00f3n que haremos coincidir con el puerto 3000 del contenedor (<code>-p 3000:3000</code>). Y con la opci\u00f3n <code>-d</code> lo haremos correr en modo demonio, en background:</p> <pre><code>docker run -p 3000:3000 -d the-example-app.nodejs\n</code></pre> <p>Tras esto s\u00f3lo queda comprobar que, efectivamente, desde nuestra m\u00e1quina podemos acceder a: <code>http://IP_Maq_Virtual:3000</code> y que all\u00ed est\u00e1 nuestra aplicaci\u00f3n en funcionamiento.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/#mejora-la-imagen","title":"Mejora la imagen","text":"<p>Muy probablemente en alg\u00fan momento de la creaci\u00f3n de la imagen recibas un mensaje similar a este:</p> <pre><code>Step 3/9 : RUN npm install -g contentful-cli\n---&gt; Running in 8f00b40eaca1\n\nadded 616 packages in 48s\n\n133 packages are looking for funding\nrun `npm fund` for details\nnpm notice \nnpm notice New minor version of npm available! 10.2.4 -&gt; 10.4.0\nnpm notice Changelog: &lt;https://github.com/npm/cli/releases/tag/v10.4.0&gt;\nnpm notice Run `npm install -g npm@10.4.0` to update!\nnpm notice \nRemoving intermediate container 8f00b40eaca1\n---&gt; b81619303488\n</code></pre> <p>Ya nos sucedi\u00f3 en la Pr\u00e1ctica 4 - Despliegue de aplicaciones con Node Express, \u00bfrecuerdas? Aunque has podido hacer funcionar la imagen pese a esta advertencia, lo cierto es que ser\u00eda mejor que npm funcionara con la \u00faltima versi\u00f3n disponible. </p> <p>Borra el contenedor creado y la imagen que hab\u00edas creado. Modifica el Docker file para que la imagen se cree actualizando npm, no a la versi\u00f3n 10.2.4 sino a la \u00faltima disponible en el momento de crear la imagen. Busca en Internet o consula a ChatGPT para obtener el comando adecuado. \u00bfQu\u00e9 comando incluyes en el Dockerfile y en qu\u00e9 posici\u00f3n?</p> <p>Vuelve a crear la imagen y el contenedor y comprueba su correcto funcionamiento.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P05-DockerizacionNodeJs/#referencias","title":"Referencias","text":"<p>Los beneficios de utilizar Docker y contenedores a la hora de programar </p> <p>Dockerizing</p> <p>Github</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/","title":"Pr\u00e1ctica 6: Despliegue de una aplicaci\u00f3n \"clusterizada\" con Node Express","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#introduccion","title":"Introducci\u00f3n","text":"<p>Cuando se construye una aplicaci\u00f3n de producci\u00f3n, normalmente se busca la forma de optimizar su rendimiento llegando a una soluci\u00f3n de compromiso. En esta pr\u00e1ctica echaremos un vistazo a un enfoque que puede ofrecer una victoria r\u00e1pida cuando se trata de mejorar la manera en que las aplicaciones Node.js manejan la carga de trabajo.</p> <p>Una instancia de Node.js se ejecuta en un solo hilo, lo que significa que en un sistema multin\u00facleo (como la mayor\u00eda de los ordenadores de hoy en d\u00eda), no todos los n\u00facleos ser\u00e1n utilizados por la aplicaci\u00f3n. Para aprovechar los otros n\u00facleos disponibles, podemos lanzar un cluster de procesos Node.js y distribuir la carga entre ellos.</p> <p></p> <p>Tener varios hilos para manejar las peticiones mejora el rendimiento (peticiones/segundo) del servidor, ya que varios clientes pueden ser atendidos simult\u00e1neamente. Veremos c\u00f3mo crear procesos hijos con el m\u00f3dulo de cluster de Node.js para, m\u00e1s tarde, ver c\u00f3mo gestionar el cluster con el gestor de procesos PM2.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#un-vistazo-rapido-a-los-clusters","title":"Un vistazo r\u00e1pido a los clusters","text":"<p>El m\u00f3dulo de cl\u00faster de Node.js permite la creaci\u00f3n de procesos secundarios (workers) que se ejecutan simult\u00e1neamente y comparten el mismo puerto de servidor. Cada hijo generado tiene su propio ciclo de eventos y memoria. Los procesos secundarios utilizan IPC (comunicaci\u00f3n entre procesos) para comunicarse con el proceso principal de Node.js.</p> <p>Tener m\u00faltiples procesos para manejar las solicitudes entrantes significa que se pueden procesar varias solicitudes simult\u00e1neamente y si hay una operaci\u00f3n de bloqueo/ejecuci\u00f3n prolongada en un worker, los otros workers pueden continuar administrando otras solicitudes entrantes; la aplicaci\u00f3n no se detendr\u00e1 hasta que finalice la operaci\u00f3n de bloqueo.</p> <p>La ejecuci\u00f3n de varios workers tambi\u00e9n permite actualizar la aplicaci\u00f3n en producci\u00f3n con poco o ning\u00fan tiempo de inactividad. Se pueden realizar cambios en la aplicaci\u00f3n y reiniciar los workers uno por uno, esperando que un proceso secundario se genere por completo antes de reiniciar otro. De esta manera, siempre habr\u00e1 workers ejecut\u00e1ndose mientras se produce la actualizaci\u00f3n.</p> <p>Las conexiones entrantes se distribuyen entre los procesos secundarios de dos maneras:</p> <ul> <li> <p>El proceso maestro escucha las conexiones en un puerto y las distribuye entre los workers de forma rotatoria. Este es el enfoque por defecto en todas las plataformas, excepto Windows.</p> </li> <li> <p>El proceso maestro crea un socket de escucha y lo env\u00eda a los workers interesados \u200b\u200bque luego podr\u00e1n aceptar conexiones entrantes directamente.</p> </li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#usando-los-clusters","title":"Usando los clusters","text":"<p>Como hemos visto necesitamos que nuestro equipo tenga varias CPU para hacer que cada proceso corra en una CPU distinta. Por tanto, crearemos un servidor DEBIAN en AWS, pero en este caso no aceptaremos los valores por defecto, sino que crearemos una instancia con 2 vCPU's.</p> <ul> <li>Crea una nueva EC2 Debian y ll\u00e1male \"DebianNodejsCluster\"</li> <li>El tipo de instancia selecci\u00f3na t2.medium. F\u00edjate que tiene 2 vCPU</li> <li>Recuerda crear un grupo de seguridad adecuado como en la pr\u00e1ctica anterior. Dale el mismo nombre que a la EC2. Tambi\u00e9n puedes usar el de la pr\u00e1ctica anterior.</li> <li>Instala Node.js y Express como hicimos en la pr\u00e1ctica anterior</li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#primero-sin-cluster","title":"Primero sin cl\u00faster","text":"<p>Para ver las ventajas que ofrece la agrupaci\u00f3n en cl\u00fasteres, comenzaremos con una aplicaci\u00f3n de prueba en Node.js que no usa cl\u00fasteres y la compararemos con una que s\u00ed los usa, se trata de la siguiente:</p> <p><pre><code>const express = require(\"express\");\nconst app = express();\nconst port = 3000;\n\napp.get(\"/\", (req, res) =&gt; {\n res.send(\"Hello World!\");\n});\n\napp.get(\"/api/:n\", function (req, res) {\n let n = parseInt(req.params.n);\n let count = 0;\n\n if (n &gt; 5000000000) n = 5000000000;\n\n for (let i = 0; i &lt;= n; i++) {\n count += i;\n }\n\n res.send(`Final count is ${count}`);\n});\n\napp.listen(port, () =&gt; {\n console.log(`App listening on port ${port}`);\n});\n</code></pre> Se trata de una aplicaci\u00f3n un tanto prefabricada en el sentido de que es algo que jam\u00e1s encontrar\u00edamos en el mundo real. No obstante, nos servir\u00e1 para ilustrar nuestro prop\u00f3sito.</p> <p>Esta aplicaci\u00f3n contiene dos rutas, una ruta ra\u00edz <code>/</code> que devuelve la cadena <code>Hello World!</code> y otra ruta <code>/api/n</code> donde se toma <code>n</code> como par\u00e1metro y va realizando una operaci\u00f3n de suma (el bucle for) cuyo resultado acumula en la variable <code>count</code> que se muestra al final.</p> <p>Si a este par\u00e1metro <code>n</code>, le damos un valor muy alto, nos permitir\u00e1 simular operaciones intensivas y de ejecuci\u00f3n prolongada en el servidor. Le damos como valor l\u00edmite <code>5000000000</code> para evitar una operaci\u00f3n demasiado costosa para nuestro ordenador.</p> <p>Task</p> <ol> <li>Deb\u00e9is conectaros al servidor Debian mediante SSH</li> <li>Deb\u00e9is crear un directorio para el proyecto de esta aplicaci\u00f3n. Ll\u00e1male <code>pruebacluster</code>.</li> <li>DENTRO del directorio ejecutar\u00e9is 2 comandos:<ol> <li><code>npm init</code> para crear autom\u00e1ticamente la estructura de carpetas y el archivo <code>package.json</code> (Con ir d\u00e1ndole a &lt;ENTER&gt; a todas las preguntas, os basta)</li> <li><code>npm install express</code> para instalar express para este proyecto</li> </ol> </li> <li>Crea el archivo del programa, que podemos llamar <code>pruebacluster.js</code>. Pega dentro el contenido de la aplicaci\u00f3n que vimos anteriormente.</li> <li>Tras esto, DENTRO del directorio, ya pod\u00e9is iniciar la aplicaci\u00f3n con: <code>node pruebacluster.js</code></li> </ol> <p>Para comprobarlo, pod\u00e9is acceder a <code>http://IP-maq-virtual:3000</code> o a <code>http://IP-maq-virtual:3000/api/50</code> donde <code>IP-maq-virtual</code> es la IP de vuestro servidor Debian en AWS.</p> <p>Vamos ver el tiempo que tardan en procesarse los programas en funci\u00f3n del <code>n</code>. Usaremos Mozilla Firefox, aunque otros navegadores tienen herramientas similares. Antes de lanzar la aplicaci\u00f3n abre las devoloper tools en Firefox. Ve al \"men\u00fa hamburguesa\" (las tres rayitas horizontales arriba a la derecha) - M\u00e1s herramientas - Herramientas para desarrolladores. En la parte inferior del navegador se abrir\u00e1n las herramientas y selecciona \"Red\". Ya podemos lanzar la aplicaci\u00f3n.</p> <p>Utilizada un valor de <code>n</code> relativamente peque\u00f1o, como el 50 del ejemplo anterior y comprobar\u00e9is que se ejecutar\u00e1 r\u00e1pidamente, devolviendo una respuesta casi inmediata, del orden de milisegundos. Recuerda o anota el valor.</p> <p>Hagamos otra simple comprobaci\u00f3n para valores de <code>n</code> m\u00e1s grandes. Desplegada e iniciada la aplicaci\u00f3n, acceded a la ruta <code>http://IP-maq-virtual:3000/api/5000000000</code>. Comprobad que ahora tarda varios segundos. Recuerda o anota el valor.</p> <p></p> <p>Ahora ya sabemos lo que le cuesta a nuestro servidor ejecutar el programa para un valor de 50 y uno de 5000000000 cuando solo est\u00e1 ejecutando un proceso. Veamos qu\u00e9 pasa si tiene que ejecutar 2 a la vez. Prepara 2 pesta\u00f1as en tu navegador, con las herramientas para desarrolladores activadas y en una de ellas la URL <code>http://IP-maq-virtual:3000/api/5000000000</code> y en la otra <code>http://IP-maq-virtual:3000/api/50</code>.</p> <p>Ya est\u00e1 el entorno de pruebas listo. Ahora ejecuta el programa con el 5000000000. Mientras esta solicitud que tarda unos segundos se est\u00e1 procesando, acceded a la otra pesta\u00f1a del navegador con <code>http://IP-maq-virtual:3000/api/50</code> y ejecutalo.</p> <p></p> <p>Utilizando las devoloper tools, podemos ver el tiempo que tardan en procesarse las solicitudes:</p> <ol> <li>La primera solicitud, al tener un valor de <code>n</code> grande, nos lleva unos cuantos segundos completarla. M\u00e1s o menos como antes</li> <li>La segunda solicitud, pese a tener un valor de <code>50</code> que ya hab\u00edamos comprobado que ofrec\u00eda una respuesta de milisegundos, tambi\u00e9n se demora unos segundos.</li> </ol> <p>\u00bfPor qu\u00e9 ocurre esto? Porque el \u00fanico subproceso estar\u00e1 ocupado procesando la otra operaci\u00f3n de ejecuci\u00f3n prolongada. El \u00fanico n\u00facleo de la CPU tiene que completar la primera solicitud antes de que pueda encargarse de la otra. As\u00ed que la segunda tarda lo que le queda de proceso a la primera, que est\u00e1 esperando m\u00e1s su tiempo de ejecuci\u00f3n.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#ahora-con-mas-cluster","title":"\u00a1Ahora con m\u00e1s cl\u00faster!","text":"<p>Ahora usaremos el m\u00f3dulo de cl\u00faster en la aplicaci\u00f3n para generar algunos procesos secundarios y ver c\u00f3mo eso mejora las cosas.</p> <p>A continuaci\u00f3n se muestra la aplicaci\u00f3n modificada:</p> <p><pre><code>const express = require(\"express\");\nconst port = 3000;\nconst cluster = require(\"cluster\");\nconst totalCPUs = require(\"os\").cpus().length;\n\nif (cluster.isMaster) {\n console.log(`Number of CPUs is ${totalCPUs}`);\n console.log(`Master ${process.pid} is running`);\n\n // Fork workers.\n for (let i = 0; i &lt; totalCPUs; i++) {\n cluster.fork();\n }\n\n cluster.on(\"exit\", (worker, code, signal) =&gt; {\n console.log(`worker ${worker.process.pid} died`);\n console.log(\"Let's fork another worker!\");\n cluster.fork();\n });\n} else {\n const app = express();\n console.log(`Worker ${process.pid} started`);\n\n app.get(\"/\", (req, res) =&gt; {\n res.send(\"Hello World!\");\n });\n\n app.get(\"/api/:n\", function (req, res) {\n let n = parseInt(req.params.n);\n let count = 0;\n\n if (n &gt; 5000000000) n = 5000000000;\n\n for (let i = 0; i &lt;= n; i++) {\n count += i;\n }\n\n res.send(`Final count is ${count}`);\n });\n\n app.listen(port, () =&gt; {\n console.log(`App listening on port ${port}`);\n });\n}\n</code></pre> Esta aplicaci\u00f3n hace lo mismo que antes pero esta vez estamos generando varios procesos secundarios que compartir\u00e1n el puerto 3000 y que podr\u00e1n manejar las solicitudes enviadas a este puerto. Los procesos de trabajo se generan utilizando el m\u00e9todo <code>child_process.fork()</code>. El m\u00e9todo devuelve un objeto <code>ChildProcess</code> que tiene un canal de comunicaci\u00f3n incorporado que permite que los mensajes se transmitan entre el hijo y su padre.</p> <p>Creamos tantos procesos secundarios como n\u00facleos de CPU hay en la m\u00e1quina en la que se ejecuta la aplicaci\u00f3n. Se recomienda no crear m\u00e1s workers que n\u00facleos l\u00f3gicos en la computadora, ya que esto puede causar una sobrecarga en t\u00e9rminos de costos de programaci\u00f3n. Esto sucede porque el sistema tendr\u00e1 que programar todos los procesos creados para que se vayan ejecutando por turnos en los n\u00facleos.</p> <p>Los workers son creados y administrados por el proceso maestro. Cuando la aplicaci\u00f3n se ejecuta por primera vez, verificamos si es un proceso maestro con <code>isMaster</code>. Esto est\u00e1 determinado por la variable <code>process.env.NODE_UNIQUE_ID</code>. Si <code>process.env.NODE_UNIQUE_ID</code> tiene valor undefined, entonces <code>isMaster</code> ser\u00e1 true.</p> <p>Si el proceso es un maestro, llamamos a <code>cluster.fork()</code> para generar varios procesos. Registramos los ID de proceso maestro y worker. Cuando un proceso secundario muere, generamos uno nuevo para seguir utilizando los n\u00facleos de CPU disponibles.</p> <p>Ahora repetiremos el mismo experimento de antes, primero realizamos una solicitud al servidor con un valor alto <code>n</code>: </p> <p></p> <p>Y ejecutamos r\u00e1pidamente otra solicitud en otra pesta\u00f1a del navegador, midiendo los tiempos de procesamiento de ambas:</p> <p></p> <p>Comprobaremos que \u00e9stos se asemejan mucho m\u00e1s a los que obtuvimos ejecutando la aplicaci\u00f3n de forma independiente.</p> <p>Note</p> <p>Con varios workers disponibles para aceptar solicitudes, se mejoran tanto la disponibilidad del servidor como el rendimiento.</p> <p>Ejecutar una solicitud en una pesta\u00f1a del navegador y ejecutar r\u00e1pidamente otra en una segunda pesta\u00f1a sirve para mostrarnos la mejora que ofrece la agrupaci\u00f3n en cl\u00fasteres para nuestro ejemplo de una forma m\u00e1s o menos r\u00e1pida, pero es un m\u00e9todo un tanto \"chapucero\" y no es una forma adecuada o confiable de determinar las mejoras de rendimiento.</p> <p>En el siguiente apartado echaremos un vistazo a algunos puntos de referencia que demostrar\u00e1n mejor cu\u00e1nto ha mejorado la agrupaci\u00f3n en cl\u00fasteres nuestra aplicaci\u00f3n.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#metricas-de-rendimiento","title":"M\u00e9tricas de rendimiento","text":"<p>Realizaremos una prueba de carga en nuestras dos aplicaciones para ver c\u00f3mo cada una maneja una gran cantidad de conexiones entrantes. Usaremos el paquete <code>loadtest</code> para esto.</p> <p>El paquete <code>loadtest</code> nos permite simular una gran cantidad de conexiones simult\u00e1neas a nuestra API para que podamos medir su rendimiento.</p> <p>Para usar <code>loadtest</code>, primero debemos instalarlo globalmente. Tras conectaros por SSH al servidor Debian:</p> <pre><code>sudo npm install -g loadtest\n</code></pre> <p>Luego ejecutamos la aplicaci\u00f3n que queremos probar (<code>node nombre_aplicacion.js</code>). Comenzaremos probando la versi\u00f3n que no utiliza la agrupaci\u00f3n en cl\u00fasteres.</p> <p>Mientras ejecutamos la aplicaci\u00f3n, en otro terminal realizamos la siguiente prueba de carga:</p> <pre><code>loadtest http://localhost:3000/api/500000 -n 1000 -c 100\n</code></pre> <p>El comando anterior enviar\u00e1 1000 solicitudes a la URL dada, de las cuales 100 son concurrentes. El siguiente es el resultado de ejecutar el comando anterior:</p> <p></p> <p>Vemos que con la misma solicitud (con n= 500000) el servidor ha podido manejar 404 solicitudes por segundo con una latencia media de 232.4 milisegundos (el tiempo promedio que tarda en completar una sola solicitud). Anota los datos que obtienes en tu caso.</p> <p>Intent\u00e9moslo de nuevo, pero esta vez con un n mayor n=5000000 (y sin cl\u00fasteres):</p> <p></p> <p>Vemos que las m\u00e9tricas arrojan resultados peores. Anota los datos que obtienes en tu caso.</p> <p>Ahora detenemos nuestra aplicaci\u00f3n sin cl\u00fasters y ejecutamos la que s\u00ed los tiene (<code>node nombre_aplicacion_cluster.js</code>). Ejecutaremos exactamente las mismas pruebas con el objetivo de realizar una comparaci\u00f3n:</p> <p></p> <p></p> <p>Anota los datos que obtienes en tu caso y comp\u00e1ralos con los obtenidos en la aplicaci\u00f3n sin clusters. Es obvio que los cl\u00fasters permiten manejar una mayor cantidad de peticiones por segundo con una menor latencia.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#uso-de-pm2-para-administrar-un-cluster-de-nodejs","title":"Uso de PM2 para administrar un cl\u00faster de Node.js","text":"<p>En nuestra aplicaci\u00f3n, hemos usado el m\u00f3dulo <code>cluster</code> de Node.js para crear y administrar manualmente los procesos.</p> <p>Primero hemos determinado la cantidad de workers (usando la cantidad de n\u00facleos de CPU como referencia), luego los hemos generado y, finalmente, escuchamos si hay workers muertos para poder generar nuevos.</p> <p>En nuestra aplicaci\u00f3n de ejemplo muy sencilla, tuvimos que escribir una cantidad considerable de c\u00f3digo solo para administrar la agrupaci\u00f3n en cl\u00fasteres. En una aplicaci\u00f3n de producci\u00f3n es bastante probable que se deba escribir a\u00fan m\u00e1s c\u00f3digo.</p> <p>Existe una herramienta que nos puede ayudar a administrar todo esto un poco mejor: el administrador de procesos <code>PM2</code>. <code>PM2</code> es un administrador de procesos de producci\u00f3n para aplicaciones Node.js con un balanceador de carga incorporado.</p> <p>Cuando est\u00e1 configurado correctamente, <code>PM2</code> ejecuta autom\u00e1ticamente la aplicaci\u00f3n en modo de cl\u00faster, generando workers y se encarga de generar nuevos workers cuando uno de ellos muera.</p> <p><code>PM2</code> facilita la parada, eliminaci\u00f3n e inicio de procesos, adem\u00e1s de disponer de algunas herramientas de monitorizaci\u00f3n que pueden ayudarnos a monitorizar y ajustar el rendimiento de su aplicaci\u00f3n.</p> <p>Para usar <code>PM2</code>, primero instalamos globalmente en nuestra Debian:</p> <pre><code>sudo npm install pm2 -g\n</code></pre> <p>Vamos a utilizarlo con nuestra primera aplicaci\u00f3n, la que no estab \"clusterizada\" en el c\u00f3digo. Para ello ejecutaremos el siguiente comando:</p> <pre><code>pm2 start nombre_aplicacion_sin_cluster.js -i 0\n</code></pre> <p>Donde:</p> <ul> <li> <p><code>-i</code>  le indicar\u00e1 a <code>PM2</code> que inicie la aplicaci\u00f3n en <code>cluster_mode</code> (a diferencia de <code>fork_mode</code>). <p>Si se establece a 0, <code>PM2</code> generar\u00e1 autom\u00e1ticamente tantos workers como n\u00facleos de CPU haya. <p>Y as\u00ed, nuestra aplicaci\u00f3n se ejecuta en modo de cl\u00faster, sin necesidad de cambios de c\u00f3digo.</p> <p>Comprueba que hay 2 procesos de tu aplicaci\u00f3n funcionando:</p> <pre><code>ps -ef | grep .js\n</code></pre> <p>Task</p> <p>Ejecuta las mismas pruebas que antes pero utilizando PM2 y comprueba si se obtienen los mismos resultados.</p> <p>Por detr\u00e1s, <code>PM2</code> tambi\u00e9n utiliza el m\u00f3dulo <code>cluster</code> de Node.js, as\u00ed como otras herramientas que facilitan la gesti\u00f3n de procesos.</p> <p>En el Terminal, obtendremos una tabla que muestra algunos detalles de los procesos generados:</p> <p></p> <p>Podemos detener la aplicaci\u00f3n con el siguiente comando:</p> <pre><code>pm2 stop app.js\n</code></pre> <p>La aplicaci\u00f3n se desconectar\u00e1 y la salida por terminal mostrar\u00e1 todos los procesos con un estado <code>stopped</code>.</p> <p></p> <p>En vez de tener pasar siempre las configuraciones cuando ejecuta la aplicaci\u00f3n con <code>pm2 start app.js -i 0</code>, podr\u00edamos facilitarnos la tarea y guardarlas en un archivo de configuraci\u00f3n separado, llamado Ecosystem. </p> <p>Este archivo tambi\u00e9n nos permite establecer configuraciones espec\u00edficas para diferentes aplicaciones.</p> <p>Crearemos el archivo Ecosystem con el siguiente comando:</p> <p></p> <p>Que generar\u00e1 un archivo llamado ecosystem.config.js. Para el caso concreto de nuestra aplicaci\u00f3n, necesitamos modificarlo como se muestra a continuaci\u00f3n:</p> <pre><code>module.exports = {\n apps: [\n {\n name: \"nombre_aplicacion\",\n script: \"nombre_aplicacion_sin_cluster.js\",\n instances: 0,\n exec_mode: \"cluster\",\n },\n ],\n};\n</code></pre> <p>Al configurar <code>exec_mode</code> con el valor <code>cluster</code>, le indica a <code>PM2</code> que balancee la carga entre cada instancia. <code>instances</code> est\u00e1 configurado a 0 como antes, lo que generar\u00e1 tantos workers como n\u00facleos de CPU.</p> <p>La opci\u00f3n <code>-i</code> o <code>instances</code> se puede establecer con los siguientes valores:</p> <ul> <li> <p><code>0</code> o <code>max</code>(en desuso) para \"repartir\" la aplicaci\u00f3n entre todas las CPU</p> </li> <li> <p><code>-1</code> para \"repartir\" la aplicaci\u00f3n en todas las CPU - 1</p> </li> <li> <p><code>n\u00famero</code> para difundir la aplicaci\u00f3n a trav\u00e9s de un n\u00famero concreto de CPU</p> </li> </ul> <p>Ahora podemos ejecutar la aplicaci\u00f3n con:</p> <pre><code>pm2 start ecosystem.config.js\n</code></pre> <p>La aplicaci\u00f3n se ejecutar\u00e1 en modo cl\u00faster, exactamente como antes.</p> <p>Podremos iniciar, reiniciar, recargar, detener y eliminar una aplicaci\u00f3n con los siguientes comandos, respectivamente:</p> <pre><code>$ pm2 start nombre_aplicacion\n$ pm2 restart nombre_aplicacion\n$ pm2 reload nombre_aplicacion\n$ pm2 stop nombre_aplicacion\n$ pm2 delete nombre_aplicacion\n\n# Cuando usemos el archivo Ecosystem:\n\n$ pm2 [start|restart|reload|stop|delete] ecosystem.config.js\n</code></pre> <p>El comando <code>restart</code> elimina y reinicia inmediatamente los procesos, mientras que el comando <code>reload</code> logra un tiempo de inactividad de 0 segundos donde los workers se reinician uno por uno, esperando que aparezca un nuevo worker antes de matar al anterior.</p> <p>Tambi\u00e9n puede verificar el estado, los registros y las m\u00e9tricas de las aplicaciones en ejecuci\u00f3n.</p> <p>Task</p> <p>Investiga los siguientes comandos y explica que salida por terminal nos ofrecen y para qu\u00e9 se utilizan:</p> <pre><code>pm2 ls\npm2 logs\npm2 monit\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#cuestiones","title":"Cuestiones","text":"<p>Fij\u00e1os en las siguientes im\u00e1genes:</p> <p></p> <p></p> <p>La primera imagen ilustra los resultados de unas pruebas de carga sobre la aplicaci\u00f3n sin cl\u00faster y la segunda sobre la aplicaci\u00f3n clusterizada.</p> <p>\u00bfSabr\u00edas decir por qu\u00e9 en algunos casos concretos, como este, la aplicaci\u00f3n sin clusterizar tiene mejores resultados?</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P06-Cluster/#referencias","title":"Referencias","text":"<p>How to install ExpressJS on Debian 11?</p> <p>Improving Node.js Application Performance With Clustering</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/","title":"Pr\u00e1ctica 7: Despliegue de una aplicaci\u00f3n en Netlify (PaaS)","text":"<p>Nota</p> <p>Para esta pr\u00e1ctica vamos a crearnos cuentas en distintos servicios cuando se os pida:</p> <p>GitHub</p> <p>Netlify</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#introduccion","title":"Introducci\u00f3n","text":"<p>En la pr\u00e1ctica anterior hemos visto c\u00f3mo desplegar una aplicaci\u00f3n de Node.js sobre un servidor Express en local (en nuestro propio servidor Debian).</p> <p>La pr\u00e1ctica anterior podr\u00eda asemejarse a las pruebas que realiza un desarrollador antes de pasar su aplicaci\u00f3n al entorno de producci\u00f3n. </p> <p>Ya sabemos que entendemos el despliegue o deployment como el proceso de mover nuestro c\u00f3digo t\u00edpicamente de un sistema de control de versiones a una plataforma de hosting donde se aloja y es servida a los usuarios finales. </p> <p>A la hora de desplegar la aplicaci\u00f3n en producci\u00f3n, podr\u00eda utilizarse el m\u00e9todo de copiar los archivos al servidor concreto v\u00eda el vetusto FTP, SSH u otros y desplegarla para dejarla funcionando. No obstante, esta pr\u00e1ctica se acerca m\u00e1s a la realidad ya que utilizaremos un repositorio de Github y una plataforma de PaaS (Platform as a Service) como Netlify para desplegar adecuadamente nuestra aplicaci\u00f3n en producci\u00f3n.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#que-es-github","title":"\u00bfQu\u00e9 es Github?","text":"<p>A pesar de que trataremos un poco m\u00e1s en profundidad Github en un tema posterior, daremos una breve explicaci\u00f3n aqu\u00ed.</p> <p>GitHub es un servicio basado en la nube que aloja un sistema de control de versiones (VCS) llamado Git. \u00c9ste permite a los desarrolladores colaborar y realizar cambios en proyectos compartidos, a la vez que mantienen un seguimiento detallado de su progreso.</p> <p></p> <p>El control de versiones es un sistema que ayuda a rastrear y gestionar los cambios realizados en un archivo o conjunto de archivos. Utilizado principalmente por ingenieros de software para hacer un seguimiento de las modificaciones realizadas en el c\u00f3digo fuente, el sistema de control de versiones les permite analizar todos los cambios y revertirlos sin repercusiones si se comete un error.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#que-es-netlify","title":"\u00bfQu\u00e9 es Netlify?","text":"<p>Netlify es un proveedor de alojamiento en la nube que proporciona servicios de backend sin servidor (serverless) para sitios web est\u00e1ticos. Est\u00e1 dise\u00f1ado para maximizar la productividad en el sentido de que permite a los desarrolladores (especialmente orientados al frontend), y a los ingenieros construir, probar y desplegar r\u00e1pidamente sitios web/aplicaciones.</p> <p>Funciona conect\u00e1ndose a un repositorio de GitHub, de donde extrae el c\u00f3digo fuente. A continuaci\u00f3n, ejecutar\u00e1 un proceso de construcci\u00f3n para pre-renderizar las p\u00e1ginas de nuestro sitio web/aplicaci\u00f3n en archivos est\u00e1ticos.</p> <p></p> <p>Hay numerosas razones a favor de usar Netlify, aqu\u00ed est\u00e1n algunas de ellas:</p> <ul> <li> <p>Netlify hace que sea incre\u00edblemente sencillo desplegar un sitio web - de hecho, la forma m\u00e1s sencilla de lograrlo es utilizar GitHub, GitLab o Bitbucket para configurar el despliegue continuo.</p> </li> <li> <p>Netlify hace que sea s\u00faper f\u00e1cil lanzar un sitio web con su soluci\u00f3n de gesti\u00f3n de DNS incorporada.</p> </li> <li> <p>Podr\u00edamos desplegar f\u00e1cilmente s\u00f3lo una rama espec\u00edfica de nuestro proyecto Git - esto es \u00fatil para probar nuevas caracter\u00edsticas que pueden o no llegar a la rama maestra/principal, o para determinar r\u00e1pidamente c\u00f3mo un PR (Pull Request) afectar\u00e1 a su sitio.</p> </li> <li> <p>Netlify te permite previsualizar cualquier despliegue que hagas o quieras hacer - esto te permite a ti y a tu equipo ver c\u00f3mo se ver\u00e1n los cambios en producci\u00f3n sin tener que desplegarlos en tu sitio existente.</p> </li> <li> <p>Netlify proporciona una pr\u00e1ctica funci\u00f3n de env\u00edo de formularios que nos permite recoger informaci\u00f3n de los usuarios.</p> </li> </ul> <p>Note</p> <p>Tanto Github como Netlify pueden ser controlados desde el terminal de nuestro Linux, por lo que seguiremos el procedimiento de contectarnos v\u00eda SSH a nuestro Debian y realizar las operaciones por terminal.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#preparacion-del-entorno","title":"Preparaci\u00f3n del entorno","text":"<p>Vuestra primera tarea ser\u00e1 registraros en Netlify con vuestro email (no con vuestra cuenta de Github) y decirle que no cuando os pida enlazar con vuestra cuenta de Github (lo haremos m\u00e1s adelante).</p> <p>Crearemos una EC2 Debian b\u00e1sica en AWS Academy. Nos conectaremos a ella por SSH, actualizaremos los repositorios e instalaremos GIT. Tambi\u00e9n instalaremos Node.js como hicimos en la pr\u00e1ctica P3.4.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#opciones-de-despliegue-en-netlify","title":"Opciones de despliegue en Netlify","text":"<p>Por mera curiosidad y ambici\u00f3n de aprendizaje, vamos a ver dos m\u00e9todos de despliegue en Netlify:</p> <ul> <li>Despliegue manual desde el CLI de Netlify, es decir, desde el terminal, a partir de un directorio local de nuestra m\u00e1quina.</li> <li>Despliegue desde un c\u00f3digo publicado en uno de nuestros repositorios de Github</li> </ul> <p>El primero nos permitir\u00e1 conocer el CLI de Netlify y el segundo nos acercar\u00e1 m\u00e1s a una experiencia real de despliegue.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#despliegue-mediante-cli","title":"Despliegue mediante CLI","text":"<p>Una vez registrados, debemos instalar el CLI de Netlify para ejecutar sus comandos desde el terminal:</p> <pre><code>sudo npm install netlify-cli -g\n</code></pre> <p>Est\u00e1 claro que para realizar acciones de deploy, Netlify nos solicitar\u00e1 una autenticaci\u00f3n, esto se hace mediante el comando:</p> <pre><code>netlify login\n</code></pre> <p>El cual nos muestra una pantalla del navegador para que concedamos la autorizaci\u00f3n pertinente. Sin embargo, recordemos el problema de que estamos conectados por SSH a nuestro servidor y no tenemos la posibilidad del uso de un entorno gr\u00e1fico. Una forma de solucionarlo la tenemos en la \"Pr\u00e1ctica Voluntaria 3.1 - Despliegue de una aplicaci\u00f3n Node.js en Heroku (PaaS)\", pero Netlify nos ofrece otra forma.</p> <p>En este caso, siguiendo las instrucciones de la documentaci\u00f3n:</p> <ul> <li> <p>Nos logeamos en Netlify</p> </li> <li> <p>Generamos el token de acceso</p> <p></p> <p></p> </li> <li> <p>Lo establecemos como variable de ambiente:</p> <p></p> <p>Y nos logueamos <pre><code>netlify login\n</code></pre></p> </li> </ul> <p>Ya estamos conectados a Netlify desde nuestro terminal. Ahora ya podemos ejecutar comandos para realizar el despliegue en Netlify. Pero todav\u00eda no tenemos nada que desplegar. Vamos a ello.</p> <p>Puesto que el inter\u00e9s en este m\u00f3dulo radica en el proceso de despliegue, suponiendo que la parte de desarrollo ya es abordada en otros m\u00f3dulos, vamos a utilizar una aplicaci\u00f3n de ejemplo que nos ahorre tiempo para centrarnos en el despliegue.</p> <p>Nos clonaremos este repositorio en el home de <code>admin</code>:</p> <p>git clone https://github.com/StackAbuse/color-shades-generator</p> <p>Entraremos ahora en el directorio creado:</p> <pre><code>cd color-shades-generator-main\n</code></pre> <p>Podemos navegar por la estructura de directorios de la aplicaci\u00f3n descargada y ver los ficheros y directorios creados. No sabemos con qu\u00e9 framework se ha creado pero lo que necesitamos saber estar\u00e1 en el fichero <code>package.json</code>.</p> <p><pre><code>cat package.json\n</code></pre> Hay 2 secciones que nos interesan especialmente. Una es \"dependencies\". Ah\u00ed est\u00e1n todas las dependencias que necesita este proyecto. Si observas ver\u00e1s que hay una palabra que se repite varias veces \"react\". Si buscas por internet ver\u00e1s que es una biblioteca para creaci\u00f3n de interfaces de usuario. Todas esas dependencias ser\u00e1n las que se instalar\u00e1n posteriormente al hacer un <code>npm install</code>.</p> <pre><code>\"dependencies\": {\n  \"@testing-library/jest-dom\": \"^5.16.1\",\n  \"@testing-library/react\": \"^12.1.2\",\n  \"@testing-library/user-event\": \"^13.5.0\",\n  \"react\": \"^17.0.2\",\n  \"react-dom\": \"^17.0.2\",\n  \"react-icons\": \"^4.3.1\",\n  \"react-scripts\": \"5.0.0\",\n  \"values.js\": \"^2.0.0\",\n  \"web-vitals\": \"^2.1.3\"\n  },\n</code></pre> <p>La otra secci\u00f3n importante es \"scripts\".</p> <pre><code>\"scripts\": {\n  \"start\": \"react-scripts start\",\n  \"build\": \"react-scripts build\",\n  \"test\": \"react-scripts test\",\n  \"eject\": \"react-scripts eject\"\n},\n</code></pre> <p>Estos son los scripts que podemos lanzar con npm para las distintas fases de desarrollo y despliegue. Los podremos lanzar con <code>npm run start</code> por ejemplo. En casi todos los proyectos encontraremos un start, build, test... Esto nos permitir\u00e1 hacer un \"build\" para generar todos los archivos que luego subiremos al servidor sin necesidad de saber los comandos necesarios en el framework espec\u00edfico que se ha usado.</p> <p>Bueno, tenemos el c\u00f3digo de nuestra aplicaci\u00f3n, tenemos nuestra cuenta en Netlify y tenemos el CLI necesario para ejecutar comandos desde el terminal en esa cuenta... \u00bfPodemos proceder al despliegue sin mayores complicaciones?</p> <p>La respuesta es NO, como buenos desarrolladores y en base a experiencias anteriores, ya sab\u00e9is que hay que hacer un build de la aplicaci\u00f3n para, posteriormente, desplegarla. Vamos a ello.</p> <p>En primer lugar, como sabemos, debemos instalar todas las dependencias que vienen indicadas en el archivo <code>package.json</code>:</p> <pre><code>npm install\n</code></pre> <p>Ya tenemos las dependencias instaladas. Vamos a probar el primer script <code>start</code>, que nos servir\u00e1 la aplicaci\u00f3n en nuestro server para probar que funciona.</p> <pre><code>npm run start\n</code></pre> <p>La respuesta ser\u00e1 algo similar a:</p> <pre><code>Compiled successfully!\n\nYou can now view color-shades-generator in the browser.\n\n  Local:            http://localhost:3000\n  On Your Network:  http://172.31.80.11:3000\n\nNote that the development build is not optimized.\nTo create a production build, use npm run build.\n\nasset static/js/bundle.js 5.55 MiB [emitted] (name: main) 1 related asset\nasset index.html 678 bytes [emitted]\nasset asset-manifest.json 190 bytes [emitted]\ncached modules 4.88 MiB (javascript) 28.2 KiB (runtime) [cached] 123 modules\nwebpack 5.65.0 compiled successfully in 2388 m\n</code></pre> <p>Prueba a acceder a la p\u00e1gina web que se est\u00e1 sirviendo. Recuerda que deber\u00e1s cambiar la localhost por la IP externa de tu EC2.</p> <p>Para dejar de servir CTRL+C</p> <p>Como nos dec\u00eda el mensaje anterior, una vez comprobada podemos crear un build para producci\u00f3n con <code>npm run build</code>. Esto nos crear\u00e1 una nueva carpeta que puede ser distinta dependiendo del framework utilizado. Una forma de saberlo es anotar, antes de ejecutar el build, todas las carpetas existentes, y ver c\u00faal es la nueva creada tras ejecutar el comando. Otra forma es conocer el framework y saber cu\u00e1l es la carpeta que crea:</p> <pre><code>npm run build\n</code></pre> <p>Si todo va bien obtendr\u00e1s algo as\u00ed:</p> <pre><code>&gt; color-shades-generator@0.1.0 build\n&gt; react-scripts build\n\nCreating an optimized production build...\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\nCompiled successfully.\n\nFile sizes after gzip:\n\n  48.93 kB  build/static/js/main.56aeaed6.js\n  965 B     build/static/css/main.e106b4ce.css\n\nThe project was built assuming it is hosted at /.\nYou can control this with the homepage field in your package.json.\n\nThe build folder is ready to be deployed.\nYou may serve it with a static server:\n\n  npm install -g serve\n  serve -s build\n\nFind out more about deployment here:\n\n  https://cra.link/deployment\n</code></pre> <p>En este caso la propia respuesta nos dice \"The build folder is ready to be deployed.\". As\u00ed que ya sabemos que la carpeta que contendr\u00e1 la aplicaci\u00f3n que debemos desplegar se llama <code>build</code>. F\u00edjate que dentro de esa carpeta hay un fichero <code>index.html</code>. En otro framework puede llamarse de otra forma y crear varios niveles de carpetas. La ruta donde est\u00e9 ese <code>index.html</code> es la que nos interesar\u00e1 m\u00e1s adelante para hacer el deploy.</p> <p>Bueno, ya tenemos la carpeta build lista para hacer un pre-deploy en Netlify y comprobar que al subirla all\u00ed, sigue funcionando:</p> <p><pre><code>netlify deploy\n</code></pre> Nos har\u00e1 algunas preguntas para el despliegue:</p> <ul> <li>Indicamos que queremos crear y configurar un nuevo site</li> <li>El Team lo dejamos por defecto</li> <li>Le indicamos el nombre que queremos emplear para la web (<code>tunombre-practica3-6</code>) sustituye <code>tunombre</code> por tu nombre de pila, y </li> <li>el directorio a utilizar para el deploy. Usaremos el directorio <code>./build</code> que vimos antes que contiene el <code>index.html</code>. Si usamos otro framework buscaremos ese fichero y pondremos aqu\u00ed la ruta completa que lo contiene.</li> </ul> <p>Y si nos indica que todo ha ido bien e incluso podemos ver el \"borrador\" (Website Draft URL) de la web que nos aporta. Copia esa URL, p\u00e9gala en el navegador de tu ordenador local y comprueba que la aplicaci\u00f3n se ha desplegado correctamente. En este caso ya es una IP p\u00fablica. No necesitas modificarla.</p> <p>Si todo va bien ya podemos pasarla a producci\u00f3n finalmente tal y como nos indica la misma salida del comando:</p> <pre><code>If everything looks good on your draft URL, deploy it to your main site URL with the --prod flag.\nnetlify deploy --prod\n</code></pre> <p>Haz la prueba. Cuando te pida el \"Publish directory\" debes ponerle <code>./build</code> nuevamente. </p> <p>Ya puedes acceder a tu aplicaci\u00f3n en <code>https://tunombre-practica3-6.netlify.app/</code>.</p> <p>Ve a la p\u00e1gina web de Netlify y busca tu aplicaci\u00f3n. Comprueba las opciones que tienes y qu\u00e9 puedes modificar desde all\u00ed.</p> <p>Atenci\u00f3n</p> <p>Si tienes que desplegar otra aplicaci\u00f3n que no sabes con qu\u00e9 framework se ha hecho necesitar\u00e1s saber para poder desplegarla:</p> <ul> <li> <p>C\u00f3mo llamar al script del \"build\". Lo tienes en la secci\u00f3n scripts del package.json</p> </li> <li> <p>El directorio que se genera al ejecutar el build y d\u00f3nde se encuentra el index.html dentro de ese directorio. O conoces el framework o buscas el index.html dentro de las carpetas creadas tras el build.</p> </li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#despliegue-mediante-conexion-con-github","title":"Despliegue mediante conexi\u00f3n con Github","text":"<p>En primer lugar, vamos a eliminar el site que hemos desplegado antes en Netlify para evitarnos cualquier problema y/o conflicto:</p> <p></p> <p>En segundo lugar, vamos a borrar el directorio donde se halla el repositorio clonado en el paso anterior para as\u00ed poder empezar de 0:</p> <pre><code>rm -rf directorio_repositorio\n</code></pre> <p>Como queremos simular que hemos picado el c\u00f3digo a man o en local y lo vamos a subir a Github por primera vez, nos descargaremos los fuentes en formato <code>.zip</code> sin que tenga ninguna referencia a Github:</p> <p><pre><code>wget https://github.com/StackAbuse/color-shades-generator/archive/refs/heads/main.zip\n</code></pre> Creamos una carpeta nueva y descomprimimos dentro el zip:</p> <pre><code>mkdir practica3_6\n\nunzip main.zip -d practica3_6/\n</code></pre> <p>Entramos en la carpeta donde est\u00e1 el c\u00f3digo:</p> <p><pre><code>cd practica3_6/color-shades-generator-main/\n</code></pre> Ahora debemos crear un repositorio completamente vac\u00edo en Github que se llame <code>practicaTresSeis</code>:</p> <p></p> <p>Y tras ello, volviendo al terminal a la carpeta donde est\u00e1bamos, la iniciamos como repositorio, a\u00f1adimos todo el contenido de la misma para el commit, hacemos el commit con el mensaje correspondiente y creamos la rama main:</p> <pre><code>$ git init\n$ git add .\n$ git commit -m \"Subiendo el c\u00f3digo...\"\n$ git branch -M main\n</code></pre> <p>Y ahora s\u00f3lo queda referenciar nuestra carpeta al repositorio reci\u00e9n creado en Github y hacer un <code>push</code> para subir todo el contenido del commit a \u00e9l:</p> <p><pre><code>$ git remote add origin https://github.com/username/practicaTresSeis.git\n$ git push -u origin main\n</code></pre> Te pedir\u00e1 un usuario y contrase\u00f1a. El usuario es el tuyo de GitHub, pero la contrase\u00f1a no. Deber\u00e1s crear un \"token personal\". Para ello:</p> <ul> <li>Ve a GitHub, selecciona tu foto arriba a la derecha y luego \"Settings\"</li> <li>Busca \"&lt;&gt; Developer settings\"</li> <li>Ahora \"Personal access tokens\" - \"Tokens (classic)</li> <li>Selecciona la casilla \"repo\"</li> <li>Y finaliza con \"Generat token\"</li> <li>Copia el token generado y esa ser\u00e1 la password que tendr\u00e1s que poner.</li> </ul> <p>Ahora que ya tenemos subido el c\u00f3digo a GitHub, de alguna manera debemos enganchar o enlazar nuestra cuenta de Github con la de Netlify para que \u00e9ste \u00faltimo pueda traerse el c\u00f3digo de all\u00ed, hacer el build y desplegarlo. As\u00ed pues, entramos en nuestro dashboard de Netlify y le damos a importar proyecto existente de <code>git</code>:</p> <p></p> <p>Le indicamos que concretamente de Github:</p> <p></p> <p>Y nos saltar\u00e1 una ventana pidiendo que autoricemos a Netlify a acceder a nuestros repositorios de Github:</p> <p></p> <p>Y luego le indicaremos que no acceda a todos nuestros repositorios sino s\u00f3lo al repositorio que necesitamos, que es donde tenemos el c\u00f3digo de nuestra aplicaci\u00f3n:</p> <p></p> <p>Y ya quedar\u00e1 todo listo:</p> <p></p> <p>Y desplegamos la aplicaci\u00f3n:</p> <p></p> <p>Netlify se encargar\u00e1 de hacer el <code>build</code> de forma autom\u00e1tica tal y como hemos visto en la imagen de arriba, con el comando <code>npm run build</code>, publicando el contenido del directorio <code>build</code>.</p> <p>Atenci\u00f3n</p> <p>Tras el deploy, en \"Site settings\" pode\u00eds y deb\u00e9is cambiar el nombre de la aplicaci\u00f3n por nombre-practica3-4, donde nombre es vuestro nombre.</p> <p>Lo que hemos conseguido de esta forma es que, cualquier cambio que hagamos en el proyecto y del que hagamos <code>commit</code> y <code>push</code> en Github, autom\u00e1ticamente genere un nuevo despliegue en Netlify. Es el principio de lo que m\u00e1s adelante veremos como despliegue continuo.</p> <p>Comprobemos que realmente es as\u00ed:</p> <ul> <li> <p>Dentro de la carpeta <code>public</code> encontramos el archivo <code>robots.txt</code>, cuyo cometido es indicar a los rastreadores de los buscadores a qu\u00e9 URLs del sitio pueden acceder. A este archivo se puede acceder a trav\u00e9s de la URL del site:</p> <p></p> </li> <li> <p>Dentro de la carpeta <code>public</code>, utilizando el editor de texto que prefir\u00e1is en vuestro terminal, modificad el archivo <code>robots.txt</code> para que excluya un directorio que se llame <code>nombre_apellido</code>, utilizando obviamente vuestro nombre y apellido.</p> <pre><code>User-agent: *\nDisallow: /nombre_y_apellido/\n</code></pre> </li> <li> <p>Haz un nuevo <code>commit</code> y <code>push</code> (del caso anterior, recuerda el commando <code>git</code> previo para a\u00f1adir los archivos a hacer commit)</p> </li> <li> <p>Comprueba en el dashboard de Netlify que se ha producido un nuevo deploy de la aplicaci\u00f3n hace escasos segundos</p> <p></p> <p></p> </li> <li> <p>Accede a <code>https://url_de_la_aplicacion/robots.txt</code> y comprueba que, efectivamente, se ve reflejado el cambio</p> <p></p> </li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#despliegue-aplicaciones-desarrolladas-en-angular","title":"Despliegue aplicaciones desarrolladas en Angular","text":"<p>Un framework muy conocido y utilizado junto a Node.js es Angular.</p> <p>Desplegar una aplicaci\u00f3n desarrollada en Angular es igual que lo visto hasta ahora. Solo hay que tener en cuenta algunas particularidades.</p> <p>La carpeta donde Angular guarda el build se llama <code>dist</code> y el index.html no est\u00e1 en esa carpeta directamente sino que crea una dentro con el nombre de la aplicaci\u00f3n. As\u00ed que el directorio para el despliegue es <code>./dist/nombreaplicacion</code>.</p> <p>Solo con esto ya podemos desplegar en Netlify exactamente igual que hemos visto antes.</p> <p>Pero si antes de desplegar en Netlify queremos probar a servir la aplicaci\u00f3n desde nuestro propio servidor corriendo el script <code>npm run start</code> hay un cambio. Al hacerlo se sirve la aplicaci\u00f3n en \"http://localhost:4200\". Si estamos en la misma m\u00e1quina podremos acceder poniendo esa URL en la barra de direcciones de nuestro navegador. Pero si nuestro servidor est\u00e1 en AWS y el navegador en nuestro equipo local, no podemos sustituir localhost por la IP externa de nuestro EC2 como hemos hecho hasta ahora. No funcionar\u00e1, porque Angular solo permite acceder desde la propia m\u00e1quina. Si queremos probarlo antes de desplegarlo deberemos primero instalar Angular de forma global con:</p> <pre><code>sudo npm install -g @angular/cli\n</code></pre> <p>Y en lugar de <code>npm run start</code> usaremos:</p> <pre><code>ng serve -o --host=IPPRIVADA\n</code></pre> <p>Y accederemos a la aplicaci\u00f3n con http://IPPUBLICA:4200 en el navegador</p> <p>Atenci\u00f3n</p> <p>F\u00edjate que primero servimos con IPPRIVADA, que es una IP que aparece bajo \"Direcciones IPv4 privadas\" y suele empezar por 172 en la consola AWS. No es la IP p\u00fablica.</p> <p>Y luego accedemos en el navegador con IPPUBLICA, no con la privada con la que servimos. </p> <p>Pero si no queremos probar antes de desplegar, todo esto no es necesario.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P07-Netlify/#referencias","title":"Referencias","text":"<p>\u00bfQu\u00e9 es Github?</p> <p>Deploying Node.js applications</p> <p>Guide to Deploying a React App to Netlify</p> <p>Angular Ya</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/","title":"Pr\u00e1ctica 8: Despliegue de una aplicaci\u00f3n Flask (Python)","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#que-es-un-framework","title":"\u00bfQu\u00e9 es un framework?","text":"<p>Actualmente en el desarrollo moderno de aplicaciones web se utilizan distintos Frameworks que son herramientas que nos dan un esquema de trabajo y una serie de utilidades y funciones que nos facilita y nos abstrae de la construcci\u00f3n de p\u00e1ginas web din\u00e1micas.</p> <p>En general los Frameworks est\u00e1n asociado a lenguajes de programaci\u00f3n (Ruby on Rails (Ruby), Symphony (PHP)), en el mundo de Python el m\u00e1s conocido es Django pero Flask es una opci\u00f3n que quiz\u00e1s no tenga una curva de aprendizaje tan elevada pero nos posibilita la creaci\u00f3n de aplicaciones web igual de complejas de las que se pueden crear en Django.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#flask","title":"Flask","text":"<p>En la actualidad existen muchas opciones para crear p\u00e1ginas web y muchos lenguajes (PHP, JAVA), y en este caso Flask nos permite crear de una manera muy sencilla aplicaciones web con Python.</p> <p>Flask es un \u201cmicro\u201d Framework escrito en Python y concebido para facilitar el desarrollo de Aplicaciones Web bajo el patr\u00f3n MVC.</p> <p>La palabra \u201cmicro\u201d no designa a que sea un proyecto peque\u00f1o o que nos permita hacer p\u00e1ginas web peque\u00f1as sino que al instalar Flask tenemos las herramientas necesarias para crear una aplicaci\u00f3n web funcional pero si se necesita en alg\u00fan momento una nueva funcionalidad hay un conjunto muy grande extensiones (plugins) que se pueden instalar con Flask que le van dotando de funcionalidad.</p> <p></p> <p>De principio en la instalaci\u00f3n no se tienen todas las funcionalidades que se pueden necesitar pero de una manera muy sencilla se pueden extender el proyecto con nuevas funcionalidades por medio de plugins.</p> <p>El patr\u00f3n MVC es una manera o una forma de trabajar que permite diferenciar y separar lo que es el modelo de datos (los datos que van a tener la App que normalmente est\u00e1n guardados en BD), la vista (p\u00e1gina HTML) y el controlador (donde se gestiona las peticiones de la app web).</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#gunicorn","title":"Gunicorn","text":"<p>Cuando se implementa una aplicaci\u00f3n web basada en Python, normalmente se tienen estas tres piezas:</p> <ul> <li>Servidor web (Nginx, Apache)</li> <li>Servidor de aplicaciones WSGI (Gunicorn, uWSGI, mod_wsgi, Waitress)</li> <li>Aplicaci\u00f3n web (Django, Flask, Pyramid, FastAPI)</li> </ul> <p>Los servidores web procesan y distribuyen las solicitudes de los navegadores y otros clientes y env\u00edan respuestas a los mismos.</p> <p>WSGI (Web Server Gateway Interface) proporciona un conjunto de reglas para estandarizar el comportamiento y la comunicaci\u00f3n entre servidores web y aplicaciones web. Mediante el uso de servidores y aplicaciones web compatibles con WSGI, los desarrolladores pueden concentrar su tiempo y energ\u00eda en el desarrollo de aplicaciones web en lugar de administrar la comunicaci\u00f3n entre la aplicaci\u00f3n y el servidor web.</p> <p></p> <p>Finalmente, Gunicorn, que es la abreviatura de Green Unicorn, es un servidor de aplicaciones WSGI que se encuentra entre el servidor web y su aplicaci\u00f3n web, gestionando la comunicaci\u00f3n entre los dos. Acepta solicitudes del servidor y las traduce (a trav\u00e9s de WSGI) en algo que la aplicaci\u00f3n web puede entender antes de pasarla a la aplicaci\u00f3n web real. Env\u00eda respuestas desde la aplicaci\u00f3n web al servidor. Tambi\u00e9n se encarga de ejecutar varias instancias de la aplicaci\u00f3n web, reinici\u00e1ndolas seg\u00fan sea necesario y distribuyendo solicitudes a instancias saludables.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#gestor-de-paquetes-pip","title":"Gestor de paquetes <code>pip</code>","text":"<p><code>pip</code> es el comando para instalar paquetes de Python integrados en las fuentes desde la versi\u00f3n 3.4.</p> <p>Este comando automatiza la conexi\u00f3n al sitio https://pypi.org/, la descarga, la instalaci\u00f3n e incluso la compilaci\u00f3n del m\u00f3dulo solicitado.</p> <p>Adem\u00e1s, se ocupa de las dependencias de cada paquete.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#entornos-virtuales-en-python","title":"Entornos virtuales en Python","text":"<p>Un entorno virtual es una forma de tener m\u00faltiples instancias paralelas del int\u00e9rprete de Python, cada una con diferentes conjuntos de paquetes y diferentes configuraciones. Cada entorno virtual contiene una copia independiente del int\u00e9rprete de Python, incluyendo copias de sus utilidades de soporte.</p> <p>Los paquetes instalados en cada entorno virtual s\u00f3lo se ven en ese entorno virtual y en ning\u00fan otro. Incluso los paquetes grandes y complejos con binarios dependientes de la plataforma pueden ser acorralados entre s\u00ed en entornos virtuales.</p> <p>De esta forma, tendremos entornos independientes entre s\u00ed, parecido a como ocurr\u00eda con los directorios de los proyectos de <code>Node.js</code>. De este modo, los entornos virtuales de Python nos permiten instalar un paquete de Python en una ubicaci\u00f3n aislada en lugar de instalarlo de manera global.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#pipenv","title":"Pipenv","text":"<p><code>Pipenv</code> es una herramienta que apunta a traer todo lo mejor del mundo de empaquetado (bundler, composer, npm, cargo, yarn, etc.) al mundo de Python. </p> <p></p> <p>Autom\u00e1ticamente crea y maneja un entorno virtual para tus proyectos, tambi\u00e9n permite agregar/eliminar paquetes desde tu Pipfile as\u00ed como como instalar/desinstalar paquetes. Tambi\u00e9n genera lo m\u00e1s importante , el archivo <code>Pipfile.lock</code>, que es usado para producir determinado build.</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#procedimiento-completo-para-el-despliegue","title":"Procedimiento completo para el despliegue","text":"<p>Vamos a empezar creando un EC2 Debian para esta pr\u00e1ctica. </p> <ul> <li>Ll\u00e1male P3.7Flask</li> <li>Ponle un procesador t2.medium, con 2 vCPU</li> <li>Crea un grupo de seguridad con acceso a puertos SSH, HTTP, HTTPS y TCP 5000. Ll\u00e1male igual que al EC2.</li> <li>Con\u00e9ctate al servidor</li> <li>Instala el servidor Web Nginx.</li> </ul> <p>Vamos a ello.</p> <ol> <li> <p>Instalamos el gestor de paquetes de Python pip:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade\nsudo apt-get install python3-pip\n</code></pre> </li> <li> <p>Instalamos el paquete <code>pipenv</code> para gestionar los entornos virtuales:</p> <pre><code>sudo apt-get install pipenv\n</code></pre> </li> <li> <p>Y comprobamos que est\u00e1 instalado correctamente mostrando su versi\u00f3n:</p> <pre><code>pipenv --version\n</code></pre> </li> <li> <p>Creamos el directorio en el que almacenaremos nuestro proyecto. Al crearlo con <code>sudo</code>, los permisos pertenecen a root y hemos de hacer que sea de nuestro usuario con chown. Y finalmente le damos los permisos adecuados como vimos en la pr\u00e1ctica de Nginx.</p> <pre><code>$ sudo mkdir /var/www/practica_flask\n$ sudo chown -R $USER:www-data /var/www/practica_flask\n$ chmod -R 775 /var/www/practica_flask/\n$ ls -la /var/www/practica_flask/\ndrwxrwxr-x 2 admin www-data 4096 Sep 30 10:56 .\n</code></pre> <p>Warning</p> <p>Es indispensable asignar estos permisos, de otra forma obtendr\u00edamos un error al acceder a la aplicaci\u00f3n cuando pongamos en marcha Nginx</p> </li> <li> <p>Dentro del directorio de nuestra aplicaci\u00f3n, creamos un archivo oculto <code>.env</code> que contendr\u00e1 las variables de entorno necesarias:</p> <pre><code>cd /var/www/practica_flask\ntouch .env\n</code></pre> </li> <li> <p>Editamos el archivo y a\u00f1adimos las variables, indicando cu\u00e1l es el archivo <code>.py</code> de la aplicaci\u00f3n y el entorno, que en nuestro caso ser\u00e1 producci\u00f3n: </p> <pre><code>FLASK_APP=wsgi.py\nFLASK_ENV=production\n</code></pre> <p>Nota</p> <p>En el mundo laboral real, se supone que la aplicaci\u00f3n previamente ha pasado por los entornos de dev, test y preprod para el desarrollo y prueba de la misma, antes de pasarla a producci\u00f3n.</p> </li> <li> <p>Iniciamos ahora nuestro entorno virtual. <code>Pipenv</code> cargar\u00e1 las variables de entorno desde el fichero <code>.env</code> de forma autom\u00e1tica:</p> <p><pre><code>cd /var/www/practica_flask\npipenv shell\n</code></pre> Veremos que se nos inicia el entorno virtual, cosa que comprobamos porque aparece su nombre al inicio del prompt del shell:</p> <pre><code>(practica_flask) admin@ip-172-31-63-141:/var/www/practica_flask$ \n</code></pre> </li> <li> <p>Usamos <code>pipenv</code> para instalar las dependencias necesarias para nuestro proyecto:</p> <pre><code>pipenv install flask gunicorn\n</code></pre> </li> <li> <p>Vamos ahora a crear la aplicaci\u00f3n Flask m\u00e1s simple posible, a modo de PoC (proof of concept o prueba de concepto). El archivo que contendr\u00e1 la aplicaci\u00f3n propiamente dicha ser\u00e1 <code>application.py</code> y <code>wsgi.py</code> se encargar\u00e1 \u00fanicamente de iniciarla y dejarla corriendo:</p> <p><pre><code>touch application.py wsgi.py\n</code></pre> Y tras crear los archivos, los editamos para dejarlos as\u00ed:</p> <p>application.py <pre><code>from flask import Flask\n    app=Flask(__name__)\n    @app.route('/')\n    def index():\n            '''Index page route'''\n            return '&lt;h1&gt;Aplicacion desplegada&lt;h1&gt;'\n</code></pre> wsgi.py <pre><code>from application import app\n    if __name__=='__main__':\n    app.run(debug=false)\n</code></pre></p> </li> <li> <p>Corramos ahora nuestra aplicaci\u00f3n a modo de comprobaci\u00f3n con el servidor web integrado de Flask. Si especificamos la direcci\u00f3n <code>0.0.0.0</code> lo que le estamos diciendo al servidor es que escuche en todas sus interfaces, si las tuviera:</p> <p></p> </li> <li> <p>Ahora podremos acceder a la aplicaci\u00f3n desde nuestro ordenador, nuestra m\u00e1quina anfitri\u00f3n, introduciendo en un navegador web: <code>http://IP-maq-virtual:5000</code>. Ojo, la IP que aparecer\u00e1 es la interna de la m\u00e1quina, no la externa. Desde tu equipo local deber\u00e1s acceder a la IP externa. Si algo falla comprueba la IP y las reglas del grupo de seguridad que creaste en AWS:</p> <p></p> <p>Tras la comprobaci\u00f3n, paramos el servidor con <code>CTRL+C</code></p> </li> <li> <p>Comprobemos ahora que Gunicorn funciona correctamente tambi\u00e9n. Si os ha funcionado el servidor de desarrollo de Flask, pod\u00e9is usar el siguiente comando para probar que la aplicaci\u00f3n funciona correctamente usando Gunicorn:</p> <p><pre><code>gunicorn --workers 2 --bind 0.0.0.0:5000 wsgi:app\n</code></pre> Donde:</p> <ul> <li> <p><code>--workers N</code> establece el n\u00famero de <code>workers</code> o hilos que queremos utilizar, como ocurr\u00eda con Node Express. Depender\u00e1 del n\u00famero de cores que le hayamos dado a la CPU de nuestra m\u00e1quina virtual.</p> </li> <li> <p><code>--bind 0.0.0.0:5000</code> hace que el servidor escuche peticiones por todas sus interfaces de red y en el puerto 5000</p> </li> <li> <p>En <code>wsgi:app</code>, <code>wsgi</code> es el nombre del archivo con extensi\u00f3n <code>.py</code> y <code>app</code> es la instancia de la aplicaci\u00f3n Flask dentro del archivo.</p> </li> </ul> <p>Accede ahora con el navegador de la misma forma que en el paso anterior.</p> </li> <li> <p>Todav\u00eda dentro de nuestro entorno virtual, debemos tomar nota de cual es el path o ruta desde la que se ejecuta <code>gunicorn</code> para poder configurar m\u00e1s adelante un servicio del sistema. Podemos averigurarlo as\u00ed:</p> <p></p> <p>Tip</p> <p>Y tras ello debemos salir de nuestro entorno virtual con el sencillo comando <code>deactivate</code></p> </li> <li> <p>Puesto que ya debemos tener instalado Nginx en nuestro sistema, lo ininciamos y comprobamos que su estado sea activo:</p> <pre><code>sudo systemctl start nginx\n\nsudo systemctl status nginx\n</code></pre> </li> <li> <p>Ya fuera de nuestro entorno virtual, crearemos un archivo para que systemd corra Gunicorn como un servicio del sistema m\u00e1s. En el ejemplo al servicio le vamos a llamar <code>flask_app.service</code>. Crea el archivo /etc/systemd/system/flask_app.service con este contenido (deber\u00e1s hacerlo como sudo):</p> <pre><code>[Unit]\nDescription=flask_app.service\nAfter=network.target\n\n[Service]\nUser=admin\nGroup=www-data\nEnvironment=\"PATH=/home/admin/.local/share/virtualenvs/practica_flask-gV07D8Rz/bin:$PATH\"\nWorkingDirectory=/var/www/practica_flask/\nExecStart=/home/admin/.local/share/virtualenvs/practica_flask-gV07D8Rz/bin/gunicorn --workers 2 --bind unix:/var/www/practica_flask/flask_app.sock -m 007 wsgi:app\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Donde:</p> <ul> <li><code>User</code>: Establece el usuario que tiene permisos sobre el directorio del proyecto (el que pusisteis en el paso 4)</li> <li><code>Group</code>: Establece el grupo que tiene permisos sobre el directorio del proyecto (el que pusisteis en el paso 4)</li> <li><code>Environment</code>: Establece el directorio <code>bin</code> (donde se guardan los binarios ejecutables) dentro del entorno virtual (lo visteis en el paso 13)</li> <li><code>WorkingDirectory</code>: Establece el directorio base donde reside nuestro proyecto </li> <li><code>ExecStart</code>: Establece el path donde se encuentra el ejecutable de <code>gunicorn</code> dentro del entorno virtual, as\u00ed como las opciones y comandos con los que se iniciar\u00e1 </li> </ul> <p>Warning</p> <p>Deb\u00e9is cambiar los valores para que coincidan con los de vuestro caso particular.</p> </li> <li> <p>Ahora, como cada vez que se crea un servicio nuevo de <code>systemd</code>, se habilita y se inicia:</p> <pre><code>systemctl enable flask_app\n\nsystemctl start flask_app\n</code></pre> <p>Recordad que el nombre del servicio es el nombre del archivo que creasteis en el paso anterior.</p> <p>No intent\u00e9is acceder a trav\u00e9s del navegador todav\u00eda. Hasta que no configuremos nginx adecuadamente no tendremos acceso a nuestra aplicaci\u00f3n.</p> <p>Comprueba que en el directorio <code>/var/www/practica_flask/</code> se ha creado el fichero <code>flask_app.sock</code>.</p> <p>Pasemos ahora a configurar Nginx, que es algo que ya deber\u00edamos tener dominado de cap\u00edtulos anteriores.</p> </li> <li> <p>Creamos un archivo con el nombre de nuestra aplicaci\u00f3n y dentro estableceremos la configuraci\u00f3n para ese sitio web. El archivo, como record\u00e1is, debe estar en <code>/etc/nginx/sites-available/practica_flask</code> y tras ello lo editamos para que quede:</p> <pre><code>server {\n    listen 80;\n    server_name practica_flask www.practica_flask; #(1)\n\n    access_log /var/log/nginx/practica_flask.access.log; #(2)\n    error_log /var/log/nginx/practica_flask.error.log;\n\n    location / { \n            include proxy_params;\n            proxy_pass http://unix:/var/www/practica_flask/flask_app.sock; #(3)\n    }\n}   \n</code></pre> <ol> <li> <p>Nombre del dominio, ya veremos m\u00e1s adelante como el DNS resolver\u00e1 este nombre para acceder a nuestra aplicaci\u00f3n.</p> </li> <li> <p>D\u00f3nde estar\u00e1n ubicados los logs de acceso y de errores.</p> </li> <li> <p>Bloque donde se le indica a Nginx que haga de proxy inverso hacia el socket creado en nuestra propia m\u00e1quina por gunicorn para acceder a nuestra aplicaci\u00f3n Flask.</p> </li> </ol> </li> <li> <p>Recordemos que ahora debemos crear un link simb\u00f3lico del archivo de sitios webs disponibles al de sitios web activos:</p> <pre><code>sudo ln -s /etc/nginx/sites-available/practica_flask /etc/nginx/sites-enabled/\n</code></pre> <p>Y nos aseguramos de que se ha creado dicho link simb\u00f3lico:</p> <pre><code>ls -l /etc/nginx/sites-enabled/ | grep practica_flask\n</code></pre> </li> <li> <p>Nos aseguramos de que la configuraci\u00f3n de Nginx no contiene errores, reiniciamos Nginx y comprobamos que se estado es activo:</p> <pre><code>sudo nginx -t\n\nsudo systemctl restart nginx\n\nsudo systemctl status nginx\n</code></pre> </li> <li> <p>Ya no podremos acceder por IP a nuestra aplicaci\u00f3n ya que ahora est\u00e1 siendo servida por Gunicorn y Nginx, necesitamos acceder por su <code>server_name</code>. Puesto que a\u00fan no hemos tratado con el DNS, vamos a editar el archivo <code>/etc/hosts</code> de nuestra m\u00e1quina anfitriona para que asocie la IP de la m\u00e1quina virtual, a nuestro <code>server_name</code>.</p> <p>Este archivo, en Linux, est\u00e1 en: <code>/etc/hosts</code></p> <p>Y en Windows: <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code></p> <p>Y deberemos a\u00f1adirle la l\u00ednea:</p> <p><code>IPSERVIDORDEBIAN practica_flask www.practica_flask</code></p> <p>donde deb\u00e9is sustituir la IPSERVIDORDEBIAN por la que tenga vuestro servidor Debian en AWS.</p> </li> <li> <p>El \u00faltimo paso es comprobar que todo el desplieuge se ha realizado de forma correcta y est\u00e1 funcionando, para ello accedemos desde nuestra m\u00e1quina anfitri\u00f3n a:</p> <p><code>http://practica_flask</code></p> <p>O:</p> <p><code>http://www.practica_flask</code></p> <p>Y deber\u00eda mostraros la misma p\u00e1gina que en el paso 14:</p> <p> </p> </li> <li> <p>Recuerda que configuramos el servicio flask_app.service para que se inicie autom\u00e1ticamente al arrancar el servidor. Desde AWS reinicia el servidor y comprueba si puedes acceder a <code>http://practica_flask</code> directamente tras su arranque.</p> <p>Ojo</p> <p>Tras reiniciarse el servidor Debian podr\u00eda cambiar su IP externa</p> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#cuestiones","title":"Cuestiones","text":"<p>Cuestion 1</p> <p>Busca, lee, entiende y explica qu\u00e9 es y para que sirve un servidor WSGI</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P08-Flask/#referencias","title":"Referencias","text":"<p>\u00bfQu\u00e9 es Flask?</p> <p>Deploy Flask The Easy Way With Gunicorn and Nginx!</p> <p>Deploy flask app with Nginx using Gunicorn</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/","title":"Crear im\u00e1genes propias","text":"<p>Ya hemos visto como usar im\u00e1genes de terceros para crear aplicaciones y servicios. Y en el cap\u00edtulo 4 vimos c\u00f3mo crear im\u00e1genes propias usando <code>docker build</code> y el fichero <code>Dockerfile</code>. Pero, \u00bfy si queremos hacer una imagen de nuestra aplicaci\u00f3n para distribuirla?</p> <p>Vamos primero a recordar brevemente el proceso de creaci\u00f3n de una imagen propia sobre la que desarrollaremos nuestra aplicaci\u00f3n. Aunque podr\u00edamos hacerla partiendo de cero, es un esfuerzo que no tiene sentido. Existe ya im\u00e1genes base para crear las nuestras y es mucho m\u00e1s f\u00e1cil crear una imagen bas\u00e1ndose en otra que hacerlo todo nosotros.</p> <p>Podemos partir de una imagen base que parte de un lenguaje de programaci\u00f3n (python, php) o de alguna distribuci\u00f3n (ubuntu, debian).</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#recordando-el-dockerfile","title":"Recordando el Dockerfile","text":"<p> Fuente: https://nilesh93.medium.com/practical-guide-on-writing-a-dockerfile-for-your-application-89376f88b3b5</p> <p>Los Dockerfile son los archivos que contienen las instrucciones que crean las im\u00e1genes. Deben estar guardados dentro de un build context, es decir, un directorio. Este directorio es el que contiene todos los archivos necesarios para construir nuestra imagen, de ah\u00ed lo de build context.</p> <p>Creamos nuestro build context</p> <pre><code>mkdir -p  ~/Sites/hello-world\ncd ~/Sites/hello-world\necho \"hello\" &gt; hello\n</code></pre> <p>Dentro de este directorio crearemos un archivo llamado Dockerfile con este contenido:</p> <pre><code>FROM busybox\nCOPY /hello /\nRUN cat /hello\n</code></pre> Directiva Explicaci\u00f3n FROM Indica la imagen base sobre la que se basa esta imagen COPY Copia un archivo del build context y lo guarda en la imagen RUN Ejecuta el comando indicado durante el proceso de creaci\u00f3n de imagen. <p>Ahora para crear nuestra imagen usaremos <code>docker build</code>.</p> <pre><code>docker build -t helloapp:v1 .\n</code></pre> <p>El par\u00e1metro <code>-t</code> nos permite etiquetar la imagen con un nombre y una versi\u00f3n. El <code>.</code> indica que el build context es el directorio actual. No olvides el punto final que casi no se ve.</p> <p>El resultado de ejecutar lo anterior ser\u00eda:</p> <pre><code>$ docker build -t helloapp:v1 .\nSending build context to Docker daemon  3.072kB\nStep 1/3 : FROM busybox\nlatest: Pulling from library/busybox\n8c5a7da1afbc: Pull complete \nDigest: sha256:cb63aa0641a885f54de20f61d152187419e8f6b159ed11a251a09d115fdff9bd\nStatus: Downloaded newer image for busybox:latest\n    ---&gt; e1ddd7948a1c\nStep 2/3 : COPY /hello /\n    ---&gt; 8a092965dbc9\nStep 3/3 : RUN cat /hello\n    ---&gt; Running in 83b5498790ca\nhello\nRemoving intermediate container 83b5498790ca\n    ---&gt; f738f117d4b6\nSuccessfully built f738f117d4b6\nSuccessfully tagged helloapp:v1\n</code></pre> <p>Y podremos ver que una nueva imagen est\u00e1 instalada en nuestro equipo:</p> <pre><code>$ docker images\nREPOSITORY   TAG  IMAGE ID      CREATED         SIZE\nhelloapp     v1   f738f117d4b6  40 seconds ago  1.16MB\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#creando-aplicaciones-en-contenedores","title":"Creando aplicaciones en contenedores","text":"<p>Vamos a crear un aplicaci\u00f3n en python y la vamos a guardar en un contenedor. Comenzamos creando un nuevo build context:</p> <pre><code>mkdir -p  ~/Sites/friendlyhello\ncd ~/Sites/friendlyhello\n</code></pre> <p>El c\u00f3digo de la aplicaci\u00f3n es el siguiente, lo guardaremos en un archivo llamado <code>app.py</code>:</p> <pre><code>from flask import Flask\nfrom redis import Redis, RedisError\nimport os\nimport socket\n\n# Connect to Redis\nredis = Redis(host=\"redis\", db=0, socket_connect_timeout=2, socket_timeout=2)\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    try:\n        visits = redis.incr(\"counter\")\n    except RedisError:\n        visits = \"&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;\"\n\n    html = \"&lt;h3&gt;Hello {name}!&lt;/h3&gt;\" \\\n            \"&lt;b&gt;Hostname:&lt;/b&gt; {hostname}&lt;br/&gt;\" \\\n            \"&lt;b&gt;Visits:&lt;/b&gt; {visits}\"\n    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname(),  visits=visits)\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0', port=80)\n</code></pre> <p>Nuestra aplicaci\u00f3n tiene una serie de dependencias (librer\u00edas de terceros) que guardaremos en el archivo requirements.txt:</p> <pre><code>Flask\nRedis\n</code></pre> <p>Y por \u00faltimo definimos nuestro Dockerfile:</p> <pre><code># Partimos de una base oficial de python\nFROM python:2.7-slim\n\n# El directorio de trabajo es desde donde se ejecuta el contenedor al iniciarse\nWORKDIR /app\n\n# Copiamos todos los archivos del build context al directorio /app del contenedor\nCOPY . /app\n\n# Ejecutamos pip para instalar las dependencias en el contenedor\nRUN pip install --trusted-host pypi.python.org -r requirements.txt\n\n# Indicamos que este contenedor se comunica por el puerto 80/tcp\nEXPOSE 80\n\n# Declaramos una variable de entorno\nENV NAME World\n\n# Ejecuta nuestra aplicaci\u00f3n cuando se inicia el contenedor\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>Para conocer todas las directivas visita la documentaci\u00f3n oficial de Dockerfile.</p> <p>En total debemos tener 3 archivos:</p> <pre><code>$ ls\napp.py  Dockerfile  requirements.txt\n</code></pre> <p>Ahora construimos la imagen de nuestra aplicaci\u00f3n:</p> <pre><code>docker build -t friendlyhello .\n</code></pre> <p>Y comprobamos que est\u00e1 creada:</p> <pre><code>$ docker image ls\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nfriendlyhello       latest              88a822b3107c        56 seconds ago      132MB\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#probar-nuestro-contenedor","title":"Probar nuestro contenedor","text":"<p>Vamos a arrancar nuestro contenedor y probar la aplicaci\u00f3n:</p> <pre><code>docker run --rm -p 4000:80 friendlyhello\n</code></pre> <p>Tip</p> <p>Normalmente los contenedores son de usar y tirar, sobre todo cuando hacemos pruebas. El par\u00e1metro <code>--rm</code> borra autom\u00e1ticamente un contenedor cuando se para. Recordemos que los datos vol\u00e1tiles siempre se deben guardar en vol\u00famenes.</p> <p>Lo que arranca la aplicaci\u00f3n Flask:</p> <pre><code>$ docker run --rm -p 4000:80 friendlyhello\n    * Serving Flask app \"app\" (lazy loading)\n    * Environment: production\n    WARNING: Do not use the development server in a production environment.\n    Use a production WSGI server instead.\n    * Debug mode: off\n    * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)\n</code></pre> <p>Comprobamos en el puerto 4000 si efectivamente est\u00e1 iniciada o no: http://localhost:4000.</p> <p>Obtendremos un mensaje como este:</p> <pre><code>Hello World!\n\nHostname: 0367b056e66e\nVisits: cannot connect to Redis, counter disabled\n</code></pre> <p>Ya tenemos una imagen lista para ser usada. Pulsamos <code>Control+C</code> para interrumpir y borrar nuestro contenedor.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#creando-la-aplicacion","title":"Creando la aplicaci\u00f3n","text":"<p>En este caso nuestro contenedor no funciona por s\u00ed mismo. Es muy habitual que dependamos de servicios para poder iniciar la aplicaci\u00f3n, habitualmente bases de datos. En este caso necesitamos una base de datos Redis que no tenemos.</p> <p>Como vimos en el apartado anterior, vamos a aprovechar las caracter\u00edsticas de Compose para levantar nuestra aplicaci\u00f3n.</p> <p>Vamos a crear el siguiente archivo docker-compose.yaml:</p> <pre><code>version: \"3\"\nservices:\n    web:\n        build: .\n        ports:\n            - \"4000:80\"\n    redis:\n        image: redis\n        ports:\n            - \"6379:6379\"\n        volumes:\n            - \"./data:/data\"\n        command: redis-server --appendonly yes\n</code></pre> <p>La principal diferencia con respecto al cap\u00edtulo anterior, es que en un servicio podemos indicar una imagen (par\u00e1metro <code>imagen</code>) o un build context (par\u00e1metro <code>build</code>). </p> <p>Esta es una manera de integrar las dos herramientas que nos proporciona Docker: la creaci\u00f3n de im\u00e1genes y la composici\u00f3n de aplicaciones con servicios.</p> <p>Ahora ya podemos lanzarla con </p> <pre><code>docker-compose up\n</code></pre> <p>Accede ahora con el navegador a http://localhost:4000/ y comprueba como tras cada nuevo acceso se va incrementando el contador.</p> <p>Recuerda parar los contenedores y borrarlos con   </p> <pre><code>docker-compose stop\ndocker-compose down\n</code></pre> <p>Y en este caso se nos crea un directorio data sobre el que no tenemos permisos y deberemos borrar para el siguiente apartado:</p> <pre><code>sudo rm -R -f ~/Sites/friendlyhello/data\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#balanceo-de-carga","title":"Balanceo de carga","text":"<p>Vamos a modificar nuestro docker-compose.yaml:</p> <pre><code>version: \"3\"\nservices:\n    web:\n        build: .\n    redis:\n        image: redis\n        volumes:\n            - \"./data:/data\"\n        command: redis-server --appendonly yes\n    lb:\n        image: dockercloud/haproxy\n        ports:\n            - 4000:80\n        links:\n            - web\n        volumes:\n            - /var/run/docker.sock:/var/run/docker.sock \n</code></pre> <p>En este caso, el servicio web no va a tener acceso al exterior (hemos eliminado el par\u00e1metro <code>ports</code>). En su lugar hemos a\u00f1adido un balanceador de carga (el servicio  <code>lb</code>).</p> <p>Vamos a arrancar esta nueva aplicaci\u00f3n, pero esta vez a\u00f1adiendo varios servicios web:</p> <pre><code>docker-compose up -d --scale web=5\n</code></pre> <p>Esperamos a que terminen de iniciar los servicios:</p> <pre><code>$ docker-compose up -d --scale web=5\nCreating network \"friendlyhello_default\" with the default driver\nCreating friendlyhello_redis_1 ... done\nCreating friendlyhello_web_1   ... done\nCreating friendlyhello_web_2   ... done\nCreating friendlyhello_web_3   ... done\nCreating friendlyhello_web_4   ... done\nCreating friendlyhello_web_5   ... done\nCreating friendlyhello_lb_1    ... done\n</code></pre> <p>Podemos comprobar como del servicio web nos ha iniciado 5 instancias, cada uno con su sufijo num\u00e9rico correspondiente. Si usamos <code>docker ps</code> para ver los contenedores disponibles tendremos:</p> <pre><code>$ docker ps\nCONTAINER ID  IMAGE                [...]   PORTS                                    NAMES\n77acae1d0567  dockercloud/haproxy  [...]   443/tcp, 1936/tcp, 0.0.0.0:4000-&gt;80/tcp  friendlyhello_lb_1\n5f12fb8b80c8  friendlyhello_web    [...]   80/tcp                                   friendlyhello_web_5\nfb0024591665  friendlyhello_web    [...]   80/tcp                                   friendlyhello_web_2\na20d20bdd129  friendlyhello_web    [...]   80/tcp                                   friendlyhello_web_4\n53d7db212df8  friendlyhello_web    [...]   80/tcp                                   friendlyhello_web_3\n41218dbbb882  friendlyhello_web    [...]   80/tcp                                   friendlyhello_web_1\n06f5bf6ed070  redis                [...]   6379/tcp                                 friendlyhello_redis_1\n</code></pre> <p>Vamos a fijarnos en el <code>CONTAINER ID</code> y vamos a volver a abrir nuestra aplicaci\u00f3n: http://localhost:4000.</p> <p>Si en esta ocasi\u00f3n vamos recargando la p\u00e1gina, veremos como cambian los hostnames, que a su vez coinciden con los identificadores de los contenedores anteriores.</p> <p>Info</p> <p>Esta no es la manera adecuada de hacer balanceo de carga, puesto que todos los contenedores est\u00e1n en la misma m\u00e1quina, lo cual no tiene sentido. Solo es una demostraci\u00f3n. Para hacer balanceo de carga real necesitar\u00edamos tener o emular un clustes de m\u00e1quinas y crear un enjambre (swarm).</p> <p>Recuerda parar los contenedores y borrarlos con   </p> <pre><code>docker compose stop\ndocker compose down\nsudo rm -R -f ~/Sites/friendlyhello/data\n</code></pre>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/P09-FlaskEnDocker/#compartir-imagenes","title":"Compartir im\u00e1genes","text":"<p>Si tenemos una imagen que queramos compartir, necesitamos usar un registro. Existe incluso una imagen que nos permite crear uno propio, pero vamos a usar el repositorio p\u00fablico de Docker. Esto ya lo aprendimos en el cap\u00edtulo 7.4 Im\u00e1genes, pero vamos a recordarlo.</p> <p>Los pasos son:</p> <ol> <li>Crear una cuenta de usuario en el repositorio oficial de Docker si no la tenemos ya.</li> <li>Pulsar sobre el bot\u00f3n \"Create Repository +\".</li> <li> <p>En el formulario hay que rellenar solo un dato obligatoriamente: el nombre. Usaremos el de la imagen: friendlyhello.</p> <p>Nuestro nombre de usuario es el namespace y es obligatorio que tenga uno. Si estuvieramos en alguna organizaci\u00f3n podr\u00edamos elegir entre varios. El resto de campos lo dejamos como est\u00e1 por el momento. La cuenta gratuita solo deja tener un repositorio privado, asi que no lo malgastaremos aqu\u00ed.</p> </li> <li> <p>Ahora tenemos que conectar nuestro cliente de Docker con nuestra cuenta en el Hub. Usamos el comando <code>docker login</code>.</p> <pre><code>$\u00a0docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: username\nPassword: ********\nWARNING! Your password will be stored unencrypted in /home/sergio/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n</code></pre> <p>Danger</p> <p>Las claves se guardan sin cifrar. Hay que configurar un almacen de claves o recordar hacer <code>docker logout</code> para borrarla.</p> <p>Visita la web de referencia para saber como crear un almacen.</p> </li> <li> <p>Para que las im\u00e1genes se puedan guardar, tenemos que etiquetarla con el mismo nombre que tengamos en nuestro repositorio m\u00e1s el namespace. Si nuestra cuenta es 'username' y el repositorio es 'friendlyhello', debemos crear la imagen con la etiqueta 'username/friendlyhello'.</p> <pre><code>$ docker build -t username/friendlyhello .\n</code></pre> <p>Tip</p> <p>Por defecto ya hemos dicho que la etiqueta si no se indica es latest. Podemos indicar m\u00e1s de una etiqueta para indicar versiones:</p> <pre><code>$ docker build -t username/friendlyhello -t username/friendlyhello:0.1.0 .\n</code></pre> <p>En la pr\u00f3xima que hagamos le subimos la versi\u00f3n en la etiqueta:</p> <pre><code>$ docker build -t username/friendlyhello -t username/friendlyhello:0.2.0 .\n</code></pre> <p>De esta manera nuestra imagen aparecer\u00e1 con tres etiquetas: latest y 0.2.0 que ser\u00e1n la misma en realidad, y 0.1.0.</p> </li> <li> <p>Ahora ya podemos enviar nuestra imagen:</p> <pre><code>$ docker push username/friendlyhello\n</code></pre> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/","title":"Pr\u00e1ctica Voluntaria 1: Despliegue de una aplicaci\u00f3n Node.js en Heroku (PaaS)","text":"<p>Atenci\u00f3n</p> <p>De un tiempo a esta parte Heroku se ha convertido en una plataforma de pago. En el momento de escribir esta gu\u00eda<sup>1</sup> ofrece el \"Student Developer Program\" que proporciona un cr\u00e9dito gratu\u00edto de $13/mes durante 12 meses para aquellos alumnos poseedores de una cuenta \"Github Student\". Pero incluso bajo estas condiciones exige proporcionar una tarjeta de cr\u00e9dito para validar la cuenta. Este es el motivo de dejar esta pr\u00e1ctica como voluntaria y no obligatoria.</p> <p>Si deseas continuar, empieza por crearte una cuenta GitHub para estudiante (habla con tu centro) y una cuenta en Heroku dentro del GitHub Student Developer Program:</p> <p>Heroku GitHub</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#introduccion","title":"Introducci\u00f3n","text":"<p>En la pr\u00e1ctica anterior hemos visto c\u00f3mo desplegar una aplicaci\u00f3n de Node.js sobre un servidor Express en local (en nuestro propio servidor Debian).</p> <p>La pr\u00e1ctica anterior podr\u00eda asemejarse a las pruebas que realiza un desarrollador antes de pasar su aplicaci\u00f3n al entorno de producci\u00f3n. </p> <p>Ya sabemos que entendemos el despliegue o deployment como el proceso de mover nuestro c\u00f3digo t\u00edpicamente de un sistema de control de versiones a una plataforma de hosting donde se aloja y es servida a los usuarios finales. </p> <p>A la hora de desplegar la aplicaci\u00f3n en producci\u00f3n, podr\u00eda utilizarse el m\u00e9todo de copiar los archivos al servidor concreto v\u00eda el vetusto FTP, SSH u otros y desplegarla para dejarla funcionando. No obstante, esta pr\u00e1ctica se acerca m\u00e1s a la realidad ya que utilizaremos un repositorio de Github y una plataforma de PaaS (Platform as a Service) como Heroku para desplegar adecuadamente nuestra aplicaci\u00f3n en producci\u00f3n.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#que-es-github","title":"\u00bfQu\u00e9 es Github?","text":"<p>A pesar de que trataremos un poco m\u00e1s en profundidad Github en un tema posterior, daremos una breve explicaci\u00f3n aqu\u00ed.</p> <p>GitHub es un servicio basado en la nube que aloja un sistema de control de versiones (VCS) llamado Git. \u00c9ste permite a los desarrolladores colaborar y realizar cambios en proyectos compartidos, a la vez que mantienen un seguimiento detallado de su progreso.</p> <p></p> <p>El control de versiones es un sistema que ayuda a rastrear y gestionar los cambios realizados en un archivo o conjunto de archivos. Utilizado principalmente por ingenieros de software para hacer un seguimiento de las modificaciones realizadas en el c\u00f3digo fuente, el sistema de control de versiones les permite analizar todos los cambios y revertirlos sin repercusiones si se comete un error.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#que-es-heroku","title":"\u00bfQu\u00e9 es Heroku?","text":"<p>Heroku es una soluci\u00f3n de Plataforma como Servicio (PaaS) basada en la nube para que el cliente solo se preocupe de desarrollar su aplicaci\u00f3n mientras Heroku se encarga de la infraestructura que hay detr\u00e1s.</p> <p>Para proporcionar este servicio se dispone de unos contenedores virtuales que son los encargados de mantener y ejecutar las aplicaciones. Estos contenedores virtuales son totalmente escalables bajo demanda. Tanto en n\u00famero como en capacidades.</p> <p></p> <p>Una ventaja de elegir Heroku es su capacidad de soportar m\u00faltiples lenguajes de programaci\u00f3n. Los principales a utilizar son: Node.js, Ruby, Python, Java, PHP, Go, Scala y Clojure. Aunque esta cantidad de lenguajes puede aumentar en el caso de utilizar Heroku Buildpacks, que permiten compilar las aplicaciones en multitud de ellos m\u00e1s.</p> <p>La desventaja la vimos al principio, , desde el punto de vista educativo, es que de un tiempo a esta parte se ha convertido en una plataforma de pago y exige proporcionar una tarjeta de cr\u00e9dito para validar la cuenta incluso en el Student Developer Program.</p> <p>Note</p> <p>Tanto Github, como Heroku, como Netlify pueden ser controlados desde el terminal de nuestro Linux, por lo que seguiremos el procedimiento de contectarnos v\u00eda SSH a nuestro Debian y realizar las operaciones por terminal.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#creacion-de-nuestra-aplicacion-para-heroku","title":"Creaci\u00f3n de nuestra aplicaci\u00f3n para Heroku","text":"<p>Vamos a realizar la pr\u00e1ctica utilizando la m\u00e1quina virtual que creamos en la pr\u00e1ctica P3.4 que llamamos \"DebianNodejs\". Tambi\u00e9n podr\u00edamos usar usar la creada en la P3.5 \"DebianNodejsCluster\" pero nos generar\u00e1 un mayor coste en AWS Academy.</p> <p>Tras loguearnos por SSH en nuestro Debian, nos crearemos un directorio para albergar la aplicaci\u00f3n con el nombre \"practicaheroku\". En ese directorio, crearemos los 3 archivos (dos <code>.html</code> y un <code>.js</code>)que conformar\u00e1n nuestra sencilla aplicaci\u00f3n de ejemplo:</p> head.htmltail.htmlaplicacion.js <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n        &lt;title&gt;Hola Mundo&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n        &lt;h1&gt;Esta es la pagina principal&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"/tailPage\"&gt;Ir a la siguiente pagina&lt;/a&gt;&lt;/p&gt;\n\n\n&lt;/body&gt;\n</code></pre> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n        &lt;title&gt;Hola Mundo&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n        &lt;h1&gt;FUNCIONA&lt;/h1&gt;\n\n&lt;/body&gt;\n</code></pre> <pre><code>var http = require('http');\nvar fs = require('fs'); // para obtener los datos del archivo html\nvar port = process.env.PORT || 8080;    //Para que funcione en Heroku ya que da error 137 con el puerto 3000\n\nhttp.createServer(function (req, res) {\n    // Set the default status code and content type for the response\n    var statusCode = 200;\n    var contentType = 'text/html';\n\n    // req.url stores the path or route of the URL\n    var url = req.url;\n\n    if (url === \"/\") {\n        fs.readFile(\"head.html\", function (err, pgres) {\n            // el primer par\u00e1metro es el path al archivo HTML\n            // y el segundo es el callback de la funci\u00f3n\n            // si el archivo no se encuentra, la funci\u00f3n devuelve un error\n            // si el archivo se encuentra, el contenido del mismo se encuentra en pgres\n            if (err) {\n                // If the file is not found, set a 404 status code and content type\n                statusCode = 404;\n                contentType = 'text/plain';\n                pgres = 'HEAD.HTML NOT FOUND';\n            }\n\n            // Set the response headers once and send the response\n            res.writeHead(statusCode, { 'Content-Type': contentType });\n            res.end(pgres);\n        });\n    } else if (url === \"/tailPage\") {\n        fs.readFile(\"tail.html\", function (err, pgres) {\n            if (err) {\n                statusCode = 404;\n                contentType = 'text/plain';\n                pgres = 'TAIL.HTML NOT FOUND';\n            }\n\n            res.writeHead(statusCode, { 'Content-Type': contentType });\n            res.end(pgres);\n        });\n    } else {\n        // Handle other routes or URLs as needed\n        res.writeHead(404, { 'Content-Type': 'text/plain' });\n        res.end('Page not found');\n    }\n}).listen(port, function () {\n    console.log(\"SERVER STARTED PORT: \" + port);\n});\n</code></pre> <p>Ahora, tal y como hacemos siempre a la hora de crear nuestra aplicaci\u00f3n Node.js, con el fin de crear el archivo <code>package.json</code>, utilizaremos en el terminal el comando:</p> <pre><code>npm init\n</code></pre> <p>Podemos probar que nuestra aplicaci\u00f3n funciona perfectamente en local:</p> <pre><code>node aplicacion.js\n</code></pre> <p>Y tras ello, debemos poder acceder, desde nuestra m\u00e1quina anfitriona a <code>http://IP-maq-virtual:8080</code></p> <p>Ya con la aplicaci\u00f3n creada y comprobada, podremos desplegarla en m\u00faltiples plataformas en la nube, como AWS, GCP, Azure, Digital Ocean, Heroku...</p> <p>\u00a1Ojo!</p> <p>Para que nos funcione en Heroku, en el archivo <code>package.json</code> que se nos ha creado al hacer el <code>npm init</code> debemos hacerle una modificaci\u00f3n.</p> <p>En el bloque scripts, debemos borrar lo que haya dentro y dejar \u00fanicamente dentro de \u00e9l:</p> <pre><code>\"start\": \"node aplicacion.js\"\n</code></pre> <p>De forma que Heroku sepa que comando utilizar para iniciar la aplicaci\u00f3n tras desplegarla.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#proceso-de-despliegue-en-heroku","title":"Proceso de despliegue en Heroku","text":"<p>Para trabajar con Heroku desde nuestro terminal, debemos instalar el propio CLI de Heroku. Consultando la documentaci\u00f3n, vemos que hemos de ejecutar:</p> <pre><code>curl https://cli-assets.heroku.com/install.sh | sh\n</code></pre> <p>Y comprobamos que se ha instalado correctamente consultando su versi\u00f3n:</p> <pre><code>heroku -v\n</code></pre> <p>Lo siguiente ser\u00e1 loguearnos en nuestra cuenta de Heroku mediante el terminal, para ello:</p> <p><pre><code>heroku login\n</code></pre> Esto en teor\u00eda nos abre una pesta\u00f1a del navegador para loguearnos en nuestra cuenta. Puesto que estamos conectados por SSH a nuestra Debian, no suceder\u00e1 esto ya que estamos en un terminal sin capacidades gr\u00e1ficas. Lo que haremos ser\u00e1 crear un proxy inverso a trav\u00e9s de SSH que nos permitir\u00e1 que las peticiones de p\u00e1ginas web de nuestra m\u00e1quina local se dirijan al servidor remoto a trav\u00e9s del tunel SSH y salgan de nuestro servidor Debian con su IP, como si fuera \u00e9l quien las hiciera. Para ello haremos lo siguiente.</p> <ol> <li>Cierra la conexi\u00f3n SSH en tu terminal local y lanza una nueva con este comando:</li> </ol> <pre><code>sudo ssh -i \"daw.pem\" -D 443 admin@ec2-xx-xx-xx-xx.compute-1.amazonaws.com\n</code></pre> <p>La opci\u00f3n -D establece un servidor SOCKS en el puerto local 443. Como nos vamos a conectar por https usaremos ese puerto.</p> <ol> <li> <p>Configura tu navegador web local para usar el servidor SOCKS como proxy. Dependiendo del navegador que est\u00e9s utilizando, los pasos pueden variar:</p> </li> <li> <p>Firefox:</p> <ul> <li>Abre Firefox.</li> <li>Ve a \"Opciones\" o \"Preferencias\" (dependiendo de tu sistema operativo).</li> <li>En la barra de b\u00fasqueda, escribe \"Proxy\".</li> <li>Haz clic en \"Configuraci\u00f3n de la red\".</li> <li>Selecciona \"Configuraci\u00f3n manual del proxy\".</li> <li>En \"SOCKS Host\", ingresa localhost y en \"Puerto\", ingresa 443.</li> <li>Marca la opci\u00f3n \"SOCKS v5\".</li> <li>Haz clic en \"Aceptar\".</li> </ul> </li> <li> <p>Chrome:</p> <ol> <li>Chrome no admite la configuraci\u00f3n directa de un proxy SOCKS desde su interfaz de usuario. Puedes usar una extensi\u00f3n como \"Proxy SwitchyOmega\" para configurar un proxy SOCKS en Chrome.   </li> </ol> </li> <li> <p>Con la configuraci\u00f3n del proxy establecida en tu navegador, cualquier solicitud de p\u00e1gina web que hagas desde tu navegador pasar\u00e1 a trav\u00e9s del servidor remoto como si el servidor remoto estuviera haciendo las solicitudes. Esto oculta tu direcci\u00f3n IP local y utiliza la del servidor remoto.</p> </li> <li> <p>Ahora puedes abrir tu navegador y navegar a cualquier p\u00e1gina web como lo har\u00edas normalmente. El tr\u00e1fico pasar\u00e1 a trav\u00e9s del servidor remoto antes de llegar a su destino.    Recuerda que esta configuraci\u00f3n solo afectar\u00e1 las solicitudes hechas desde el navegador configurado. Otros programas o aplicaciones en tu equipo local no usar\u00e1n autom\u00e1ticamente este proxy a menos que se configuren para hacerlo. Para desactivar el proxy, simplemente revierte la configuraci\u00f3n en tu navegador web.</p> </li> </ol> <p>Ahora que ya tenemos el navegador preparado, vuelve al terminal con nuestro servidor Debian y ejecuta el comando de login.</p> <pre><code>$ heroku login\nheroku: Press any key to open up the browser to login or q to exit: \nOpening browser to https://cli-auth.heroku.com/auth/cli/browser/0f52dd14-45d0-4b9a-b891-565258097f92?requestor=SFMyNTY.g2gDbQAAAAw1NC44MC4yMTAuNTZuBgBoDInGigFiAAFRgA.Q5VcF-T9kPlbI2-EHpkyMlkodGeX2-RKdx1dBEFSlLA\nheroku: Waiting for login...\nLogging in... done\nLogged in as j.munozjimeno@edu.gva.es\n</code></pre> <p>Ver\u00e1s que te dice que est\u00e1 abriendo un \"browser\" para el login. Pero no lo hace. Simplemente copiaremos la URL y la pegaremos en nuestro navegador para loguearnos. Recuerda, tiene que ser el navegador que prepararmos antes. As\u00ed, la petici\u00f3n es como si la realizara nuestro server Debian a la web de autenticaci\u00f3n de Heroku. Si todo va bien nos permitir\u00e1 logernos con el usuario previamente creado.</p> <p>Antes de continuar, conviene asegurarnos de que tenemos la \u00faltima versi\u00f3n de git en nuestra Debian:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install git\n</code></pre> <p>Ahora, dentro del directorio que hab\u00edamos creado previamente para nuestra aplicaci\u00f3n, se trata de seguir unos sencillos pasos:</p> <p>Tip</p> <p>Aqu\u00ed aparece explicado con lenguaje llano m\u00e1s adelante en el m\u00f3dulo ya hablaremos con mayor propiedad de estas acciones con git</p> <ol> <li> <p>Nos aseguramos de que nuestro directorio no es a\u00fan un repositorio: <code>git status</code></p> <p>Y lo iniciamos: <code>git init</code></p> <p></p> </li> <li> <p>Ahora a\u00f1adimos todos los archivos presentes en el directorio (<code>.</code>) para ser enviados al repositorio: <code>git add .</code></p> <p>Y los preparamos para que sean envidos al repositorio: <code>git commit -m \"Comentario explicativo del commit\"</code></p> <p></p> </li> <li> <p>Creamos nuestra aplicaci\u00f3n en Heroku: <code>heroku create</code></p> <p></p> <p>Esto crear\u00e1 un git remoto que conectar\u00e1 con nuestro repositorio git local</p> </li> <li> <p>Desplegamos nuestra aplicaci\u00f3n en el server de Heroku : <code>git push heroku master</code></p> <p>Y comprobamos que la instancia est\u00e1 corriendo: <code>heroku ps:scale web=1</code></p> <p></p> <p></p> </li> <li> <p>El comando <code>heroku open</code> abrir\u00eda nuestra aplicaci\u00f3n en el navegador. Sin embargo, por el problema explicado antes de estar conectados por SSH, esto no ocurrir\u00e1. No obstante, podemos acceder a nuestra aplicaci\u00f3n de otra forma r\u00e1pida y sencilla desde nuestro dashboard de Heroku:</p> <ul> <li> <p>Localizamos nuestra aplicaci\u00f3n:</p> <p></p> </li> <li> <p>Y tras hacer click en ella, localizamos el bot\u00f3n que nos permite abrirla y volvemos a hacer click:</p> <p></p> </li> <li> <p>Comprobando que nuestra aplicaci\u00f3n, efectivametne se ha desplegado en Heroku y funciona a la perfecci\u00f3n:</p> <p></p> <p></p> </li> </ul> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/PV01-Heroku/#referencias","title":"Referencias","text":"<p>\u00bfQu\u00e9 es Github?</p> <p>\u00bfQu\u00e9 es Heroku?</p> <p>Deploying Node.js applications</p> <p>List of all limitations in Heroku platform</p> <ol> <li> <p>Septiembre 2023\u00a0\u21a9</p> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/","title":"Servidores de aplicaciones","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#introduccion","title":"Introducci\u00f3n","text":"<p>Un servidor de aplicaciones es una plataforma de software que tiene la capacidad de crear aplicaciones web y servirlas en un entorno de servidor. En esencia, act\u00faa como un intermediario entre el servidor web y la base de datos, permitiendo que las aplicaciones funcionen de manera eficiente.</p> <p></p> <p>Este servidor puede estar compuesto por varios componentes inform\u00e1ticos que trabajan juntos para admitir m\u00faltiples aplicaciones en la nube y basadas en la web. A menudo, se combina con un servidor web o incluso puede contener su propio servidor web, lo que lo convierte en un servidor de aplicaciones web. Su versatilidad le permite funcionar en conjunto con otros servidores de aplicaciones al mismo tiempo.</p> <p>Adem\u00e1s de su capacidad principal de servir aplicaciones web, los servidores de aplicaciones tambi\u00e9n pueden realizar otras tareas importantes, como procesamiento de transacciones, mensajer\u00eda, administraci\u00f3n de recursos y conexiones, y seguridad. Pueden incluir interfaces gr\u00e1ficas de usuario para su gesti\u00f3n y control, todo con el objetivo de hacer que las aplicaciones funcionen sin problemas y de manera segura.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#servidor-de-aplicaciones","title":"Servidor de aplicaciones","text":"<p>Las aplicaciones vienen en diversas formas y tama\u00f1os, y tienen una variedad de usos. En un mundo en el que confiamos en una serie de procesos comerciales cruciales, los servidores de aplicaciones son potentes sistemas inform\u00e1ticos que proporcionan recursos para que los usuarios y clientes web utilicen aplicaciones.</p> <p>Como mencionamos anteriormente, los servidores de aplicaciones se encuentran f\u00edsica o virtualmente entre los servidores de bases de datos, que almacenan los datos de las aplicaciones, y los servidores web que interact\u00faan con los clientes. Estos servidores de aplicaciones y el middleware relacionado son sistemas operativos que dan respaldo al desarrollo y la entrega de aplicaciones.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#terminologia-de-los-servidores-de-aplicaciones","title":"Terminolog\u00eda de los servidores de aplicaciones","text":"T\u00e9rmino Descripci\u00f3n Servidor web Responsable de almacenar, procesar y entregar los datos de E/S de las p\u00e1ginas web Cliente web Punto final que intenta acceder a los recursos de la web o de la aplicaci\u00f3n HTTPS Protocolo de comunicaci\u00f3n seguro entre el servidor web y los clientes web JSON Lenguaje para el intercambio entre los servidores web y de aplicaciones L\u00f3gica de negocio Reglas para el almacenamiento de datos y la transferencia de recursos de la aplicaci\u00f3n Aplicaci\u00f3n Un programa de software o un sitio web unido a una base de datos"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#el-papel-del-servidor-de-aplicaciones-en-la-arquitectura-de-servicios","title":"El papel del servidor de aplicaciones en la arquitectura de servicios","text":"<p>Cuando los usuarios de las aplicaciones, ya sea usuarios f\u00edsicos o los clientes web, solicitan acceso a una aplicaci\u00f3n, el servidor de aplicaciones suele hacer el trabajo pesado en el backend para almacenar y procesar las solicitudes din\u00e1micas de las aplicaciones.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#por-que-necesitamos-servidores-de-aplicaciones","title":"\u00bfPor qu\u00e9 necesitamos servidores de aplicaciones?","text":"<p>Cada d\u00eda, miles de millones de usuarios web realizan peticiones HTTP, esperando un acceso instant\u00e1neo a diversas aplicaciones. Ya sea meditando con Headspace por la ma\u00f1ana, trabajando en un informe extenso en Google Docs o consultando Twitter durante la pausa para el caf\u00e9, todas estas aplicaciones se ejecutan en un servidor de aplicaciones y se entregan a trav\u00e9s de un servidor web.</p> <p>Los servidores web tienen la responsabilidad de atender las solicitudes HTTP/HTTPS de los usuarios web y proporcionar respuestas HTTP/HTTPS. A diferencia de los servidores de aplicaciones, los servidores web est\u00e1n dise\u00f1ados para manejar solicitudes de datos est\u00e1ticos de varios sitios web de manera eficiente y segura. Sin embargo, cuando se trata de solicitudes din\u00e1micas, como las generadas por aplicaciones, a menudo se necesita asistencia adicional.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#los-servidores-de-aplicaciones-optimizan-el-trafico-y-anaden-seguridad","title":"Los servidores de aplicaciones optimizan el tr\u00e1fico y a\u00f1aden seguridad","text":"<p>Para lograr un rendimiento \u00f3ptimo del servidor web, no es suficiente con manejar las solicitudes HTTP de los clientes web y gestionar los recursos de varios sitios web al mismo tiempo. Los servidores de aplicaciones llenan este vac\u00edo con un dise\u00f1o de alta potencia dise\u00f1ado espec\u00edficamente para manejar las solicitudes de contenido web din\u00e1mico.</p> <p>Adem\u00e1s, los servidores de aplicaciones proporcionan redundancia software y una capa adicional de seguridad. Al estar ubicados entre una base de datos y un servidor web, facilitan la tarea de preservar y duplicar la arquitectura de la aplicaci\u00f3n a trav\u00e9s de la red. </p> <p></p> <p>Este paso adicional entre las posibles comunicaciones web maliciosas y los datos cr\u00edticos en el servidor de base de datos agrega una capa de seguridad adicional. Adem\u00e1s, dado que los servidores de aplicaciones pueden procesar solicitudes relacionadas con la l\u00f3gica empresarial, se vuelve mucho m\u00e1s dif\u00edcil llevar a cabo un intento de inyecci\u00f3n SQL.</p> <p>Las organizaciones pueden aumentar a\u00fan m\u00e1s la protecci\u00f3n de sus datos utilizando un servidor proxy inverso colocado frente a sus bases de datos. Los servidores proxy y las VPN son herramientas efectivas para anonimizar y cifrar las comunicaciones, lo que protege tanto a los usuarios como los datos empresariales.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#como-funcionan-los-servidores-de-aplicaciones","title":"\u00bfC\u00f3mo funcionan los servidores de aplicaciones?","text":"<p>Pongamos como ejemplo un servidor de aplicaciones Java.</p> <p>\u00bfQu\u00e9 son los servlets?</p> <p>Un servlet es un programa Java que se ejecuta en un servidor Web y construye o sirve p\u00e1ginas web. De esta forma se pueden construir p\u00e1ginas din\u00e1micas, basadas en diferentes fuentes variables: datos proporcionados por el usuario, fuentes de informaci\u00f3n variable (p\u00e1ginas de noticias, por ejemplo), o programas que extraigan informaci\u00f3n de bases de datos.</p> <p>Comparado con un CGI, un servlet es m\u00e1s sencillo de utilizar, m\u00e1s eficiente (se arranca un hilo por cada petici\u00f3n y no un proceso entero), m\u00e1s potente y portable. Con los servlets podremos, entre otras cosas, procesar, sincronizar y coordinar m\u00faltiples peticiones de clientes, reenviar peticiones a otros servlets o a otros servidores.</p> <p>Como la mayor\u00eda de los servidores de hoy en d\u00eda, los servidores de aplicaciones contienen caracter\u00edsticas de seguridad, transacciones, servicios, clustering, diagn\u00f3sticos y bases de datos. En lo que se diferencian los servidores de aplicaciones es en su capacidad para procesar peticiones de servlets (programas Java) desde un servidor web.</p> <p>En la imagen siguiente, se muestra el flujo general de los servidores de aplicaciones web:</p> <ol> <li>El cliente abre un navegador y solicita acceso a un sitio web</li> <li>El servidor web recibe la petici\u00f3n HTTP y responde con la p\u00e1gina web deseada</li> <li>El servidor web gestiona las peticiones de datos est\u00e1ticos, pero el cliente quiere utilizar una herramienta interactiva</li> <li>Al tratarse de una petici\u00f3n de datos din\u00e1micos, el servidor web transfiere la petici\u00f3n a un servidor de aplicaciones</li> <li>El servidor de aplicaciones recibe la petici\u00f3n HTTP y la convierte en una petici\u00f3n de servlet</li> <li>El servlet llega al servidor de la base de datos, y el servidor de aplicaciones recibe una respuesta del servlet</li> <li>El servidor de aplicaciones traduce la respuesta del servlet al formato HTTP para el acceso del cliente</li> </ol> <p></p> <p>Al recibir una solicitud de servlet de un servidor web, el servidor de aplicaciones procesa la solicitud y responde al servidor web mediante la respuesta de servlet. Dado que los servidores de aplicaciones trabajan principalmente con peticiones de l\u00f3gica de negocio, el servidor web traduce la respuesta del servlet y pasa una respuesta HTTP accesible para el usuario.</p> Servidor de aplicaciones Servidor web Dise\u00f1ado para Sirve peticiones HTTP y de otra l\u00f3gica de negocio Sirve peticiones HTTP Almacena y proporciona L\u00f3gica de negocio Contenido web est\u00e1tico La utilizaci\u00f3n de los recursos es Pesada Ligera Soporta Transacciones distribuidas y Enterprise JavaBeans (EJB) Servlets, Java Server Pages (JSP) y JSON"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#servidores-de-aplicaciones-en-la-decada-de-2020","title":"Servidores de aplicaciones en la d\u00e9cada de 2020","text":"<p>El mercado de servidores de aplicaciones espera crecer a una tasa de crecimiento anual compuesto CAGR del 13,2%, aumentando de casi 17 mil millones de d\u00f3lares en 2020 a 41 mil millones de d\u00f3lares en 2026. Este crecimiento continuo no es sorprendente, ya que la conectividad a Internet y la dependencia de las aplicaciones siguen aumentando.</p> <p>La migraci\u00f3n a plataformas y servicios en la nube y el auge de los dispositivos IoT son dos impulsores clave en el mercado moderno de infraestructura y middleware de aplicaciones. A esto se suma un movimiento hacia pol\u00edticas de BYOD (Bring Your Own Device) y una fuerza laboral remota que depende de una mayor conectividad y eficiencia operativa.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#servidores-de-aplicaciones-el-mejor-amigo-de-un-servidor-web","title":"Servidores de aplicaciones: El mejor amigo de un servidor web","text":"<p>Los servidores de aplicaciones son esenciales para satisfacer las demandas de interconexi\u00f3n de hoy en d\u00eda. Las empresas est\u00e1n, en \u00faltima instancia, atentas a los intereses de los clientes y, sin una conexi\u00f3n escalable y estable a los recursos de la aplicaci\u00f3n, los clientes modernos pueden abandonar el barco.</p> <p>Los servidores de aplicaciones desempe\u00f1an el papel de conector y mejor aliado para los servidores web. Cuando los servidores web tienen una solicitud de cliente que es demasiado pesada, los servidores de aplicaciones hacen posible mantener una comunicaci\u00f3n fluida con contenido web din\u00e1mico.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T01/#referencias","title":"Referencias","text":"<ul> <li> <p>What is an application server? (I)</p> </li> <li> <p>What is an application server? (II)</p> </li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/","title":"Despliegue de aplicaciones web","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#que-es-el-despliegue-de-aplicaciones-web","title":"\u00bfQu\u00e9 es el despliegue de aplicaciones web?","text":"<p>El despliegue en el desarrollo de software y web significa pasar los cambios o actualizaciones de un entorno de funcionamiento a otro. Al configurar un sitio web, siempre se tendr\u00e1 el sitio web en vivo, que se llama el entorno en vivo o entorno de producci\u00f3n.</p> <p>Si se quiere tener la capacidad de hacer cambios sin afectar a un sitio web en producci\u00f3n, se puede (y se debe) a\u00f1adir entornos adicionales. Estos entornos se llaman entornos de desarrollo o entornos de despliegue. Los entornos de desarrollo adicionales suelen ser un entorno local, un entorno de desarrollo y un entorno de preparaci\u00f3n o preproducci\u00f3n. El n\u00famero de entornos que se necesitan depende de cada caso y de la complejidad del proyecto en el que se est\u00e9 trabajando.</p> <p>Aunque los modelos de despliegue pueden variar, el m\u00e1s com\u00fan es el cl\u00e1sico modelo de despliegue \"de izquierda a derecha\" cuando se trabaja con m\u00faltiples entornos de despliegue. En este modelo, los cambios se realizan en entornos locales, de desarrollo o de preparaci\u00f3n (dependiendo de la configuraci\u00f3n) y se van pasando de izquierda a derecha a trav\u00e9s de los diferentes entornos, terminando en el de producci\u00f3n.</p> <p>Una vez completado este proceso de despliegue, los nuevos cambios ser\u00e1n visibles en el entorno activo.</p> <p></p> <p>En la imagen anterior se muestra una forma muy simplificada y cl\u00e1sica de manejar los despliegues cuando se trabaja con sitios web. No necesariamente se necesitan todos los entornos anteriores, pero el proceso sigue siendo el mismo.</p> <p>Al utilizar m\u00faltiples entornos se obtiene una lista de ventajas; la principal es que se pueden hacer cambios sin que afecten a su sitio web en vivo. Una vez que los cambios se hacen, se prueban y est\u00e1n listos para ser pasados a producci\u00f3n, el proceso de despliegue se encarga del resto.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#de-que-pasos-consta-el-proceso-despliegue","title":"\u00bfDe qu\u00e9 pasos consta el proceso despliegue?","text":"<p>El flujo del proceso de despliegue consta de 5 pasos: Planificaci\u00f3n, desarrollo, pruebas, despliegue y supervisi\u00f3n.</p> <p>A continuaci\u00f3n nos adentraremos en cada uno de los 5 pasos, pero antes una nota r\u00e1pida.</p> <p>El flujo del proceso de despliegue que aparece a continuaci\u00f3n cubre los aspectos b\u00e1sicos, que se dividen en 5 pasos. Esto no significa que sea la \u00fanica manera de hacerlo. Podr\u00eda haber un proceso mejor para cada caso. Es una simplificaci\u00f3n para cubrir las partes m\u00e1s importantes.</p> <ol> <li> <p>Recordar tener un plan de despliegue de software</p> <p>Para asegurarse de que el proceso de despliegue se desarrolle con la mayor fluidez posible, lo mejor es tener un plan de despliegue que se siga en todo momento. Al tener un plan nos aseguramos de que todo se haga de la misma manera cada vez que se realicen cambios. Esto es especialmente \u00fatil cuando varios usuarios trabajan en el mismo proyecto.</p> <p>Un plan de despliegue debe incluir reglas sobre cu\u00e1ndo desplegar desde los entornos locales a los sitios de desarrollo o de pre-producci\u00f3n, as\u00ed como horarios para cuando los nuevos cambios pueden ir a un entorno de producci\u00f3n. Al tener un plan establecido, se reduce el riesgo de conflictos entre los diferentes cambios y se asegura que el proceso de despliegue sea lo m\u00e1s f\u00e1cil y fluido posible. Si se est\u00e1 trabajando en un proyecto de c\u00f3digo abierto, tambi\u00e9n da la oportunidad de hacer Release Candidates y dejar que la comunidad lo pruebe para detectar cualquier error que se pueda haber pasado por alto.</p> <p>Adem\u00e1s de un plan general, tambi\u00e9n es importante planificar cada uno de los cambios que se vaya a realizar. Este proceso ser\u00e1 muy r\u00e1pido para los cambios menores, pero deber\u00eda ser mucho m\u00e1s extenso para los grandes cambios. Si se planifica con mucha antelaci\u00f3n, se estar\u00e1 mucho m\u00e1s preparado para tener un proceso de despliegue sin problemas.</p> </li> <li> <p>El desarrollo propiamente dicho</p> <p>Una vez que se tenga el plan en marcha, es el momento de realizar el desarrollo real. Para garantizar que cualquier desarrollo pueda realizarse simult\u00e1neamente y sin romper nada, es importante trabajar \u00fanicamente en entornos locales o de desarrollo. Una vez que el proceso de desarrollo est\u00e1 hecho, es el momento de empezar a probar y desplegar los cambios a trav\u00e9s de la configuraci\u00f3n de su entorno.</p> </li> <li> <p>Probar los cambios</p> <p>Probar los cambios es crucial para garantizar que no haya errores en el entorno de producci\u00f3n final. Pero las pruebas no pueden completarse sin desplegar los cambios en nuevos entornos. </p> <p>Una vez que se haya comprobado que todos los cambios funcionan en el entorno local o de desarrollo, es el momento de desplegar los cambios en el siguiente entorno. Esto debe hacerse hasta el entorno de preproducci\u00f3n, donde se deben realizar las pruebas finales de control de calidad. Si todo est\u00e1 correctamente probado y funciona en un entorno parecido al entorno real, es el momento de desplegarlo en producci\u00f3n.</p> <p>Si se descubren errores por el camino en cualquier entorno, es importante tener un plan para manejarlos. Por lo general, cualquier cambio que no pase las pruebas en el entorno de pre-producci\u00f3n debe ser enviado de nuevo a la fase de desarrollo y -una vez corregido- volver a trabajar en los entornos siguientes.</p> </li> <li> <p>Desplegar los cambios en el entorno de producci\u00f3n</p> <p>Una vez que se han realizado todas las pruebas en los entornos anteriores y se han corregido los errores, es el momento de desplegar los cambios en el entorno de producci\u00f3n. Esto deber\u00eda ser algo bastante seguro, pero todos los que han trabajado en el desarrollo de software saben que algo puede salir mal.</p> <p>As\u00ed que, aunque es f\u00e1cil detenerse aqu\u00ed, es importante incluir el \u00faltimo paso del proceso: la monitorizaci\u00f3n.</p> </li> <li> <p>Supervisar los cambios</p> <p>Una vez que los nuevos cambios est\u00e9n en marcha y los usuarios reales utilicen activamente el sitio web o la aplicaci\u00f3n, es importante supervisar que todo funcione seg\u00fan lo previsto. Independientemente de la planificaci\u00f3n realizada, existe la posibilidad de que los usuarios se encuentren con problemas o realicen acciones que usted no hab\u00eda previsto durante la planificaci\u00f3n y el desarrollo.</p> <p>Un buen consejo para la monitorizaci\u00f3n es planificar los lanzamientos para los momentos en los que la menor cantidad de usuarios lo noten y en los que se tengan recursos de desarrollo listos en caso de que haya que arreglar algo. De este modo, el n\u00famero de usuarios afectados por cualquier error ser\u00e1 m\u00ednimo y se tendr\u00e1 gente preparada para arreglarlo o revertir los cambios si es necesario. </p> <p>Si se han de revertir los cambios, es importante mantener la calma y tener un proceso para manejarlo con la misma minuciosidad con la que se manejan los despliegues.</p> </li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#diferentes-tipos-de-despliegue","title":"Diferentes tipos de despliegue","text":"<p>Cuando se trata del tipo de despliegue, a menudo se divide en dos partes. Por lo general, se dividir\u00e1 entre metadatos y contenido, ya que estos tienen diferentes impactos en un nuevo entorno y deben ser manejados de manera diferente.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#despliegue-de-metadatos","title":"Despliegue de metadatos","text":"<p>Los metadatos incluyen los cambios en el c\u00f3digo, las plantillas, las hojas de estilo, los archivos, etc. Estos cambios a menudo requerir\u00e1n una comprobaci\u00f3n de validaci\u00f3n entre entornos para ver si tiene alg\u00fan conflicto imprevisto que deba resolverse. Muchas herramientas de despliegue incluyen comprobaciones de coherencia y ayudan a guiarte en caso de conflictos.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#despliegue-de-contenidos","title":"Despliegue de contenidos","text":"<p>El contenido, como el texto, las im\u00e1genes y los v\u00eddeos, se maneja de forma diferente durante el despliegue, ya que es menos complicado moverlo entre entornos que los metadatos. Por esa raz\u00f3n, a menudo ver\u00e1s que las herramientas de despliegue hacen que el despliegue de contenido sea accesible para los editores de contenido y no s\u00f3lo para los desarrolladores. De esta manera, un editor de contenidos no depende de un desarrollador cuando se trata de enviar nuevos contenidos a un entorno activo.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#mejores-practicas-de-despliegue","title":"Mejores pr\u00e1cticas de despliegue","text":"<p>Cuando se trabaja con entornos de despliegue, es importante, como se ha mencionado anteriormente, tener un plan y un proceso claro para ello en el equipo. Para ampliar ese proceso hemos reunido algunas mejores pr\u00e1cticas que son buenas para implementar como parte de su proceso.</p> <p>Se ha de tener en cuenta que las siguientes pr\u00e1cticas recomendadas se refieren principalmente al desarrollo de software y de la web. Si  se est\u00e1n llevando a cabo otros tipos de desarrollo puede haber otras cosas a considerar en el flujo de trabajo de despliegue.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#utilizar-git","title":"Utilizar Git","text":"<p>Esto puede parecer obvio, pero tener un sistema de control de versiones es inestimable para cualquier flujo de trabajo de despliegue. Sin \u00e9l, es probable que se produzcan errores si se trabaja en equipo.</p> <p>Incluso si eres el \u00fanico desarrollador que trabaja en un proyecto, es muy recomendable utilizar Git en caso de que necesites volver a versiones anteriores o si alguien nuevo se une a tu equipo.</p> <p>Sin Git ser\u00e1 dif\u00edcil asegurar la consistencia en el flujo de trabajo de despliegue y puede llevar a que se cometan m\u00e1s errores por desplegar c\u00f3digo inacabado o por no tener a todos los miembros del equipo trabajando en la misma versi\u00f3n del c\u00f3digo.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#trabajar-en-ramas","title":"Trabajar en ramas","text":"<p>Como regla general, tu equipo deber\u00eda trabajar en ramas. Hacerlo as\u00ed permitir\u00e1 trabajar en varias cosas al mismo tiempo sin que se afecten entre s\u00ed.</p> <p>Un ejemplo es cuando se encuentra un error que debe ser corregido. Si un desarrollador est\u00e1 utilizando una rama para trabajar en una nueva caracter\u00edstica, puede hacer r\u00e1pidamente una nueva rama del entorno de desarrollo para trabajar en el error. De este modo, habr\u00e1 dos ramas diferentes que no chocar\u00e1n ni crear\u00e1n posibles conflictos de fusi\u00f3n m\u00e1s adelante.</p> <p>Trabajar con ramas tambi\u00e9n ayuda al equipo con las preguntas y respuestas a la hora de desplegar en un entorno de preproducci\u00f3n. Tener los cambios en ramas separadas y fusionarlas dar\u00e1 a los testers una mejor visi\u00f3n de lo que se \"empuj\u00f3\" (se hizo push) y lo que deben probar.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#utilizar-un-entorno-local-como-entorno-de-desarrollo","title":"Utilizar un entorno local como entorno de desarrollo","text":"<p>Aunque es posible trabajar directamente en un entorno de desarrollo, en la mayor\u00eda de los casos se ahorrar\u00e1 mucho tiempo trabajando localmente. Al instalar el sitio web o el software de forma local, se podr\u00e1 trabajar de forma m\u00e1s eficiente y acelerar las pruebas y la verificaci\u00f3n del c\u00f3digo.</p> <p>En primer lugar, no hay que confirmar, empujar y desplegar constantemente un cambio antes de poder verificar si funciona. Y cuando algo no funciona (esto nos pasa a todos) tendr\u00e1s que revertirlo, empujarlo de nuevo y volver a desplegarlo.</p> <p>En lugar de eso, puedes simplemente ejecutarlo todo localmente y, una vez que funcione como es debido, puedes empujarlo directamente al entorno de pre-producci\u00f3n para una prueba m\u00e1s rigurosa. </p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#revisar-las-diferencias-antes-de-desplegarlo-en-el-entorno-real","title":"Revisar las diferencias antes de desplegarlo en el entorno real","text":"<p>Una vez que el equipo de pruebas se haya asegurado de que todo funciona en el entorno de pruebas, es el momento de desplegar el c\u00f3digo en el entorno real. </p> <p>Pero antes de hacer el despliegue final, es importante hacer una revisi\u00f3n final de las diferencias entre el entorno actual en producci\u00f3n y el entorno de desarrollo del que se parte. </p> <p>Incluso despu\u00e9s de las pruebas exhaustivas y la garant\u00eda de calidad, las cosas pueden ir mal tan pronto como se llega al entorno real. Y una vez que eso sucede, a menudo puede ser muy estresante implementar correcciones r\u00e1pidas o hacer una reversi\u00f3n completa de la versi\u00f3n. Por lo general, se querr\u00e1 evitar esto a toda costa, por lo que es muy recomendable hacer una revisi\u00f3n final del c\u00f3digo antes de pulsar el bot\u00f3n de despliegue.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#considerar-tener-grupos-de-usuarios-con-diferentes-permisos","title":"Considerar tener grupos de usuarios con diferentes permisos","text":"<p>Mientras que cualquier desarrollador debe ser capaz de empujar los cambios a los entornos de test, puede ser una buena idea restringir qui\u00e9n puede desplegarlos en vivo.</p> <p>Para equipos peque\u00f1os, esto puede no tener mucho sentido, ya que puede crear un cuello de botella para implantar nuevos cambios. Pero si se trata de un equipo m\u00e1s grande con un nivel de experiencia muy variado entre los miembros del equipo, puede ser una gran idea dejar que s\u00f3lo los desarrolladores senior desplieguen en el entorno de producci\u00f3n.</p> <p>Esto asegura efectivamente un mayor nivel de control sobre el flujo de \"releases\" y tambi\u00e9n significa que al menos un par de ojos senior han visto lo que est\u00e1 pasando en el entorno real. Si lo que se tiene es un enfoque muy iterativo con lanzamientos r\u00e1pidos como el utilizado en la metodolog\u00eda CD (Continous Delivery), esto podr\u00eda ralentizarlo todo demasiado. Aun as\u00ed, dado que los cambios que se empujan son normalmente m\u00e1s peque\u00f1os con este enfoque, probablemente no se sufrir\u00e1n grandes retrasos. Y si significa detectar algunos errores m\u00e1s, el tiempo que se ahorra al no tener que corregir errores compensar\u00e1 el tiempo invertido.</p> <p>Hablando de romper cosas...</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#mantener-la-calma-incluso-si-algo-se-rompe","title":"Mantener la calma, incluso si algo se rompe","text":"<p>Acabas de desplegar en tu entorno de producci\u00f3n y ahora tu sitio web est\u00e1 roto. Menuda liada, \u00bfahora qu\u00e9 se hace?</p> <p>Desgraciadamente, estas cosas ocurren - no importa lo cuidadoso que se sea. Pero en lugar de entrar en p\u00e1nico y aplicar hotfixes o retroceder inmediatamente, es importante mantener la calma y asegurarse de que lo que est\u00e1 haciendo no va a romper las cosas a\u00fan m\u00e1s.</p> <p>En primer lugar, se deber\u00eda comprobar si es posible realizar una reversi\u00f3n o rollback y si realmente se arreglar\u00eda algo. En algunas situaciones, es posible que se hayan hecho cambios que son irreversibles y un rollback s\u00f3lo causar\u00eda problemas a\u00fan mayores.</p> <p>Tambi\u00e9n hay que comprobar si lo que se ha roto es una caracter\u00edstica existente o nueva. De nuevo, si la cosa que se rompi\u00f3 no era parte de la nueva versi\u00f3n, probablemente no servir\u00e1 de nada hacer un rollback.</p> <p>As\u00ed que en lugar de entrar en p\u00e1nico, se debe tener un plan preparado y respirar hondo antes de ponerse a trabajar en la b\u00fasqueda de una soluci\u00f3n. Puede parecer sencillo, pero puede ayudar a salir de una mala situaci\u00f3n mucho m\u00e1s r\u00e1pido que lanz\u00e1ndose directamente.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#a-que-hora-del-dia-se-deben-desplegar-los-cambios","title":"\u00bfA qu\u00e9 hora del d\u00eda se deben desplegar los cambios?","text":"<p>En caso de que algo se rompa al desplegar en el entorno de producci\u00f3n, es importante encontrar el mejor momento para hacerlo. Y aunque este momento var\u00eda mucho de un proyecto a otro, hay dos preguntas que pueden hacerse para determinar cu\u00e1ndo desplegar los cambios:</p> <ol> <li>\u00bfCu\u00e1ndo tiene la menor cantidad de usuarios activos?</li> <li>\u00bfCu\u00e1ndo tiene a alguien preparado para supervisar y solucionar los problemas despu\u00e9s del despliegue?</li> </ol>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#cuando-tiene-el-menor-numero-de-usuarios-activos","title":"\u00bfCu\u00e1ndo tiene el menor n\u00famero de usuarios activos?","text":"<p>Por lo general, lo que se quiere es que el menor n\u00famero posible de personas se vea afectado por sus nuevos cambios. Por lo tanto, como regla general, debe buscar cualquier momento del d\u00eda en el que el menor n\u00famero de usuarios est\u00e9 utilizando activamente el sitio web o software.</p> <p>En el caso de los sitios web, esto puede hacerse consultando las herramientas de an\u00e1lisis de datos que se tengan en marcha, por ejemplo, Google Analytics. All\u00ed se podr\u00e1n crear informes personalizados que muestren a qu\u00e9 hora del d\u00eda se  tiene menos tr\u00e1fico, as\u00ed como identificar las horas punta en las que definitivamente no se deber\u00eda hacer ning\u00fan cambio.</p> <p>Adem\u00e1s de mirar la hora del d\u00eda, tambi\u00e9n puede valer la pena mirar c\u00f3mo se reparte la actividad de los usuarios entre los d\u00edas de la semana. </p> <p>Este an\u00e1lisis es muy bueno, pero a menudo acabar\u00e1 con la misma respuesta: Deber\u00edan publicarse los cambios durante la noche. Y aunque esto podr\u00eda parecer una gran idea si s\u00f3lo nos fij\u00e1ramos en esta cuesti\u00f3n, es importante que tambi\u00e9n tengamos en cuenta la siguiente.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#hay-alguien-despierto-y-preparado-para-solucionar-posibles-problemas-en-ese-momento","title":"\u00bfHay alguien despierto y preparado para solucionar posibles problemas en ese momento?","text":"<p>Si la respuesta es no, entonces desplegar los cambios en mitad de la noche podr\u00eda no ser la mejor idea.</p> <p>En su lugar, se deber\u00edan identificar las franjas horarias en las que puedas encontrar el mejor equilibrio entre el n\u00famero de usuarios activos y los desarrolladores dispuestos a solucionar los problemas. Esto variar\u00e1 mucho dependiendo del proyecto y del equipo, pero en general, se deber\u00edan encontrar algunas opciones. Y si ya se tiene un horario fijo de despliegue, incluso puede convencerse al equipo de que est\u00e9 listo a horas extra\u00f1as del d\u00eda. Es mucho m\u00e1s f\u00e1cil convencer a alguien de que venga unas horas antes si sabe que s\u00f3lo ocurre una vez cada ciclo o sprint. </p> <p>Es por este motivo que en muchas empresas se trabaja con guardias rotativas para ofrecer una disponibilidad total.</p> <p>Y no menos importante, \u00bfcu\u00e1nto tiempo tiene el equipo por delante para solucionar los problemas? Si planificamos un despliegue una hora antes del cierre de las oficinas un viernes por la tarde, aunque tengamos a todo el equipo listo para solucionar posibles errores, la presi\u00f3n del tiempo restante puede ser contraproducente.</p> <p>Info</p> <p>Aunque no hay un momento perfecto para el despliegue, definitivamente hay momentos que son mejores que otros.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#cuales-son-las-ventajas-del-despliegue-utilizando-multiples-entornos","title":"\u00bfCu\u00e1les son las ventajas del despliegue utilizando m\u00faltiples entornos?","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#reduccion-del-riesgo-de-romper-un-sitio-web-en-produccion","title":"Reducci\u00f3n del riesgo de romper un sitio web en producci\u00f3n","text":"<p>Una de las principales razones para utilizar m\u00faltiples entornos y confiar en el despliegue es reducir el riesgo de que los cambios tengan un impacto negativo en un sitio web en vivo. Mientras que los cambios menores se pueden hacer f\u00e1cilmente directamente en un sitio web en vivo, los cambios m\u00e1s grandes se pueden hacer en entornos separados sin el riesgo de romper nada en el entorno en vivo.</p> <p>Tener varios usuarios trabajando en el mismo sitio web tambi\u00e9n garantiza que nadie se arriesgue a romper algo debido a los cambios de otro usuario.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#ahorro-de-tiempo","title":"Ahorro de tiempo","text":"<p>Sin la preocupaci\u00f3n de romper algo en un sitio web en vivo, se pueden realizar los cambios en el orden que se prefiera. Esto significa que se puede optimizar el flujo de trabajo para realizar los cambios sin tener en cuenta el aspecto o el funcionamiento del sitio web mientras se lleva a cabo.</p> <p>Si se trabaja en un entorno local tambi\u00e9n existe la ventaja de que los cambios se procesan m\u00e1s r\u00e1pido y no hay dependencias de ning\u00fan problema de conectividad.</p> <p>A la hora de desplegar los cambios, tambi\u00e9n se ahorrar\u00e1 tiempo, ya que se podr\u00e1n realizar todos los cambios al mismo tiempo en lugar de tener que hacerlo en varios pasos m\u00e1s peque\u00f1os.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#el-contenido-sensible-al-tiempo-es-mas-facil-de-gestionar","title":"El contenido sensible al tiempo es m\u00e1s f\u00e1cil de gestionar","text":"<p>Si se est\u00e1n llevando a cabo campa\u00f1as que son sensibles al tiempo y que s\u00f3lo pueden ponerse en marcha a partir de un determinado d\u00eda u hora, entonces la ejecuci\u00f3n de m\u00faltiples entornos y el uso del despliegue pueden ahorrar una gran cantidad de estr\u00e9s.</p> <p>Al crear todo el contenido en un entorno de pre-producci\u00f3n puedes terminar tu campa\u00f1a sin preocuparte de que sea visible para tus usuarios. Y cuando llegue el momento de lanzarla, podr\u00e1 hacerla visible en muy poco tiempo despleg\u00e1ndola en su entorno real.</p> <p>Y si la herramienta de despliegue incluye roles de usuario con configuraci\u00f3n de permisos, es posible que un editor de contenidos haga todo esto -incluyendo el despliegue de los cambios- sin involucrar a un desarrollador en el proceso.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T02/#referencias","title":"Referencias","text":"<p>What is deployment in software and web development</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/","title":"Despliegue de aplicaciones Java y JavaScript","text":"<p>Dos de los lenguajes m\u00e1s utilizados en el despliegue de aplicaciones web son Java y JavaScript, que si bien comparten un nombre similar, son lenguajes completamente diferentes, tanto en prop\u00f3sito como en implementaci\u00f3n, y esto tambi\u00e9n afecta c\u00f3mo se manejan a la hora de hacer un despliegue de aplicaciones.</p> <p>Diferencias clave:</p> <ul> <li>Naturaleza del lenguaje:<ul> <li>Java: Lenguaje compilado y orientado a objetos. Se utiliza para crear aplicaciones robustas y multiplataforma (backend, aplicaciones m\u00f3viles, software de escritorio, etc.).</li> <li>JavaScript: Lenguaje interpretado y basado en eventos. Es principalmente usado en el desarrollo web (frontend y, cada vez m\u00e1s, en el backend con Node.js).</li> </ul> </li> <li>Ejecuci\u00f3n:<ul> <li>Java: Necesita la M\u00e1quina Virtual de Java (JVM) para ejecutarse, lo que permite su portabilidad (\"escribe una vez, ejecuta en cualquier lugar\").</li> <li>JavaScript: Se ejecuta directamente en navegadores web o en entornos como Node.js.</li> </ul> </li> <li>Casos de uso principales:<ul> <li>Java: Backend de aplicaciones empresariales, sistemas Android, aplicaciones de escritorio.</li> <li>JavaScript: Interactividad en p\u00e1ginas web, aplicaciones frontend (React, Angular) y backend ligero con Node.js.</li> </ul> </li> </ul> <p>Diferencia en el despliegue de aplicaciones:</p> <ul> <li> <p>Java: </p> <ul> <li>Las aplicaciones en Java generalmente se compilan a bytecode, formato binario no espec\u00edfico de ning\u00fan sistema operativo que luego es ejecutado por la JVM.</li> <li>Desplegar una aplicaci\u00f3n Java suele implicar:<ul> <li>Generar un archivo .jar (Java ARchive) o .war (Web ARchive).</li> <li>Configurar un servidor de aplicaciones compatible con Java, como Tomcat.</li> <li>Garantizar que la m\u00e1quina donde se despliega tenga una JVM adecuada.</li> </ul> </li> </ul> </li> <li> <p>JavaScript: </p> <ul> <li>En el caso de aplicaciones web, los archivos JavaScript (junto con HTML y CSS) se despliegan directamente en un servidor web (como Apache o Nginx) y se sirven al navegador.</li> <li>Para aplicaciones backend con Node.js, se despliega el c\u00f3digo fuente y se ejecuta con el entorno Node.js instalado en el servidor.</li> <li>El despliegue puede implicar herramientas como Webpack (para empaquetar y optimizar archivos), y servicios como Vercel, Netlify o Docker para aplicaciones modernas.</li> </ul> </li> </ul> <p>En este tema veremos c\u00f3mo desplegar aplicaciones Java sobre un servidor Tomcat y tambi\u00e9n como desplegar aplicaciones JavaScript con Node.js.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#despliegue-de-aplicaciones-java","title":"Despliegue de aplicaciones Java","text":"<p>En los apartados anteriores hemos visto, en t\u00e9rminos generales, qu\u00e9 es un servidor de aplicaciones y un despliegue de aplicaciones web. Ahora vamos a centrarnos en un caso concreto, las aplicaciones Java.</p> <p>En el lado del servidor, tenemos que conseguir que nuestro servidor HTTP sea capaz de ejecutar programas de aplicaci\u00f3n que recojan los par\u00e1metros de peticiones del cliente, los procesen y devuelvan al servidor un documento que \u00e9ste pasar\u00e1 a su vez al cliente.</p> <p>As\u00ed, para el cliente el servidor no habr\u00e1 hecho nada distinto a lo estipulado en el protocolo HTTP, pero el servidor podr\u00e1 valerse de herramientas externas para procesar y servir la petici\u00f3n solicitada, pudiendo as\u00ed no limitarse a servir p\u00e1ginas est\u00e1ticas, sino utilizar otras aplicaciones (servlets, JSP...) para servir documentos con contenido din\u00e1mico.</p> <p>Los programas de aplicaci\u00f3n son t\u00edpicamente programas que realizan consultas a bases de datos, procesan la informaci\u00f3n resultante y devuelven la salida al servidor, entre otras tareas.</p> <p>Vamos a centrarnos en las aplicaciones web JavaEE, en las que los componentes din\u00e1micos que recibir\u00e1n las peticiones HTTP en el servidor ser\u00e1n los servlets y JSPs. Estos componentes podr\u00e1n analizar esta petici\u00f3n y utilizar otros componentes Java para realizar las acciones necesarias (beans, EJBs, etc).</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#estructura-de-una-aplicacion-java","title":"Estructura de una aplicaci\u00f3n Java","text":"<p>Una aplicaci\u00f3n web JavaEE que utilice servlets o p\u00e1ginas JSP debe tener una estructura de ficheros y directorios determinada:</p> <ul> <li> <p>En el directorio ra\u00edz de la aplicaci\u00f3n se colocan las p\u00e1ginas HTML o JSP (podemos dividirlas tambi\u00e9n en directorios si queremos)</p> </li> <li> <p>Colgando del directorio inicial de la aplicaci\u00f3n, se tiene un directorio WEB-INF, que contiene la informaci\u00f3n Web relevante para la aplicaci\u00f3n.</p> </li> <li> <p>El resto de elementos de la aplicaci\u00f3n (im\u00e1genes, etc), podemos estructurarlos como nos convenga.</p> </li> </ul> <p></p> <p>Esta estructura estar\u00e1 contenida dentro de alg\u00fan directorio, que ser\u00e1 el directorio correspondiente a la aplicaci\u00f3n Web, y que podremos, si lo hacemos convenientemente, copiar en el servidor que queramos. Es decir, cualquier servidor Web JavaEE soporta esta estructura en una aplicaci\u00f3n Web, s\u00f3lo tendremos que copiarla en el directorio adecuado de cada servidor.</p> <p>Cada aplicaci\u00f3n web JavaEE es un contexto, una unidad que comprende un conjunto de recursos, clases Java y su configuraci\u00f3n. Cuando hablemos de contexto, nos estaremos refiriendo a la aplicaci\u00f3n web en conjunto.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#empaquetamiento","title":"Empaquetamiento","text":"<p>Una forma de distribuir aplicaciones Web es empaquetar toda la aplicaci\u00f3n (a partir de su directorio inicial) dentro de un fichero WAR (de forma parecida a como se hace con un TAR o un JAR), y distribuir dicho fichero. Podemos crear un fichero WAR de la misma forma que creamos un JAR, utilizando la herramienta JAR.</p> <p>Estos ficheros WAR son un est\u00e1ndar de JavaEE, por lo que podremos utilizarlos en los diferentes servidores de aplicaciones JavaEE existentes. </p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#despliegue-de-archivos-war","title":"Despliegue de archivos WAR","text":"<p>Los archivos WAR, son un tipo especial de JAR utilizado para distribuir los artefactos o contenido de las aplicaciones Web en tecnolog\u00eda JEE: p\u00e1ginas Web HTML o JSP, clases Java, servlets Java, archivos XML, librer\u00edas de etiquetas (tag libraries) y otros recursos.</p> <p>El empaquetamiento en archivos WAR es algo est\u00e1ndar, pero no as\u00ed el proceso de despliegue, que es dependiente del servidor. No obstante, la mayor\u00eda de servidores JavaEE funcionan en este aspecto de modo similar: permiten desplegar las aplicaciones desde una consola de administraci\u00f3n y tambi\u00e9n \"dejando caer\" el fichero en determinado directorio.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#maven","title":"Maven","text":"<p>Maven es una herramienta open-source, que se cre\u00f3 en 2001 con el objetivo de simplificar los procesos de build (compilar y generar ejecutables a partir del c\u00f3digo fuente).</p> <p></p> <p>Antes de existir Maven, si quer\u00edamos compilar y generar ejecutables de un proyecto, ten\u00edamos que analizar qu\u00e9 partes de c\u00f3digo se deb\u00edan compilar, qu\u00e9 librer\u00edas utilizaba el c\u00f3digo, d\u00f3nde incluirlas, qu\u00e9 dependencias de compilaci\u00f3n hab\u00eda en el proyecto\u2026</p> <p>En el mejor de los casos, se empleaban unos pocos minutos para saber c\u00f3mo hacer una build del proyecto. En el peor de los casos, el proceso de build era tan complejo que un desarrollador pod\u00eda tardar horas en saber c\u00f3mo compilar y generar los ejecutables a partir del c\u00f3digo.</p> <p>Ahora, la build de cualquier proyecto Maven, independientemente de sus m\u00f3dulos, dependencias o librer\u00edas, consiste simplemente en ejecutar el comando <code>mvn install</code>.</p> <p>Por otra parte, antes de Maven, cada vez que sal\u00eda una nueva versi\u00f3n de un analizador est\u00e1tico de c\u00f3digo, de un framework de pruebas unitarias (como JUnit) o cualquier librer\u00eda, hab\u00eda que parar todo el desarrollo para reajustar el proceso de build a las nuevas necesidades.</p> <p>Y\u2026 \u00bfc\u00f3mo se ejecutaban las pruebas? \u00bfC\u00f3mo se generaban informes? Sin Maven, en cada proyecto esto se hac\u00eda de distinta manera.</p> <p>Lo cierto es que Maven es mucho m\u00e1s que una herramienta que hace builds del c\u00f3digo.</p> <p>Podr\u00edamos decir, que Maven es una herramienta capaz de gestionar un proyecto software completo, desde la etapa en la que se comprueba que el c\u00f3digo es correcto, hasta que se despliega la aplicaci\u00f3n, pasando por la ejecuci\u00f3n de pruebas y generaci\u00f3n de informes y documentaci\u00f3n.</p> <p>Para ello, en Maven se definen tres ciclos de build del software con una serie de etapas diferenciadas. Por ejemplo el ciclo por defecto tiene las etapas de:</p> <ul> <li>Validaci\u00f3n (validate): Validar que el proyecto es correcto.</li> <li>Compilaci\u00f3n (compile).</li> <li>Test (test): Probar el c\u00f3digo fuente usando un framework de pruebas unitarias.</li> <li>Empaquetar (package): Empaquetar el c\u00f3digo compilado y transformarlo en alg\u00fan formato tipo .jar o .war.</li> <li>Pruebas de integraci\u00f3n (integration-test): Procesar y desplegar el c\u00f3digo en alg\u00fan entorno donde se puedan ejecutar las pruebas de integraci\u00f3n.</li> <li>Verificar que el c\u00f3digo empaquetado es v\u00e1lido y cumple los criterios de calidad (verify).</li> <li>Instalar el c\u00f3digo empaquetado en el repositorio local de Maven, para usarlo como dependencia de otros proyectos (install).</li> <li>Desplegar el c\u00f3digo a un entorno (deploy).</li> </ul> <p>Para poder llevar a cabo alguna de estas fases en nuestro c\u00f3digo, tan solo tendremos que ejecutar <code>mvn</code> y el nombre de la fase (la palabra que puse entre par\u00e9ntesis). Adem\u00e1s van en cadena, es decir, si empaquetamos el c\u00f3digo (package), Maven ejecutar\u00e1 desde la fase de validaci\u00f3n (validate) a empaquetaci\u00f3n (package). As\u00ed de simple.</p> <p>Por otra parte, con Maven la gesti\u00f3n de dependencias entre m\u00f3dulos y distintas versiones de librer\u00edas se hace muy sencilla. En este caso, solo tenemos que indicar los m\u00f3dulos que componen el proyecto, o qu\u00e9 librer\u00edas utiliza el software que estamos desarrollando en un fichero de configuraci\u00f3n de Maven del proyecto llamado POM (Project Object Module).</p> <p>Adem\u00e1s, en el caso de las librer\u00edas, no tienes ni tan siquiera que descargarlas a mano. Maven posee un repositorio remoto (Maven central) donde se encuentran la mayor\u00eda de librer\u00edas que se utilizan en los desarrollos de software, y que la propia herramienta se descarga cuando sea necesario.</p> <p>Digamos que Maven aporta una sem\u00e1ntica com\u00fan al proceso de build y desarrollo del software.</p> <p>Incluso, establece una estructura com\u00fan de directorios para todos los proyectos. Por ejemplo</p> <ul> <li>el c\u00f3digo estar\u00e1 en <code>${ra\u00edz del proyecto}/src/main/java</code>, </li> <li>los recursos en <code>${ra\u00edz del proyecto }/src/main/resources</code>. </li> <li>Los tests est\u00e1n en <code>${ra\u00edz del proyecto }/src/test</code>.</li> </ul> <p>Probablemente todo esto no quede claro todav\u00eda. Tras leer la parte te\u00f3rica, te recomiendo que realices la \"Pr\u00e1ctica 3 -  Despliegue en Tomcat con Maven\". Y despu\u00e9s vuelvas a leer la teor\u00eda. Seguro que as\u00ed te queda m\u00e1s claro el proceso.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T03/#referencias","title":"Referencias","text":"<p>Simple y r\u00e1pido. Entiende qu\u00e9 es Maven en menos de 10 min.</p> <p>Maven in 5 Minutes</p> <p>APRENDIENDO A PROGRAMAR BY EM</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/","title":"Despliegue de aplicaciones Javascript","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#despliegue-de-aplicaciones-nodejs-con-express","title":"Despliegue de aplicaciones Node.js con Express","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#que-es-nodejs","title":"\u00bfQu\u00e9 es Node.js?","text":"<p>Node JS es un entorno de ejecuci\u00f3n de JavaScript r\u00e1pido que utilizamos para construir aplicaciones del lado del servidor. Pero por s\u00ed mismo no sabe c\u00f3mo servir archivos, manejar peticiones ni m\u00e9todos HTTP, as\u00ed que aqu\u00ed es donde entra en juego Express JS.</p> <p>Node.js no es un lenguaje de programaci\u00f3n. M\u00e1s bien, es un entorno de ejecuci\u00f3n que se utiliza para ejecutar JavaScript fuera del navegador.</p> <p></p> <p>Node.js tampoco es un framework (una plataforma para desarrollar aplicaciones de software). El tiempo de ejecuci\u00f3n de Node.js se construye sobre un lenguaje de programaci\u00f3n -en este caso, JavaScript- y ayuda a la ejecuci\u00f3n de los propios frameworks.</p> <p>En resumen, Node.js no es un lenguaje de programaci\u00f3n ni un marco de trabajo; es un entorno para ellos.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#que-es-express","title":"\u00bfQu\u00e9 es Express?","text":"<p>Express JS es un framework de Node.js dise\u00f1ado para construir aplicaciones web de API's y aplicaciones m\u00f3viles multiplataforma de forma r\u00e1pida y hacer  que Node.js sea f\u00e1cil.</p> <p></p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#que-es-npm","title":"\u00bfQu\u00e9 es npm?","text":"<p>NPM responde a las siglas de Node Package Manager o manejador de paquetes de node, es la herramienta por defecto de JavaScript para la tarea de compartir e instalar paquetes.</p> <p></p> <p>Tal como reza su documentaci\u00f3n, npm se compone de al menos dos partes principales.</p> <ul> <li> <p>Un repositorio online para publicar paquetes de software libre para ser utilizados en proyectos Node.js</p> </li> <li> <p>Una herramienta para la terminal (command line utility) para interactuar con dicho repositorio que te ayuda a la instalaci\u00f3n de utilidades, manejo de dependencias y la publicaci\u00f3n de paquetes.</p> </li> </ul> <p>As\u00ed pues, NPM es un gestor de paquetes para Javascript. Es una especie de Maven para paquetes Javascript, es decir, sirve para instalar y gestionar versiones de paquetes y librer\u00edas js.</p> <p>NPM lleva mucho tiempo siendo el referente en cuanto a gestores de paquetes javascript, pero desde hace un tiempo le ha salido un competidor: Yarn. Los de yarn aseguran que su gestor de librer\u00edas js es mucho m\u00e1s r\u00e1pido y potente, pero de momento el uso de NPM es mayoritario.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#packagejson","title":"package.json","text":"<p>Cada proyecto en JavaScript puede enfocarse como un paquete npm con su propia informaci\u00f3n de paquete y su archivo <code>package.json</code> para describir el proyecto.</p> <p><code>package.json</code> se generar\u00e1 cuando se ejecute <code>npm init</code> para inicializar un proyecto JavaScript/Node.js, con los siguientes metadatos b\u00e1sicos proporcionados por los desarrolladores:</p> <ul> <li> <p>name: el nombre de la librer\u00eda/proyecto JavaScript</p> </li> <li> <p>version: la versi\u00f3n del proyecto. </p> </li> <li> <p>description: la descripci\u00f3n del proyecto</p> </li> <li> <p>license: la licencia del proyecto</p> </li> </ul>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#npm-scripts","title":"NPM scripts","text":"<p>package.json tambi\u00e9n soporta la propiedad scripts que puede definirse para ejecutar herramientas de l\u00ednea de comandos que se instalan en el contexto local del proyecto. Por ejemplo, la porci\u00f3n de scripts de un proyecto npm puede tener un aspecto similar a este:</p> <p><pre><code>{\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"format\": \"prettier --write **/*.ts\",\n    \"format-check\": \"prettier --check **/*.ts\",\n    \"lint\": \"eslint src/**/*.ts\",\n    \"pack\": \"ncc build\",\n    \"test\": \"jest\",\n    \"all\": \"npm run build &amp;&amp; npm run format &amp;&amp; npm run lint &amp;&amp; npm run pack &amp;&amp; npm test\"\n  }\n}\n</code></pre> Con eslint, prettier, ncc, jest no necesariamente instalados como ejecutables globales sino como locales de tu proyecto dentro de <code>node_modules/.bin/</code>.</p> <p>Como en el caso de Maven, todo lo anterior es imposible de entender sin ponerse manos a la obra. Ahora es el momento de hacer las pr\u00e1cticas \"Pr\u00e1ctica 4 - Despliegue de aplicaciones con Node Express\" y \"Pr\u00e1ctica 5 - Despliegue de una aplicaci\u00f3n \"clusterizada\" con Node Express\". Despu\u00e9s o durante la realizaci\u00f3n de las mismas consulta nuevamente este apartado te\u00f3rico y comprender\u00e1s todo mucho mejor.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T04/#referencias","title":"Referencias","text":"<p>Simple y r\u00e1pido. Entiende qu\u00e9 es Maven en menos de 10 min.</p> <p>Maven in 5 Minutes</p> <p>T\u00edtulo de experto universitario en desarrollo de aplicaciones y servicios con JavaEE</p> <p>Qu\u00e9 es Node.js y por qu\u00e9 deber\u00eda usarlo</p> <p>APRENDIENDO A PROGRAMAR BY EM</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/","title":"CI/CD (Continous Integration/Continous Deployment-Delivery)","text":""},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#introduccion","title":"Introducci\u00f3n","text":"<p>Aunque este apartado ser\u00e1 objeto de un tema espec\u00edfico m\u00e1s adelante, no podemos dejar un tema dedicado al tema de despliegues de aplicaciones web sin mencionarlo.</p> <p>La CI/CD es un m\u00e9todo para distribuir las aplicaciones a los clientes con frecuencia mediante el uso de la automatizaci\u00f3n en las etapas del desarrollo de aplicaciones. Los principales conceptos que se le atribuyen son la integraci\u00f3n, la distribuci\u00f3n y la implementaci\u00f3n continuas. Se trata de una soluci\u00f3n para los problemas que puede generar la integraci\u00f3n del c\u00f3digo nuevo para los equipos de desarrollo y de operaciones (tambi\u00e9n conocida como \"el infierno de la integraci\u00f3n\").</p> <p>En concreto, el proceso de integraci\u00f3n y distribuci\u00f3n continuas incorpora la automatizaci\u00f3n y la supervisi\u00f3n permanentes en todo el ciclo de vida de las aplicaciones, desde las etapas de integraci\u00f3n y prueba hasta las de distribuci\u00f3n e implementaci\u00f3n. Este conjunto de pr\u00e1cticas se conoce como \"canales de CI/CD\" y cuenta con el respaldo de los equipos de desarrollo y de operaciones que trabajan en conjunto de manera \u00e1gil, con un enfoque de DevOps o de ingenier\u00eda de confiabilidad del sitio (SRE).</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#cual-es-la-diferencia-entre-la-integracion-la-distribucion-y-la-implementacion-continuas","title":"\u00bfCu\u00e1l es la diferencia entre la integraci\u00f3n, la distribuci\u00f3n y la implementaci\u00f3n continuas?","text":"<p>Estas siglas tienen diferentes significados. \"CI\" siempre se refiere a la integraci\u00f3n continua, que es un proceso de automatizaci\u00f3n para los desarrolladores. El \u00e9xito de la CI implica que se dise\u00f1en, prueben y combinen los cambios nuevos en el c\u00f3digo de una aplicaci\u00f3n con regularidad en un repositorio compartido. Supone una soluci\u00f3n al problema de que se desarrollen demasiadas divisiones de una aplicaci\u00f3n al mismo tiempo, que luego podr\u00edan entrar en conflicto entre s\u00ed.</p> <p>La sigla \"CD\" se refiere a la distribuci\u00f3n o la implementaci\u00f3n continuas, y se trata de conceptos relacionados que suelen usarse indistintamente. Ambos se refieren a la automatizaci\u00f3n de las etapas posteriores del proceso, pero a veces se usan por separado para explicar hasta d\u00f3nde llega la automatizaci\u00f3n.</p> <p>Por lo general, la distribuci\u00f3n continua se refiere a que los cambios que implementa un desarrollador en una aplicaci\u00f3n se someten a pruebas autom\u00e1ticas de errores y se cargan en un repositorio (como GitHub o un registro de contenedores), para que luego el equipo de operaciones pueda implementarlos en un entorno de producci\u00f3n en vivo. Es una soluci\u00f3n al problema de la falta de supervisi\u00f3n y comunicaci\u00f3n entre los equipos comerciales y de desarrollo, as\u00ed que su prop\u00f3sito es garantizar que la implementaci\u00f3n del c\u00f3digo nuevo se lleve a cabo con el m\u00ednimo esfuerzo.</p> <p>La implementaci\u00f3n continua (la otra definici\u00f3n de \"CD\") hace referencia al lanzamiento autom\u00e1tico de los cambios que implementa el desarrollador desde el repositorio hasta la producci\u00f3n, para ponerlos a disposici\u00f3n de los clientes. As\u00ed ya no se sobrecarga a los equipos de operaciones con procesos manuales que retrasan la distribuci\u00f3n de las aplicaciones. Con este tipo de implementaci\u00f3n, se aprovechan los beneficios de la distribuci\u00f3n continua y se automatiza la siguiente etapa del proceso.</p> <p></p> <p>La CI/CD puede incluir solamente la integraci\u00f3n y la distribuci\u00f3n continuas, o las tres pr\u00e1cticas vinculadas, con la implementaci\u00f3n continua. Para complicar un poco m\u00e1s las cosas, a veces se utiliza el t\u00e9rmino \"distribuci\u00f3n continua\" para abarcar tambi\u00e9n los procesos de la implementaci\u00f3n continua.</p> <p>En realidad, no vale la pena profundizar en la sem\u00e1ntica. Solo debe recordar que la integraci\u00f3n y la distribuci\u00f3n continuas son un proceso que suele percibirse como una canalizaci\u00f3n e implica incorporar un alto nivel de automatizaci\u00f3n permanente y supervisi\u00f3n constante al desarrollo de las aplicaciones.</p> <p>El significado de los t\u00e9rminos var\u00eda en cada caso y depende de la cantidad de automatizaci\u00f3n que se haya incorporado a la canalizaci\u00f3n de integraci\u00f3n y distribuci\u00f3n continuas. Muchas empresas comienzan con la incorporaci\u00f3n de la CI, y luego van automatizando la distribuci\u00f3n y la implementaci\u00f3n, por ejemplo, con las aplicaciones desarrolladas directamente en la nube.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#integracion-continua-continous-integration","title":"Integraci\u00f3n continua - Continous Integration","text":"<p>El objetivo del dise\u00f1o de las aplicaciones modernas es que los desarrolladores puedan trabajar de forma simult\u00e1nea en distintas funciones de la misma aplicaci\u00f3n. Sin embargo, si una empresa fusiona todo el c\u00f3digo fuente diversificado en un solo d\u00eda (conocido como el \"d\u00eda de la fusi\u00f3n\"), las tareas pueden tornarse tediosas, manuales y muy lentas. Esto se debe a que si un desarrollador que trabaja de forma aislada implementa un cambio en una aplicaci\u00f3n, existe la posibilidad de que entre en conflicto con las modificaciones que otros desarrolladores implementaron al mismo tiempo. El problema puede agravarse a\u00fan m\u00e1s si cada desarrollador personaliza su propio entorno de desarrollo integrado (IDE) local, en lugar de que todo el equipo adopte un IDE com\u00fan, idealmente basado en la nube.</p> <p></p> <p>La integraci\u00f3n continua (CI) permite que los desarrolladores incorporen los cambios del c\u00f3digo a un repositorio compartido con mayor frecuencia, o incluso a diario. Una vez que se incorporan las modificaciones del desarrollador, se validan con la compilaci\u00f3n autom\u00e1tica de la aplicaci\u00f3n y la ejecuci\u00f3n de distintas pruebas automatizadas (generalmente, de unidad e integraci\u00f3n), para garantizar que los cambios no hayan introducido una falla. Esto significa que se debe probar todo, desde las clases y el funcionamiento hasta los distintos m\u00f3dulos que conforman toda la aplicaci\u00f3n. Si una prueba autom\u00e1tica detecta un conflicto entre el c\u00f3digo nuevo y el actual, la CI facilita la resoluci\u00f3n de esos errores con rapidez.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#distribucion-continua-continous-delivery","title":"Distribuci\u00f3n continua - Continous Delivery","text":"<p>Despu\u00e9s de la automatizaci\u00f3n de las compilaciones y las pruebas de unidad e integraci\u00f3n de la CI, la distribuci\u00f3n continua automatiza el traslado del c\u00f3digo validado hacia un repositorio. Por eso, para que la distribuci\u00f3n continua sea eficaz, es importante que la CI ya est\u00e9 incorporada al proceso de desarrollo. El objetivo de la distribuci\u00f3n continua es tener una base de c\u00f3digo que pueda implementarse en el entorno de producci\u00f3n en cualquier momento.</p> <p></p> <p>Cada etapa (desde la incorporaci\u00f3n de los cambios al c\u00f3digo hasta la distribuci\u00f3n de las compilaciones listas para la producci\u00f3n) implica la automatizaci\u00f3n de las pruebas y del lanzamiento del c\u00f3digo. Al final de este proceso, el equipo de operaciones puede implementar una aplicaci\u00f3n para la producci\u00f3n de forma r\u00e1pida y sencilla.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#implementacion-continua-continous-deployment","title":"Implementaci\u00f3n continua - Continous deployment","text":"<p>La \u00faltima etapa del canal consolidado de CI/CD es la implementaci\u00f3n continua, que automatiza el lanzamiento de una aplicaci\u00f3n a la producci\u00f3n, ya que es una extensi\u00f3n de la distribuci\u00f3n continua, la cual automatiza el traslado de una compilaci\u00f3n lista para la producci\u00f3n a un repositorio del c\u00f3digo. Debido a que no hay ninguna entrada manual en la etapa anterior a la producci\u00f3n, la implementaci\u00f3n continua depende en gran medida del correcto dise\u00f1o de la automatizaci\u00f3n de las pruebas.</p> <p></p> <p>En la pr\u00e1ctica, los cambios que implementan los desarrolladores en la aplicaci\u00f3n en la nube podr\u00edan ponerse en marcha unos cuantos minutos despu\u00e9s de su creaci\u00f3n (siempre que hayan pasado las pruebas automatizadas). Esto facilita mucho m\u00e1s la recepci\u00f3n e incorporaci\u00f3n permanente de los comentarios de los usuarios. En conjunto, todas estas pr\u00e1cticas de CI/CD permiten que se implementen las aplicaciones con menos riesgos, ya que es m\u00e1s f\u00e1cil incorporar los cambios en las aplicaciones poco a poco, en lugar de hacerlo todo de una sola vez. Sin embargo, tambi\u00e9n deben realizarse muchas inversiones iniciales, ya que se deben dise\u00f1ar las pruebas automatizadas para que se adapten a las distintas etapas de prueba y lanzamiento en el canal de la CI/CD.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#conclusion","title":"Conclusi\u00f3n","text":"<p>Se ha explicado en este tema cu\u00e1les son las caracter\u00edsticas, usos y diferencias entre los servidores web y los servidores de aplicaciones.</p> <p>Tambi\u00e9n hemos explicado detalladamente en qu\u00e9 consiste un proceso de despliegue cl\u00e1sico de una aplicaci\u00f3n web, cu\u00e1les son sus fases y caracter\u00edsticas. Para reforzar este proceso, hemos listado una serie de buenas pr\u00e1cticas a la hora de llevarlo a cabo.</p> <p>Por \u00faltimo, hemos presentado las nuevas tendencias en el mundo del despliegue, como son las t\u00e9cnicas de CI/CD, que abordaremos de forma m\u00e1s profunda en el Tema 7.</p>"},{"location":"Ud6%20Servidores%20de%20aplicaciones/T07/#referencias","title":"Referencias","text":"<p>\u00bfQu\u00e9 son la integraci\u00f3n y la distribuci\u00f3n continuas (CI/CD)?</p>"},{"location":"Ud7%20CI-CD/P8_1/","title":"Pr\u00e1ctica 8.1- Toma de contacto con CI/CD usando Github actions","text":""},{"location":"Ud7%20CI-CD/P8_1/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"Ud7%20CI-CD/P8_1/#que-es-github-actions","title":"\u00bfQu\u00e9 es Github actions?","text":"<p>GitHub Actions es una plataforma de integraci\u00f3n y despliegue continuos (CI/CD) que te permite automatizar tu proceso de compilaci\u00f3n, pruebas y despliegue. Puedes crear flujos de trabajo (workflows) y crear y probar cada solicitud de cambios en tu repositorio o desplegar solicitudes de cambios fusionadas a producci\u00f3n. Todo se hace desde tu cuenta GitHub, as\u00ed que no has de hacer nada adicional para usarla.</p> <p>GitHub Actions va m\u00e1s all\u00e1 de solo DevOps y te permite ejecutar flujos de trabajo cuando otros eventos suceden en tu repositorio. Por ejemplo, puedes ejecutar un flujo de trabajo para que agregue autom\u00e1ticamente las etiquetas adecuadas cada vez que alguien cree una propuesta nueva en tu repositorio.</p> <p>GitHub proporciona m\u00e1quinas virtuales Linux, Windows y macOS para que ejecutes tus flujos de trabajo o puedes hospedar tus propios ejecutores auto-hospedados en tu propio centro de datos o infraestructura en la nube.</p> <p>Un workflow ejecutar\u00e1 uno o m\u00e1s \"jobs\" que se definen mediante un archivo YAML. Estos archivos se ubican en el directorio <code>.github/workflows</code> de un repositorio y puede haber varios archivos de workflow para diferentes cometidos.</p> <p>Un evento es una actividad que dispara un flujo de trabajo o workflow. Estos eventos pueden ser un push, un pull request o un merge.</p> <p>Por \u00faltimo, los jobs son acciones o pasos que se ejecutan dentro de un workflow.</p> <p>Una acci\u00f3n es una aplicaci\u00f3n personalizada para la plataforma de GitHub Actions que realiza una tarea compleja pero que se repite frecuentemente.</p> <p>Para entender detalladamente todos los componentes, pod\u00e9is consultar aqu\u00ed. Para entender bien el resto de la pr\u00e1ctica te recomiendo su lectura.</p>"},{"location":"Ud7%20CI-CD/P8_1/#acciones-previas","title":"Acciones previas","text":"<p>Atenci\u00f3n</p> <p>Antes de comenzar esta pr\u00e1ctica, deb\u00e9is tener una cuenta en Docker Hub: https://hub.docker.com/ y en GitHub https://github.com/.</p> <p>En esta pr\u00e1ctica vamos a unir muchas cosas que hemos aprendido en este curso y nos servir\u00e1 de recopilatorio del curso. As\u00ed que te guiar\u00e9 en puntos espec\u00edficos de la misma, pero en otros te indicar\u00e9 lo que has de hacer y deber\u00e1s hacerlo por ti mismo. Puedes consultar pr\u00e1cticas pasadas si no sabes c\u00f3mo hacer alguna cosa.</p> <p>Vamos a trabajar en AWS sobre una m\u00e1quina virtual EC2 Debian con las opciones por defecto. </p> <p>Vamos a utilizar una aplicaci\u00f3n simple en NodeJS, que correr\u00e1 en un servidor Express. Por tanto, necesitamos tener instalados en nuestro sistema Node.js y Yarn.</p> <p>As\u00ed pues, las primeras acciones a realizar ser\u00e1n:</p> <ul> <li>En AWS crea una m\u00e1quina virtual Debian con las opciones por defecto. Ll\u00e1male \"AnimalFarm\" y a su grupo de seguridad ponle el mismo nombre.</li> <li>Actualiza los paquetes a la \u00faltima versi\u00f3n.</li> <li>Instala Git y config\u00faralo con tus datos, incluyendo el login para que pueda conectar con tu cuenta GitHub mediante clave ssh.</li> <li>Instala Docker y config\u00faralo para que pueda hacer \"push\" de tus contenedores a tu cuenta DockerHub.</li> <li>Instala Node.js </li> <li>Instala Yarn.</li> </ul> <p>Instalaci\u00f3n de Yarn</p> <p>Yarn es un gestor de paquetes de JavaScript y en Debian se puede instalar mediante npm, apt o script.  Aqu\u00ed se explican los 3 m\u00e9todos de instalaci\u00f3n, elegid el que m\u00e1s os guste.</p>"},{"location":"Ud7%20CI-CD/P8_1/#comenzamos","title":"Comenzamos","text":"<p>Como hemos comentado vamos a trabajar con una aplicaci\u00f3n simple en NodeJS que se llama \"Animal Farm\", que correr\u00e1 en un servidor Express.</p> <p>El objetivo de esta pr\u00e1ctica ser\u00e1 utilizar GitHub Actions para a\u00f1adir ciertas automatizaciones iniciales a nuestro repositorio. Haremos que se disparen pruebas sobre nuestro c\u00f3digo cuando se abra un pull request y, autom\u00e1ticamente, construiremos una imagen Docker para nuestra aplicaci\u00f3n. Adem\u00e1s, podremos hacer que dicha imagen docker se env\u00ede autom\u00e1ticamente a DockerHub y a GitHub Container Registry, completando as\u00ed el ciclo completo de integraci\u00f3n y despliegue cont\u00ednuo.</p> <p>La aplicaci\u00f3n que usaremos est\u00e1 aqu\u00ed. Empieza por hacer un fork de dicho repositorio en tu cuenta GitHub.</p> <p>Nota</p> <p>Por si el propietario del repositorio lo borrara, puedes encontrar copia de los ficheros que contiene aqu\u00ed. Puedes generar tu propio repositorio a partir de estos ficheros.</p> <p>Ahora clona tu repositorio en local y echa un ojo a lo que tiene:</p> <pre><code>$ git clone git@github.com:jmunozji/animal-farm-nodejs.git\n$ cd animal-farm-nodejs\n</code></pre> <p>En el paquete encontraremos lo siguiente:</p> <ul> <li>app.js - Es la aplicaci\u00f3n que estamos desplegando</li> <li>test/test.js - Es el c\u00f3digo que testear\u00e1 si la aplicaci\u00f3n app.js es correcta</li> <li>.github/workflows - Son los flujos que haremos que GitHub ejecute para testear la aplicaci\u00f3n y desplegar los contenedores</li> </ul> <p>Iremos viendo todo poco a poco.</p> <p>Utilizamos ahora yarn para instalar los m\u00f3dulos requeridos de Node.js</p> <pre><code>$ yarn install\n</code></pre> <p>Y utilizamos yarn una vez m\u00e1s para iniciar la aplicaci\u00f3n:</p> <pre><code>$ yarn start\n</code></pre> <p>Si ahora accedemos a la IP de la m\u00e1quina virtual, en el puerto 8080, deber\u00edamos tener acceso al sitio web y ver la ejecuci\u00f3n de la aplicaci\u00f3n:</p> <p></p> <p>Si actualiz\u00e1is varias veces, podr\u00e9is ver qu\u00e9 otros animales hay en la granja. </p> <p>Para la ejecuci\u00f3n y vamos a probar las pruebas. Tenemos una bater\u00eda de pruebas, no muy exhaustiva, en el directorio <code>test</code>. Probemos a ejecutarlos con yarn:</p> <p></p> <p>Llegados a este punto hemos probado la ejecuci\u00f3n del programa y hemos realizado la bater\u00eda de tests que comprueban que el c\u00f3digo es correcto.</p>"},{"location":"Ud7%20CI-CD/P8_1/#creando-nuestro-primer-workflow","title":"Creando nuestro primer workflow","text":"<p>Todos los repositorios de GitHub vienen con Actions activado por defecto. Comprobad en vuestro repositorio que existe una pesta\u00f1a llamada Actions. Los habilitaremos.</p> <p></p> <p>Lo que necesit\u00e1is hacer es, en los settings de vuestro repositorio buscar el apartado de Actions y darle permisos para realizar cualquier acci\u00f3n si no est\u00e1 ya activada. Pod\u00e9is consultar el procedimiento en detalle aqu\u00ed</p> <p>Como ya hemos dicho, Actions ejecuta los workflows, los cuales suelen estar asociados a fases espec\u00edficas del ciclo de desarrollo. Por ejemplo, un workflow que corra cuando se abra un \"pull request\". Tambi\u00e9n hemos comentado que dentro de los workflows est\u00e1n los jobs, que son acciones individuales dentro de un workflow. Por ejemplo:</p> <pre><code>Workflow 1\n    1. Clona el repositorio\n    2. Instala los prerrequisitos\n    3. Ejecuta los tests\n</code></pre> <p>En la introducci\u00f3n tambi\u00e9n se ha explicado d\u00f3nde y c\u00f3mo se definen estos workflows. El repositorio que hemos clonado ya los tiene definidos, as\u00ed que vamos a verlos. En el repositorio clonado en nuestra Debian, comprobamos que existe el directorio donde se guardan los \"workflows\" y entraremos en \u00e9l:</p> <pre><code>$ ls .github/workflows\n$ cd .github/workflows\n</code></pre>"},{"location":"Ud7%20CI-CD/P8_1/#testeando-nuestro-codigo-con-un-workflow","title":"Testeando nuestro c\u00f3digo con un workflow","text":"<p>Como lo prometido es deuda, vamos a usar un workflow que ejecute nuestras pruebas (archivo ./test/test.js) cuando abramos un nuevo \"pull request\" en GitHub. Para ello se crea un archivo YAML.  </p> <p>En el directorio de nuestros workflows ya hay un archivo llamado <code>test</code>, que definir\u00e1 nuestras pruebas:</p> <pre><code>ls test.yml\n</code></pre> <p>Nota</p> <p>El formato YAML puede llegar a ser bastante pu\u00f1etero hasta que sea correcto. Pod\u00e9is comprobar si vuestro archivo .yml est\u00e1 correctamente formateado en este validador online </p> <p>Y el contenido del archivo es el siguiente:</p> <pre><code>name: Animal Farm Node.js CI  #(1)\n\non: #(2)\n  push:\n   branches:\n      - main\n  pull_request:\n    branches:\n      - main\njobs: #(3)\n  build:\n    runs-on: ubuntu-latest #(4)\n    steps: #(5)\n    - name: Checkout repository # (6)\n      uses: actions/checkout@v2 #(7)\n    - name: Use Node.js\n      uses: actions/setup-node@v1 #(8)\n      with:\n        node-version: '18.x'\n    - name: Run Yarn #(9)\n      run: yarn\n    - name: Run tests\n      run: yarn test\n</code></pre> <ol> <li>Nombre descriptivo para nuestro workflow</li> <li> <p>En este bloque on definimos cu\u00e1ndo va a ejecutarse nuestro workflow:</p> <ul> <li>Cuando alguien haga push sobre la rama main</li> <li>Cuando alguien abra un pull request desde la rama main</li> </ul> </li> <li> <p>Aqu\u00ed se definen los jobs, en nuestro caso uno solo: <code>build</code>. </p> </li> <li>Cada job corre en una plataforma esec\u00edfica, pudiendo elegir entre Linux, Windows o MacOS. En nuestro caso particular vamos a ejecutar nuestro job en un contenedor usando Ubuntu Linux.</li> <li>Las tareas o pasos que ejecutar\u00e1 el job. Si un paso falla, por norma general, fallar\u00e1 todo el job.</li> <li>Nombramos cada paso del job</li> <li>Este paso b\u00e1sicamente hace un clonado del repositorio.    Hace uso de una acci\u00f3n pre-empaquetada (<code>actions/checkout@v2</code>). Este tipo de acciones las suele proporcionar la comunidad de GitHub y, normalmente, ejecutan tareas que de otra forma supondr\u00edan m\u00faltiples pasos o supondr\u00edan una configuraci\u00f3n muy repetitiva.</li> <li>Se trata de otra acci\u00f3n pre-empaquetada. Se encarga de intalar Node.js dentro del contenedor que est\u00e1 corriendo o ejecutando nuestro job. Podemos pasarle argumentos, en este caso con el bloque <code>with</code> le decimos qu\u00e9 versi\u00f3n de Node.js debe instalar.</li> <li>Estos pasos son el n\u00facleo de nuestro job ya que se encargar\u00e1 de ejecutar yarn para instalar los m\u00f3dulos necesarios de Node.js y, en el \u00faltimo paso, ejecutar los tests con <code>yarn tests</code></li> </ol>"},{"location":"Ud7%20CI-CD/P8_1/#comprobando-nuestro-workflow","title":"Comprobando nuestro workflow","text":"<p>Vamos a realizar un cambio en nuestra aplicaci\u00f3n para despu\u00e9s crear un pull request con \u00e9l.</p> <ol> <li>Crea una nueva rama y ll\u00e1male \"feat-nuevoanimal\". </li> <li>Posici\u00f3nate en la nueva rama.</li> <li>Edita el filchero <code>app.js</code> , a\u00f1adiendo un nuevo animal junto con su onomatopeya.</li> <li>Ejecuta los tests para ver si el c\u00f3digo es correcto.</li> <li>Si los test no te dan OK, revisa y soluciona el motivo. Revisa el fichero test/test.js tambi\u00e9n.</li> <li>Confirma los cambios y s\u00fabe la nueva rama a GitHub.</li> <li>Comprueba en GitHub que se ha creado la nueva rama y que contiene los cambios realizados.</li> </ol> Soluci\u00f3n <ol> <li>Creamos una nueva rama y nos posicionamos en ella con el comando: <pre><code>  $ git checkout -b feat-nuevoanimal\n</code></pre></li> <li>Edita con nano el fichero <code>app.js</code> a\u00f1adiendo un nuevo animal junto con su onomatopeya. Guarda los cambios.</li> <li>Ejecuta los \"test\" en local. No te dar\u00e1n bien porque hay que modificar el fichero test/test.js para que tenga en cuenta el nuevo animal introducido. Modif\u00edcalo.</li> <li>Comprueba que los tests en local son correctos antes de continuar. No tendr\u00eda mucho sentido que el programador suba al repositorio un c\u00f3digo que no supera las pruebas localmente, \u00bfno?</li> <li>Confirma los cambios y s\u00fabelos a GitHub.   <pre><code>  $ git add app.js\n  $ git commit -a -m \u201cA\u00f1adido un nuevo animal\u201d\n  $ git push origin feat-nuevoanimal\n</code></pre></li> </ol> <p>Ahora crearemos un pull request para esta rama. Recuerda que un \"Pull request\" es una solicitud para introducir en la rama principal los cambios realizados en una rama.</p> <p></p> <p>Warning</p> <p>Tened cuidado de hacer el \"Pull request\" de vuestra rama \"feat-nuevoanimal\" a vuestra rama \"main\" en vuestro repositorio y no sobre la rama main del proyecto principal \"jamtur01/animal-farm-nodejs\".</p> <p></p> <p>Recuerda que nuestro Workflow se ejecutaba en 2 ocasiones:</p> <ul> <li>Cuando alguien haga push sobre la rama main</li> <li>Cuando alguien abra un pull request desde la rama main</li> </ul> <p>En este caso hemos abierto el pull request. De forma autom\u00e1tica se ejecutar\u00e1n los tests para comprobar que el c\u00f3digo que solicitamos incluir en la rama principal supera los tests antes de aceptar o rechazar el pull request. </p> <p></p> <p>En la pesta\u00f1a de checks podremos comprobar el estado de nuestro workflow.</p> <p>Tarea</p> <p>Comprueba si este workflow se ha completado con \u00e9xito (check verde) o no (aspa roja). En caso de no haberlo hecho, modifica el test con lo necesario y s\u00fabelo al repositorio para que se pueda completar con \u00e9xito. Recuerda, el test est\u00e1 definido en test/test.js </p> <p>Cuando el workflow se ejecute correctamente, deberemos ver algo como esto:</p> <p></p>"},{"location":"Ud7%20CI-CD/P8_1/#un-workflow-para-construir-imagenes-de-docker","title":"Un workflow para construir im\u00e1genes de Docker","text":"<p>Nuestro objetivo ahora, puesto que hemos automatizado los tests a nuestro c\u00f3digo, es que cuando \u00e9stos se completen con \u00e9xito, y se acepte el Pull Request haciendo merge con la rama principal, se construya una imagen Docker de nuestra aplicaci\u00f3n y autom\u00e1ticamente se suba a los repositorios de Docker Hub y Github Container Registry (el repositorio para im\u00e1genes Docker de GitHub). </p> <p>En primer lugar, como ya sabemos, revisaremos y modificaremos el archivo para el nuevo workflow:</p> <pre><code>cd .github/workflows\nnano docker.yml\n</code></pre> <p>Y lo editamos, introduciendo el c\u00f3digo yaml necesario:</p> <pre><code>name: Publish Docker image\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v2\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v1\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v1\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Login to GitHub Container Registry\n        uses: docker/login-action@v1\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GHRC_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: | #(1)\n            jmunozji/animal-farm-nodejs:latest\n            ghcr.io/jmunozji/animal-farm-nodejs:latest\n</code></pre> <ol> <li>Sustituid <code>jmunozji</code> por vuestro nombre de usuario de Docker Hub y Github Container Registry (ghcr) respectivamente</li> </ol> <p>Vamos a analizar el contenido de este fichero:</p> <p>Hemos llamado a nuestro nuevo workflow Publish Docker image. En este caso nuestro bloque <code>on</code> s\u00f3lo se \"dispara\" o activa cuando se produce un merge en la rama main.</p> <p>Tenemos un job en nuestro workflow llamado <code>build-and-push</code> que se ejecuta en <code>ubuntu-latest</code>. Este job hace check out (clonado) usando la action que usamos en nuestro anterior workflow. Tras ello, utiliza unas actions pre-empaquetadas nuevas, con el fin de configurar un entorno para construir im\u00e1genes de Docker usando QEMU y Docker buildx.</p> <p>Aclaraci\u00f3n</p> <p>Qemu es una aplicaci\u00f3n de c\u00f3digo abierto que emula diferentes arquitecturas hardware y permite virtualizar.</p> <p>Buildx es un plugin de Docker para ampliar las capacidades a la hora de construir im\u00e1genes.</p> <p>Utilizamos otra Action para hacer login en ambos, Docker Hub y Github Container Registry. En los pasos de esta nueva Action vemos un nuevo elemento, las variables</p> <pre><code>${{ secrets.DOCKERHUB_USERNAME }}\n</code></pre> <p>Las Actions pueden usar variables para personalizar los workflows y permitir que introduzcamos datos externos. Estos datos pueden incluir secretos (secrets), como nuestro usuario y password/token de Docker Hub, variables de entorno como nuestro path o valores espec\u00edficamente definidos por el usuario.</p> <p>Nota</p> <p>Los secretos cifrados permiten almacenar informaci\u00f3n sensible en un repositorio.</p> <p>Los secretos son variables cifradas que creas en una organizaci\u00f3n, repositorio o entorno de repositorio. Los secretos que creas est\u00e1n disponibles para utilizarse en los flujos de trabajo de GitHub Actions. GitHub garantiza que los secretos se cifren antes de llegar a GitHub y permanezcan cifrados hasta que los use en un flujo de trabajo.</p> <p>M\u00e1s informaci\u00f3n aqu\u00ed.</p> <p>Para configurar los secrets de nuestro repositorio, debemos acceder dentro de \u00e9l a <code>Settings &gt; Secrets and variables &gt; Actions</code>:</p> <p></p> <p>Y ah\u00ed crearemos los secretos para nuestro repositorio con el mismo nombre que aparecen en el archivo del workflow, as\u00ed como los valores pertinentes para vuestro caso.</p> <p>Para DockerHub pod\u00e9is usar el usuario y contrase\u00f1a o crear un Token para esta pr\u00e1ctica. En caso de no tenerlo, pod\u00e9is crearos un token en Docker Hub en <code>Account Settings &gt; Security</code>.</p> <p>Pero para conectarnos al Github Container Registry (el repositorio para im\u00e1genes Docker de GitHub) hemos de generar un Token personal (classic) de GitHub.</p> <p>Ve a tu usuario, Settings - Developer settings Personal access tokens - Tokens (classic) y selecciona \"Generate new token\" y aseg\u00farate de darle estos permisos:</p> <pre><code>write:packages    Upload packages to GitHub Package Registry\n  read:packages   Download packages from GitHub Package Registry\ndelete:packages   Delete packages from GitHub Package Registry\n</code></pre> <p>Copia el token. Ahora ve al repositorio, Settings - Secrets and Variables - Actions. Crea un \"New Repository Secret\", ll\u00e1male GHRC_TOKEN y as\u00edgnale el token que acabas de crear.</p> <p>En \u00faltima instancia, nuestro workflow construye la nueva imagen de Docker usando el Dockerfile disponible en nuestro repositorio y hace push de la imagen construida tanto a Docker Hub como a Github Container Registry.</p> <p>Cuidado</p> <p>No olvid\u00e9is hacer otra vez commit y push para subir este workflow al repositorio, de otra forma, al no existir en el repositorio y s\u00f3lo en vuestra m\u00e1quina local, no se ejecutar\u00e1.</p> <p>En este momento, si ya hemos entendido el fichero y hemos creado los \"secrets\" en el repositorio, ya podemos hacer que se ejecute el nuevo workout, que recordemos se \"dispara\" al hacer merge en la rama main.</p> <p>As\u00ed las cosas, hagamos merge de nuestro PR (Pull Request). Vamos a aceptar el \"Pull request\" con la opci\u00f3n \"Merge pull request\" y \"Confirm merge\". Esto activar\u00e1 nuestros dos workflows, el primero que correr\u00e1 una vez m\u00e1s los tests para confirmar que la nueva rama main est\u00e1 funcionando correctamente y el segundo que construir\u00e1 la imagen Docker y har\u00e1 el push a los repositorios de im\u00e1genes.</p> <p></p> <p>Si todo se ha hecho bien, funcionar\u00e1 correctamente.</p> <p>Merge del pull request:</p> <p></p> <p>Resultado de los workflows:</p> <p></p> <p></p> <p>Ahora podemos comprobar que el contenedor se ha creado y subido tanto a DockerHub como a Github Container Registry.</p> <p>En DockerHub:</p> <ol> <li>Comprobad, entrando via web, que la imagen Docker que acab\u00e1is de construir est\u00e1 disponible en vuestro repositorio personal. </li> <li>Comprobad que pod\u00e9is descargarla y correr el contenedor asociado sin problemas:</li> </ol> <p><pre><code>docker run -d -p 9000:8080 jmunozji/animal-farm-nodejs\n</code></pre> 3. Comprueba que el contenedor est\u00e1 funcionando correctamente accediendo a la aplicaci\u00f3n en <code>http://IP_Maq_Virtual:9000</code> (hemos hecho corresponder el puerto 8080 del contenedor con el 9000 del anfitri\u00f3n)</p> <p>En GitHub Container Registry</p> <ol> <li>Ve a Packages y comprueba que el contenedor est\u00e1 ah\u00ed. Quiz\u00e1s tengas que borrar los filtros para verlo.</li> <li>Desde la consola con\u00e9ctate al repositorio de contenedores GitHub Container Regystry   <pre><code>$ export CR_PAT=TUPERSONALACCESSTOKEN\n$admin@ip-172-31-84-190:~$ echo $CR_PAT | docker login ghcr.io -u TUUSUARIOGITHUB --password-stdin\nWARNING! Your password will be stored unencrypted in /home/admin/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\nLogin Succeeded\n</code></pre>   Cambia TUPERSONALACCESSTOKEN y TUUSUARIOGITHUB por tus valores personales. Ojo, este token no es el mismo que usamos antes. Deber\u00e1s crear un token para este cometido con los permisos adecuados.</li> <li>Crea y lanza el contenedor con    <pre><code>$ docker run -d -p 9000:8080 ghcr.io/jmunozji/animal-farm-nodejs\n</code></pre></li> <li>Comprueba que el contenedor est\u00e1 funcionando correctamente accediendo a la aplicaci\u00f3n en <code>http://IP_Maq_Virtual:9000</code> (hemos hecho corresponder el puerto 8080 del contenedor con el 9000 del anfitri\u00f3n)</li> </ol> <p>Y esto es s\u00f3lo una peque\u00f1\u00edsima muestra de todo lo que se puede hacer con GitHub Actions. Probablemente no has captado toda la potencia al hacer la pr\u00e1ctica poco a poco. Ahora que todo est\u00e1 preparado y funcionando prueba a hacer lo siguiente:</p> <ol> <li>Borra la rama feat-nuevoanimal</li> <li>Crea una nueva rama y posici\u00f3nate en ella.</li> <li>Crea un nuevo animal con su onomatopeya. Modifica el test adecuadamente</li> <li>Confirma cambios y haz un push de la nueva rama</li> <li>Crea un pull request.</li> <li>Comprueba c\u00f3mo se ejecutan los test en GitHub. Si hay alg\u00fan problema solucionalo.</li> <li>Haz el merge con la rama principal</li> <li>Comprueba c\u00f3mo autom\u00e1ticamente se crean las im\u00e1genes docker en DockerHub y GHRC.</li> </ol>"},{"location":"Ud7%20CI-CD/P8_1/#referencias","title":"Referencias","text":"<p>Build a CI/CD workflow with Github Actions </p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/","title":"CI/CD (Integraci\u00f3n y despliegue continuo)","text":"<p>Informaci\u00f3n</p> <p>Estos apuntes est\u00e1n basados en gran medida en unos apuntes de Domingo Gallardo y se distribuyen porque su licencia as\u00ed lo permite.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#continuous-delivery-cd","title":"Continuous Delivery (CD)","text":"<p>Una idea fundamental de las metodolog\u00edas \u00e1giles es entregar valor frecuentemente para obtener una pronta retroalimentaci\u00f3n del cliente. Para ello es necesario tener muy engrasados los procesos de despliegue y puesta en producci\u00f3n del software. </p> <p>Una de las formas que facilita la optimizaci\u00f3n de la puesta en producci\u00f3n de software es la pr\u00e1ctica de XP (eXtreme Programming) de Integraci\u00f3n continua (Continuous Integration). En esta pr\u00e1ctica los miembros del equipo integran sus commits diariamente en el proyecto y en cada integraci\u00f3n se lanzan tests automatizados que verifican que los cambios no introducen errores.</p> <p>Adem\u00e1s de esta pr\u00e1ctica, debemos tener tambi\u00e9n automatizados todos los procesos de compilaci\u00f3n (build) y despliegue (deployment) de la aplicaci\u00f3n en los distintos entornos de prueba. Esto es lo que se denomina Despliegue continuo (Continuous Deployment). En esta l\u00ednea, se han popularizado herramientas como Docker o Kubernetes que facilitan el despliegue del software y su automatizaci\u00f3n y cada vez se demandan m\u00e1s profesionales (denominados DevOps) con capacidad de gestionar estos despliegues automatizados.</p> <p>Y en los \u00faltimos a\u00f1os se ha dado un paso m\u00e1s all\u00e1 y se ha comenzado a hablar de Entrega continua (Continous Delivery en ingl\u00e9s) con la idea de promover software que est\u00e9 listo en cualquier momento para salir a producci\u00f3n.</p> <p>En este tema veremos todos estos conceptos, con la idea de tomar un primer contacto con todos ellos. Necesitar\u00edamos un curso (o m\u00e1s) para verlos en profundidad. Intentaremos al menos conocer los conceptos b\u00e1sicos para poder seguir profundizando en alguno de ellos en el futuro.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#el-problema-de-la-puesta-en-produccion","title":"El problema de la puesta en producci\u00f3n","text":"<p>En las empresas tradicionales no \u00e1giles el proceso de subir a producci\u00f3n una nueva versi\u00f3n es un proceso muy complicado y estresante. Se hace pocas veces, cuatro o cinco veces al a\u00f1o, durante el fin de semana cuando todos los servicios est\u00e1n parados.</p> <p>El proceso de genera muchos trastornos y dolores de cabeza. El equipo de operaciones tiene que estar pendiente del m\u00f3vil para detectar posibles problemas y ca\u00eddas del sistema. Una vez puesto el software en producci\u00f3n el equipo de desarrollo se dedicar\u00e1 continuamente a corregir bugs y solucionar problemas detectados por los usuarios.</p> <p>Esto no es \u00e1gil. Esto no permite conseguir lo que hemos comentado muchas veces de un ciclo corto de retroalimentaci\u00f3n para que el cliente pueda probar r\u00e1pidamente las nuevas caracter\u00edsticas y se pueda comprobar su valor. Recordemos que en ambientes inciertos y no predecibles es fundamental poder validar con el cliente las nuevas funcionalidades introducidas, para adaptarse y corregir posibles errores.</p> <p>La realizaci\u00f3n de entregas frecuentes tambi\u00e9n permite minimizar el riesgo. Todo el tiempo que estamos desarrollando algo sin ponerlo en producci\u00f3n es un riesgo acumulado. Hasta que no est\u00e1 en producci\u00f3n y ha sido aceptado por el cliente no sabemos si lo que estamos desarrollando va a ser validado o no. Cuanto menos tardemos en validarlo, menor ser\u00e1 el riesgo.</p> <p>La siguiente figura est\u00e1 sacada de la charla de Eduardo Ferro (@eferro) Continuous Delivery: Germinando una cultura \u00e1gil moderna. </p> <p></p> <p>En la figura de la izquierda se entrega mucho valor de golpe y el riesgo que se ha ido acumulando es mucho mayor que en la figura de la derecha, en la que se entregan peque\u00f1os incrementos de valor que nos permiten tener una retroalimentaci\u00f3n m\u00e1s r\u00e1pida y adaptar mucho mejor el producto a las necesidades de los clientes.</p> <p></p> <p>El proceso de puesta en producci\u00f3n del software depende mucho del tipo de software. En un extremo, por ejemplo, una p\u00e1gina web se puede cambiar modificando directamente el fichero HTML en la propia m\u00e1quina en la que se est\u00e1 ejecutando el servidor web. No hace falta ni recompilar, ni reiniciar el servidor. En el otro extremo, un software de control de una placa de un satelite espacial puede estar embebido en el propio firmware de la placa y para realizar un cambio puede ser necesario hasta volver a grabar y producir la placa.</p> <p>En general, la mayor\u00eda de sistemas software se encuentran entre ambos extremos. Es importante analizar con detalle cu\u00e1l es el proceso de despliegue de nuestro software, cu\u00e1nto tarda en subir a producci\u00f3n un cambio de una l\u00ednea de c\u00f3digo y cu\u00e1les son los cuellos de botella en el proceso.</p> <p></p> <p>La denominada ultima milla consiste en los pasos necesarios para la puesta en producci\u00f3n de nuestro sistema. De nada nos sirve tener un equipo \u00e1gil que hace iteraciones y reuniones con el cliente si despu\u00e9s tenemos un equipo de QA (Quality Assurance) con un 90% de pruebas manuales y otro de operaciones que tiene que configurar manualmente cualquier nuevo despliegue a producci\u00f3n y al que le cuesta dos d\u00edas revertir un despliegue fallido.</p> <p>Debemos analizar cu\u00e1l es nuestro proceso de release y hacer lo posible por mejorarlo. Encontrar los cuellos de botella, reducir los tiempos, automatizar todo lo que podamos. De forma que pasemos de un release por trimestre a un release mensual. Y despu\u00e9s a un release cada dos semanas. Y despu\u00e9s a un release semanal. Y despu\u00e9s a un posible release con cada posible cada cambio. Al final, como dice Eduardo Ferro en la charla mencionada anteriormente, el tiempo de subir un commit a producci\u00f3n debe ser de menos de 15 minutos y debemos de poder automatizar el proceso de puesta en producci\u00f3n hasta el extremo que lo podamos hacer a discreci\u00f3n, cuando queramos, \u00fanicamente pulsando un bot\u00f3n.</p> <p>Un elemento central de todo el proceso de despliegue es la configuraci\u00f3n de un pipeline de despliegue lo m\u00e1s automatizada posible.</p> <p></p> <p>el pipeline representa todos los pasos necesarios que llevan el c\u00f3digo fuente hasta producci\u00f3n. Lo veremos en detalle m\u00e1s adelante, pero es interesante adelantarla aqu\u00ed. En la imagen se puede ver:</p> <ul> <li>Compilaci\u00f3n de todas las dependencias en binarios. En el caso de una   aplicaci\u00f3n Java podr\u00edamos tener dependencias   externas (que no har\u00eda falta compilar, s\u00f3lo descargarse) y   dependencias de librer\u00edas internas que s\u00ed que estamos modificando y   que deber\u00edamos recompilar.</li> <li>Empaquetamiento, construcci\u00f3n de un \u00fanico binario a partir de todos   los binarios existentes. En el caso de una aplicaci\u00f3n Java, la fase   de package (por ejemplo, realizada con Maven) generar\u00eda un fichero   WAR que podr\u00edamos distribuir. Tambi\u00e9n, si utilizamos Docker, en esta   fase generaremos una m\u00e1quina Docker que podremos distribuir.</li> <li>Despliegue en distintos   entornos de   prueba y lanzamiento de pruebas en los distintos entornos. Cada   entorno tiene su propia configuraci\u00f3n, definida por variables de   entorno o par\u00e1metros de los comandos de puesta en marcha.</li> <li>Despliegue en entorno de staging (r\u00e9plica muy similar al entorno de   producci\u00f3n).</li> <li>Despliegue en entorno de producci\u00f3n.</li> </ul> <p>En el enfoque de entrega continua el proceso anterior est\u00e1 completamente automatizado y la puesta en producci\u00f3n se puede modular y realizar en el momento que nos interese pulsando \u00fanicamente un bot\u00f3n en cualquier momento. </p> <p>Recordemos que la forma m\u00e1s tradicional de enfrentar el problema del lanzamiento es separar una rama de release de la rama de desarrollo.</p> <p></p> <p>Al separar la rama de release podemos seguir introduciendo cambios en la rama de desarrollo sin afectar para nada al release. En la rama de release se realiza todo el pipeline de despliegue y se prueba en todos los entornos. Se introducen correcciones de peque\u00f1os bugs encontrados y se tambi\u00e9n se puede incluir alg\u00fan commit escogido de la rama de desarrollo haciendo un <code>cherry-pick</code>. Finalmente, la \u00faltima versi\u00f3n comprobada se pasa a producci\u00f3n y mezcla con la rama de releases y con la de desarrollo.</p> <p>En el enfoque de lanzamiento continuo no existen ramas de release, sino que en cualquier commit de la rama principal es candidato a ser puesto en producci\u00f3n. </p> <p></p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#integracion-continua","title":"Integraci\u00f3n continua","text":"<p>La Integraci\u00f3n continua es una pr\u00e1ctica en la que los miembros del equipo integran su trabajo frecuentemente en el proyecto. Se trata de una pr\u00e1ctica de XP (eXtreme Programming) en la que se recomienda que cada miembro integre sus cambios diariamente. Esto lleva a m\u00faltiples integraciones cada d\u00eda. Cada integraci\u00f3n es verificada por una compilaci\u00f3n autom\u00e1tica (automated build) en la que se lanzan todos los tests y se detectan errores lo m\u00e1s r\u00e1pidamente posible.</p> <p>Esta pr\u00e1ctica obliga a que todos los cambios realizados por los desarrolladores sean puestos en com\u00fan continuamente, lo que promueve la compartici\u00f3n de conocimiento entre todos los miembros del equipo. Cuando una persona va a integrar sus cambios primero debe comprobar que \u00e9stos son compatibles con los cambios que ha habido en el proyecto. Como se integra diariamente, \u00e9stos no ser\u00e1n demasiados y si hay alg\u00fan error ser\u00e1 f\u00e1cil de solucionar.</p> <p>Sin embargo, si se desarrolla una versi\u00f3n separada que tarda mucho en integrarse ser\u00e1 muy posible que cuando se realice la integraci\u00f3n surjan muchos problemas de m\u00e1s dif\u00edcil soluci\u00f3n.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#trunk-based-vs-feature-branches","title":"Trunk based vs. feature branches","text":"<p>Uno de los debates frecuentes relacionados con los flujos de trabajo de Git es si es m\u00e1s conveniente un flujo de trabajo trunk based (basado en la rama principal) o uno con feature branches (ramas de caracter\u00edsticas).</p> <p></p> <p>La imagen anterior est\u00e1 tambi\u00e9n sacada de la charla de Eduardo Ferro. En ella se muestran los dos flujos de trabajo y se muestran parejas de desarrolladores porque est\u00e1n aplicando tambi\u00e9n pair programming.</p> <p>En el flujo de desarrollo trunk based todos los desarrolladores publican sus commits continuamente (al menos una vez al d\u00eda) sobre la rama principal del proyecto. Esto obliga a mantenerse continuamente al d\u00eda sobre los cambios que otros est\u00e1n introduciendo y a tener cuidado de que nuestros cambios vayan en la misma direcci\u00f3n.</p> <p>El desarrollador actualiza su repositorio local y comienza a programar un peque\u00f1o incremento (c\u00f3digo y tests). Cuando termina lanza todos los tests para asegurarse de que no se ha roto nada. Antes de publicar los cambios, vuelve a actualizar el repositorio local con los nuevos cambios que se han a\u00f1adido a la rama principal y vuelve a lanzar los tests. Si todo funciona bien, publica los cambios en el repositorio compartido.</p> <p>Entre las ventajas de esta t\u00e9cnica se encuentran:</p> <ul> <li>La integraci\u00f3n de un nuevo commit es f\u00e1cil porque la rama principal   ha cambiado poco desde el commit anterior que integramos. No ha   habido demasiado tiempo para que el proyecto diverja mucho.</li> <li>La transparencia en los cambios hace que se detecten antes los   errores</li> <li>El conocimiento del equipo evoluciona conjuntamente. Todo el mundo   tiene informaci\u00f3n actualizada a diario de los cambios que se van   introduciendo en el proyecto.</li> <li>Obliga a dividir los cambios grandes en cambios peque\u00f1os que se van   integrando poco a poco. Esto obliga a hacer un mayor esfuerzo de   dise\u00f1o y utilizar mejores arquitecturas de software.</li> </ul> <p>Entre los inconvenientes podemos destacar:</p> <ul> <li>Interrupciones m\u00e1s frecuentes en el flujo de trabajo del equipo   debido a problemas introducidos por malos commits.</li> <li>No se pueden hacer pull requests en los que se haga una revisi\u00f3n de   c\u00f3digo.</li> <li>Necesidad m\u00e1s frecuente de reverts que corrigen equivocaciones.</li> <li>Obliga al equipo a una gran disciplina y a una gran madurez. No se   deben buscar culpables por los errores introducidos. Los errores   nos hacen aprender.</li> </ul> <p>El flujo de desarrollo de ramas de caracter\u00edsticas se basa en separar ramas de caracter\u00edsticas de la rama principal. En cada rama de caracter\u00edstica se desarrolla una caracter\u00edstica y se integra en la rama principal cuando est\u00e9 terminada. Esta integraci\u00f3n se puede hacer usando un pull request.</p> <p>Ventajas:</p> <ul> <li>Se integran en la rama principal cambios completos.</li> <li>Durante el desarrollo de la caracter\u00edstica puedes aislarte del resto   del desarrollo del proyecto y centrarte \u00fanicamente en la   caracter\u00edstica que est\u00e1s desarrollando.</li> <li>Los fallos son locales a la rama. Un fallo no afecta al resto del   equipo. Puedes tomarte un tiempo en arreglar el fallo sin que el   resto del equipo se quede bloqueado.</li> <li>Posibilidad de usar pull requests y realizar revisiones de c\u00f3digo.</li> </ul> <p>Inconvenientes:</p> <ul> <li>Si las ramas tienen una duraci\u00f3n muy larga el proyecto puede haberse   modificado mucho cuando vayamos a hacer la integraci\u00f3n, haci\u00e9ndola   bastante complicada.</li> <li>El conocimiento compartido sobre el c\u00f3digo del proyecto es mucho   menor y se limita a los posibles conflictos que podemos tener en la   rama que hemos desarrollado.</li> <li>El primero que integra su rama no tiene problemas, los problemas los   tienen las siguientes integraciones. Esto crea un efecto perverso en   el que intentamos ser los primeros posiblemente a costa de menos   calidad en el c\u00f3digo.</li> </ul> <p>Posiblemente, la mejor opci\u00f3n sea comenzar con ramas de caracter\u00edsticas e ir haci\u00e9ndolas cada vez m\u00e1s cortas, de forma que se integren cada dos o tres d\u00edas como m\u00e1ximo. Al igual que en el enfoque de trunk based podr\u00edan no ser caracter\u00edsticas completas, sino peque\u00f1os incrementos. Por ejemplo, una rama podr\u00eda contener la parte de backend de la caracter\u00edstica y despu\u00e9s har\u00edamos la de frontend. Y cuando el equipo se acostumbre a hacer ramas cada vez m\u00e1s peque\u00f1as, podr\u00edamos plantearnos la opci\u00f3n de pasar a un modelo basado en trunk.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#herramientas-de-integracion-continua","title":"Herramientas de integraci\u00f3n continua","text":"<p>Una de las caracter\u00edsticas fundamentales de la integraci\u00f3n continua es que cada vez que se integra un commit en la rama principal se debe realizar una construcci\u00f3n autom\u00e1tica del proyecto, lanz\u00e1ndose todos los tests en el entorno de integraci\u00f3n continua y construy\u00e9ndose el binario candidato a desplegar en producci\u00f3n.</p> <p>La forma de realizar esto es mediante las denominadas herramientas de integraci\u00f3n continua.</p> <p></p> <p>Podemos elegir como herramientas de integraci\u00f3n continua una herramienta que instalamos en nuestros propios servidores de integraci\u00f3n (CI server) o construcci\u00f3n continua (continuous build server) como Jenkins o tambi\u00e9n en un servicio en la nube como GitHub Actions.</p> <p>Cualquiera de estas herramientas permiten automatizar el lanzamiento de tests y la compilaci\u00f3n autom\u00e1tica de la aplicaci\u00f3n y la generaci\u00f3n de una aplicaci\u00f3n distribuible. Esta aplicaci\u00f3n puede ser un binario, un JAR o WAR, una m\u00e1quina Docker, etc. que puede ser desplegada en distintos entornos, incluido el de producci\u00f3n.</p> <p></p> <p>El servicio de integraci\u00f3n continua genera tambi\u00e9n notificaciones autom\u00e1ticas a todos los miembros del equipo indicando el estado de la compilaci\u00f3n. Tambi\u00e9n suele proporcionar un panel de control con la indicaci\u00f3n del estado de cada build.</p> <p></p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#generacion-del-ejecutable","title":"Generaci\u00f3n del ejecutable","text":"<p>El resultado de la compilaci\u00f3n autom\u00e1tica realizada por el servidor de integraci\u00f3n continua debe ser un artefacto desplegable en los distintos entornos en los que vamos a probar la aplicaci\u00f3n. La aplicaci\u00f3n s\u00f3lo se debe compilar una \u00fanica vez y el resultado debe almacenarse en un sitio accesible por cualquier proceso y miembro del equipo.</p> <p>Es fundamental que las herramientas usadas para construir la aplicaci\u00f3n puedan ser usadas desde l\u00ednea de comando. De esta forma es mucho m\u00e1s sencillo adaptar y configurar distintos tipos de scripts de compilaci\u00f3n (build scripts). Entre las herramientas m\u00e1s usadas destacamos las siguientes:</p> <ul> <li>Make (C, Unix)</li> <li>Rake (Ruby) </li> <li>Maven (Java)</li> <li>Gradle (Java, Scala, etc.)</li> <li>sbt (Scala, Play Framework)</li> </ul> <p>Igual que hay distintas herramientas de compilaci\u00f3n para los diferentes lenguajes de programaci\u00f3n, existen diferentes formatos en los que se guardan los artefactos binarios resultantes de la compilaci\u00f3n. </p> <p></p> <p>Por ejemplo, el binario resultante de una aplicaci\u00f3n C es un fichero compilado que se ejecutar\u00e1 en el sistema operativo para el que haya sido compilada la aplicaci\u00f3n, mientras que el resultante de una aplicaci\u00f3n Java es un fichero JAR que podremos desplegar en cualquier m\u00e1quina en la que tengamos instalado un JRE (Java Runtime Environment).</p> <p>Adem\u00e1s tenemos el problema a\u00f1adido de generaci\u00f3n de distintos binarios para diferentes sistemas operativos. Por ejemplo, si estamos desarrollando una aplicaci\u00f3n de escritorio que va a funcionar en Windows, Linux y Mac deberemos generar los binarios correspondientes a esas distintas plataformas y despu\u00e9s testearlos de forma autom\u00e1tica en distintos ordenadores cada uno con su sistema operativo espec\u00edfico.</p> <p>En la actualidad se est\u00e1 haciendo cada vez m\u00e1s popular la utilizaci\u00f3n de im\u00e1genes Docker como artefacto binario a distribuir y ejecutar. </p> <p></p> <p>Entre las ventajas de este enfoque se encuentran el ser multiplaforma (para ejecutarlas basta con tener instalado el Docker Engine) y que los contenedores (servicios en ejecuci\u00f3n) se pueden configurar y combinar o ejecutar en clusters usando herramientas como Kubernetes.</p> <p>Es una buena pr\u00e1ctica darle a cada artefacto binario compilado un nombre distinto en el que aparezca el n\u00famero de versi\u00f3n. En el caso de la integraci\u00f3n continua, normalmente se le da al binario un nombre en el que aparece la fecha e incluso la hora de la compilaci\u00f3n. De esta forma, las distintas compilaciones pueden ser identificadas de forma \u00fanica. </p> <p>En el caso en que nuestra aplicaci\u00f3n dependa de paquetes externos es conveniente descargarlos y almacenarlos en un sitio centralizado de forma que no tengan que descargarse de Internet cada vez que se realiza una nueva compilaci\u00f3n. Para ello es conveniente configurar correctamente las cach\u00e9s del sistema de build que estemos utilizando.</p> <p>La aplicaci\u00f3n desplegable debe consistir en un \u00fanico artefacto con el nombre correcto que contenga todo lo necesario para ejecutarse en distintos entornos de prueba y pueda ser puesto en producci\u00f3n. El artefacto debe almacenarse en un lugar centralizado, accesible desde los distintos entornos de forma autom\u00e1tica. Por ejemplo, podemos usar un servidor web local y dejar el fichero en una URL concreta.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#principios-y-practicas-de-integracion-continua","title":"Principios y pr\u00e1cticas de integraci\u00f3n continua","text":"<p>A continuaci\u00f3n presentamos en forma de \u00edtems un resumen de los elementos importantes de la integraci\u00f3n continua que hemos visto hasta ahora.</p> <ul> <li>Desarrollo de c\u00f3digo<ul> <li>El sistema debe siempre poder ser construido (build) y probado con \u00e9xito. </li> <li>Todo el mundo hace merge de los cambios con frecuencia.</li> <li>Despu\u00e9s de cada commit, el sistema se integra inmediata y autom\u00e1ticamente.</li> <li>Se desarrolla el sistema en peque\u00f1os incrementos.</li> </ul> </li> <li>Testing<ul> <li>Los desarrolladores prueban su c\u00f3digo en sus espacios de trabajo privados. </li> <li>Despu\u00e9s mezclan los cambios en el repositorio.</li> </ul> </li> <li>Servidor de integraci\u00f3n continua (CI server):<ul> <li>Monitoriza el repositorio y comprueba los cambios cuando ocurren.</li> <li>Construye el sistema y ejecuta las pruebas unitarias y de integraci\u00f3n.</li> <li>Informa al equipo de la construcci\u00f3n con \u00e9xito o de los fallos.</li> </ul> </li> <li>Errores en los build<ul> <li>El equipo arregla el problema lo antes posible.</li> <li>Continuar para integrar y probar continuamente durante todo el   proyecto. </li> </ul> </li> <li>El \u00faltimo ejecutable compilado debe estar f\u00e1cilmente disponible<ul> <li>El resultado de la compilaci\u00f3n debe ser un artefacto ejecutable   disponible para desplegar en distintos entornos, incluso en   producci\u00f3n.</li> </ul> </li> </ul>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#configuracion-del-despliegue","title":"Configuraci\u00f3n del despliegue","text":"<p>Para hacer integraci\u00f3n continua es necesario tener m\u00faltiples entornos. En el entorno de trabajo del desarrollador se pueden lanzar los tests m\u00e1s r\u00e1pidos y utilizar una configuraci\u00f3n en la que usemos una base de datos en memoria (como H2) que acelere la velocidad de los tests que utilicen base de datos.</p> <p>Se puede configurar un primer entorno de integraci\u00f3n continua para que se ejecuten en \u00e9l tests m\u00e1s lentos y con una configuraci\u00f3n m\u00e1s parecida a la del entorno de producci\u00f3n. Por ejemplo, se puede utilizar una configuraci\u00f3n en la que se utilice una base de datos similar a la que se usa en producci\u00f3n, poblada con datos de prueba. En este entorno se deben lanzar los tests r\u00e1pidos y tambi\u00e9n tests m\u00e1s lentos de integraci\u00f3n.</p> <p>Y despu\u00e9s tendremos otros entornos cada vez m\u00e1s similares al entorno de producci\u00f3n en los que tambi\u00e9n se realizar\u00e1n todos los tests autom\u00e1ticos y otros tests manuales necesarios para tener la confirmaci\u00f3n de que todo est\u00e1 funcionando correctamente.</p> <p>En todos estos entornos deberemos instalar la misma aplicaci\u00f3n compilada, y tendremos que modificar en cada caso su configuraci\u00f3n. Es importante tener la capacidad de automatizar tanto la gesti\u00f3n de entornos de despliegue (arrancar las bases de datos correctas, configurar puertos, etc.) como la instalaci\u00f3n y ejecuci\u00f3n de la aplicaci\u00f3n en el entorno.</p> <p>Antiguamente los distintos entornos eran m\u00e1quinas f\u00edsicas distintas, con configuraciones distintas previamente instaladas en cada una de ellas. Hoy en d\u00eda es mucho m\u00e1s com\u00fan utilizar entornos virtuales f\u00e1cilmente construibles a partir de scripts y c\u00f3digo usando herramientas de virtualizaci\u00f3n como Docker, Kubernetes, etc. Tambi\u00e9n es habitual la utilizaci\u00f3n de entornos en la nube (Heroku, GitHub Actions, Amazon Web Services, etc.) tanto para prueba como para producci\u00f3n.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#entornos-de-despliegue","title":"Entornos de despliegue","text":"<p>Podemos diferenciar diferentes tipos de entornos (configuraci\u00f3n de servicios y servidores) en los que se despliega y prueba el build de la aplicaci\u00f3n. En general, ordenados de menor a mayor parecido a producci\u00f3n, podemos diferenciar.</p> <ul> <li>Local: ordenador del desarrollador. Se ejecutan tests unitarios de la caracter\u00edstica que se est\u00e1 desarrollando. </li> <li>Desarrollo/Trunk/Master: ordenador de integraci\u00f3n continua conectado a la rama de desarrollo en el que se ejecutan todos los tests unitarios continuamente. </li> <li>Integraci\u00f3n: Entorno en el que se sustituyen los mocks y bases de datos de memoria por servicios reales, aunque con copias parciales de los datos de producci\u00f3n.</li> <li>Test/QA: Entornos en los que se realizan pruebas funcionales, de interfaz de usuario, de performance o de seguridad, entre otros. Pueden ser manuales y/o automatizados.</li> <li>Stage/Preproducci\u00f3n: Entorno id\u00e9ntico al de producci\u00f3n en el que se hace la \u00faltima validaci\u00f3n de la nueva versi\u00f3n a desplegar a producci\u00f3n. Copia de la base de datos de producci\u00f3n y con servidores similares a los de producci\u00f3n, para poder comprobar rendimiento.</li> <li>Producci\u00f3n: Entorno que usan los clientes reales de la aplicaci\u00f3n.</li> </ul>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#configuracion-de-la-aplicacion","title":"Configuraci\u00f3n de la aplicaci\u00f3n","text":"<p>La aplicaci\u00f3n debe poder funcionar en distintos entornos sin tener que ser recompilada. Para ello es necesario poder configurar su funcionamiento definiendo par\u00e1metros que podamos modificar previamente a su ejecuci\u00f3n sin tener que recompilarla.</p> <p>Existen multitud de elementos que podemos necesitar configurar dependiendo del entorno en que queremos que funcione la aplicaci\u00f3n. Por ejemplo:</p> <ul> <li>URL de conexi\u00f3n a la base de datos</li> <li>Usuario y contrase\u00f1a de conexi\u00f3n a la base de datos</li> <li>Puerto en el que la aplicaci\u00f3n va a recibir las peticiones</li> <li>Direcciones de los servicios a los que debe conectarse (por ejemplo,   servicio SMTP de correo electr\u00f3nico)</li> </ul> <p>En cada entorno en los que va a funcionar la aplicaci\u00f3n estos par\u00e1metros van a tener unos valores distintos que hay que pasarle a la aplicaci\u00f3n cuando se ponga en funcionamiento. </p> <p>Existen diversas formas de definir estas propiedades. Las m\u00e1s usuales son:</p> <ul> <li>Mediante ficheros de configuraci\u00f3n de la aplicaci\u00f3n.</li> <li>Mediante variables de entorno cuyos valores establecemos con scripts   antes de lanzar la aplicaci\u00f3n.</li> <li>Mediante argumentos del comando que lanza la aplicaci\u00f3n</li> </ul> <p>Estas distintas configuraciones deben estar tambi\u00e9n guardadas en el control de versiones, igual que el c\u00f3digo de la aplicaci\u00f3n, para poder tambi\u00e9n controlar su evoluci\u00f3n y sus cambios.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#configuracion-de-imagenes-docker","title":"Configuraci\u00f3n de im\u00e1genes Docker","text":"<p>Docker tambi\u00e9n tiene muchas estrategias que permiten configurar la ejecuci\u00f3n de una imagen. Una de las m\u00e1s utilizadas es hacer que la imagen utilice variables de entorno que pueden ser modificadas en al lanzar el contenedor. Para ello debemos definir en la imagen estas variables con el comando <code>ENV</code>, pudiendo dar valores por defecto.</p> <p>Por ejemplo, podemos definir el siguiente <code>Dockerfile</code>:</p> <pre><code>FROM alpine\nENV saludo=\"Hola, mundo!\"\nCMD echo $saludo\n</code></pre> <p>Creamos la imagen:</p> <pre><code>$ docker build -t saludo .\n</code></pre> <p>Si lanzamos la imagen muestra el saludo por defecto:</p> <pre><code>$ docker run saludo\nHola, mundo!\n</code></pre> <p>Y podemos configurar el saludo de varias formas. Por ejemplo, indicando el valor del par\u00e1metro al hacer <code>run</code>:</p> <pre><code>$ docker run -e \"saludo=\u00bfQu\u00e9 tal est\u00e1s?\" saludo\n\u00bfQu\u00e9 tal est\u00e1s?\n</code></pre> <p>O guardando el valor del par\u00e1metro en un fichero de propiedades que pasamos al ejecutar la imagen. Por ejemplo, en el fichero <code>propiedades.txt</code> escribimos lo siguiente:</p> <pre><code>saludo=\u00bfQu\u00e9 passsa, colega?\n</code></pre> <p>Y ejecutamos la imagen de la siguiente forma:</p> <pre><code>$ docker run --env-file=propiedades.txt saludo\n\u00bfQu\u00e9 passsa, colega?\n</code></pre>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#entrega-continua","title":"Entrega continua","text":"<p>El concepto de Entrega continua (Continuous Delivery) es una extensi\u00f3n de la Integraci\u00f3n continua que se populariz\u00f3 a ra\u00edz del libro que publicaron en 2010 Jez Humble y David Farley (ver las referencias).</p> <p></p> <p>Es un concepto que parte de la integraci\u00f3n continua para llegar a una automatizaci\u00f3n completa de la puesta en producci\u00f3n. El objetivo es conseguir una puesta en producci\u00f3n (release) del software:</p> <ul> <li>Poco arriesgada</li> <li>Frecuente</li> <li>Barata</li> <li>R\u00e1pida</li> <li>Predecible</li> <li>Reproducible</li> </ul> <p>En palabras de Jez Humble, la entrega continua consiste en:</p> <p>\u201cReduce the cost, time, and risk of delivering incremental changes to users\u201d</p> <p>Jez Humble (2013), Charla Adopting Continuous Delivery</p> <p>Otra frase muy importante, que ya hemos comentado alguna vez:</p> <p>\u201cHow long would it take your organization to deploy a change that involved just one single line of code? Do you do this on a repeatable, reliable basis?\u201d </p> <p>Mary Poppendieck</p> <p>Algunas t\u00e9cnicas que se utilizan en la Entrega continua (muchas de ellas ya las hemos visto):</p> <ul> <li>Peque\u00f1os cambios que se despliegan continuamente</li> <li>Todos los builds son candidatos al release </li> <li>Todo en el control de versiones (se debe poder probar cualquier release)</li> <li>Pipelines de despliegue (deployment pipelines) </li> <li>Integraci\u00f3n continua: automatizaci\u00f3n de builds, tests, despliegues, entornos</li> </ul>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#pipeline-de-despliegue","title":"Pipeline de despliegue","text":"<p>Tal y como hemos comentado cuando habl\u00e1bamos de integraci\u00f3n continua, un elemento central es de la automatizaci\u00f3n es el pipeline de despliegue. un pipeline de despliegue es una implementaci\u00f3n automatizada del proceso de construcci\u00f3n, despliegue, prueba y lanzamiento de nuestro sistema.</p> <p>La utilizaci\u00f3n de un pipeline de despliegue garantiza la visibilidad de todo el proceso, lo que garantiza un feedback temprano y un control continuo del mismo.</p> <p>Explicaci\u00f3n del libro de Jeff Humble:</p> <p>Cada cambio que se realiza sobre la configuraci\u00f3n de la aplicaci\u00f3n, su c\u00f3digo fuente o sus datos, lanza la creaci\u00f3n de una nueva instancia de el pipeline. Uno de los primeros pasos en el pipeline es crear los binarios y los instaladores. El resto de el pipeline ejecuta una serie de tests sobre los binarios para probar que pueden ser lanzados. Cada test que pasa el candidato a release nos da m\u00e1s confianza de que funcionar\u00e1 correctamente esta combinaci\u00f3n particular de c\u00f3digo binario, informaci\u00f3n de configuraci\u00f3n, entorno y datos. Si el candidato a release pasa todos los tests, puede ser lanzado.</p> <p>En el libro de Humble y Farley se muestra el siguiente esquema que representa sus distintos elementos.</p> <p></p> <ul> <li>En la parte superior se muestra el sistema de control de versiones,   en donde se almacena el c\u00f3digo del proyecto y los datos de las   distintas configuraciones de los entornos y de la aplicaci\u00f3n. Las   configuraciones de los entornos y de la aplicaci\u00f3n se deben guardar   en el sistema de control de versiones para gestionar su evoluci\u00f3n y   modificaci\u00f3n de la misma forma que gestionamos la evoluci\u00f3n del   c\u00f3digo.</li> <li>En la parte inferior se muestra el repositorio de artefactos en   donde se almacenan los binarios de la aplicaci\u00f3n. Puede ser, por   ejemplo, Docker Hub en el caso de ser una aplicaci\u00f3n dockerizada.</li> <li>En la fase de commit el c\u00f3digo se compila y se lanzan los tests   unitarios. Se generan los binarios que se almacenan en el   repositorio de artefactos.</li> <li>En la fase de aceptaci\u00f3n se configuran y despliegan los binarios en   un entorno similar al de producci\u00f3n. Se realizan test de   aceptaci\u00f3n/integraci\u00f3n y se valida la aplicaci\u00f3n y se deja lista para ser   publicada a producci\u00f3n por parte de Operaciones.</li> <li>En la fase de UAT (User Acceptance Testing) se realizan pruebas   manuales en un entorno lo m\u00e1s parecido posible al de producci\u00f3n.</li> <li>En la fase capacidad se realizan tests de rendimiento.</li> <li>El binario se despliega en producci\u00f3n si todas las fases anteriores   se pasan con \u00e9xito.</li> </ul> <p>En la siguiente figura se muestra un ejemplo de posible secuencia de despliegue:</p> <p></p> <p>Son muy \u00fatiles los tableros de control de el pipeline de despliegue, como por ejemplo el que proporciona Jenkins.</p> <p></p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#pequenos-cambios","title":"Peque\u00f1os cambios","text":"<p>Tal y como hemos comentado en la introducci\u00f3n del tema, una pr\u00e1ctica fundamental de los equipos que utilizan las t\u00e9cnicas de entrega continua es subir a producci\u00f3n continuamente peque\u00f1os cambios con los que se van introduciendo poco a poco las nuevas funcionalidades.</p> <p></p> <p>Por ejemplo, en la charla de Juan Ignacio S\u00e1nchez Continuous Integration at CartoDB (v\u00eddeo) se explica c\u00f3mo es el proceso de integraci\u00f3n continua en Carto, una importante empresa espa\u00f1ola de gesti\u00f3n de datos geogr\u00e1ficos.</p> <p>Algunas de las m\u00e9tricas que muestra en la charla reflejan claramente cu\u00e1l es el funcionamiento de la integraci\u00f3n continua en la empresa. Su producto opensource m\u00e1s importante es CartoDB (enlace a su repositorio GitHub). En la \u00e9poca de la charla el producto integraba una media de 22 pull requests semanales y 15 despliegues en producci\u00f3n.</p> <p>Si todos los cambios son peque\u00f1os, \u00bfc\u00f3mo se introducen los cambios grandes en el proyecto?. Por ejemplo, nuevas caracter\u00edsticas complejas en las que se necesitan combinar distintas funcionalidades elementales.</p> <p>Es posible ir desarrollando, probando y colocando las piezas en el c\u00f3digo (sin mostrar en la interfaz de usuario) para que el sistema evolucione hacia un momento futuro en sea f\u00e1cil introducir una caracter\u00edstica totalmente nueva mediante un peque\u00f1o cambio. Como dice Kent Beck:</p> <p>Make the change easy, then make the easy change.</p> <p>Para ello podemos usar las siguientes estrategias:</p> <ul> <li>Codificaci\u00f3n y prueba de las peque\u00f1as funcionalidades por separado.</li> <li>Buen dise\u00f1o de c\u00f3digo, por ejemplo seleccionar una implementaci\u00f3n   concreta utilizando interfaces y factor\u00edas, pero dejar la estructura   lista para introducir futuros cambios.</li> <li>Peque\u00f1os cambios en las APIs compatibles con los tests de   regresi\u00f3n.</li> <li>Uso de mocks.</li> <li>Interruptores de caracter\u00edsticas.</li> </ul> <p></p> <p>Esta \u00faltima t\u00e9cnica es muy interesante. Consiste en definir interruptores o flags booleanos en el c\u00f3digo que hagan que ciertas caracter\u00edsticas se muestren o no en la aplicaci\u00f3n dependiendo de si los flags est\u00e1n o no activos.</p> <p>En este art\u00edculo se puede encontrar una explicaci\u00f3n en profundidad de m\u00faltiples t\u00e9cnicas usadas para implementar los interruptores de caracter\u00edsticas. Dependiendo de la t\u00e9cnica es posible hasta definir interruptores que se puedan modificar en tiempo de ejecuci\u00f3n e incluso que se puedan mostrar o no la funcionalidad a seg\u00fan qu\u00e9 usuarios implementando un sistema de canary release. </p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#canary-release","title":"Canary release","text":"<p>La idea del canary release consiste en configurar un sistema de despliegue que permita mantener simult\u00e1neamente en producci\u00f3n dos versiones de la aplicaci\u00f3n. En el caso de una aplicaci\u00f3n web, podr\u00edamos configurar un proxy o router intermedio que se encargue de encauzar las peticiones de los usuarios a una versi\u00f3n de la aplicaci\u00f3n o a otra.</p> <p>Cuando se lanza una caracter\u00edstica nueva se puede configurar el proxy para que s\u00f3lo sea probada por una peque\u00f1a cantidad de usuarios y detectar posibles errores en este despliegue reducido. Cuando se haya comprobado con este peque\u00f1o grupo que todo funciona correctamente se modifica la configuraci\u00f3n del proxy para que todos accedan a la nueva versi\u00f3n.</p> <p>La configuraci\u00f3n del proxy puede llegar a ser bastante compleja, haciendo el filtro de usuarios en funci\u00f3n de par\u00e1metros que nos interesen (localizaci\u00f3n, tipo de usuario, etc.).</p> <p>Este sistema tambi\u00e9n puede utilizarse, junto con el de interruptores de caracter\u00edsticas, para realizar pruebas A/B de nuevas caracter\u00edsticas.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#devops","title":"DevOps","text":"<p>Tradicionalmente el trabajo de los desarrolladores y el de los t\u00e9cnicos de operaciones (responsables de la puesta en producci\u00f3n del sistema, monitorizaci\u00f3n de servidores, etc. ) son contrapuestos.</p> <ul> <li>Developers:<ul> <li>Su trabajo es a\u00f1adir nuevas caracter\u00edsticas.</li> <li>Trabajan en entornos locales (\u201cen mi m\u00e1quina funciona\u201d).</li> <li>Utilizan herramientas y lenguajes que permiten abstraer y automatizar.</li> </ul> </li> <li>Operations: <ul> <li>Su trabajo es mantener el sitio web seguro, estable y r\u00e1pido.</li> <li>Detectar problemas, apagar fuegos.</li> </ul> </li> </ul> <p>Los desarrolladores quieren introducir cambios r\u00e1pidamente en el sistema, mientras que a los t\u00e9cnicos de operaciones les gustar\u00eda mantener el sistema lo m\u00e1s estable posible.</p> <p>Los profesionales DevOps representan una nueva filosof\u00eda de trabajo, que combina elementos propios de los desarrolladores y de operaciones, incorporando todas las nuevas t\u00e9cnicas de las que hemos estado hablando en este tema y herramientas denominadas Infrastructure-as-code como Docker, Kubernetes, Ansible, Terraform,etc. en las que podemos definir la configuraci\u00f3n de entornos y servidores usando c\u00f3digo y ficheros almacenables en un sistema de control de versiones, en lugar de tener que configurar f\u00edsicamente el hardware.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#principos-y-buenas-practicas","title":"Principos y buenas pr\u00e1cticas","text":"<p>En la charla mencionada anteriormente sobre pr\u00e1cticas de integraci\u00f3n continua en Carto, Juan Ignacio S\u00e1nchez lista 10 buenas pr\u00e1cticas que ellos est\u00e1n siguiendo. Muchas ya las hemos visto, pero es interesante repasarlas todas juntas, validadas por la experiencia de su \u00e9xito en una empresa puntera de desarrollo de software. Son las siguientes:</p> <ol> <li>Mantener un repositorio de c\u00f3digo</li> <li>Automatizar la compilaci\u00f3n</li> <li>Hacer la compilaci\u00f3n auto-testeable (mediante test autom\u00e1ticos)</li> <li>Todo el mundo realiza commits en la rama principal todos los d\u00edas</li> <li>Cada commit en la rama principal debe ser compilado</li> <li>Mantener la compilaci\u00f3n r\u00e1pida</li> <li>Testear en un clon del entorno de producci\u00f3n</li> <li>Hacer f\u00e1cil de obtener los \u00faltimos productos compilados</li> <li>Todo el mundo puede ver los resultados de las \u00faltimas compilaciones</li> <li>Automatizar el despliegue</li> </ol>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#consejos-adicionales","title":"Consejos adicionales","text":"<p>La integraci\u00f3n continua y el despliegue continuo son dos conceptos que pueden convertirse en aliados muy poderosos para nuestro equipo si ponemos los medios necesarios.</p> <p>Es obvio que nada de esto es posible sin una bater\u00eda de pruebas s\u00f3lidas, extensas y consistentes. Si no disponemos de pruebas unitarias de calidad y que cubran la totalidad de nuestro c\u00f3digo, lo m\u00e1s probable es que nuestro CI nos de muchos falsos positivos (fallos que no han sido detectados por las pruebas unitarias), que a su vez provocar\u00e1 que se desplieguen fallos en nuestros entornos de pre-producci\u00f3n y producci\u00f3n.</p> <p>Por ejemplo, si el proceso de integraci\u00f3n continua se ejecuta en nuestro servidor de Gitlab en vez de en el ordenador de cada desarrollador de nuestro equipo, estaremos facilitando la tarea de comprobaci\u00f3n automatizada de error. A\u00fan m\u00e1s importante, si dicho proceso se ejecuta en pocos minutos, estaremos creando un h\u00e1bito entre las personas del proyecto de enviar m\u00e1s a menudo sus cambios al repositorio, ya que hacerlo les permitir\u00e1 obtener una visi\u00f3n r\u00e1pida sobre la calidad de su trabajo. Esto a su vez har\u00e1 que la frecuencia de los cambios que se env\u00edan al repositorio sea m\u00e1s alta, mientras que el tama\u00f1o de cada cambio enviado sea m\u00e1s peque\u00f1o. Las tareas de revisi\u00f3n se har\u00e1n m\u00e1s amenas y f\u00e1ciles, y por lo tanto, mejora la velocidad con la que se integran dichos cambios en \u00abdevelop\u00bb. Nuestro equipo de control de calidad podr\u00e1 tener un flujo continuo de trabajo, lo cual reducir\u00e1 los tiempos \u00abmuertos\u00bb (personas \u00abbloqueadas\u00bb a la espera de que otras personas terminen su trabajo).</p> <p>Por \u00faltimo, cabe decir que no es obligatorio que el despliegue continuo tenga lugar en cuanto un cambio se mezcle en las ramas de \u00abdevelop\u00bb o \u00abmaster\u00bb. Existen muchos casos en los que el l\u00edder del equipo (o una persona con rol similar) deber\u00e1 tomar la decisi\u00f3n de dar luz verde al proceso de despliegue en base a m\u00e1s factores. Es decir, el proceso en s\u00ed puede estar automatizado (es lo mas recomendable), pero la acci\u00f3n que desencadena el despliegue puede ser humana.</p>"},{"location":"Ud7%20CI-CD/Ud8_1_cicd/#referencias","title":"Referencias","text":"<ul> <li>Charla de Eduardo Ferro (2020): Continuous Delivery: Germinando una   cultura \u00e1gil moderna. </li> <li>Martin Fowler (2006): Continuous Integration</li> <li>Jez Humble y David Farley (2010): Continuous Delivery</li> <li>Integraci\u00f3n continua y despliegue continuo</li> </ul>"}]}